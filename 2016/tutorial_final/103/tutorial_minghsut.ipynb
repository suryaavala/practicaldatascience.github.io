{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis (Using Yelp Review Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Language is one of the most complicated tools. Though we use language to communicate, to express feelings, and to share information everyday, it is still common that we can easily misunderstand things. One reason is that language itself contains a lot of amubiguity. For example, \"Jane saw Mary standing at the bank with an umbrella. She waved to her.\", these particular sentences raise at least three ambiguities and there are no absolute correct answers to those questions.\n",
    "\n",
    "When we consider the actual hidden idea behind language, there are more aspects we have to consider. For example, emotions of speakers, negations, sarcasm, metaphors, and even the social relations between speakers and listeners can easily affect the words being used and the composition of sentences.\n",
    "\n",
    "However, to understand(or to guess) the true meaning behind a piece of given text is always a challenge for humans and machines also! To be more specific, there are many websites which provides \"review\" information of products or services and customers of these websites often rely heavily on these reviews to make decisions. If one can understand what kind of perceptions do users have toward a products, he/she can generate greater business value by not looking at the transaction numbers only but also what the users actually express.\n",
    "\n",
    "### preface\n",
    "\n",
    "This tutorial will introduce simple sentiment analysis methods and provide a simple demo on evaluating and predicting Yelp review data. More than that, thie tutorial will also explore some existing sentiment libraries and do a demo of sentiment analysis on reviews.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tutorial content\n",
    "\n",
    "\n",
    "We will cover the following topics in this tutorial:\n",
    "- [Installing the libraries](#Installing-the-libraries)\n",
    "- [Getting the data](#Getting-the-data)\n",
    "- [Explaining models and assumptions](#Explaining-models-and-assumptions)\n",
    "    * [Source-Channel paradigm](#Source-Channel-paradigm)\n",
    "    * [Sentiment analysis models](#Sentiment-analysis-models)\n",
    "    * [Naive Bayes Classifier with negation](#Naive-Bayes-Classifier-with-negation)\n",
    "    * [Vader](#Vader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing the libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before getting started, you'll need to install the various libraries that we will use.  You can install nltk using `pip` and use `nltk.download()` to obtain required libraries:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'nltk'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-1eb611f2919a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpunkt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msentiwordnet\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mswn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwordnet\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mwn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'nltk'"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import nltk.tokenize.punkt\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import subjectivity\n",
    "from nltk.sentiment import SentimentAnalyzer\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk import tokenize\n",
    "from nltk.sentiment.util import *\n",
    "\n",
    "import io, time, json\n",
    "import sys\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from yelpAPI import *\n",
    "\n",
    "from collections import OrderedDict\n",
    "import codecs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the data\n",
    "\n",
    "This tutorial uses python package beautiful soup to crawl yelp data as we did in 15688 first assignment. However, to provide better analysis of user, we are going to crawl three-level data and therefore construct a network between user and restaurants.\n",
    "\n",
    "The steps are as following:\n",
    "\n",
    "1. crawl 1000 restaurants in Pittsburgh\n",
    "2. from these restaurants, crawl the recommend reviews and not-recommend reviews and mark a link from reviewer to restaurants\n",
    "    * e.g. 997 recommend reviews found in https://www.yelp.com/biz/gaucho-parrilla-argentina-pittsburgh\n",
    "    * e.g. 198 not-recommend reviews found in https://www.yelp.com/not_recommended_reviews/gaucho-parrilla-argentina-pittsburgh\n",
    "3. from these reviewers, crawl all the reviews they left for other restaurants\n",
    "4. for new restaurants obtained in step 3, crawl all the reviews for the restaurant, mark a link between reviewers and restaurants only for the users we have seen in step 2.\n",
    "\n",
    "The reason we are doing a second level search is that the distribution of the number of reviews left by reviewers is very skewed from the data we get from step 2. Most users (80%) only review once in the 1000 restaurant we get from first step so we only have a single point to describe these users, which is not enough and can cause significant variance.\n",
    "\n",
    "Now we can get all the reviews by any user by doing step 3, but we cannot get the label since Yelp does not distinguish \"recommend\" reviews from \"not recommend\" reviews on users page but only distinguish them on page of restaurants. This is the reaon why we have to do the fourth step, to obtain the \"recommend\" or \"not recommend\" label.\n",
    "\n",
    "After 4 steps of crawling, we get \n",
    "- 1000 restaurants in Pittsburgh.\n",
    "- 35158 users\n",
    "- 89882 reviews (reviews of the 1000 restaurants left by 35158 users) \n",
    "- and we crawl XXXX more restaurants reviewed by those 35158 users to get the review labels\n",
    "\n",
    "During the crawling process, we sent more than 700,000 requests to Yelp and three of my machines get banned by Yelp robot check. The total crawling process may take more than 2 days."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crawler result data example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### user-id-mapping\n",
    "\n",
    "<pre>\n",
    "id  userId                  neg pos\n",
    "1\t Zq31drx-JM2R1MKQg8uJQw\t2\t0\n",
    "2\t We1kda5rqra8ClvV34Od4A\t4\t0\n",
    "3\t m5lzdUZ00UkQEO-UXzTW9A\t2\t0\n",
    "4\t bSvNU2vABlaBi1ooF4KNJg\t15\t0\n",
    "5\t MUsXhUuDRzGLkh2l3aNDGA\t6\t0\n",
    "6\t yq-MN1tqPA11TNWS7ZrIYQ\t1\t0\n",
    "7\t nr97lipURi7lx-uexT3RkA\t0\t5\n",
    "8\t qGDIsH6b4GTo37krG8ZfzQ\t6\t0\n",
    "9\t 9KUJxI5AZqm5K1TBe7lFfg\t2\t0\n",
    "10\tBLrtsER8kfkNlRWoCXYPqA\t0\t1\n",
    "...\n",
    "</pre>\n",
    "\n",
    "### review metadata (graph)\n",
    "\n",
    "<pre>\n",
    "id    reviewId               userId rating label date\n",
    "1\t BLkdRAJhSTsqy7bdMwONsg\t1\t5.0\t1\t2016-10-31\n",
    "2\t aATT7y3AkCwyjiiiQpig9w\t1\t5.0\t1\t2016-10-26\n",
    "3\t xjDkNv3JodG04_7Oq2JD-g\t1\t5.0\t1\t2016-10-23\n",
    "4\t Hi10sGSZNxQH3NLyWSZ1oA\t1\t5.0\t1\t2016-10-7\n",
    "5\t bsMGQruRQGgQZK4KA9Q4Aw\t1\t5.0\t1\t2016-10-4\n",
    "6\t 1nmIXJFvl0tI4gUMygKT2g\t1\t5.0\t1\t2016-10-23\n",
    "7\t 8Wi0srNRAF9hSAzg1qnchw\t1\t5.0\t1\t2016-9-18\n",
    "8\t iipaDtoA1zHFkbAF3Gn5Rg\t1\t5.0\t1\t2016-9-8\n",
    "9\t 242-DHMPDzfjYrb45dd9ZQ\t1\t5.0\t1\t2016-10-23\n",
    "10\taomkMAGFrL-gD6cqQjB4bw\t1\t4.0\t1\t2016-10-8\n",
    "...\n",
    "</pre>\n",
    "\n",
    "### review content\n",
    "<pre>\n",
    "1\taVT6N0mvnM5vmr2_igf1QQ\tMy wife and I made an unexpected overnight stay in Pittsburgh ... of your way to try Gaucho, you will not be disappointed.\n",
    "2\tGcY4xubTKS2qzAszScim3A\tSo. Good. Other than the staff ... through but press on. You're welcome.\n",
    "...\n",
    "</pre>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crawler code snippet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-9-32980a2b37f6>, line 17)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-9-32980a2b37f6>\"\u001b[0;36m, line \u001b[0;32m17\u001b[0m\n\u001b[0;31m    print \">>> get restaurants. count: \" + str(len(businesses))\u001b[0m\n\u001b[0m                                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#####################################\n",
    "# load \"recommended\" and \"non-recommended\" reviews for all \n",
    "# restaurants given in a file, \"argv = subset\"\n",
    "# generate three files\n",
    "# 1. review content\n",
    "# 2. metadata\n",
    "# 3. userId mapping\n",
    "#####################################\n",
    "\n",
    "# load 1000 restaurants in Pittsburgh\n",
    "client = authenticate(\"inputData/authenticate.json\")\n",
    "businesses = all_restaurants(client, 'Pittsburgh')\n",
    "print \">>> get restaurants. count: \" + str(len(businesses))\n",
    "\n",
    "cnt = 1\n",
    "f = io.open('outputData/businessesIdMapping.tsv', 'w', encoding='utf8')\n",
    "for business in businesses:\n",
    "\tf.write(str(cnt) + \"\\t\" + business.id + \"\\n\")\n",
    "\tcnt += 1\n",
    "\n",
    "subset = sys.argv[1]\n",
    "\n",
    "f_reviews_content = io.open('outputData/reviews_content_' + subset + '.tsv', 'w', encoding='utf8')\n",
    "f_userIdMapping = io.open('outputData/user_id_mapping_' + subset + '.tsv', 'w', encoding='utf8')\n",
    "f_metaData = io.open('outputData/metaData_' + subset + '.tsv', 'w', encoding='utf8')\n",
    "\n",
    "userIdDict = {}\n",
    "\n",
    "# read 1000 restaurants in Pittsburgh\n",
    "f = open('outputData/businessesIdMapping.tsv', 'r')\n",
    "businessLines = [line.rstrip('\\n\\r') for line in f]\n",
    "cnt = 1\n",
    "\n",
    "for businessLine in businessLines[int(subset): int(subset) + 100]:\n",
    "\tbusinessId = businessLine.split('\\t')[0]\n",
    "\n",
    "\tprint \">>> \" + businessId + \" extracting recommended reviews from: \" + businessLine.split('\\t')[1]\n",
    "\turl = 'https://www.yelp.com/biz/' + businessLine.split('\\t')[1]\n",
    "\treviews = extract_reviews(url)\n",
    "\tprint \">>> extrated \" + str(len(reviews)) + \" from \" + businessLine.split('\\t')[1]\n",
    "\n",
    "\tfor review in reviews:\n",
    "\n",
    "\t\t# added user to user set\n",
    "\t\tif review['user_id'] not in userIdDict:\n",
    "\t\t\tuserIdDict[review['user_id']] = {'pos': 0, 'neg': 1}\n",
    "\t\telse:\n",
    "\t\t\tuserIdDict[review['user_id']]['neg'] += 1\n",
    "\t\tf_reviews_content.write(str(cnt) + \"\\t\" + review['review_id'] + \"\\t\" + review['text'] + \"\\n\")\n",
    "\t\tf_metaData.write(str(cnt) + \"\\t\" + review['user_id'] + \"\\t\" + businessId + \"\\t\" + str(review['rating']) + \"\\t\" + \"1\\t\" + review['date'] + \"\\n\")\n",
    "\t\tcnt += 1\n",
    "\n",
    "\tprint \">>> \" + businessId + \"  extracting non-recommended reviews from: \" + businessLine.split('\\t')[1]\n",
    "\turl = '/not_recommended_reviews/' + businessLine.split('\\t')[1]\n",
    "\treviews = extract_unrecommend_reviews(url)\n",
    "\tprint \">>> extrated \" + str(len(reviews)) + \" from \" + businessLine.split('\\t')[1]\n",
    "\n",
    "\tfor review in reviews:\n",
    "\t\t# added user to user set\n",
    "\t\tif review['user_id'] not in userIdDict:\n",
    "\t\t\tuserIdDict[review['user_id']] = {'pos': 1, 'neg': 0}\n",
    "\t\telse:\n",
    "\t\t\tuserIdDict[review['user_id']]['pos'] += 1\n",
    "\n",
    "\t\tf_reviews_content.write(str(cnt) + \"\\t\" + review['review_id'] + \"\\t\" + review['text'] + \"\\n\")\n",
    "\t\tf_metaData.write(str(cnt) + \"\\t\" + review['user_id'] + \"\\t\" + businessId + \"\\t\" + str(review['rating']) + \"\\t\" + \"-1\\t\" + review['date'] + \"\\n\")\n",
    "\t\tcnt += 1\n",
    "\n",
    "print \"... finished crawling, extracted \" + str(cnt-1) + \" reviews in total\"\n",
    "\n",
    "cnt = 1\n",
    "for userId, count in userIdDict.iteritems():\n",
    "\tf_userIdMapping.write(str(cnt) + \"\\t\" + userId + \"\\t\" + str(count['neg']) + \"\\t\" + str(count['pos']) + \"\\n\")\n",
    "\tcnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "Missing parentheses in call to 'print' (<ipython-input-7-0e170379721b>, line 21)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-7-0e170379721b>\"\u001b[0;36m, line \u001b[0;32m21\u001b[0m\n\u001b[0;31m    print \">>> aggregating users: \"\u001b[0m\n\u001b[0m                                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m Missing parentheses in call to 'print'\n"
     ]
    }
   ],
   "source": [
    "#####################################\n",
    "# aggregate subset files into three files \n",
    "# re-number the reviews\n",
    "# aggregate userId mapping into one bigger user file\n",
    "# number users and update metadata\n",
    "# 1. review content\n",
    "# 2. metadata\n",
    "# 3. userId mapping\n",
    "#####################################\n",
    "\n",
    "# aggregate users\n",
    "def aggregateUsers():\n",
    "\tusers = OrderedDict()\n",
    "\tcountAllUsers = 0\n",
    "\tfor i in range(10):\n",
    "\t\tf = open('outputData/user_id_mapping_' + str(i * 100) + '.tsv', 'r')\n",
    "\t\tlines = [line.rstrip('\\n\\r') for line in f]\n",
    "\t\tprint \">>> FILE: \" + str(i * 100) + \" COUNT: \" + str(len(lines))\n",
    "\t\tcountAllUsers += len(lines)\n",
    "\n",
    "\t\tfor line in lines:\n",
    "\t\t\tparts = line.split(\"\\t\")\n",
    "\t\t\tif parts[1] not in users:\n",
    "\t\t\t\tusers[parts[1]] = [int(parts[2]), int(parts[3])]\n",
    "\t\t\telse:\n",
    "\t\t\t\tusers[parts[1]][0] += int(parts[2])\n",
    "\t\t\t\tusers[parts[1]][1] += int(parts[3])\n",
    "\n",
    "\tprint \">>> total number of users: \" + str(len(users)) + \" ...writing to file\"\n",
    "\tf_userIdMapping = open('outputData/user_id_mapping_all.tsv', 'w')\n",
    "\tcnt = 1\n",
    "\tfor k,v in users.iteritems():\n",
    "\t\tf_userIdMapping.write(str(cnt) + \"\\t\" + str(k) + \"\\t\" + str(v[0]) + \"\\t\" + str(v[1]) + \"\\n\")\n",
    "\t\tcnt += 1\n",
    "\n",
    "def aggregateReviewMetaData():\n",
    "\tf_metaData = open('outputData/metaData_all.tsv', 'w')\n",
    "\tcnt = 1\n",
    "\tfor i in range(10):\n",
    "\t\tf = open('outputData/metaData_' + str(i * 100) + '.tsv', 'r')\n",
    "\t\tlines = [line.rstrip('\\n\\r') for line in f]\n",
    "\t\tprint \">>> FILE: \" + str(i * 100) + \" COUNT: \" + str(len(lines))\n",
    "\n",
    "\t\tfor line in lines:\n",
    "\t\t\tparts = line.split(\"\\t\")\n",
    "\t\t\titems = parts[1:5]\n",
    "\t\t\tdate = parts[5].replace(\"Updatedreview\", \"\").split(\"/\")\n",
    "\n",
    "\t\t\titems.insert(0, str(cnt))\n",
    "\t\t\titems.append(date[2] + \"-\" + date[0] + \"-\" + date[1])\n",
    "\t\t\tcnt += 1\n",
    "\n",
    "\t\t\tf_metaData.write(\"\\t\".join(items) + \"\\n\")\n",
    "\n",
    "def aggregateReviewContents():\n",
    "\tf_reviewContent = open('outputData/reviews_content_all.tsv', 'w')\n",
    "\tcnt = 1\n",
    "\tfor i in range(10):\n",
    "\t\tf = open('outputData/reviews_content_' + str(i * 100) + '.tsv', 'r')\n",
    "\t\tlines = [line.rstrip('\\n\\r') for line in f]\n",
    "\t\tprint \">>> FILE: \" + str(i * 100) + \" COUNT: \" + str(len(lines))\n",
    "\n",
    "\t\tfor line in lines:\n",
    "\t\t\tparts = line.split(\"\\t\", 1)\n",
    "\t\t\tf_reviewContent.write(str(cnt) + \"\\t\" + parts[1] + \"\\n\")\n",
    "\t\t\tcnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-8-635c7f614020>, line 20)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-8-635c7f614020>\"\u001b[0;36m, line \u001b[0;32m20\u001b[0m\n\u001b[0;31m    print len(oldBiz)\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#####################################\n",
    "# get viewed restaurants by the 35158 users extracted from 1000 restaurants\n",
    "#####################################\n",
    "offset = sys.argv[1]\n",
    "\n",
    "# load 1000 restaurant in Pittsburgh\n",
    "oldBiz = set()\n",
    "f = open('outputData/businessesIdMapping.tsv', 'r')\n",
    "businessLines = [line.rstrip('\\n\\r') for line in f]\n",
    "for line in businessLines:\n",
    "\toldBiz.add(line.split(\"\\t\")[1])\n",
    "\n",
    "f = open('outputData/user_id_mapping_all.tsv', 'r')\n",
    "userLines = [line.rstrip('\\n\\r') for line in f]\n",
    "newBiz = OrderedDict()\n",
    "\n",
    "for line in userLines[int(offset): int(offset) + 500]:\n",
    "\tparts = line.split(\"\\t\")\n",
    "\n",
    "\tbusinesses = getBizFromUserPage(parts[1])\n",
    "\tprint \">>> \" + parts[0] + \"  extracted \" + str(len(businesses)) + \" from user: \" + parts[1]\n",
    "\tfor biz in businesses:\n",
    "\t\tif biz not in oldBiz:\n",
    "\t\t\tnewBiz[biz] = parts[1]\n",
    "\n",
    "cnt = 1\n",
    "f_newBiz = open('outputData/newBiz_' + offset + '.tsv', 'w')\n",
    "for k, v in newBiz.iteritems():\n",
    "\tf_newBiz.write(str(cnt) + \"\\t\" + v + \"\\t\" + k + \"\\n\")\n",
    "\tcnt += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explaining models and assumptions\n",
    "\n",
    "### Source-Channel paradigm\n",
    "\n",
    "Source-Channel paradigm is a system that intend to capture the relationship between observed data and underlying data generating source. Here, for sentiment analysis, we assume that we have positive or negative perception for reviews(it can be boolean or a continous number between two values). Source-Channel paradigm assumes a prior probability P(S) for sentiment S and the channel can produce a document(review) D from a given S and the producing probability is P(S|D). Therefore, our task is to find the most likily S* given an observed D. The following equation shows the relationship:\n",
    "\n",
    "<img src='sourceChannelEquation.png'>\n",
    "\n",
    "\n",
    "And the source-channel paradigm can be visualized as:\n",
    "\n",
    "<img src='sourceChannel.png'>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Language models (unigram)\n",
    "\n",
    "We use unigram to represent reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment analysis models (negation and amplifiers)\n",
    "\n",
    "The idea behind this model is that we assume the sentiment score of a review is numerical calculable. There are three main assumptions:\n",
    "+ Sentiment score of a sentence is the aggregation of words in the sentence.\n",
    " \n",
    " * This [awesome] movie is the [best] one I [have ever seen].\n",
    " \n",
    " \n",
    "+ Sentiment score of a word can be flipped by a negation word.\n",
    "\n",
    " * This restaurant does [not] have the good food it claims.\n",
    " \n",
    " * The soup [could have been] more delicious if...\n",
    "\n",
    "\n",
    "+ Sentiment score of a word can be amplified or diminished by another amplifier tokens.\n",
    "  \n",
    " * The setting of this novel is [very] interesting[!]\n",
    " * it was the [WORST] experience I have ever had [in my life].\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Negation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "When analyzing sentiment of reviews, negation word can play a very significant role here. Consider the following two simple cases:\n",
    "* This is the best steak house in Pittsburgh.\n",
    "* This is not the best steak house in Pittsburgh.\n",
    "\n",
    "One single word 'not' can change the entire meaning of the sentence but if we approach the two using simple unigram and bag of words model, we will consider the two extremely similar to each other. We must deal with negation words when analyzing reviews. Gladly, nltk package provide a very simple way to mark words as negated.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-13-0487901cfba6>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-13-0487901cfba6>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    print mark_negation(test)\u001b[0m\n\u001b[0m                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "test1 = ('This is the best steak house in Pittsburgh.'.split(\" \"), 'subj')\n",
    "test2 = ('This is not the best steak house in Pittsburgh.'.split(\" \"), 'subj')\n",
    "print mark_negation(test1)\n",
    "print mark_negation(test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `mark_negation()` will annotate sentences and extract any negation and the negated phrases. Basically, it will treat the negated words as if they are different tokens. So the previous example will produce:\n",
    "\n",
    "* (['This', 'is', 'the', 'best', 'steak', 'house', 'in', 'Pittsburgh.'], 'subj')\n",
    "* (['This', 'is', 'not', 'the_NEG', 'best_NEG', 'steak_NEG', 'house_NEG', 'in_NEG', 'Pittsburgh._NEG'], 'subj')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build model using nltk.NaiveBayesClassifier with negations\n",
    "\n",
    "After we know how to treat negation in sentences, we can try to model reviews with different ratings. For demonstration purpose, we use Naive Bayes Classifier as a multi-class classifier. We train our model with 450 reviews from each categories and test our result on 50 of each. Note that the original distribution of reviews are very skewed (with reviews of ratings 5 being the most). To avoid the prior dominate the result, we construct a balanced training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open('inputData/metaData_all.tsv', 'r')\n",
    "metaDataLines = [line.rstrip('\\n\\r') for line in f]\n",
    "\n",
    "f = codecs.open('inputData/reviews_content_all.tsv', 'r', 'utf8')\n",
    "reviewsContentLines = [line.rstrip('\\n\\r') for line in f]\n",
    "\n",
    "# put reviews in five different bucket by ratings\n",
    "buckets = {\n",
    "\t'1.0': [], '2.0': [], '3.0': [], '4.0': [], '5.0': [],\n",
    "}\n",
    "\n",
    "for i in range(20000):\n",
    "\tr = reviewsContentLines[i].split(\"\\t\")[2]\n",
    "\ttokens = nltk.word_tokenize(r.encode('ascii', 'ignore').decode('ascii'))\n",
    "\trating = metaDataLines[i].split(\"\\t\")[3]\n",
    "\tbuckets[rating].append((tokens, rating))\n",
    "\n",
    "training_docs = []\n",
    "testing_docs = []\n",
    "\n",
    "# get reviews from buckets. \n",
    "for k, v in buckets.iteritems():\n",
    "\ttraining_docs.extend(v[0: 450])\n",
    "\ttesting_docs.extend(v[450: 500])\n",
    "\n",
    "sentim_analyzer = SentimentAnalyzer()\n",
    "all_words_neg = sentim_analyzer.all_words([mark_negation(doc) for doc in training_docs])\n",
    "\n",
    "unigram_feats = sentim_analyzer.unigram_word_feats(all_words_neg, min_freq=4)\n",
    "sentim_analyzer.add_feat_extractor(extract_unigram_feats, unigrams=unigram_feats)\n",
    "\n",
    "training_set = sentim_analyzer.apply_features(training_docs)\n",
    "test_set = sentim_analyzer.apply_features(testing_docs)\n",
    "\n",
    "trainer = NaiveBayesClassifier.train\n",
    "classifier = sentim_analyzer.train(trainer, training_set)\n",
    "\n",
    "for key,value in sorted(sentim_analyzer.evaluate(test_set).items()):\n",
    "    print('{0}: {1}'.format(key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "Number of features: 4703\n",
    "Evaluating NaiveBayesClassifier results...\n",
    "Accuracy: 0.484\n",
    "F-measure [1.0]: 0.556701030928\n",
    "F-measure [2.0]: 0.354166666667\n",
    "F-measure [3.0]: 0.229885057471\n",
    "F-measure [4.0]: 0.387096774194\n",
    "F-measure [5.0]: 0.771653543307\n",
    "Precision [1.0]: 0.574468085106\n",
    "Precision [2.0]: 0.369565217391\n",
    "Precision [3.0]: 0.27027027027\n",
    "Precision [4.0]: 0.418604651163\n",
    "Precision [5.0]: 0.636363636364\n",
    "Recall [1.0]: 0.54\n",
    "Recall [2.0]: 0.34\n",
    "Recall [3.0]: 0.2\n",
    "Recall [4.0]: 0.36\n",
    "Recall [5.0]: 0.98\n",
    "</pre>\n",
    "\n",
    "The result is not very impressive but it is somewhat reasonable since we see the model is performing much better in radical ratings (1 and 5 stars) and rating 3 has the worst performance. It can be understand that it is always easier to identify if a review has strong opinion than neutral. As a human, when we feel strongly against or supportive toward an object, the language we use to describe it will be much more different than when we do not feel much about the object.\n",
    "\n",
    "Also, another way to evaluate our model could be treating the problem as a regression-like problem because mistake a 5-star review to 1-star should be penalize more than predicting it as a 4-star. For multi-class classifier like the one we use, it does not really tell the true error of our model because it will count the prediction as error once no matter how far the prediction is to the true value. But for the purpose of this tutorial, we will not focus on discussing the philosophy of how to evaluate the problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Amplifiers: Capital words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def allCapitalCount(reviewFile, outFile):\n",
    "    with codecs.open(reviewFile, 'r', 'utf-8') as f:\n",
    "        data1 = f.readlines()\n",
    "    f.close()\n",
    "    writer = csv.writer(open(outFile, 'wb'))\n",
    "    regex = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "    \n",
    "    for line in data1:\n",
    "        count = re.split(\"\\s+\", line, 1)[0]\n",
    "        if len(re.split(\"\\s+\", line, 1)) > 1:\n",
    "            line = re.split(\"\\s+\", line, 1)[1]\n",
    "            words = nltk.word_tokenize(line)\n",
    "            word = list()\n",
    "            countWord = 0\n",
    "            countAllCapital = 0\n",
    "\n",
    "            for w in words:\n",
    "                if w.isupper():\n",
    "                    countAllCapital += 1\n",
    "                new_token = regex.sub(u'', w)\n",
    "                if not new_token == u'':\n",
    "                    word.append(new_token)\n",
    "                    countWord += 1\n",
    "            if countWord > 0:\n",
    "                percAllCapital = (float(countAllCapital)/countWord)\n",
    "            else:\n",
    "                percAllCapital = 0.0\n",
    "            writer.writerow([count, percAllCapital])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Amplifiers: Exclamation marks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "Missing parentheses in call to 'print' (<ipython-input-10-19f7d5095c4a>, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-10-19f7d5095c4a>\"\u001b[0;36m, line \u001b[0;32m9\u001b[0m\n\u001b[0;31m    print \"\\n>>> running excSentenceCount...\"\u001b[0m\n\u001b[0m                                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m Missing parentheses in call to 'print'\n"
     ]
    }
   ],
   "source": [
    "def excSentenceCount(filename, outputFile):\n",
    "    with codecs.open(filename, 'r', 'utf-8') as f:\n",
    "        data1 = f.readlines()\n",
    "    f.close()\n",
    "    writer = csv.writer(open(outputFile, 'wb'))\n",
    "    \n",
    "    for line in data1:\n",
    "        count = re.split(\"\\s+\", line, 1)[0]\n",
    "        if len(re.split(\"\\s+\", line, 1)) > 1:\n",
    "            line = re.split(\"\\s+\", line, 1)[1]\n",
    "            tokenized_sentences = nltk.sent_tokenize(line)\n",
    "            countExc = 0\n",
    "            countSent = 0\n",
    "            for sentence in tokenized_sentences:\n",
    "                countSent += 1\n",
    "                if '!' in sentence:\n",
    "                    countExc += 1\n",
    "            if countSent > 0:\n",
    "                ratioExcSent = float(countExc)/countSent\n",
    "            else:\n",
    "                ratioExcSent = 0.0\n",
    "            writer.writerow([count, ratioExcSent])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Vader to model polarity\n",
    "\n",
    "<a href=\"https://pypi.python.org/pypi/vaderSentiment\">VADER</a> (Valence Aware Dictionary and sEntiment Reasoner) is a lexicon and rule-based sentiment analysis tool that is specifically attuned to sentiments expressed in social media, and works well on texts from other domains.\n",
    "\n",
    "Vader is already trained with a great variety of corpus and we can use it directly to analyze the polarity of any review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# example sentence borrow from http://www.nltk.org/howto/sentiment.html\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "ss1 = sid.polarity_scores(\"VADER is smart, handsome, and funny.\")\n",
    "ss2 = sid.polarity_scores(\"VADER is smart, handsome, and funny!\")\n",
    "ss3 = sid.polarity_scores(\"VADER is bad, boring, and funny.\")\n",
    "ss4 = sid.polarity_scores(\"VADER is bad, boring, and funny!\")\n",
    "print ss1, ss2, ss3, ss4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output of the program is:\n",
    "\n",
    "<pre>\n",
    "{'neg': 0.0, 'neu': 0.254, 'pos': 0.746, 'compound': 0.8316}\n",
    "{'neg': 0.0, 'neu': 0.248, 'pos': 0.752, 'compound': 0.8439}\n",
    "{'neg': 0.496, 'neu': 0.256, 'pos': 0.248, 'compound': -0.4404}\n",
    "{'neg': 0.508, 'neu': 0.25, 'pos': 0.242, 'compound': -0.4926}\n",
    "</pre>\n",
    "\n",
    "We can see by adding the exclamation mark, positive reviews score higher in positive score and negative reviews became more negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "Missing parentheses in call to 'print' (<ipython-input-18-e669d950ff9f>, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-18-e669d950ff9f>\"\u001b[0;36m, line \u001b[0;32m9\u001b[0m\n\u001b[0;31m    print ss1\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m Missing parentheses in call to 'print'\n"
     ]
    }
   ],
   "source": [
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "ss1 = sid.polarity_scores(\"VADER is SMART, HANDSOME, and FUNNY.\")\n",
    "ss2 = sid.polarity_scores(\"VADER is smart, handsome, and funny.\")\n",
    "ss3 = sid.polarity_scores(\"VADER is BAD, BORING, and FUNNY.\")\n",
    "ss4 = sid.polarity_scores(\"VADER is bad, boring, and funny.\")\n",
    "print ss1, ss2, ss3, ss4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output of the program is:\n",
    "\n",
    "<pre>\n",
    "{'neg': 0.0, 'neu': 0.214, 'pos': 0.786, 'compound': 0.9}\n",
    "{'neg': 0.0, 'neu': 0.254, 'pos': 0.746, 'compound': 0.8316}\n",
    "{'neg': 0.523, 'neu': 0.216, 'pos': 0.261, 'compound': -0.5622}\n",
    "{'neg': 0.496, 'neu': 0.256, 'pos': 0.248, 'compound': -0.4404}\n",
    "</pre>\n",
    "\n",
    "We can see by making some words ALL CAPITAL, positive reviews score higher in positive score and negative reviews became more negative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Vader to Yelp reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = codecs.open('inputData/reviews_content_all.tsv', 'r', 'utf8')\n",
    "reviewsContent = [line.rstrip('\\n\\r').split(\"\\t\")[2] for line in f]\n",
    "f = open('inputData/metaData_all.tsv', 'r')\n",
    "metaDataLines = [line.rstrip('\\n\\r') for line in f]\n",
    "\n",
    "sentences = reviewsContent[0:1000]\n",
    "categories = {\n",
    "\t'1.0': {'cnt': 0, 'neg': 0, 'neu': 0, 'pos': 0},\n",
    "\t'2.0': {'cnt': 0, 'neg': 0, 'neu': 0, 'pos': 0},\n",
    "\t'3.0': {'cnt': 0, 'neg': 0, 'neu': 0, 'pos': 0},\n",
    "\t'4.0': {'cnt': 0, 'neg': 0, 'neu': 0, 'pos': 0},\n",
    "\t'5.0': {'cnt': 0, 'neg': 0, 'neu': 0, 'pos': 0}\n",
    "}\n",
    "\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "for i in range(len(sentences)):\n",
    "    print(sentences[i][0:50] + \" ...\")\n",
    "    ss = sid.polarity_scores(sentences[i])\n",
    "    print ss\n",
    "    ratings = metaDataLines[i].split(\"\\t\")[3]\n",
    "    categories[ratings]['cnt'] += 1\n",
    "    categories[ratings]['neg'] += ss['neg']\n",
    "    categories[ratings]['neu'] += ss['neu']\n",
    "    categories[ratings]['pos'] += ss['pos']\n",
    "\n",
    "for k, v in categories.iteritems():\n",
    "\tprint \">>> ratings: \" + k\n",
    "\tprint \"neg: \" + str(float(v['neg'])/v['cnt'])\n",
    "\tprint \"neu: \" + str(float(v['neu'])/v['cnt'])\n",
    "\tprint \"pos: \" + str(float(v['pos'])/v['cnt'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output of the program is:\n",
    "<pre>\n",
    ">>> ratings: 5.0\n",
    "neg: 0.025626429479\n",
    "neu: 0.733320203304\n",
    "pos: 0.241049555273\n",
    ">>> ratings: 4.0\n",
    "neg: 0.0287669172932\n",
    "neu: 0.757466165414\n",
    "pos: 0.21384962406\n",
    ">>> ratings: 3.0\n",
    "neg: 0.045380952381\n",
    "neu: 0.799952380952\n",
    "pos: 0.154714285714\n",
    ">>> ratings: 2.0\n",
    "neg: 0.0808888888889\n",
    "neu: 0.796037037037\n",
    "pos: 0.123111111111\n",
    ">>> ratings: 1.0\n",
    "neg: 0.0888181818182\n",
    "neu: 0.831636363636\n",
    "pos: 0.0795454545455\n",
    "</pre>\n",
    "\n",
    "We can see clearly 5-star reviews score higher than others and the order is consistent across categories.\n",
    "Vader is awesome!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
