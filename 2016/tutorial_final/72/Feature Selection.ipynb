{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Feature Selection:\n",
    "\n",
    "Feature selection is the process in machine learning and statistics used select a subset of the available features to use in modeling and implementation. Conventional wisdom says the more features and data we have available to us, the better the model we can create. However, there are several reasons why we would choose to not use the full feature set. \n",
    "\n",
    "First, by selecting a subset, models can be simplified and easier to interpret by analysts or researchers. Along these same lines, if there is a cost associated with collecting data (e.g. acquiring and setting up sensors, or survey data), you would only want to collect data for the features that best predict the output. \n",
    "\n",
    "Second, reducing the number of inputs to the model can reduce the time and computational resources needed to train the model. Additionally, some models (like linear regression) cannot be run when you have more features than examples.  \n",
    "\n",
    "Finally, feature selection is important in creating models that generalize from training data to testing data. By using feature selection and cross validation, we can measure the right level of complexity for the model and choose the number of features accordingly. \n",
    "\n",
    "Now that we know <b> why </b> we need feature selection, let's now focus on the the <b>how</b>. We will cover three different algorithms in the sklearn package and write a simple function of our own to do the fourth method: \n",
    "<li> Variance Threshold </li>\n",
    "<li> Univariate Selection </li>\n",
    "<li> Recursive Feature Elimination </li>\n",
    "<li> Greedy Forward Selection </li>\n",
    "\n",
    "To complete the tutorial, we will use data from Center for Machine Learning and Intelligent Systems to predict wine quality, being a low quality wine and 1 being a high quality wine. The available features in this set are: total sulfur dioxide, free sulfur dioxide, fixed acidity, residual sugar, alcohol, citric acid, volatile acidity, sulphates, pH, chlorides, and density.\t\n",
    "\n",
    "Below we will import the necessary packages, the dataset, and code to separate the dataset into training and test sets. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Set of Features :  11\n",
      "['fixed acidity' 'volatile acidity' 'citric acid' 'residual sugar'\n",
      " 'chlorides' 'free sulfur dioxide' 'total sulfur dioxide' 'density' 'pH'\n",
      " 'sulphates' 'alcohol']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn import svm\n",
    "\n",
    "###randomly separate test and train\n",
    "np.random.seed(12345)\n",
    "wine_data = pd.read_csv('winequality-red2.csv')\n",
    "msk = np.random.rand(len(wine_data)) < 0.7\n",
    "train = wine_data[msk]\n",
    "test =  wine_data[~msk]\n",
    "\n",
    "###this is the outcome variable from the CSV (0 and 1)\n",
    "outcome_train = train[\"outcome-good?\"]\n",
    "outcome_test = test[\"outcome-good?\"]\n",
    "\n",
    "##create training set\n",
    "input_train = train.copy(deep=True)\n",
    "input_train = input_train.drop(\"quality\", axis = 1 )\n",
    "input_train = input_train.drop(\"outcome-good?\", axis = 1 )\n",
    "\n",
    "##create test set\n",
    "input_test = test.copy(deep=True)\n",
    "input_test = input_test.drop(\"quality\", axis = 1 )\n",
    "input_test = input_test.drop(\"outcome-good?\", axis = 1)\n",
    "\n",
    "##get number of features\n",
    "print \"Full Set of Features : \",  input_train.shape[1]\n",
    "print input_train.columns.values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although this tutorial is not about classification, we do need some means of comparing the selected features using some model's performance. For this, we will use sklearn's SVM classifier with a linear kernal, and use accuracy to assess the quality of the features selected. Other permformance metrics like AUC, precision, or recall could also be used here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def classify(train_data,data_output): \n",
    "    clf = sklearn.svm.SVC(kernel = \"linear\")\n",
    "    clf.fit(train_data, data_output)\n",
    "    return clf\n",
    "\n",
    "def evaluate_classifier(classifier, X_validation, y_validation):\n",
    "    predicted_values = classifier.predict(X_validation)\n",
    "    y_validation = list(y_validation)\n",
    "    correct_sum = 0\n",
    "    for i in range (len(predicted_values)):\n",
    "        if predicted_values[i] == y_validation[i]:\n",
    "            correct_sum = correct_sum + 1 \n",
    "    accuracy = (correct_sum*1.0)/(len(predicted_values)*1.0)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the train and test data sets that we created above, we can start with a baseline using all of the features. This will servie as a baseline to compare each of the algorithms with. \n",
    "\n",
    "Using the 11 features, we get a ~75% accuracy when determining whether a wine is good enough. For reference, the class is approximately balanced, so this represents a ~50% lift over a default classifyer.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy :  0.757668711656\n",
      "test accuracy :  0.777777777778\n"
     ]
    }
   ],
   "source": [
    "clf_full = classify(input_train, outcome_train)\n",
    "\n",
    "print \"train accuracy : \" , evaluate_classifier(clf_full, input_train, outcome_train)\n",
    "print \"test accuracy : \", evaluate_classifier(clf_full, input_test, outcome_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing Features with low variance\n",
    "\n",
    "One of the simpliest feature selection techniques within sklearn is VarianceThreshold, which basically removes features with low variances. Intuitively, this makes sense because if our output varies , if our inputs are to have any relationship with the output, they must also vary. \n",
    "\n",
    "Below, I have implemented this in two steps. First, I use the package to just view the variances, and then I actually select a cut off threshold of 1.0  which leaves me with the 5 top features. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>variance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>total sulfur dioxide</td>\n",
       "      <td>1005.299714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>free sulfur dioxide</td>\n",
       "      <td>114.102707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fixed acidity</td>\n",
       "      <td>2.611355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>residual sugar</td>\n",
       "      <td>2.483650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>alcohol</td>\n",
       "      <td>1.110811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>citric acid</td>\n",
       "      <td>0.037475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>volatile acidity</td>\n",
       "      <td>0.033972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sulphates</td>\n",
       "      <td>0.033288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>pH</td>\n",
       "      <td>0.023422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chlorides</td>\n",
       "      <td>0.002583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>density</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                features     variance\n",
       "6   total sulfur dioxide  1005.299714\n",
       "5    free sulfur dioxide   114.102707\n",
       "0          fixed acidity     2.611355\n",
       "3         residual sugar     2.483650\n",
       "10               alcohol     1.110811\n",
       "2            citric acid     0.037475\n",
       "1       volatile acidity     0.033972\n",
       "9              sulphates     0.033288\n",
       "8                     pH     0.023422\n",
       "4              chlorides     0.002583\n",
       "7                density     0.000003"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "## To start, I won't put any value as the threshold, I will just view all of variances. \n",
    "sel = VarianceThreshold((0.0))\n",
    "sel.fit_transform(input_train, outcome_train)\n",
    "\n",
    "##view the variances in a *pretty* dataframe\n",
    "df = pd.DataFrame()\n",
    "df[\"features\"]= list(input_train.columns.values)\n",
    "df[\"variance\"]= sel.variances_\n",
    "\n",
    "\n",
    "df = df.sort_values(by =\"variance\", ascending= False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of features remaining =  5\n",
      "accuracy:  0.717353198948\n",
      "test accuracy:  0.736897274633\n"
     ]
    }
   ],
   "source": [
    "## since I know I want the top five values, I can also choose a threshold value that will give me a cut off of that. \n",
    "sel = VarianceThreshold((1))\n",
    "var_features = sel.fit_transform(input_train)\n",
    "var_features_test = sel.transform(input_test)\n",
    "var_feature_names =input_train.columns.values[sel.fit(input_train).get_support(indices = True)]\n",
    "print \"number of features remaining = \", var_features.shape[1]\n",
    "\n",
    "## now plug the reduced var_features data frame into the classifier and report the accuracy\n",
    "classifier = classify(var_features, outcome_train)\n",
    "train_accuracy_var = evaluate_classifier(classifier, var_features, outcome_train)\n",
    "test_accuracy_var = evaluate_classifier(classifier, var_features_test, outcome_test)\n",
    "print \"accuracy: \", train_accuracy_var\n",
    "print \"test accuracy: \", test_accuracy_var\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given how simple this method is, it actually does a pretty good job selecting features that predict the outcome. \n",
    "\n",
    "For full disclosure, in practice, you probably wouldn't see anyone  using this method to select the k best features from a large feature set. However, if your reason for feature selection is computational resources, this can be a fast and inexpensive way to remove excess features before you begin additional feature selection or modeling. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate Feature Selection\n",
    "\n",
    "Univariate feature selection is another very simple, but widely used algorithm for selecting features. Univariate feature selection works by performing univariate statistical tests with respect to the output on each feature individually. The implementer can choose the following tests in the SelectKBest method depending on the research question: \n",
    "</n>\n",
    "<li> <u> Classification </u> : f_classif, chi2, SelectFpr, SelectFdr, SelectFwe, mutual_info_classif </li>\n",
    "<li> <u> Regression </u> : mutual_info_regression, f_regression </li>\n",
    "<li> <u> Both </u> : GenericUnivariateSelect </li>\n",
    "\n",
    "The second parameter it accepts is k, which is the number of features it should return. Below I've implemented Univariate feature selection using f_classif, and k=5. If we change this to f_classif, we are choosing a different statistical tests and therefore we get a different set of features. If you were to use this method in practice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remaining features : 5\n",
      "['fixed acidity' 'volatile acidity' 'citric acid' 'sulphates' 'alcohol']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import *\n",
    "\n",
    "##Fit\n",
    "univariate_sel = SelectKBest(f_classif, k=5).fit(input_train, outcome_train)\n",
    "\n",
    "##Transform both test and train according to train\n",
    "univariate_features = univariate_sel.transform(input_train) \n",
    "univariate_features_test = univariate_sel.transform(input_test) \n",
    "univariate_feature_names = input_train.columns.values[univariate_sel.get_support(indices = True)]\n",
    "\n",
    "#Retrieve the Column Names of the Remaining features\n",
    "print \"remaining features :\" ,univariate_features.shape[1]\n",
    "print univariate_feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy:  0.737510955302\n",
      "test accuracy:  0.769392033543\n"
     ]
    }
   ],
   "source": [
    "##Use same code to evaluate the feature selected\n",
    "classifier = classify(univariate_features, outcome_train)\n",
    "train_accuracy_uni =evaluate_classifier(classifier, univariate_features, outcome_train)\n",
    "test_accuracy_uni = evaluate_classifier(classifier, univariate_features_test, outcome_test)\n",
    "\n",
    "\n",
    "print \"train accuracy: \",train_accuracy_uni\n",
    "print \"test accuracy: \", test_accuracy_uni"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though this is such a straightforward and simple method, we get really good results compared to the full feature set. Additionally, univariate selection is one of the least computationally expense methods we will look at. \n",
    "\n",
    "Unvariate feature selection does have its limitations, however. In practice, we often have large, correlated feature sets but univariate selection does independent tests. Therefore, you could end up with 5 highly correlated features, where 4 of them are providing duplicative information. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recursive Feature Elimination\n",
    "\n",
    "The next feature selection algorithm we will look at is Recursive Feature Elimination(RFE). RFE first works by training a linear model using the full feature set. Using the weights of each feature, RFE removes n number of features with the smallest absolute weights until the desired number of features is reached. \n",
    "\n",
    "RFE is a _greedy_ algorithm, meaning that that the exhaustive set of possibilities is never explored. The algorithm always selects the feature with the smallest weights irrespective with how different combinations perform together after other features are removed.  \n",
    "\n",
    "RFE from sklearn accepts many more parameters than the previous algorithms we looked at. First, the algorithm has to get the weights for each feature. Below you can see that I first used a Support Vector Machine with a linear kernal to get the weights. If we were instead solving a regression problem, we would probabaly want to use a  linear regression model for the weights. One of the limitations to this method is that you have to fit an algorithm that has weights, therefore, a more complex, non linear SVM kernal and other machine learning algorithms won't work. \n",
    "\n",
    "After fitting the model, you call the RFE method and pass the model object, the number of features you want to retain, and the number of features to remove at each step. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remaining features : 5\n",
      "['volatile acidity' 'citric acid' 'chlorides' 'pH' 'sulphates']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "##linear model to fit\n",
    "svc = sklearn.svm.SVR(kernel=\"linear\", C=1)\n",
    "\n",
    "##create rfe object \n",
    "rfe = RFE(svc, 5, step=1)\n",
    "\n",
    "##fit the rfe with our training data\n",
    "fit = rfe.fit(input_train, outcome_train)\n",
    "\n",
    "##transform train and test data bases on fit \n",
    "##note: this is why we choose fit and not fit transform\n",
    "rfe_features = rfe.transform(input_train)\n",
    "rfe_features_test = rfe.transform(input_test)\n",
    "\n",
    "##get feature names\n",
    "rfe_features_names = input_train.columns.values[fit.get_support(indices = True)]\n",
    "\n",
    "print \"remaining features :\" ,rfe_features.shape[1]\n",
    "print rfe_features_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy 0.708150744961\n",
      "train accuracy 0.731656184486\n"
     ]
    }
   ],
   "source": [
    "classifier = classify(rfe_features, outcome_train)\n",
    "train_accuracy_rfe = evaluate_classifier(classifier, rfe_features, outcome_train)\n",
    "test_accuracy_rfe = evaluate_classifier(classifier, rfe_features_test, outcome_test)\n",
    "print \"train accuracy\" , train_accuracy_rfe\n",
    "print \"train accuracy\", test_accuracy_rfe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Greedy Forward Selection\n",
    "Finally, one of the most common feature selection techniques in practice is Greedy Forward Feature Selection (GFFS). This will be the only one that we don't implement from a sklearn. \n",
    "\n",
    "Greedy Forward Selection work exactly as it sounds. Beginning with the single feature that best predicts the outcome, in each step you add the next best feature that, combined with the features already selected, best predicts the outcome. The evaluation of \"next best\" is somewhat up for debate. I chose to use accuracy because that is what I have shown above, but you could just as easily use AUC, Recall, Precision, etc. For a regression task, you might use something like R-squares, mean squared error, or absolute square error. These decisions would depend on the application or research question. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features selected :  ['volatile acidity' 'alcohol' 'fixed acidity' 'free sulfur dioxide'\n",
      " 'total sulfur dioxide']\n"
     ]
    }
   ],
   "source": [
    "def forward_select(input_train, outcome_train, number_of_features):\n",
    "    ###initialize dataframes of selected features and remaining features\n",
    "    sel_feat = pd.DataFrame()\n",
    "    remain = input_train.copy()\n",
    "    ###initialize a list that will be used for target measures (accuracy in this case)\n",
    "    for i in range(number_of_features):\n",
    "        acc_df = []\n",
    "        for feature in remain: \n",
    "            considered = sel_feat.copy(deep = True)\n",
    "            considered[feature] = remain[feature]\n",
    "            model =  classify(considered, outcome_train)\n",
    "            acc_df.append(evaluate_classifier(model, considered, outcome_train))\n",
    "        index_max = np.argmax(acc_df)\n",
    "        selected_feature = remain.columns.values[index_max]\n",
    "        sel_feat[selected_feature] = remain[selected_feature]\n",
    "        del remain[selected_feature]\n",
    "    print \"features selected : \", sel_feat.columns.values\n",
    "    return sel_feat\n",
    "    \n",
    "    \n",
    "FS_features = forward_select(input_train, outcome_train, 5)\n",
    "FS_test_features = input_test[FS_features.columns.values]\n",
    "\n",
    "classifier = classify(FS_features, outcome_train)\n",
    "train_accuracy_fw = evaluate_classifier(classifier, FS_features, outcome_train)\n",
    "test_accuracy_fw = evaluate_classifier(classifier, FS_test_features, outcome_test)\n",
    "print \"train accuracy\" , train_accuracy_fw\n",
    "print \"test accuracy\", test_accuracy_fw\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results of this method are most similar to the univariate analysis. This could potentially be due to the small desired feature set, but univariate includes both sulfer dioxide metrics, which are likely correlated. Univariate does not pick up on this, but greedy does."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bringing it all together\n",
    "\n",
    "The code below depicts which features were selected by which algorithm, and performance of a model with those features. In practice, feature selection tends to be a highly supervised process, and therefore you can learn about about your data and models from looking at the results of these algorithms. \n",
    "\n",
    "The wine data set that I chose was somewhat limited in that there wasn't a huge difference in the model performance between algorithms. However, the key take-aways from this lesson should be two-fold. \n",
    "\n",
    "First, we achieved <b>equal or better performance using less than 50% </b> of the available features. Secondly, <b>no two methods selected the exact same features </b>. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def display_df(full_features, selected_features):\n",
    "    xlist = []\n",
    "    for feature in full_features:\n",
    "        if feature in selected_features:\n",
    "            xlist.append(\"x\")\n",
    "        else:\n",
    "            xlist.append(\"\")\n",
    "    return xlist\n",
    "\n",
    "variance_threshold = display_df(input_train, var_feature_names)\n",
    "univariate = display_df(input_train, univariate_feature_names)\n",
    "rfe = display_df(input_train, rfe_features_names)\n",
    "forward_selection = display_df(input_train, FS_features)\n",
    "\n",
    "df=pd.DataFrame()\n",
    "df[\"Features\"] = pd.Series(list(input_train.columns.values) + [\"train acc\", \"test acc\"])\n",
    "df[\"Variance Threshold\"] = pd.Series(variance_threshold + [train_accuracy_var, test_accuracy_var])\n",
    "df[\"Univariate Selection\"] = pd.Series(univariate + [train_accuracy_uni, test_accuracy_uni])\n",
    "df[\"Recursive Feature Elim\"] = pd.Series(rfe + [train_accuracy_rfe, test_accuracy_rfe])\n",
    "df[\"Forward Selection\"] = pd.Series(forward_selection + [train_accuracy_fw, test_accuracy_fw])\n",
    "df\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Reading\n",
    "\n",
    "Feature selection is an active area of research in machine learning and statistics. Two methods that I did not cover in tutorial, but are widely used for certain applications are Tree-Based Selection and Orthagonal Matching Pursuit. \n",
    "\n",
    "Tree-Based Learning uses the results of random forests to calculate and rank feature performance based on how many trees the feature is selected in. Orthagonal Matching Persuit is a typically used for video and audio files and can reliably recover a signal using random linear measurements of that signal.\n",
    "\n",
    "More info here: \n",
    "</n>\n",
    "\n",
    "Tree-Based Learning: \n",
    "http://blog.datadive.net/selecting-good-features-part-iii-random-forests/\n",
    "\n",
    "Orthagonal Mathching Persuit: \n",
    "http://www.stat.yale.edu/~snn7/courses/stat679fa13/references/omptrogil.pdf\n",
    "http://math.mit.edu/~liewang/OMP.pdf\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
