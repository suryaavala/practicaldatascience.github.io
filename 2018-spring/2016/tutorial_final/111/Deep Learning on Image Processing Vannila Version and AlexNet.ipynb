{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning on Image Processing Vannila Version and AlexNet\n",
    "\n",
    "(This tutorial will improve over time, this is not the final version just, first draft)\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this tutorial we are going to dive into deep learning, use deep learning to solve image classification problem, build different models, implement the most trendy two type of neural net : Convolutional Neural Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  TensorFlow\n",
    "Google's TensorFlow is currently the most popular Deep Learning library repositoy on GitHub. TensorFlow generally have a faster compile time than other main stream deep learning frameworks currently, and its computational graphs can be distributed on a cluster for computations. We are not going to experiment every deep learning framework here like Theano, Torch etc. TensorFlow performed well in the ImageNet category. \n",
    "\n",
    "### Installation\n",
    "Detailed steps for installation can be found in the link below:\n",
    "\n",
    "https://www.tensorflow.org/versions/r0.11/get_started/os_setup.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training/Testing data\n",
    "We are going to start off with digit recognition problem since it is much quicker to finish running each epoch compared to big images. MNIST data sets has two parts: an image of a handwritten digit and a corresponding label.\n",
    "<img src =\"http://yann.lecun.com/exdb/lenet/gifs/asamples.gif\">\n",
    "Tensor flow made it easy to load in digit recognition data by using tensorflow.examples.tutorials.mnist.\n",
    "\n",
    "\n",
    "The MNIST data is split into three parts: 55,000 data points of training data (mnist.train), 10,000 points of test data (mnist.test), and 5,000 points of validation data (mnist.validation).\n",
    "\n",
    "Each image is 28 pixels by 28 pixels. We can interpret this as a big array of numbers:\n",
    "<img src =\"https://www.tensorflow.org/versions/r0.11/images/MNIST-Matrix.png\">\n",
    "Later on we can process images like cifar-10 or larger.\n",
    "\n",
    "Preview:\n",
    "<img src = \"http://karpathy.github.io/assets/cifar_preview.png\">\n",
    "\n",
    "A little bit history about hand-written digit recogniton problem can be traced back to work of Yann LeCun at AT&T lab, which can be found here: \n",
    "http://yann.lecun.com/exdb/lenet/ (LeNet)\n",
    "\n",
    "##### One Hot Representation:\n",
    "We are using one-hot 10-dimensional vector indicating which digit class (0 through 1) the corresponding MNIST image belongs to. One-hot vector was also applied to NLP field but definately not best word representation as it is very sparse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Parameters\n",
    "I am going to explain each variable one by one and come back to explain some of them that will only make sense later on when we explored the model:\n",
    "\n",
    "* training_iters : number of forward propagation, backward propagation epoch\n",
    "* batch_size : mini batch training, I will explain later on\n",
    "* img_vec_size : MNIST img is of size 28*28\n",
    "* num_class : MNIST classes range 0-9 for digit 0-9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_iters = 200000\n",
    "batch_size = 100\n",
    "img_vec_size = 784  # MNIST img 28*28\n",
    "num_class = 10      # MNIST classes 0-9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Placeholder\n",
    "The concept of placeholder is unique to tensorflow. Placeholder is a value that we will input when we ask TensorFlow to run a computation. By creating nodes for the input images and target output classes, we are building the computation graphs inside TensorFlow. We will assign the shape for both x and y. \n",
    "\n",
    "### Concept about Dropout:\n",
    "We will apply drop out to our CNN, intentionally \"forget\" some of the neuron in each layer to:\n",
    "1. prevent the entire network from overfitting \n",
    "2. it is also one easy way to have Ensemble Learning inside a neural network, a good analogy is the Rndom Forest, where you combine results of weak learner(individual decision tree)\n",
    "3. It makes Forward Propagation a bit faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, img_vec_size])\n",
    "y_ = tf.placeholder(tf.float32, [None, num_class])\n",
    "\n",
    "#   Dropout to :    prevent overfit\n",
    "#                   \"Ensemble Learning\"\n",
    "#                   A bit faster fp\n",
    "keep_prob = tf.placeholder(tf.float32) # probablity for dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Weight and Bias\n",
    "We don't want identically zero for weight initialization.\n",
    "We still want the weights for neurons to be very close to zero, but with randomness thus we can use Gaussian distribution with 0.1 stddev.\n",
    "\n",
    "It is actually very common to simply use 0 bias initialization.\n",
    "\n",
    "Concept about filter(CONV) will be explained below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "W_dict = {\n",
    "    'W_conv1': weight_variable([5, 5, 1, 32]),      # 5x5 size filter, 1 channel, 32 depth\n",
    "    'W_conv2': weight_variable([5, 5, 32, 64]),     # 5x5 size filter, 32 , 64 depth\n",
    "    'W_fc1': weight_variable([7 * 7 * 64, 1024]),   # fc layer, 'vectorize' 7*7*64 inputs, 1024 outputs\n",
    "    'W_fc2': weight_variable([1024, num_class])     # 1024 inputs, 10 output classes\n",
    "}\n",
    "\n",
    "b_dict = {\n",
    "    'b_conv1': bias_variable([32]), # match the depth of convolution \"cube\"\n",
    "    'b_conv2': bias_variable([64]),\n",
    "    'b_fc1': bias_variable([1024]),\n",
    "    'b_fc2': bias_variable([num_class])\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Now, lets build our first CNN (Vannila Version first) block by block :)\n",
    "\n",
    "##  Convolutional Neural Net\n",
    "This is a picture of traditional Deep Neural network vs. convolutional neural network:\n",
    "<img src = \"https://annalyzin.files.wordpress.com/2016/01/cnn_overview.png?w=459&h=236\">\n",
    "<img src = \"http://i.stack.imgur.com/OH3gI.png\">\n",
    "\n",
    "Note that CNN only has fully connected layer in the very end vs. DNN has traditional fully connected layers everywhere.\n",
    "\n",
    "## Importent to remember:\n",
    "1. Keep elongate the \"depth\" of convolution \"block\" by conv+relu together\n",
    "2. Shrink the surface area by pooling\n",
    "\n",
    "## Filter\n",
    "\n",
    "The CONV filter is usually a small filter to scan through the image by some different weights. And by choosing a number of filters and concatenating them together we can have a \"block\" of depth. The size of filter is often very small like 3*3, 5*5, larger size is not recommended. \n",
    "\n",
    "<img src= \"http://i.stack.imgur.com/GvsBA.jpg\">\n",
    "\n",
    "## Convolution\n",
    "The process of using filter to scan through the image and get raw \"extracted features\".\n",
    "We will do some image padding in the end to make sure the big block have same width and height of original picture\n",
    "(Will further explain)\n",
    "\n",
    "<img src= \"http://deeplearning.stanford.edu/wiki/images/6/6c/Convolution_schematic.gif\">\n",
    "\n",
    "## ReLU\n",
    "\n",
    "Activation function fro each neuron.\n",
    "We have sigmoid, tanh as well but they are subject to gradient vanishing and slow converge.\n",
    "Backprop suffers from a fundamental problem - vanishing gradient. \n",
    "During training, the gradient decreases in value back through the net. \n",
    "Higher gradient values lead to faster training, the layers closest to the input layer take the longest to train. \n",
    "\n",
    "<img src= \"http://deepdish.io/public/images/activation-functions.svg\">\n",
    "\n",
    "## Pooling\n",
    "\n",
    "We usually use max pooling to get the most representative feature of each filter block out of the convoluted block.\n",
    "Max pooling is more frequently used compared to mean poling method.\n",
    "Why pooling? Think about a distorted picture or picture with different color tone, or hand writing digit with some stains, we can still be able to do feature extraction with these external interfrence since we are only looking for most important features.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Merge matmul+bias then relu 2 step into one convolution step\n",
    "def convolution(x, W, b):\n",
    "    return tf.nn.relu(tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME') + b)\n",
    "\n",
    "# Pooling block size n*n\n",
    "def max_pooling(x, n):\n",
    "    return tf.nn.max_pool(x, ksize=[1, n, n, 1], strides=[1, n, n, 1], padding='SAME')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structure of CNN\n",
    "We use three main types of layers to build ConvNet architectures: \n",
    "1. Convolutional Layer \n",
    "2. Pooling Layer \n",
    "3. Fully-Connected Layer \n",
    "\n",
    "Typical workflow:\n",
    "#### [INPUT - CONV - RELU - POOL - FC]\n",
    "\n",
    "We can use the combination of CONV - RELU - POOL as major block to build the entire CNN as long as the dimension connection between each block is compatible.\n",
    "Conv Nets transform the original image layer by layer from the original pixel values to the final class scores.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cnn(X, weight, bias, dropout):\n",
    "    # Reshape input igm to 4-D\n",
    "    X = tf.reshape(X, shape=[-1, 28, 28, 1])\n",
    "\n",
    "    # Convolution Layer 1\n",
    "    conv1 = convolution(X, weight['W_conv1'], bias['b_conv1'])\n",
    "    # Max Pooling\n",
    "    conv1 = max_pooling(conv1, n=2)\n",
    "    # Dropout\n",
    "    # conv1_drop = tf.nn.dropout(conv1, dropout)\n",
    "\n",
    "    # Convolution Layer 2\n",
    "    conv2 = convolution(conv1, weight['W_conv2'], bias['b_conv2'])\n",
    "    # Max Pooling\n",
    "    conv2 = max_pooling(conv2, n=2)\n",
    "    # Dropout\n",
    "    # conv2_drop = tf.nn.dropout(conv2, dropout)\n",
    "\n",
    "    # Fully Connected Layer 1\n",
    "    conv2flat = tf.reshape(conv2, [-1, weight['W_fc1'].get_shape().as_list()[0]]) \n",
    "    # Reshape col of conv2flat to row of W_fc1 same as: tf.reshape(conv2_drop, [-1, 7*7*64])\n",
    "    fc1 = tf.nn.relu(tf.matmul(conv2flat, weight['W_fc1']) + bias['b_fc1']) # Relu activation\n",
    "    fc1_drop = tf.nn.dropout(fc1, dropout)\n",
    "\n",
    "    output = tf.nn.softmax(tf.matmul(fc1_drop, weight['W_fc2']) + bias['b_fc2'])\n",
    "    return output\n",
    "\n",
    "# Build CNN Graph\n",
    "y_conv = cnn(x, W_dict, b_dict, keep_prob)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It should take a while, please use GPU supported version of tensorflow if you have good resource ...\n",
    "\n",
    "## Evaluation:\n",
    "\n",
    "A nice function to determine the loss of a model is \"cross-entropy.\" Cross-entropy comes from thinking about information compressing codes in information theory but it winds up being an important idea in lots of areas, from gambling to machine learning. We will use gradient discent to train using entrophy value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Cost\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y_conv), reduction_indices=[1]))\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "\n",
    "# Eval\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "\n",
    "#Train and Eval in session\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "\n",
    "    for i in range(20000):\n",
    "        batch = mnist.train.next_batch(128) # power of 2 for parellel processing ?\n",
    "        if i%100 == 0:\n",
    "            train_accuracy = accuracy.eval(feed_dict={x:batch[0], y_: batch[1], keep_prob: 1.0})\n",
    "            print \"step %d, training accuracy %g\"%(i, train_accuracy)\n",
    "        train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.75}) #should be close to 0.5 for more layers\n",
    "\n",
    "    print \"test accuracy %g\"%accuracy.eval(feed_dict={x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0})"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Below are the reference output and you can see accuracy based on entrophy for every step of 100:\n",
    "\n",
    "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
    "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
    "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
    "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
    "step 0, training accuracy 0.109375\n",
    "step 100, training accuracy 0.859375\n",
    "step 200, training accuracy 0.898438\n",
    "step 300, training accuracy 0.96875\n",
    "step 400, training accuracy 0.953125\n",
    "step 500, training accuracy 0.96875\n",
    "step 600, training accuracy 0.960938\n",
    "step 700, training accuracy 0.953125\n",
    "step 800, training accuracy 0.976562\n",
    "step 900, training accuracy 0.976562\n",
    "step 1000, training accuracy 1\n",
    "step 1100, training accuracy 0.984375\n",
    "step 1200, training accuracy 0.984375\n",
    "step 1300, training accuracy 0.992188\n",
    "step 1400, training accuracy 0.992188\n",
    "step 1500, training accuracy 0.984375\n",
    "step 1600, training accuracy 1\n",
    "step 1700, training accuracy 0.992188\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alex Net\n",
    "\n",
    "<img src=\"http://images.duanshishi.com/mac_blogs_alexnet_architecture.jpg\">\n",
    "\n",
    "Next, let's build a Alex Net in next notebook.\n",
    "\n",
    "Let's restart and clear output from kernel.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning on Image Processing  2 of 2 AlexNet Version\n",
    "\n",
    "## Alex Net\n",
    "\n",
    "<img src=\"http://www.panderson.me/images/alexnet2012-small.png\">\n",
    "\n",
    "Next, let's build a Alex Net\n",
    "\n",
    "Alex Net is developed by Alex Krizhevsky, the first work that contributed to the \"bloom\" of Convolutional Networks in Computer Vision. Compare to the architecture of vanilla version of CNN and LeNet, AlexNet is deeper, bigger, and it has Convolutional Layers stacked on top of each other. AlexNet won the 2012 ImageNet competetion with 16% top 5 error rate.\n",
    "\n",
    "In this tutorial we will shrink the surface area in order to match the mnist data set. 224by224 to 28by28\n",
    "\n",
    "First, import required modules and load MNIST data as usual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Parameters and Tensorflow placeholders\n",
    "\n",
    "* training_iters : number of forward propagation, backward propagation epoch\n",
    "* batch_size : mini batch training, I will explain later on\n",
    "* img_vec_size : MNIST img is of size 28*28\n",
    "* num_class : MNIST classes range 0-9 for digit 0-9\n",
    "* dropout : rate of neurons about to be forgotten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "training_iters = 200000\n",
    "batch_size = 64\n",
    "display_step = 20\n",
    "img_vec_size = 784 #img 28*28\n",
    "num_class = 10  \n",
    "dropout = 0.8 # Ideally, for large images this number should be getting close to 0.6 but 0.8 works perfect for mnist\n",
    "\n",
    "# tf Graph input\n",
    "x = tf.placeholder(tf.float32, [None, img_vec_size])\n",
    "y = tf.placeholder(tf.float32, [None, num_class])\n",
    "keep_prob = tf.placeholder(tf.float32) # dropout (keep probability)\n",
    "\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define wieghts and bias for AlexNet\n",
    "* Keep elongate the \"depth\" of convolution \"block\" by conv+relu \n",
    "* Shrink the surface area by pooling\n",
    "* We use 4 max pooling layers here and 2 fully connected layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Alex Net W & b\n",
    "W_dict = {\n",
    "    'wc1': weight_variable([3, 3, 1, 64]),          # 3x3 size filter, 1 channel, 64 depth\n",
    "    'wc2': weight_variable([3, 3, 64, 128]),        # 3x3 size filter, 64 , 128 depth\n",
    "    'wc3': weight_variable([3, 3, 128, 256]),       # 3x3 size filter\n",
    "    'wc4': weight_variable([2, 2, 256, 512]),       # 2x2 size filter try to avoid 2*2 in shallow net\n",
    "    'wfc1': weight_variable([2 * 2 * 512, 1024]),   # fc layer1, 'vectorize' 2*2*512 inputs, 1024 outputs\n",
    "    'wfc2': weight_variable([1024, 1024]),          # fc2 1024 inputs, 1024 output classes\n",
    "    'wDest': weight_variable([1024, num_class])\n",
    "}\n",
    "\n",
    "b_dict = {\n",
    "    'bc1': bias_variable([64]),\n",
    "    'bc2': bias_variable([128]),\n",
    "    'bc3': bias_variable([256]),\n",
    "    'bc4': bias_variable([512]),\n",
    "    'bfc1': bias_variable([1024]),\n",
    "    'bfc2': bias_variable([1024]),\n",
    "    'bDest': bias_variable([num_class])\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we define conv, pool step and normalization for faster converge as we did in last notebook tutorial (1 of 2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Merge matmul+bias then relu 2 step in tutorial into one convolution step\n",
    "def convolution(name, x, W, b):\n",
    "    return tf.nn.relu(tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME') + b, name=name)\n",
    "\n",
    "# Pooling block size n*n\n",
    "def max_pooling(name, x, n):\n",
    "    return tf.nn.max_pool(x, ksize=[1, n, n, 1], strides=[1, n, n, 1], padding='SAME', name=name)\n",
    "\n",
    "# Parameter referencing existing AlexNet implementation \n",
    "def norm(name, poolingRes, depth_radius=4):\n",
    "    return tf.nn.lrn(poolingRes, depth_radius, bias=1.0, alpha=0.001 / 9.0, beta=0.75, name=name)\n",
    "    # Local Response Normalization with depth_radius (divide by sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structure of AlexNet\n",
    "We use three main types of layers to build AlexNet architectures: \n",
    "1. Convolutional Layer \n",
    "2. Pooling Layer \n",
    "3. Fully-Connected Layer \n",
    "\n",
    "AlexNet workflow:\n",
    "#### [INPUT - CONV - POOL - NORM - \n",
    "####                 CONV - POOL - NORM - \n",
    "####                 CONV - POOL - NORM - \n",
    "####                 CONV - POOL - NORM \n",
    "####                 - FC1- FC2 - OUTPUT]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def alexNet(X, weight, bias, dropout):\n",
    "    # Reshape input igm to 4-D\n",
    "    X = tf.reshape(X, shape=[-1, 28, 28, 1])\n",
    "\n",
    "    # Convolution Layer 1\n",
    "    conv1 = convolution('conv1', X, weight['wc1'], bias['bc1'])\n",
    "    # Max Pooling\n",
    "    pool1 = max_pooling('pool1', conv1, n=2)\n",
    "    # Normalization\n",
    "    norm1 = norm('norm1', pool1)\n",
    "    # Dropout\n",
    "    norm1 = tf.nn.dropout(norm1, dropout)\n",
    "\n",
    "    # Convolution Layer 2\n",
    "    conv2 = convolution('conv2', norm1, weight['wc2'], bias['bc2'])\n",
    "    # Max Pooling\n",
    "    pool2 = max_pooling('pool2', conv2, n=2)\n",
    "    # Normalization\n",
    "    norm2 = norm('norm2', pool2)\n",
    "    # Dropout\n",
    "    norm2 = tf.nn.dropout(norm2, dropout)\n",
    "\n",
    "    # Convolution Layer 3\n",
    "    conv3 = convolution('conv3', norm2, weight['wc3'], bias['bc3'])\n",
    "    # Max Pooling\n",
    "    pool3 = max_pooling('pool3', conv3, n=2)\n",
    "    # Normalization\n",
    "    norm3 = norm('norm3', pool3)\n",
    "    # Dropout\n",
    "    norm3 = tf.nn.dropout(norm3, dropout)\n",
    "\n",
    "    # Convolution Layer 4\n",
    "    conv4 = convolution('conv4', norm3, weight['wc4'], bias['bc4'])\n",
    "    # Max Pooling\n",
    "    pool4 = max_pooling('pool4', conv4, n=2)\n",
    "    # Normalization\n",
    "    norm4 = norm('norm4', pool4)\n",
    "    # Dropout\n",
    "    norm4 = tf.nn.dropout(norm4, dropout)\n",
    "\n",
    "    # Memory Peak here\n",
    "    # Fully Connected Layer 1\n",
    "    fc1 = tf.reshape(norm4, [-1, weight['wfc1'].get_shape().as_list()[0]]) \n",
    "    # Reshape column of conv4(norm4) to wfc1 row number for them to connect\n",
    "    fc1 = tf.nn.relu(tf.matmul(fc1, weight['wfc1']) + bias['bfc1'], name='fc1') \n",
    "\n",
    "    # Fully Connected Layer 2\n",
    "    fc2 = tf.nn.relu(tf.matmul(fc1, weight['wfc2']) + bias['bfc2'], name='fc2') \n",
    "\n",
    "    # Output\n",
    "    output = tf.matmul(fc2, weight['wDest']) + bias['bDest']\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation:\n",
    "\n",
    "Evaluate accuracy using cross-entropy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Softmax_cross_entropy_with_logits\n",
    "# http://stackoverflow.com/questions/34240703/difference-between-tensorflow-tf-nn-softmax-and-tf-nn-softmax-cross-entropy-with\n",
    "\n",
    "# Build AlexNet in Graph\n",
    "y_alexnet = alexNet(x, W_dict, b_dict, keep_prob)\n",
    "\n",
    "# Cost\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(y_alexnet, y))\n",
    "optimizer = tf.train.AdamOptimizer(0.001).minimize(cost)\n",
    "\n",
    "# Eval\n",
    "correct_prediction = tf.equal(tf.argmax(y_alexnet,1), tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "#Train and Eval in session\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    sess.run(init)\n",
    "    epoch = 1\n",
    "    # Keep training until reach max iterations\n",
    "    while epoch * batch_size < training_iters:\n",
    "        #batch = mnist.train.next_batch(64)\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        # Train\n",
    "        sess.run(optimizer, feed_dict={x: batch_xs, y: batch_ys, keep_prob: dropout})\n",
    "        if epoch % display_step == 0:\n",
    "            # batch accuracy\n",
    "            train_accuracy = accuracy.eval(feed_dict={x: batch_xs, y: batch_ys, keep_prob: 1.0})\n",
    "            print \"Iter \" + str(epoch*batch_size) + \", Batch Training Accuracy= \" + \"{:.5f}\".format(train_accuracy)\n",
    "        epoch += 1\n",
    "\n",
    "    print \"Final Testing Accuracy:\", sess.run(accuracy, feed_dict={x: mnist.test.images, y: mnist.test.labels, keep_prob: 1.})\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Below are the reference output:\n",
    "(it seems AlexNet peforms worse than LeNet for mnist but you will notice a big difference on CIFAR 10 dataset)\n",
    "\n",
    "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
    "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
    "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
    "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
    "Iter 1280, Batch Training Accuracy= 0.03125\n",
    "Iter 2560, Batch Training Accuracy= 0.21875\n",
    "Iter 3840, Batch Training Accuracy= 0.20312\n",
    "Iter 5120, Batch Training Accuracy= 0.20312\n",
    "Iter 6400, Batch Training Accuracy= 0.28125\n",
    "Iter 7680, Batch Training Accuracy= 0.29688\n",
    "Iter 8960, Batch Training Accuracy= 0.31250\n",
    "Iter 10240, Batch Training Accuracy= 0.43750\n",
    "Iter 11520, Batch Training Accuracy= 0.59375\n",
    "Iter 12800, Batch Training Accuracy= 0.60938\n",
    "Iter 14080, Batch Training Accuracy= 0.59375\n",
    "Iter 15360, Batch Training Accuracy= 0.79688\n",
    "Iter 16640, Batch Training Accuracy= 0.73438\n",
    "Iter 17920, Batch Training Accuracy= 0.84375\n",
    "Iter 19200, Batch Training Accuracy= 0.81250\n",
    "Iter 20480, Batch Training Accuracy= 0.92188\n",
    "Iter 21760, Batch Training Accuracy= 0.79688\n",
    "Iter 23040, Batch Training Accuracy= 0.95312\n",
    "Iter 24320, Batch Training Accuracy= 0.90625\n",
    "Iter 25600, Batch Training Accuracy= 0.93750\n",
    "Iter 26880, Batch Training Accuracy= 0.95312\n",
    "Iter 28160, Batch Training Accuracy= 0.90625\n",
    "Iter 29440, Batch Training Accuracy= 0.92188\n",
    "Iter 30720, Batch Training Accuracy= 0.95312\n",
    "Iter 32000, Batch Training Accuracy= 0.96875\n",
    "Iter 33280, Batch Training Accuracy= 0.93750\n",
    "Iter 34560, Batch Training Accuracy= 0.95312\n",
    "Iter 35840, Batch Training Accuracy= 0.98438\n",
    "Iter 37120, Batch Training Accuracy= 0.90625\n",
    "Iter 38400, Batch Training Accuracy= 0.95312\n",
    "Iter 39680, Batch Training Accuracy= 0.92188\n",
    "Iter 40960, Batch Training Accuracy= 0.90625\n",
    "Iter 42240, Batch Training Accuracy= 0.92188\n",
    "Iter 43520, Batch Training Accuracy= 0.95312\n",
    "Iter 44800, Batch Training Accuracy= 0.93750\n",
    "Iter 46080, Batch Training Accuracy= 0.95312\n",
    "Iter 47360, Batch Training Accuracy= 0.96875\n",
    "Iter 48640, Batch Training Accuracy= 0.95312\n",
    "Iter 49920, Batch Training Accuracy= 0.89062\n",
    "Iter 51200, Batch Training Accuracy= 0.95312\n",
    "Iter 52480, Batch Training Accuracy= 0.98438\n",
    "Iter 53760, Batch Training Accuracy= 1.00000\n",
    "Iter 55040, Batch Training Accuracy= 0.95312\n",
    "Iter 56320, Batch Training Accuracy= 0.95312\n",
    "Iter 57600, Batch Training Accuracy= 0.96875\n",
    "Iter 58880, Batch Training Accuracy= 0.96875\n",
    "Iter 60160, Batch Training Accuracy= 1.00000\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##      Reference:\n",
    "1. TensorFlow official documents \n",
    "2. Stanford CS231n 2016 Jan Lectures \n",
    "3. Aymeric Damien TF example\n",
    "4. Bay Area Deep Learning\n",
    "5. Picture of models from various tech blogs\n",
    "6. Deep Learing.TV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
