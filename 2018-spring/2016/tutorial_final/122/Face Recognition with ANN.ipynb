{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Recognition using Artificial Neural Network with PyBrain Library\n",
    "\n",
    "This tutorial will introduce you the basic concepts of Artificial Neural Network and use the Multilayer Feedforward Network to work on face recognition. \n",
    "The goal is to train a Multilayer Feedforward Network on a faces dataset to recognize \"pose\" of the person in the image. The network takes the grayscale of each pixel in the image as inputs, and outputs which direction the person is looking at. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Artificial Neural Network\n",
    "Aritificial Neural Network(ANN) is a computational model inspired from how biological neural network works. It is used to estimate values for functions after learning from training sets. Back Propagation algorithm is often used for network parameter adjustment to best fit the input and output training pairs. ANN can deal with complicated logical and non-linear computations with high robustness. It is widely used in many areas such as machine vision and speech recognition.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Multilayer Feedforward Network\n",
    "Multilayer Feedforward Network is a typical network as ANN, which will be used for face recognition in this tutorial. This network consists of several layers. The i'th layer only accept the output of i-1'th layer as its input. There is no feedback among any neural cells in the network. There are usually the following three kinds of layers in a Multilayer Feedforward Network: \n",
    "- **Input Layer**, where neurons accept large amount of non-linear input vectors.\n",
    "- **Output Layer**, where output vectors are formed. \n",
    "- **Hidden Layer**, which lays between the input and output layer.The more hidden layers there are, the more robustness the network will achieve. \n",
    "\n",
    "<img src=\"Multilayer Feedforward Network Layers.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Faces Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Face Images\n",
    "The dataset contains images of 20 different people with different poses, face expressions, wearing/not wearing sunglasses and different image resolutions. There are 20 folders in the faces directory, each contains several images for one person. The name of the .pgm image files has the following pattern, which provides all the information we need: \n",
    "\n",
    "&lt;userid&gt;\\_&lt;pose&gt;\\_&lt;expression&gt;\\_&lt;eyes&gt;[\\_&lt;scale&gt;].pgm\n",
    "\n",
    "| **Attribute** | **Explanation**             | \n",
    "|----------|-------------|\n",
    "| userid      | The unique id of the person in the image; has 20 values since there are images of 20 persons in this data set |\n",
    "| pose | Head position; 4 values: straight, left, right, up |\n",
    "| expression | Facial expression; 4 values: neutral, happy, sad, angry |\n",
    "| eyes | Wearing sunglasses or not; 2 values: open, sunglasses |\n",
    "| scale | Scale of the image file; If not specified, the file has a resolution of 128x120. A value 2 means the resolution is 64x60, 4 means 32x30. |\n",
    "\n",
    "( In this tutorial, we will focus on the 32x30 .pgm files and the \"pose\" attribute. )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Helper Functions\n",
    "\n",
    "We will have several helper functions to handle with the image files, such as extracting pixels(features) from an image, or generating \"poses\"(targets) attribute from the filename.\n",
    "\n",
    "- First we need to have a function to extract grey scale of each pixel in the image, as the network inputs. OpenCV library will help us deal with this problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def extractGrayScale(filepath):\n",
    "    \"\"\"\n",
    "    Extract gray scale of a given image.\n",
    "    \n",
    "    Args:\n",
    "    filepath(str): path of the image file.\n",
    "    \n",
    "    Return:\n",
    "    (list): list of floats that each float, between 0 and 1, indicates a gray scale of a pixel in the image\n",
    "    \"\"\"\n",
    "    img = cv2.imread(filepath, cv2.IMREAD_GRAYSCALE)\n",
    "    grayscale = [itm for row in img for itm in row]\n",
    "    normalized = [float(x)/255 for x in grayscale]\n",
    "    return normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Second we need to generate input features, that is to generate all the gray scales for a given image file list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def genFeature(files):\n",
    "    \"\"\"\n",
    "    Generating input features from a given image dataframe\n",
    "    \n",
    "    Args:\n",
    "    files(list): list of filenames(str)\n",
    "    \n",
    "    Return:\n",
    "    (list): 2D list, each sub-list length is 30x32=960, storing the normalized gray scales. \n",
    "    \"\"\"\n",
    "    table = []\n",
    "    for f in files:\n",
    "        table.append(extractGrayScale(f))\n",
    "    return table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Third, we will generate targets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def genTarget(files):\n",
    "    \"\"\"\n",
    "    Generating targets from a given image list\n",
    "    \n",
    "    Args:\n",
    "    files(list): list of filenames(str)\n",
    "    \n",
    "    Return:\n",
    "    (list): list of strings indicates the \"pose\"\n",
    "    \"\"\"\n",
    "    target = []\n",
    "    for f in files:\n",
    "        features = f.split('/')[-1].split('_')\n",
    "        target.append(features[1])\n",
    "    \n",
    "    return target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train and test with PyBrain library\n",
    "\n",
    "Since we are recognizing \"pose\" from an 30x32 pixel image, so that the network should have 32x30=960 input units and 4 output unit. The Feedforward Network and Classification Dataset in Pybrain library in PyBrain will help with this problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Introduction to PyBrain\n",
    "\n",
    "PyBrain is a Machine Learning Library for Python. It's short for Python-Based Reinforcement Learning, Artificial Intelligence and Neural Network Library. Just as the name suggests, it contains most of the common algorithms for neural networks, for reinforcement learning (and the combination of the two), for unsupervised learning, and for evolution. It has multiple network modules and also support users to define custom networks. It also has different kinds of datasets, like supervised, sequential, classification and importantce dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Classification Dataset\n",
    "The classification dataset aims to facilitate dealing with classification problems, which will be used in this tutorial. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- First import the dataset module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pybrain.datasets import ClassificationDataSet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Define some variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "files = glob.glob(\"./faces/**/*_4.pgm\")\n",
    "\n",
    "n_pixels = 960\n",
    "n_input = n_pixels\n",
    "n_output = 4\n",
    "n_files = len(files)\n",
    "\n",
    "category = [\"straight\", \"left\", \"right\", \"up\"]\n",
    "\n",
    "proportion = .75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Generate two lists: one for feature and one for target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "featurelist = genFeature(files)\n",
    "targetlist = genTarget(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create a Classification DataSet that has 960 inputs and 4 classes, since there are 4 \"poses\". \n",
    "- Add samples to the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ds = ClassificationDataSet(n_input, nb_classes=n_output)\n",
    "for i in xrange(n_files):\n",
    "    ds.addSample(featurelist[i], [category.index(targetlist[i])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Split the dataset to two parts, the major part as the training set, the minor part as the testint set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainDS, testDS = ds.splitWithProportion(proportion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The following code aims only to fix a bug pyBrain has. Their splitWithProportion() function is not working properly! The returning datasets' type should be consistent with the argument, but it is always returning a SupervisedDataSet, no matter what the argument type is! So the code below tries to convert the returning dataset back to ClassificationDataSet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# refer to - http://stackoverflow.com/questions/27887936/attributeerror-using-pybrain-splitwithportion-object-type-changed\n",
    "trainDS_temp = trainDS\n",
    "trainDS = ClassificationDataSet(n_input, nb_classes=n_output)\n",
    "for n in xrange(0, trainDS_temp.getLength()):\n",
    "    trainDS.addSample( trainDS_temp.getSample(n)[0], trainDS_temp.getSample(n)[1] )\n",
    "\n",
    "testDS_temp = testDS\n",
    "testDS = ClassificationDataSet(n_input, nb_classes=n_output)\n",
    "for n in xrange(0, testDS_temp.getLength()):\n",
    "    testDS.addSample( testDS_temp.getSample(n)[0], testDS_temp.getSample(n)[1] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Converts the target classes to a 1-of-k representation, in our case k is 4, retaining the old targets as a field class. This step is needed for creating the network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainDS._convertToOneOfMany( )\n",
    "testDS._convertToOneOfMany( )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Check the input, target and class fields of the training and testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"training set\", trainDS\n",
    "print \"testing set\", testDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Create a Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Import all the modules needed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pybrain.utilities import percentError\n",
    "from pybrain.tools.shortcuts import buildNetwork\n",
    "from pybrain.structure.modules import SoftmaxLayer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create a network with 960 input units, 4 output units, and a hiden layer with 6 units. \n",
    "\n",
    "There are multiple ways to do it, if we want a standard network, we can do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_hidden = 6\n",
    "net = buildNetwork( n_input, n_hidden, n_output, outclass=SoftmaxLayer )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we can define a custom network with modules and connections:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pybrain.structure import FeedForwardNetwork\n",
    "from pybrain.structure import LinearLayer, SigmoidLayer, SoftmaxLayer\n",
    "from pybrain.structure import FullConnection\n",
    "\n",
    "net = FeedForwardNetwork()\n",
    "\n",
    "inLayer = LinearLayer(n_input)\n",
    "hiddenLayer = SigmoidLayer(n_hidden)\n",
    "outLayer = SoftmaxLayer(n_output)\n",
    "\n",
    "net.addInputModule(inLayer)\n",
    "net.addModule(hiddenLayer)\n",
    "net.addOutputModule(outLayer)\n",
    "\n",
    "in_to_hidden = FullConnection(inLayer, hiddenLayer)\n",
    "hidden_to_out = FullConnection(hiddenLayer, outLayer)\n",
    "\n",
    "net.addConnection(in_to_hidden)\n",
    "net.addConnection(hidden_to_out)\n",
    "\n",
    "net.sortModules()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can check the structure of the network by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FeedForwardNetwork-15\n",
      "   Modules:\n",
      "    [<LinearLayer 'LinearLayer-12'>, <SigmoidLayer 'SigmoidLayer-16'>, <SoftmaxLayer 'SoftmaxLayer-17'>]\n",
      "   Connections:\n",
      "    [<FullConnection 'FullConnection-13': 'LinearLayer-12' -> 'SigmoidLayer-16'>, <FullConnection 'FullConnection-14': 'SigmoidLayer-16' -> 'SoftmaxLayer-17'>]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4. Training and Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pybrain.supervised.trainers import BackpropTrainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create a trainer with the training dataset, with 0.003 momentum, 0.003 learning rate, and 0.01 weight decay. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainer = BackpropTrainer( net, dataset=trainDS, momentum=0.003, learningrate=0.003 , verbose=False, weightdecay=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Train it! and store the training error and the percent error on the test dataset for every epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_epoch = 300\n",
    "errs_train = []\n",
    "errs_test = []\n",
    "for i in xrange(n_epoch):\n",
    "    trainer.train()\n",
    "    err_train = percentError(trainer.testOnClassData(dataset=trainDS), trainDS['class'])\n",
    "    err_test = percentError(trainer.testOnClassData(dataset=testDS), testDS['class'])\n",
    "    \n",
    "    errs_train.append(err_train)\n",
    "    errs_test.append(err_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Print out the training error and the testing error for every 20 epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print \"epoch    training err  testing err\"\n",
    "for i in range(0, n_epoch, 20):\n",
    "    print '{0:4} {1:13.2f}% {2:12.2f}%'.format(i, errs_train[i], errs_test[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It should print the following table:\n",
    "<img src=\"table1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use matplotlib library to visulize the error percentages to get a better understanding. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "matplotlib.use(\"svg\")\n",
    "from matplotlib import pyplot as plt\n",
    "# plt.styles.use('ggplot')\n",
    "matplotlib.rcParams['figure.figsize'] = (10.0, 5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(range(n_epoch), errs_train, label=\"Training Errors\")\n",
    "plt.plot(range(n_epoch), errs_test, label=\"Testing Errors\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Error percentage(%)\")\n",
    "plt.legend()\n",
    "plt.gca().yaxis.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"graph1.png\">\n",
    "As we can see from the above graph, at epoch 0, the error percentages are 75% since there are 4 kinds of \"poses\" so a random network can achieve 25% correctness. \n",
    "\n",
    "Then, both of the traning and testing errors are decreasing rapidly at the very begining. After about 120 epochs, the testing error reaches its limitation, that is roughly 10% error rate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for lr in np.arange(0.001, 0.01, 0.002):\n",
    "    net = buildNetwork( n_input, n_hidden, n_output, outclass=SoftmaxLayer )\n",
    "    trainer = BackpropTrainer( net, dataset=trainDS, momentum=0.003, learningrate=lr , verbose=False, weightdecay=0.01)\n",
    "    \n",
    "    errs_test = []\n",
    "    for i in xrange(n_epoch):\n",
    "        trainer.train()\n",
    "        err_test = percentError(trainer.testOnClassData(dataset=testDS), testDS['class'])\n",
    "        errs_test.append(err_test)\n",
    "        \n",
    "    plt.plot(range(n_epoch), errs_test, label=\"Learning Rate = \" + str(lr))\n",
    "\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Test Error percentage(%)\")\n",
    "plt.legend()\n",
    "plt.gca().yaxis.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"graph2.png\">\n",
    "From the result, we can conclude that when the learning rate increases, the epochs needed to reach the 10% error percentage decreases. However, when the learning rate is 0.009, the situation is not getting better anymore, the converge is getting slower again because 0.009 is a too high learning rate. \n",
    "\n",
    "For this dataset, a learning rate between 0.003 and 0.007 seems to be good. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also try different number of hidden layer neurons, or change the layer type, or any other arguments to compare which module can achieve a better output accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
