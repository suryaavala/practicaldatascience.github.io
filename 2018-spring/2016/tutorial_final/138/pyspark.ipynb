{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial for Apache Spark with Python (PySpark)\n",
    "## Introduction\n",
    "\n",
    "Big data represents a large collection of data that is not possible to be processed with the traditional data processing applications. Big data has three different characteristics: variety, volume, and velocity. In modern analytics, the trend is now moving towards bringing in as many kinds of data and as much data as possible. The ability of analyzing such data becomes one of the basis for the competition in all areas including business and academy. Data practitioners are now analyzing tweets, follower-followee graph on top of the tranditional relational data everyday to extract insights hidden behind these data set. Although precise analysis of big data can bring valuable insights and improve our lives, processing large amounts of information has been a difficult challenge as data today accumulates at an unprecedented rate. In today, Big Data analytic systems such as Apache Hadoop and Apache Spark are widely used for processing large data to extract insights.\n",
    "\n",
    "### Apache Hadoop\n",
    "After the introduction of Google File System and MapReduce programming model by Google, the open source project called 'Apache Hadoop' has quickly emerged as a de-facto standard for big data processing framework. Hadoop consists of distributed file system (HDFS) and processing engine (MapReduce). The main benefit of Hadoop is that users can perform distributed computing over hundreds of nodes by simply implementing map and reduce function while the framework takes care of job scheduling, fault tolerance, or loss prevention. \n",
    "\n",
    "### Apache Spark\n",
    "Apache Spark is the open source big data processing framework that is scalable, fast, and easy-to-use. One of the most important improvement of Spark over Hadoop is that it allows to cache data in-memory for reuse in the future. It introduces an abstraction called Resilient Distributed Data Sets (RDDs). RDDs are imutable objects which are partitioned across the cluster and can be cached in memory for reuse in the distributed setting. RDDs gain fault tolerance by maintaining lineage information that can be used to reconstruct lost partitions. A user can tranform RDDs by combining pre-defined set of operators such as map, group by key, filter, join, and etc. Apache Spark provides its programming API for several languages including Java, Scala, and Python. In this tutorial, we are going to look into Python version (pySpark).\n",
    "\n",
    "## Installation\n",
    "- download spark at http://spark.apache.org/downloads.html\n",
    "- extract the file anywhere you would like to. From now on, I refer this installed path as $SPARK_HOME\n",
    "    \n",
    "  **export SPARK_HOME=\"your path to spark\"**\n",
    "  \n",
    "    \n",
    "- restart jupyter using pyspark shell using the following command and open this notebook again from the jupyter.\n",
    "  \n",
    "  **PYSPARK_DRIVER_PYTHON=\"jupyter\" PYSPARK_DRIVER_PYTHON_OPTS=\"notebook\" $SPARK_HOME/bin/pyspark**\n",
    "  \n",
    "\n",
    "- once the code given below works, we are ready to start to use pyspark. \n",
    "\n",
    "Note that we are testing under the local mode of the pyspark. One of the benefit of Spark is that the framework takes in charge of distributing the work over hundreds nodes of the cluster. In other words, the code that we are writing here can automatically run over multiple nodes of cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/shlee0605/688/tutorial\n"
     ]
    }
   ],
   "source": [
    "# import all necessary library for this tutorial\n",
    "import pyspark\n",
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import string\n",
    "import nltk\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "matplotlib.rcParams['figure.figsize'] = (10.0, 5.0) # you should adjust this to fit your screen\n",
    "\n",
    "# check the current directory path that you extract the tar file.\n",
    "current_directory = os.getcwd()\n",
    "print current_directory\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resilient Distributed Datasets (RDDs)\n",
    "As mentioned above, Spark is developed around the data model called Resilient Distributed Datasets (RDDs). RDDs are immutable key-value pairs of 'fault-tolerent' data set that can be processed in parallel. We can either parallelize the existing collections or we can read the data from external sources such as local file system, HDFS (distributed file system), and HBase (NoSQL key-value store). Moreover, there are two different types of operations that we can perform over RDDs: transformation and actions. Transformations are creating new RDD object from the existing ones while actions return the result to the driver program. The full list of transformations and actions that we can trigger is listed at http://spark.apache.org/docs/latest/programming-guide.html#transformations. Since we now have the understanding of basic concepts of Spark and we also have installed it on our system, it is time to start to learn how to perform data analysis using Spark."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Data Processing with Spark\n",
    "For this section, we will go over the basic spark programs that computes word counts from text data and degree distribution from graph data. From the examples, we will go over how to create RDD from the external data source and how to use \"transformations\" and \"actions\" over RDDs. Spark programming is heavily dependent on using transformations and passing lambda functions for representing logics. This is very similar to the computation over Panda's dataframe. You can refer to the following website for more information on the function passing and closure (about variable scopes): http://spark.apache.org/docs/latest/programming-guide.html#passing-functions-to-spark. Let's first start with the data loading on Spark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25975\n",
      "[u'The Project Gutenberg EBook of The Federalist Papers, by ', u'Alexander Hamilton and John Jay and James Madison', u'', u'This eBook is for the use of anyone anywhere at no cost and with', u'almost no restrictions whatsoever.  You may copy it, give it away or', u're-use it under the terms of the Project Gutenberg License included', u'with this eBook or online at www.gutenberg.net', u'', u'', u'Title: The Federalist Papers']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Data Loading\n",
    "\"\"\"\n",
    "\n",
    "# change path to your file\n",
    "filePath = \"file:///\" + current_directory + \"/data/pg18.txt\"\n",
    "\n",
    "# read the text file from the external storage and create the RDD \n",
    "textFile = sc.textFile(filePath)\n",
    "\n",
    "# count the number of lines by calling count() which is an \"action\"\n",
    "lineCount = textFile.count()\n",
    "\n",
    "# print out the first 10 lines of text file and the total line count\n",
    "print lineCount\n",
    "print textFile.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Count Example\n",
    "The algorithm of word count in map-reduce fashion is present below.\n",
    "1. split line with the space\n",
    "2. for each word in the line, emit `(word, 1)`\n",
    "3. group the data based on the key and add the count values in the reduce function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'', 7254), (u'delusions.', 1), (u'four', 44), (u'ocean,', 1), (u'proposes,', 1), (u'impera1', 1), (u'towns', 4), (u'vassals', 2), (u'looking', 4), (u'LAST', 1), (u'pardon', 5), (u'granting', 7), (u'pre-eminence', 6), (u'ENDEAVORS', 1), (u'quadruple', 1), (u'\"NO', 1), (u'innocence,', 1), (u'dissolution', 14), (u'navigating', 1), (u'co-operation', 11)]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Word Count Example\n",
    "\"\"\"\n",
    "# compute word count using \"transformations\"\n",
    "counts = textFile.flatMap(lambda x: x.split(\" \")) \\\n",
    "              .map(lambda x: (x, 1)) \\\n",
    "              .reduceByKey(lambda x, y: x + y)\n",
    "\n",
    "# print out 20 samples by calling take which is an \"action\"\n",
    "print counts.take(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spark Internal\n",
    "Since we now have seen an example of spark program, let's look into Spark internals more in detail to understand how Spark execute this user code on the cluster. Before we dive into the internal of Spark, I list the terms that we should know.\n",
    "\n",
    "- Driver: A JVM process that is responsible for orchestrating the execution of the job.\n",
    "- Executor: A JVM process that is responsible for executing tasks.\n",
    "- Job: A job is the entire user code portion that reads input from the source, run computation over the data, and write output data to the sink.\n",
    "- Stages: A job is divided into multiple stages. Each stage represents the each computation boundaries (e.g. map, shuffle...etc)\n",
    "- Tasks: Each stage is further divided into tasks. Each task is usually matched with a partition of data and the task is executed one executor.\n",
    "- DAG: A user program (transformation / actions over RDDs) is represented as the directed acyclic graph.\n",
    "\n",
    "The overall life cycle of the spark program is represented below. \n",
    "\n",
    "1. A user submit the job using either Spark interactive shell or `spark-job` script.\n",
    "2. A driver program translates the transforms in the user program into a DAG graph.\n",
    "3. The graph is submitted to DAG Scheduler, which splits the graph into stages.\n",
    "4. DAG scheduler submits each stage to task scheduler once it is ready to execute.\n",
    "5. Task Scheduler then assigns tasks to executor via cluster manager and it also keeps track of the status of the tasks. If the executor fails to execute the task, the schduler would assign the task to another executor in order to acheive fault tolerance.\n",
    "6. Executors execute tasks and write output to the distributed file system or send the result to driver based on user's action.\n",
    "\n",
    "\n",
    "\n",
    "![spark2](img/3.png)\n",
    "\n",
    "The image is taken from the slide by Databricks, which is the company that develops Apache Spark. (http://files.meetup.com/3138542/dev-meetup-dec-2012.pptx)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Examples\n",
    "### Tweet Sentiment Analysis\n",
    "In this section, we will implement the tweets sentiment analysis that categorize the tweets into positive and negative tweets. For the score of each positive/negative word, I got the list from http://www2.imm.dtu.dk/pubdb/views/publication_details.php?id=6010. This spark program processes the raw tweets data, and compute the sentiment score for each tweet based on the score from the above source.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive Tweets\n",
      "17 - We're thrilled to unveil the stunning restoration of this iconic landmark. Thank you to our brilliant team @TrumpDC! https://t.co/loToqDulGj\n",
      "16 - \"Ireland! You were outstanding. Blessed to play along side such amazing acts for such a warm crowd. I hope you had as much fun as we did. \n",
      "15 - Thank you to Perform Better for the opportunity to present and share with all of these fantastic fit pros! Great... https://t.co/cjLelhpugI\n",
      "15 - RT @realDonaldTrump: It is wonderful to be in beautiful Doonbeg touring @Trump_Ireland. I'm truly honored by the wonderful welcome to my fa…\n",
      "15 - Another awesome week in Canada. Thanks to @RBCCanadianOpen for a wonderful event &amp; the fans who always make me feel like one of their own!\n",
      "\n",
      "Negative Tweets\n",
      "-10 :  killed Sunday (9-11) in Fresno and my wife's heartbroken plea to end gun violence. http…\"\n",
      "-9 : WATCH NOW: @realDonaldTrump spoke to victims of illegal immigrant crime at the Remembrance Project in Houston. https://t.co/IgsE0kZvFn\n",
      "-8 : RT @MJM2335: @mcuban @MichaelCohen212 @HillaryClinton @realDonaldTrump that was the worst burn ever Marco. Bow down to president trump bitch\n",
      "-8 : Watching all of @Beyonce videos WTF MIND IS BLOWN. Queen fucking B.\n",
      "-7 : NFL HELL: EAGLES Plan Demonstration For 'Social Injustice'... https://t.co/QzxkIDEZ7h\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Tweet Sentiment Analysis\n",
    "\"\"\"\n",
    "\n",
    "def text_process(text, lemmatizer=nltk.stem.wordnet.WordNetLemmatizer()):\n",
    "    \"\"\" Normalizes case and handles punctuation\n",
    "    Inputs:\n",
    "        text: str: raw text\n",
    "        lemmatizer: an instance of a class implementing the lemmatize() method\n",
    "                    (the default argument is of type nltk.stem.wordnet.WordNetLemmatizer)\n",
    "    Outputs:\n",
    "        list(str): tokenized text\n",
    "    \"\"\"\n",
    "    text = text.encode('ascii','ignore')\n",
    "    text = text.lower()\n",
    "    text = text.replace(\"'s\", \"\")\n",
    "    text = text.replace(\"'\", \"\")\n",
    "    test_trans = \" \" * len(string.punctuation)\n",
    "    text = text.translate(string.maketrans(string.punctuation,test_trans))  \n",
    "    \n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    result = []\n",
    "    for i in range(0, len(tokens)):\n",
    "        try:\n",
    "            result.append(lemmatizer.lemmatize(tokens[i]))\n",
    "        except:\n",
    "            continue\n",
    "    return result\n",
    "\n",
    "def parse_senti_score(path):\n",
    "    # read sentiment score\n",
    "    senti_file = open(sentiScorePath, \"rb\")\n",
    "    senti_lookup = {}\n",
    "    for line in senti_file:\n",
    "        cols = line.split(\"\\t\")\n",
    "        senti_lookup[cols[0]] = int(cols[1])\n",
    "    return senti_lookup\n",
    "\n",
    "def split(s):\n",
    "    cols = s.split(\",\")\n",
    "    return cols[-1]\n",
    "\n",
    "def compute_senti(s, senti_lookup):\n",
    "    lookup_table = senti_lookup.value\n",
    "    \n",
    "    words = text_process(s)\n",
    "    score = 0\n",
    "    for word in words:\n",
    "        if word in lookup_table:\n",
    "            score += lookup_table[word]\n",
    "    return (score, s)\n",
    "\n",
    "# read raw edges file to form RDD\n",
    "senti_score_path = current_directory + \"/data/AFINN-111.txt\"\n",
    "tweet_file_path = \"file:///\" + current_directory + \"/data/tweets.csv\"\n",
    "\n",
    "# using a broadcast variable for distributed lookup table\n",
    "senti_score = parse_senti_score(senti_score_path)\n",
    "senti_lookup = sc.broadcast(senti_score)\n",
    "\n",
    "# read the data\n",
    "data = sc.textFile(tweet_file_path)\n",
    "header = data.first()\n",
    "tweets = data.filter(lambda x: x != header) \\\n",
    "             .map(split)\n",
    "\n",
    "# compute sentiment\n",
    "senti_tweets = tweets.map(lambda x: compute_senti(x, senti_lookup))\n",
    "\n",
    "# filter tweets with positive score, negative score and sort them in order\n",
    "positive_tweets = senti_tweets.filter(lambda x: x[0] > 0).sortByKey(False)\n",
    "negative_tweets = senti_tweets.filter(lambda x: x[0] < 0).sortByKey(True)\n",
    "\n",
    "# print out top 5 positive/negative tweets\n",
    "print \"Positive Tweets\"\n",
    "for tweet in positive_tweets.take(5):\n",
    "    print tweet[0], \"-\", tweet[1]\n",
    "\n",
    "print\n",
    "print \"Negative Tweets\"\n",
    "for tweet in negative_tweets.take(5):\n",
    "    print tweet[0], \":\", tweet[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Degree Distribution\n",
    "For the next example, we use graph data processing using Spark. We are loading the data from HW2 (edges.csv), compute degree distribution and present the graph in order to validate the correctness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "screen_name,friend\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([   2.,    6.,    2.,    5.,    4.,    4.,    3.,    1.,    4.,  148.]),\n",
       " array([   2. ,   11.8,   21.6,   31.4,   41.2,   51. ,   60.8,   70.6,\n",
       "          80.4,   90.2,  100. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnAAAAFZCAYAAAAYWBLAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUkHANY4PIwoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10e092110>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Degree Distribution Computation\n",
    "\"\"\"\n",
    "\n",
    "# read raw edges file to form RDD\n",
    "edgeFilePath = \"file:///\" + current_directory + \"/data/edges.csv\"\n",
    "data = sc.textFile(edgeFilePath)\n",
    "header = data.first()\n",
    "edges = data.filter(lambda x: x != header) \\\n",
    "            .mapPartitions(lambda x: csv.reader(x))\n",
    "\n",
    "# compute degree distribution using transformations\n",
    "degree = edges.groupByKey() \\\n",
    "              .map(lambda x: len(x[1]))\n",
    "\n",
    "# retrieve the distribution data.\n",
    "final_data = degree.collect()\n",
    "\n",
    "# compute group by\n",
    "plt.title(\"Degree Distribution for Tweets Edge Data\")\n",
    "plt.xlabel(\"Degree\", size=12)\n",
    "plt.ylabel(\"Frequency\", size=12)\n",
    "plt.hist(final_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Complex Iterative Graph Processing (Connected Components)\n",
    "Since we now know how to use basic Spark's programming APIs including transformations and actions, it is time to move to the complex example. For this section, I implment the connected components algorithm that is iterative in nature. I implement 'Hash-to-Min' algorithm introduced in https://arxiv.org/pdf/1203.5387.pdf. This algorithm uses the propagating mechanism to compute the connected components. The detailed explanation of the algorithm can be found in page 3 of the paper. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Connected Components\n",
    "\"\"\"\n",
    "\n",
    "# split function that is used to pre-process the input data\n",
    "def split(s):\n",
    "    nodes = s.split(\"\\t\")\n",
    "    return ((int(nodes[0]), int(nodes[1])), (int(nodes[1]), int(nodes[0])))\n",
    "\n",
    "# initialize the C_v\n",
    "def initialize_Cv(n):\n",
    "    return (n[0], set(n[1]) | set([n[0]]))\n",
    "\n",
    "# computing hash function based on the hash algorithm in the paper\n",
    "def compute_hash(s):\n",
    "    vertex = s[0]\n",
    "    neighbors = s[1]\n",
    "    neighbor_min = min(neighbors)\n",
    "    result = []\n",
    "    for n in neighbors:\n",
    "        if n != neighbor_min:\n",
    "            result.append((n, set([neighbor_min])))\n",
    "    result.append((neighbor_min, neighbors))\n",
    "    for n in neighbors:\n",
    "        if neighbor_min != n:\n",
    "            result.append((n, set([neighbor_min])))\n",
    "    return result\n",
    "\n",
    "# filtering case\n",
    "def export(v):\n",
    "    vertex = v[0]\n",
    "    neighbor_min = min(v[1])\n",
    "    if neighbor_min == vertex:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def compute_connected_components(file_path, num_iter, print_list):\n",
    "    # read raw edges file to form RDD\n",
    "    data = sc.textFile(file_path)\n",
    "    \n",
    "    # create adjacency list (node -> list of neighbors)\n",
    "    graph = data.flatMap(split) \\\n",
    "                .distinct() \\\n",
    "                .groupByKey()\n",
    "\n",
    "    # initialize connected component result (C_v in the paper)\n",
    "    connected_result = graph.map(initialize_Cv)\n",
    "    \n",
    "    # start the iteration\n",
    "    for i in range(num_iter):\n",
    "        # map phase of the algorithm\n",
    "        intermediate = connected_result.flatMap(lambda s: compute_hash(s))\n",
    "\n",
    "        # reduce phase\n",
    "        connected_result = intermediate.reduceByKey(lambda a,b: a | b)\n",
    "\n",
    "    # filtering out unnecessary output\n",
    "    filtered_output = connected_result.filter(lambda v: export(v))\n",
    "\n",
    "    final_collected_result = filtered_output.collect()\n",
    "    if print_list:\n",
    "        for x in final_collected_result:\n",
    "            print list(x[1])\n",
    "    else:\n",
    "        print len(final_collected_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simple example verification\n",
      "[0, 1, 2, 3]\n",
      "[4, 5, 6]\n",
      "[8, 7]\n"
     ]
    }
   ],
   "source": [
    "# verify with the small data set :\n",
    "# (0,1), (1,2), (2,3), (4,5), (5,6), (7,8)\n",
    "# this example should yield three groups: [0,1,2,3], [4,5,6], [7,8]\n",
    "simple = \"file:///\" + current_directory + \"/data/simple-graph.txt\"\n",
    "tweet_edge = \"file:///\" + current_directory + \"/data/tweet-edges.txt\"\n",
    "\n",
    "print \"simple example verification\"\n",
    "compute_connected_components(simple, 10, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we now have the spark implementation to compute connected components, let's run this algorithm over the existing data. For this task, I will use the edges.csv data from HW2 which is the follower-followee graph data. In order to use the data into our implementation, we first need to convert the data format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "screen_name,friend\n",
      "\n",
      "realDonaldTrump,Trump\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_edges_file = open(current_directory + \"/data/edges.csv\", \"rb\")\n",
    "\n",
    "# print first two lines\n",
    "print raw_edges_file.readline()\n",
    "print raw_edges_file.readline()\n",
    "\n",
    "# close file\n",
    "raw_edges_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our implementation assumes that the edges are represented as (follower(int), followee(int)). So, from the above example, we need convert (realDonaldTrump,Trump) -> (0,1). Let's convert this data into the correct format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connected components of tweet edges data: \n",
      "6\n"
     ]
    }
   ],
   "source": [
    "# open the files\n",
    "raw_edges_file = open(current_directory + \"/data/edges.csv\", \"rb\")\n",
    "processed_edges_file = open(current_directory + \"/data/processed_edges.txt\", \"wb\")\n",
    "\n",
    "# ignore the first line\n",
    "raw_edges_file.readline()\n",
    "\n",
    "mapping_table = {}\n",
    "count = 0\n",
    "for line in raw_edges_file:\n",
    "    splits = line.split(',')\n",
    "    if splits[0] not in mapping_table.keys():\n",
    "        mapping_table[splits[0]] = count\n",
    "        count += 1\n",
    "    if splits[1] not in mapping_table.keys():\n",
    "        mapping_table[splits[1]] = count\n",
    "        count +=1\n",
    "    converted_line = str(mapping_table[splits[0]]) + \"\\t\" + str(mapping_table[splits[1]]) + \"\\n\"\n",
    "    processed_edges_file.write(converted_line)\n",
    "    \n",
    "raw_edges_file.close()\n",
    "processed_edges_file.close()\n",
    "\n",
    "# this example uses the tweet edge data given from hw2 - string names(nodes) are converted to number.\n",
    "# expected output: 6\n",
    "processed_edge_data_path = \"file:///\" + current_directory + \"/data/processed_edges.txt\"\n",
    "print \"connected components of tweet edges data: \"\n",
    "compute_connected_components(processed_edge_data_path, 10, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Useful References\n",
    "This tutorial covers how to use Spark programming API to write the data processing logic. Although I used the small data sets for examples, the beauty of Apache Spark is that all the code we wrote in this tutorial can be run on over tens or hundreds of machines to process extremely large data set. \n",
    "\n",
    "For deploying Spark cluster, one can choose to use his/her own servers by manually installing spark on their machines. Easier way is to use AWS EMR service, which allows a user to deploy Spark cluster with several clicks. The detailed information can be found at https://aws.amazon.com/emr/details/spark/.\n",
    "\n",
    "- Spark Programming Guide: http://spark.apache.org/docs/latest/programming-guide.html\n",
    "- Spark Paper (\"Resilient Distributed Datasets\"): http://www-bcf.usc.edu/~minlanyu/teach/csci599-fall12/papers/nsdi_spark.pdf\n",
    "- Finding Connected Components in Map-Reduce in Logarithmic Rounds: https://arxiv.org/pdf/1203.5387.pdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
