{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Markov Chain Text Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to create a program that can write poem that reads like Shakespeare? This is actually an interview question from Khan Academy for summer internship... You may consider using Machine Learning, Deep Leaning and all those fancy algorithms and techniques, as it seems a highly creative and unpredictable process, and you may assume that the program has to be trained very well in order to sound like Shakespeare."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, what if I tell you that the program can be extremely simple and you can implement it within 30 minutes, and all the resources you need to teach the program to learn Shakespeare's style are just a couple of his works? This tutorial will teach you to implement a text generator that can create new gibberish that reads like normal. Besides, depending on the resources you choose to \"train\" the algorithm, the text generator can mimic the style of certain writer (e.g. Shakespeare)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This program is based on the idea of Markov Chain,\n",
    "which is a probabalistic model about the transition between different states. Below is a diagram of a Markov Chain: ![title](markovdiag.png) Given you current state, Markov Chain will randomly choose the next state from the connected states specified by the graph. Moreover, different states have different possibilities of being chosen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take the above diagram as an example, if the current the state is sunny, then the next state might turn rainy with 10% probablity, might stay sunny with 50% probablity, and might turn cloudy with 40% probablity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In general, Markov Chain will randomly choose the next state based on the current state.\n",
    "Thus Markov Chain can create new stuff based on the recent history. In our case, we can consider each state being the last several words we have generated, and the states we can transition to in the next step are the potential next word we will generate. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we use the program to generate any text, we need to feed some texts to program so that it can construt all the possible states and the corresponding probablistic transitions between them. In other words, the program needs to, at first, build up the markov chain by doing some statistics over some legitimate texts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "First of all, as each state of our Markov Chain consists of words, we need a function that takes in a file, reads the file, and then split the file into words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_and_split(file_name):\n",
    "    \n",
    "    # open the file\n",
    "    stream = open(file_name)\n",
    "    startposition = 0\n",
    "    stream.seek(startposition)\n",
    "    \n",
    "    # process the file into string\n",
    "    processed_file = stream.read()\n",
    "    \n",
    "    # split the string into list of words\n",
    "    words = processed_file.split()\n",
    "    \n",
    "    return words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to build up a python dictionary that maps a tuple of last several words seen to a list of words that can potentially be the next word. We will write a function that takes in a list of words (parameter source), and also a size for how many words we should look back to determine the next word (parameter tuple_size). By the way, \"tuple_size\" should be consistent with the function we will write later that serves to generate the new texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_dictionary(source, tuple_size):\n",
    "    \n",
    "    # initialize an empty dictionary\n",
    "    dictionary = {}\n",
    "    \n",
    "    # get the length of the input \"source\"\n",
    "    n = len(source)\n",
    "    \n",
    "    # iterate from the the (tuple_size)th element in the list\n",
    "    # so that we have enough \"history\" to look at\n",
    "    for i in range(0, n):\n",
    "        \n",
    "        # determine the endpoints of the segment we use to build the key\n",
    "        startIndex = i - tuple_size\n",
    "        endIndex = i\n",
    "        \n",
    "        # fetch the segment\n",
    "        if startIndex < 0:\n",
    "            offset_front_index = (startIndex + n)\n",
    "            first_part = source[offset_front_index : n]\n",
    "            second_part = source[0 : endIndex]\n",
    "            segment = first_part + second_part\n",
    "        else:\n",
    "            segment = source[startIndex : endIndex]\n",
    "        \n",
    "        # turn the segment list into a tuple so that it can act as a key\n",
    "        key = tuple(segment)\n",
    "        \n",
    "        # check whether the key already existent in the dictionary\n",
    "        key_exists = key in dictionary\n",
    "        \n",
    "        if key_exists:\n",
    "            current_word = source[i]\n",
    "            # append the current_word at the end of the old list\n",
    "            current_list = dictionary[key]\n",
    "            current_list.append(current_word)\n",
    "        else:\n",
    "            current_word = source[i]\n",
    "            # create the new list with the current_word\n",
    "            dictionary[key] = [current_word]\n",
    "            \n",
    "    return dictionary       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's test the functions above a little bit, \n",
    "and have a general idea about the direction we are proceeding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['How', 'to', 'create', 'a', 'program', 'that', 'can', 'write', 'poem', 'that', 'reads', 'like', 'Shakespeare?', 'This', 'is', 'actually', 'an', 'interview', 'question', 'from', 'Khan', 'Academy', 'for', 'summer', 'internship...', 'You', 'may', 'consider', 'using', 'Machine', 'Learning,', 'Deep', 'Leaning', 'and', 'all', 'those', 'fancy', 'algorithms', 'and', 'techniques,', 'as', 'it', 'seems', 'a', 'highly', 'creative', 'and', 'unpredictable', 'process,', 'and', 'you', 'may', 'assume', 'that', 'the', 'program', 'has', 'to', 'be', 'trained', 'very', 'well', 'in', 'order', 'to', 'sound', 'like', 'Shakespeare.']\n"
     ]
    }
   ],
   "source": [
    "preprocessed = read_and_split(\"test_prep.txt\")\n",
    "print preprocessed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does our markov chain look like? Test build_dictionary function! Recall that this function takes in two arguments, one is the file (in the format of array of words), the other is the number of words for each state. We will test our function on the same file but with two different tuple_size parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('creative',): ['and'], ('the',): ['program'], ('internship...',): ['You'], ('you',): ['may'], ('in',): ['order'], ('This',): ['is'], ('from',): ['Khan'], ('may',): ['consider', 'assume'], ('like',): ['Shakespeare?', 'Shakespeare.'], ('sound',): ['like'], ('for',): ['summer'], ('to',): ['create', 'be', 'sound'], ('has',): ['to'], ('it',): ['seems'], ('program',): ['that', 'has'], ('using',): ['Machine'], ('algorithms',): ['and'], ('an',): ['interview'], ('You',): ['may'], ('summer',): ['internship...'], ('assume',): ['that'], ('very',): ['well'], ('Academy',): ['for'], ('Learning,',): ['Deep'], ('consider',): ['using'], ('Machine',): ['Learning,'], ('well',): ['in'], ('reads',): ['like'], ('interview',): ['question'], ('Deep',): ['Leaning'], ('actually',): ['an'], ('highly',): ['creative'], ('a',): ['program', 'highly'], ('trained',): ['very'], ('poem',): ['that'], ('Leaning',): ['and'], ('order',): ['to'], ('seems',): ['a'], ('process,',): ['and'], ('is',): ['actually'], ('write',): ['poem'], ('unpredictable',): ['process,'], ('as',): ['it'], ('techniques,',): ['as'], ('fancy',): ['algorithms'], ('can',): ['write'], ('and',): ['all', 'techniques,', 'unpredictable', 'you'], ('be',): ['trained'], ('all',): ['those'], ('those',): ['fancy'], ('Shakespeare?',): ['This'], ('Khan',): ['Academy'], ('create',): ['a'], ('How',): ['to'], ('question',): ['from'], ('that',): ['can', 'reads', 'the'], ('Shakespeare.',): ['How']}\n"
     ]
    }
   ],
   "source": [
    "temp_result = build_dictionary(preprocessed, 1)\n",
    "print temp_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('and', 'techniques,'): ['as'], ('Khan', 'Academy'): ['for'], ('unpredictable', 'process,'): ['and'], ('a', 'highly'): ['creative'], ('those', 'fancy'): ['algorithms'], ('to', 'create'): ['a'], ('program', 'that'): ['can'], ('for', 'summer'): ['internship...'], ('as', 'it'): ['seems'], ('like', 'Shakespeare.'): ['How'], ('algorithms', 'and'): ['techniques,'], ('you', 'may'): ['assume'], ('order', 'to'): ['sound'], ('may', 'assume'): ['that'], ('sound', 'like'): ['Shakespeare.'], ('highly', 'creative'): ['and'], ('write', 'poem'): ['that'], ('summer', 'internship...'): ['You'], ('be', 'trained'): ['very'], ('to', 'sound'): ['like'], ('Machine', 'Learning,'): ['Deep'], ('You', 'may'): ['consider'], ('may', 'consider'): ['using'], ('Shakespeare?', 'This'): ['is'], ('very', 'well'): ['in'], ('to', 'be'): ['trained'], ('How', 'to'): ['create'], ('is', 'actually'): ['an'], ('Leaning', 'and'): ['all'], ('trained', 'very'): ['well'], ('interview', 'question'): ['from'], ('well', 'in'): ['order'], ('Learning,', 'Deep'): ['Leaning'], ('like', 'Shakespeare?'): ['This'], ('using', 'Machine'): ['Learning,'], ('an', 'interview'): ['question'], ('and', 'you'): ['may'], ('that', 'the'): ['program'], ('creative', 'and'): ['unpredictable'], ('reads', 'like'): ['Shakespeare?'], ('from', 'Khan'): ['Academy'], ('it', 'seems'): ['a'], ('seems', 'a'): ['highly'], ('and', 'unpredictable'): ['process,'], ('has', 'to'): ['be'], ('that', 'reads'): ['like'], ('can', 'write'): ['poem'], ('poem', 'that'): ['reads'], ('fancy', 'algorithms'): ['and'], ('Academy', 'for'): ['summer'], ('actually', 'an'): ['interview'], ('program', 'has'): ['to'], ('process,', 'and'): ['you'], ('that', 'can'): ['write'], ('techniques,', 'as'): ['it'], ('Shakespeare.', 'How'): ['to'], ('a', 'program'): ['that'], ('all', 'those'): ['fancy'], ('This', 'is'): ['actually'], ('internship...', 'You'): ['may'], ('question', 'from'): ['Khan'], ('Deep', 'Leaning'): ['and'], ('assume', 'that'): ['the'], ('consider', 'using'): ['Machine'], ('create', 'a'): ['program'], ('in', 'order'): ['to'], ('the', 'program'): ['has'], ('and', 'all'): ['those']}\n"
     ]
    }
   ],
   "source": [
    "temp_result = build_dictionary(preprocessed, 2)\n",
    "print temp_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do you notice the difference between 'build_dictionary(preprocessed, 1)' and 'build_dictionary(preprocessed, 2)'? \n",
    "Most entries have exactly one choice of word, because the file we are experimenting on is basically the first paragraph of this tutorial, so the resource and variation are very limited. However, we can still find some entires in 'build_dictionary(preprocessed, 1)' that has several choices (for instance, ('and',): ['all', 'techniques,', 'unpredictable', 'you'], and ('to',): ['create', 'be', 'sound'],) whereas there isn't any entry with multiple choices of words in 'build_dictionary(preprocessed, 2)'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason is that the more words each state consists of, the more detailed each state will be, and so the behavior of each state will be more predictable. Since we want a random speech generator, does it mean that we should make the 'tuple_size' parameter as large as possible? We will discuss this tradeoff later after we compelte a functional markov chain text generator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement the text generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have done all the preparation work, so we should move on to the \"magical\" function that actually creates new texts, based on the texts resources preprocessed by the two functions above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Remember that we rely on a markov chain, so when we choose the next word, it only depends on the last several words we generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_text(lib, tuple_size, length):\n",
    "    \n",
    "    # initialize an empty string\n",
    "    result = \"\"\n",
    "    \n",
    "    # initialize a random number generator based on time\n",
    "    random.seed()\n",
    "    \n",
    "    # first, choose the starting state\n",
    "    lib_length = len(lib)\n",
    "    keys = lib.keys()\n",
    "    # generate a random number within range\n",
    "    last_index = lib_length - 1\n",
    "    init = random.randint(0, last_index)\n",
    "    # obtain a random 'key', that is, our initial state\n",
    "    init = keys[init]\n",
    "    init = list(init)\n",
    "    # add every string in the list to our result, seperated by space\n",
    "    for word in init:\n",
    "        result = result + \" \"\n",
    "        result = result + word\n",
    "    \n",
    "    # a counter keeps track of the length of already generated text\n",
    "    count = tuple_size\n",
    "    \n",
    "    # maintain a queue keeping track of the last tuple_size many words we generated\n",
    "    # this queue represents the state in our markov chain\n",
    "    state = init\n",
    "    \n",
    "    # start generating the text\n",
    "    while count < length:\n",
    "        \n",
    "        # fetch the choices of the next word based on the current state\n",
    "        state_tuple = tuple(state)\n",
    "        choices = lib[state_tuple]\n",
    "        \n",
    "        # randomly select the next word from the choices\n",
    "        choices_length = len(choices)\n",
    "        last_index = choices_length - 1\n",
    "        choice = random.randint(0, last_index)\n",
    "        next_word = choices[choice]\n",
    "        \n",
    "        # add the word into our result\n",
    "        result = result + \" \" \n",
    "        result = result + next_word\n",
    "        \n",
    "        # maintain our state\n",
    "        state.pop(0)\n",
    "        state.append(next_word)\n",
    "        \n",
    "        # increment the counter\n",
    "        count = count + 1\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrap up everything\n",
    "Before we test our final product, it's a good practice and style to modularize our text generator into a class. Each instance of such class should be initialized with a file, and can generate different new texts by user's choice of length and tuple_size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MarkovChainTextGenerator:\n",
    "    \n",
    "    # constructor\n",
    "    def __init__ (self, file_name):\n",
    "        \n",
    "        # save the file in the good format\n",
    "        processed_file = read_and_split(file_name)\n",
    "        self.source = processed_file\n",
    "        \n",
    "    def generate (self, tuple_size, output_length):\n",
    "        \n",
    "        # build up our markov chain\n",
    "        library = build_dictionary(self.source, tuple_size)\n",
    "        \n",
    "        # generate the speech\n",
    "        result = generate_text(library, tuple_size, output_length)\n",
    "        \n",
    "        return result\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fantastic! Now, we should test our generator on something REAL!!! We will use real Shakespeare's sonnets to train our library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test it out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "generator_from_sonnets = MarkovChainTextGenerator(\"sonnets.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " bred Where all you alone kingdoms of year set, And sweets and poets can lend, And my heart's right gracious, And play the weary car, Like to this huge rondure hems. O' let your countenance fill'd his rank thoughts canst not, if never shaken; It suffers not every where! And take a gilded monuments Of my mind, thy mind; Those hours, that deep vermilion in youth convertest. Herein lives in my love's might. O, that I feel thou turn back the subject lends not press My life repair, Which husbandry in selling hours in my heart doth shadow doth come\n"
     ]
    }
   ],
   "source": [
    "temp_result = generator_from_sonnets.generate(1, 100)\n",
    "print temp_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " she lies, That she hath thee, is of my wailing chief, A loss in love loves not to tell me so; As testy sick men, when their deaths be near, No news but health from their physicians know; For if you read this line, remember not The hand that writ it; for I love you dearer: Yet then my eye doth feast And to the most of praise add something more; But that thou mayst in me is wanting, And so of you, As he takes thee hence. O, that you alone are you? In whose confine immured is the\n"
     ]
    }
   ],
   "source": [
    "temp_result = generator_from_sonnets.generate(2, 100)\n",
    "print temp_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we compare the two generated texts above, the one with tuple_size 1 is clearly more random, but it reads more like gibberish. The one with tuple_size 2 reads more legit, but it has many segments that are exactly the same as Shakespeare's original works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, a good text generator based on Markov Chain should achieve a optimal balance between randomness and legitimacy, so the tuple_size parameter can't be too high or too low."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's test it on something more interesting. Maybe our generator can write a play? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "generator_from_hamlet = MarkovChainTextGenerator(\"hamlet.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " sleep: Thus bad but mutes or fortune's star, Their residence, both friend and helpful to this more violent property and bloody deed is eaten. A sister be free, Confound the minutes of actions fair thought thy face doth hourly grow great, the most grave, Who shall stand a state, The inward breaks, and the question: Whether in together; And call the Dane. Fran. I forbid my lord? Ham. How strangely? Clown. A little of fierce events, As may the matter if the stars with you- why the hobby-horse, whose huge spokes ten thousand souls and dole, Taken to double grace;\n"
     ]
    }
   ],
   "source": [
    "temp_result = generator_from_hamlet.generate(1, 100)\n",
    "print temp_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " me most To my sick soul (as sin's true nature is) Each toy seems Prologue to some great amiss. So full of threats to all- To you alone. Mar. Look with what courteous action It waves you to ravel all this matter out, That I essentially am not in their birth,- wherein they are actions that a man faithful and honourable. Pol. I did proceed? Hor. I think I saw him yesterday, or t'other day, Or then, or then, with such or such; and, as you please; But if you mouth it, as many of our neglected tribute. Haply the\n"
     ]
    }
   ],
   "source": [
    "temp_result = generator_from_hamlet.generate(2, 100)\n",
    "print temp_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe a mixture of Shakespeare's different works? (sonnets + Macbeth + King Lear + Hamlet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's implement a helper function that combines different file sources into one single file so that our generator can be initialized with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def combine_files(file_list, output_file_name):\n",
    "    with open(output_file_name, 'w') as outfile:\n",
    "        length = len(file_list)\n",
    "        for i in range(0,length):\n",
    "            file_name = file_list[i]\n",
    "            with open(file_name) as infile:\n",
    "                for line in infile:\n",
    "                    outfile.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "files = [\"sonnets.txt\", \"hamlet.txt\", \"macbeth.txt\", \"KingLear.txt\"]\n",
    "output_file_name = \"Mixed.txt\"\n",
    "combine_files(files, output_file_name)\n",
    "generator_from_mixed = MarkovChainTextGenerator(output_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " indeed, it feed and on the scenes, set forth? OSWALD OSWALD Why, then, finding By his speech, but he loved mansionry, that fair name. So much of art; They were sent To offer you at my man's scope, Each toy in the noble having weigh'd it, And braggart with swift As 'Well, well, my friends, deserved at the riotous appetite. Down from thee, And that more worthier way of view in by your beauty shall be the sisters saluted me, true event, and sue a fast, Thence comes here? Follow me like a vice must not too rough night. EDMUND\n"
     ]
    }
   ],
   "source": [
    "temp_result = generator_from_mixed.generate(1,100)\n",
    "print temp_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " But that thou teachest how to make one twain, By praising him here by me, Do thou for him if I be so able as now. Lord. The Queen his mother shall uncharge the practice And call it winter, which being full of changes his age is; the observation we have shuffled off this mortal coil, Must give us bearing To tell us what Lord Hamlet said. We heard it all.- My lord, as will fill up The cistern of my mystery; you would drive me into him, I say. Servants bind him REGAN Hard, hard. O filthy traitor! GLOUCESTER\n"
     ]
    }
   ],
   "source": [
    "temp_result = generator_from_mixed.generate(2,100)\n",
    "print temp_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " may be, very like. Pol. Hath there been such a time- I would fain know that- That I have frequent been with unknown minds And given to time your own dear-purchased right That I have hoisted sail to all the world besides methinks are dead. Since I left you, mine eye is famish'd for a look, Or heart in love with sighs himself doth smother, With my love's picture then my eye doth feast And to the last bended their light on me. Pol. Come, go with me. Exeunt SCENE III. The British camp near Dover. Enter GLOUCESTER, and EDGAR\n"
     ]
    }
   ],
   "source": [
    "temp_result = generator_from_mixed.generate(3,100)\n",
    "print temp_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we use more resources to train the markov chain, we can use bigger number for the tuple_size parameter, so as to achieve more legitimate codes with acceptable degree of randomness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further Thoughts\n",
    "1. Once the generator starts working, the tuple_size is fixed, what if we change it randomly throughout the process to better the randomness?\n",
    "2. When we train our Markov Chain, we didn't take care of the unwanted effects of punctuation. That is, \"me\" and \"me.\" and \"me,\" will be treated as three different things. We should be able to optimize it by seperating the word and the punctuation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thank you so much for reading my tutorial!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shangda (Harry) Li, andrewID: shangdal"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
