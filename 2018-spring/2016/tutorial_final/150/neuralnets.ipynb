{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In machine learning, a *neural network* is a learning algorithm which aims to simulate a human brain by using layers of *neurons* to process input into output. They boast incredible power, and are often used to tackle extremely difficult problems with high dimensionality inputs.\n",
    "\n",
    "In this tutorial, we will show how to use the premade neural network package `scikit-neuralnetwork` and then walk through how to program one from the mathematical theory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "At a high level, a neural net performs multistep processing by passing data through its layers of neurons. Each layer is composed of weights which weigh evidence in the inputs to make some abstract conclusions. Each additional layer then takes these conclusions as input to produce even more abstract conclusions. This composition of multiple abstractions is very good at identifying patterns in large, chaotic inputs, like images.\n",
    "\n",
    "![An image visualizing the different layers of a Convolution Neural Network.](img/convnet.jpeg \"Convolutional Neural Network\")\n",
    "<center> A visualization of the different layers of outputs in an image recognition *convolutional* neural network. \n",
    "<br /> Source: http://cs231n.github.io/convolutional-networks/ </center>\n",
    "\n",
    "The above example shows how an image of a car is processed along the layers of a neural network. The conclusions made at each layer are not entirely obvious, but you should be able to see that the network is slowly figuring out the location of the car in the image. It determined the road and the background are not important, and has highlighted the shape and outline of the car in the later stages.\n",
    "\n",
    "While powerful, neural nets are not often used in practice because they require much time and data to train. However, they can still usually be found as the basis for image-related applications. One notable application of neural nets among the Japanese animation fandom is [waifu2x](http://waifu2x.udp.jp/), which is used for image upscaling. The network takes in a small image as input, and is trained to predict how the image looks like at 2x resolution.\n",
    "\n",
    "![](img/waifu2x_demo.jpg \"Waif2x Demo\")\n",
    "<center> Demo of waifu2x\n",
    "<br /> Source: http://waifu2x.udp.jp/ </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playing with a Pre-Built Library\n",
    "\n",
    "We can examine the capabilities of a neural net using the [`scikit-neuralnetwork` package](http://scikit-neuralnetwork.readthedocs.io/en/latest/guide_model.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n",
    "This tutorial was written with the [Anaconda Python package](https://www.continuum.io/downloads) installed on a Windows 10 machine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure you can run the following commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Should all be available from the Anaconda package.\n",
    "import numpy as np\n",
    "import pickle\n",
    "import cPickle\n",
    "import gzip\n",
    "import matplotlib\n",
    "matplotlib.use(\"svg\")\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, install the `scikit-neuralnetwork` package. Run the following pip command in console.\n",
    "\n",
    "```\n",
    "pip install scikit-neuralnetwork\n",
    "```\n",
    "\n",
    "`scikit-neuralnetwork` depends on a package called [Theano](http://deeplearning.net/software/theano/). Theano is a popular optimization package for performing mathematical computation. Optimizations are often necessary in neural networks due to the computational intesity of training one.\n",
    "\n",
    "If you acquired Theano through the above pip command, then you may need additional steps to get Theano to work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First try importing `scikit-neuralnetwork`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda2\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Acquired from the pip-install command.\n",
    "from sknn.mlp import Classifier, Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you get a warning about \"missing g++,\" try the following steps (worked for my Windows 10 machine):\n",
    "\n",
    "1. Download TDM-GCC (gcc compiler suite for Windows): http://tdm-gcc.tdragon.net/download\n",
    "2. Check that the command `g++` works in Command Prompt. If not, check that `TDM-GCC-64\\bin` is in your system PATH.\n",
    "3. Run `conda install mingw libpython` in console.\n",
    "\n",
    "Then try running the import line again.\n",
    "\n",
    "(Taken from [StackOverflow: How to Install Theano on Anaconda Python 2.7](http://stackoverflow.com/questions/33687103/how-to-install-theano-on-anaconda-python-2-7-x64-on-windows))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be working with the classic [MNIST dataset](http://yann.lecun.com/exdb/mnist/). It's a high curated dataset of images of handwritten digits. Each digit is labeled and also scaled and centered as a 28 px x 28 px image. Here are some examples:\n",
    "\n",
    "![](img/mnist_100_digits.png \"100 digits of MNIST\")\n",
    "<center>100 images of digits from the MNIST dataset\n",
    "<br />Source:  Michael Nielsen's online book [*Neural Network and Deep Learning*](http://neuralnetworksanddeeplearning.com/chap1.html) </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using Michael Nielsen's `mnist_loader` from his [online book](http://neuralnetworksanddeeplearning.com/) to load the dataset. `mnist_loader` loads all of the images as 1D-Numpy Arrays of black intensity values as well as labels of each image. It also divides the data into training, validation, and test.\n",
    "\n",
    "The .py file for `mnist_loader` has been included with this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the following archive (16.3 MB) of MNIST data. No need to uzip it. Just place it in the same folder as this notebook.\n",
    "\n",
    "https://github.com/mnielsen/neural-networks-and-deep-learning/blob/master/data/mnist.pkl.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import mnist_loader\n",
    "training_data, validation_data, test_data = mnist_loader.load_data_wrapper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The inputs (or features) of our data are the 1D Arrays of pixel pntensities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image data:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.01171875],\n",
       "       [ 0.0703125 ],\n",
       "       [ 0.0703125 ],\n",
       "       [ 0.0703125 ],\n",
       "       [ 0.4921875 ],\n",
       "       [ 0.53125   ],\n",
       "       [ 0.68359375],\n",
       "       [ 0.1015625 ],\n",
       "       [ 0.6484375 ],\n",
       "       [ 0.99609375],\n",
       "       [ 0.96484375],\n",
       "       [ 0.49609375],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.1171875 ],\n",
       "       [ 0.140625  ],\n",
       "       [ 0.3671875 ],\n",
       "       [ 0.6015625 ],\n",
       "       [ 0.6640625 ],\n",
       "       [ 0.98828125],\n",
       "       [ 0.98828125],\n",
       "       [ 0.98828125],\n",
       "       [ 0.98828125],\n",
       "       [ 0.98828125],\n",
       "       [ 0.87890625],\n",
       "       [ 0.671875  ],\n",
       "       [ 0.98828125],\n",
       "       [ 0.9453125 ],\n",
       "       [ 0.76171875],\n",
       "       [ 0.25      ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.19140625],\n",
       "       [ 0.9296875 ],\n",
       "       [ 0.98828125],\n",
       "       [ 0.98828125],\n",
       "       [ 0.98828125],\n",
       "       [ 0.98828125],\n",
       "       [ 0.98828125],\n",
       "       [ 0.98828125],\n",
       "       [ 0.98828125],\n",
       "       [ 0.98828125],\n",
       "       [ 0.98046875],\n",
       "       [ 0.36328125],\n",
       "       [ 0.3203125 ],\n",
       "       [ 0.3203125 ],\n",
       "       [ 0.21875   ],\n",
       "       [ 0.15234375],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.0703125 ],\n",
       "       [ 0.85546875],\n",
       "       [ 0.98828125],\n",
       "       [ 0.98828125],\n",
       "       [ 0.98828125],\n",
       "       [ 0.98828125],\n",
       "       [ 0.98828125],\n",
       "       [ 0.7734375 ],\n",
       "       [ 0.7109375 ],\n",
       "       [ 0.96484375],\n",
       "       [ 0.94140625],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.3125    ],\n",
       "       [ 0.609375  ],\n",
       "       [ 0.41796875],\n",
       "       [ 0.98828125],\n",
       "       [ 0.98828125],\n",
       "       [ 0.80078125],\n",
       "       [ 0.04296875],\n",
       "       [ 0.        ],\n",
       "       [ 0.16796875],\n",
       "       [ 0.6015625 ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.0546875 ],\n",
       "       [ 0.00390625],\n",
       "       [ 0.6015625 ],\n",
       "       [ 0.98828125],\n",
       "       [ 0.3515625 ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.54296875],\n",
       "       [ 0.98828125],\n",
       "       [ 0.7421875 ],\n",
       "       [ 0.0078125 ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.04296875],\n",
       "       [ 0.7421875 ],\n",
       "       [ 0.98828125],\n",
       "       [ 0.2734375 ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.13671875],\n",
       "       [ 0.94140625],\n",
       "       [ 0.87890625],\n",
       "       [ 0.625     ],\n",
       "       [ 0.421875  ],\n",
       "       [ 0.00390625],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.31640625],\n",
       "       [ 0.9375    ],\n",
       "       [ 0.98828125],\n",
       "       [ 0.98828125],\n",
       "       [ 0.46484375],\n",
       "       [ 0.09765625],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.17578125],\n",
       "       [ 0.7265625 ],\n",
       "       [ 0.98828125],\n",
       "       [ 0.98828125],\n",
       "       [ 0.5859375 ],\n",
       "       [ 0.10546875],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.0625    ],\n",
       "       [ 0.36328125],\n",
       "       [ 0.984375  ],\n",
       "       [ 0.98828125],\n",
       "       [ 0.73046875],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.97265625],\n",
       "       [ 0.98828125],\n",
       "       [ 0.97265625],\n",
       "       [ 0.25      ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.1796875 ],\n",
       "       [ 0.5078125 ],\n",
       "       [ 0.71484375],\n",
       "       [ 0.98828125],\n",
       "       [ 0.98828125],\n",
       "       [ 0.80859375],\n",
       "       [ 0.0078125 ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.15234375],\n",
       "       [ 0.578125  ],\n",
       "       [ 0.89453125],\n",
       "       [ 0.98828125],\n",
       "       [ 0.98828125],\n",
       "       [ 0.98828125],\n",
       "       [ 0.9765625 ],\n",
       "       [ 0.7109375 ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.09375   ],\n",
       "       [ 0.4453125 ],\n",
       "       [ 0.86328125],\n",
       "       [ 0.98828125],\n",
       "       [ 0.98828125],\n",
       "       [ 0.98828125],\n",
       "       [ 0.98828125],\n",
       "       [ 0.78515625],\n",
       "       [ 0.3046875 ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.08984375],\n",
       "       [ 0.2578125 ],\n",
       "       [ 0.83203125],\n",
       "       [ 0.98828125],\n",
       "       [ 0.98828125],\n",
       "       [ 0.98828125],\n",
       "       [ 0.98828125],\n",
       "       [ 0.7734375 ],\n",
       "       [ 0.31640625],\n",
       "       [ 0.0078125 ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.0703125 ],\n",
       "       [ 0.66796875],\n",
       "       [ 0.85546875],\n",
       "       [ 0.98828125],\n",
       "       [ 0.98828125],\n",
       "       [ 0.98828125],\n",
       "       [ 0.98828125],\n",
       "       [ 0.76171875],\n",
       "       [ 0.3125    ],\n",
       "       [ 0.03515625],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.21484375],\n",
       "       [ 0.671875  ],\n",
       "       [ 0.8828125 ],\n",
       "       [ 0.98828125],\n",
       "       [ 0.98828125],\n",
       "       [ 0.98828125],\n",
       "       [ 0.98828125],\n",
       "       [ 0.953125  ],\n",
       "       [ 0.51953125],\n",
       "       [ 0.04296875],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.53125   ],\n",
       "       [ 0.98828125],\n",
       "       [ 0.98828125],\n",
       "       [ 0.98828125],\n",
       "       [ 0.828125  ],\n",
       "       [ 0.52734375],\n",
       "       [ 0.515625  ],\n",
       "       [ 0.0625    ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prints the 1D Numpy array representing an image.\n",
    "print \"Image data:\"\n",
    "training_data[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training data labels (or outputs) are \"0\", \"1\", \"2\", ..., \"9\", but given as a 1D Numpy Array in a [One-Hot Encoding](https://en.wikipedia.org/wiki/One-hot). In this case, it means that if the image labelled as a \"5\", then the 5th element of the one-hot encoded array is 1 and the rest of the elements are 0. If an image was labelled \"8\", then only the 8th element would be 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Label:\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "This represents the label: 5\n"
     ]
    }
   ],
   "source": [
    "# Prints the training_data labels\n",
    "# It's 1D Numpy Array which represents a \"One-Hot Encoding\" of what digit it is\n",
    "# So if index 5 is 1, then the digit is a \"5\"\n",
    "print \"Training Data Label:\"\n",
    "print training_data[0][1]\n",
    "\n",
    "# You can use numpy.argmax to determine the label.\n",
    "print \"This represents the label:\", (training_data[0][1]).argmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only the training data is in one-hot. The validation and test dataset labels are integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Data Label:\n",
      "3 <type 'numpy.int64'>\n",
      "Testing Data Label:\n",
      "7 <type 'numpy.int64'>\n"
     ]
    }
   ],
   "source": [
    "print \"Validation Data Label:\"\n",
    "print validation_data[0][1], type(validation_data[0][1])\n",
    "\n",
    "print \"Testing Data Label:\"\n",
    "print test_data[0][1], type(test_data[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The image data as an array doesn't really make much sense to us humans. We can get a visual of the array using `matlibplot`. The results should resemble the original image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The below image shows a 5\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x9c56dd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The below image shows a 0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xa446240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The below image shows a 4\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAADVNJREFUeJzt3X/sXfVdx/HXCyrihhLsbJtQxvUnGCdpBhJN+aOEuaEu\nluyPirAEkLDFDSWZy+jYtN8uEqk6EgxBE+hGx0bYnGJZjAgL+dYUZVRHZ3EtXaK3oxv9UhkjNjFa\n5O0f9xTut3zv59zv9/4459v385Hc9HzP+5x73r3t655z7jnf+3FECEAupzXdAIDpI/hAQgQfSIjg\nAwkRfCAhgg8kNFLwbV9p+4Dtg7ZvHVdTACbLS72Ob/s0SQclXSHpu5L2SLo6Ig6ctBw3CgANiQgv\nNH/FCM95qaRvRcQhSbL9kKSNkg68edEtfdOzkjaMsNlJmxX9jWJW7e1vVu3tTRp/f1sHVkY51D9X\n0vN9Px+u5gFoOT7cAxIa5VD/O5Le3vfz2mreAmb7ps8cYZPT0Gm6gRqdphuo0Wm6gYJO0w3U6Iy4\nfrd61Bvlw73TJT2n3od7L0h6WtJvRsT+k5aL+ef4AKZj6/g/3IuI/7N9s6TH1Dtl2H5y6AG00yiH\n+oqIRyVdMKZeAEwJH+4BCRF8ICGCDyRE8IGECD6QEMEHEiL4QEIEH0iI4AMJEXwgIYIPJETwgYQI\nPpAQwQcSIvhAQgQfSIjgAwkRfCAhgg8kRPCBhAg+kBDBBxIi+EBCBB9IiOADCRF8ICGCDyRE8IGE\nCD6QEMEHEiL4QEIrRlnZdlfSK5Jek3Q8Ii4dR1PA2PzpTLF85KMu1tesjfLzHy4/f1uNFHz1Ar8h\nIl4eRzMApmPUQ32P4TkATNmooQ1Jj9veY/umcTQEYPJGPdRfHxEv2P4x9d4A9kfE7jcvNts33ake\nAMarWz3qjRT8iHih+vOo7YclXSppgeBvGGUzAIbS0fyd6q6BSy75UN/2W2yfVU2/VdK7JT271OcD\nMD2j7PFXS3rYdlTP84WIeGw8bQGYpCUHPyL+Q9K6MfYyGZtnyvX31qx/Wc36aLUbf+/uYn31JTVP\n8P7x9dImXIoDEiL4QEIEH0iI4AMJEXwgIYIPJETwgYRGvVe/9T72R1uL9Vt1R7G+UreOsx2M3Q8V\nqx/SPeXV76p5+lM0IezxgYQIPpAQwQcSIvhAQgQfSIjgAwkRfCChU/Qq5Ru2/fxMsf69fWdOpxFM\nyEeK1b/z5mL9vDir/PSeWWQ/ywN7fCAhgg8kRPCBhAg+kBDBBxIi+EBCBB9I6JS/jq//aboBTFL8\n7RnF+u2/Vl5/W+33Lby6uIaWCfb4QEIEH0iI4AMJEXwgIYIPJETwgYQIPpBQ7XV829vVG0V+LiIu\nquadI+mLks6X1JW0KSJemWCfg/3iTLH8V0+Vv1f/8jG2ggZ8bbTVP33DJ2uWmBltAy01zB7/s5Le\nc9K8zZK+GhEXSHpC0sfH3RiAyakNfkTslvTySbM3StpRTe+QdNWY+wIwQUs9x18VEXOSFBFHJK0a\nX0sAJm1c9+pHuTzbN92pHgDGq1s96i01+HO2V0fEnO01kl4sL75hiZsBMLyO5u9Udw1ccthDfVeP\nEx6RdH01fZ2kncO2BqB5tcG3/aCkf5T0M7a/bfsGSXdI+mXbz0m6ovoZwDJRe6gfEdcMKL1rzL0s\nyY3/dHexfsDFMtfxW++3i9WXbi/fp1Hr/tFWX664cw9IiOADCRF8ICGCDyRE8IGECD6QEMEHElr2\n36v/+/pUsf75mvU/pj+pWeI/F9UPxuul6BTrf15zn8Yn1pfrn3xyxF/oX6bY4wMJEXwgIYIPJETw\ngYQIPpAQwQcSIvhAQsv+Ov6otn/65polZqbRxjK2oVw+UK7H98sX4u+vuU5f54ydNcM9vO3O0Taw\nTLHHBxIi+EBCBB9IiOADCRF8ICGCDyRE8IGE0l/H15U19Y9OePuXzZTrZ5bLmx7fUaxfoweL9ZU1\n3zfwqr9erP+3yt9rf+GFxbK0u1zu1Kz+vZr68Ut+pGaJnNjjAwkRfCAhgg8kRPCBhAg+kBDBBxIi\n+EBCtdfxbW+X9F5JcxFxUTVvi6SbJL1YLXZbRDw6sS4Lntd5xfoKHS3Wv/GO8i98X/T+Rbe0KNs+\nX74O/mrN+j9a8/vqK2vWv+wPyvW/jl8p1q9+6aFi/fjbfrimgb8olp/Xh4r1/eVnl7ozdUukNMwe\n/7OS3rPA/Dsj4p3Vo5HQA1ia2uBHxG5JLy9QGvG7UQA0ZZRz/Jtt77V9n+2zx9YRgIlb6r3690j6\nVESE7T+UdKekGwcvPts33VH9HdgAFq9bPeotKfgR0f+J2b2SvlJeY8NSNgNgUTqav1PdNXDJYQ/1\nrb5zettr+mrvk/Ts0L0BaNwwl/MeVG+XvdL2tyVtkXS57XWSXlPv2OKDE+wRwJg5Iia7ATt67xXN\nuC5WF+v3/3P5OnHTzrvkYLF++IafLj/B/TPja2YCfjZ+vVi/1hcX6594R/n5/Wxz//eat1URseDV\nN+7cAxIi+EBCBB9IiOADCRF8ICGCDyRE8IGETvnr+Gi3mCt/H8Ht5dswtCrKX5jwAf/kYls6hXAd\nH0Afgg8kRPCBhAg+kBDBBxIi+EBCBB9IaKnfuQe0wgdueqBmiZlptLHssMcHEiL4QEIEH0iI4AMJ\nEXwgIYIPJETwgYQIPpAQwQcSIvhAQgQfSIjgAwkRfCAhgg8kRPCBhGp/H9/2Wkmfk7Ra0muS7o2I\nP7N9jqQvSjpfUlfSpoh4ZYK9IqHjNfWz7z5SrL9y3/h6OZUMs8d/VdJHIuLnJP2SpA/bvlDSZklf\njYgLJD0h6eOTaxPAONUGPyKORMTeavqYpP2S1kraKGlHtdgOSVdNqkkA47Woc3zbHUnrJD0laXVE\nzEm9NwdJq8bdHIDJGPo792yfJenLkm6JiGO9MfHmKQzCN9s33akeAMarWz3qDRV82yvUC/0DEbGz\nmj1ne3VEzNleI+nFwc+wYahmAIyio/k71V0Dlxz2UP8zkr4ZEXf1zXtE0vXV9HWSdp68EoB2GuZy\n3npJ10raZ/sZ9Q7pb5O0TdKXbP+WpEOSNk2yUQDjUxv8iHhS0ukDyu8abzvAfD9QUz/jB/93Kn2c\narhzD0iI4AMJEXwgIYIPJETwgYQIPpAQwQcSGvpefaCNHtWVxfrF3Fe2IPb4QEIEH0iI4AMJEXwg\nIYIPJETwgYQIPpAQ1/HRanXfq4+lYY8PJETwgYQIPpAQwQcSIvhAQgQfSIjgAwlxHR+NWrXqULF+\ni86fUie5sMcHEiL4QEIEH0iI4AMJEXwgIYIPJFQbfNtrbT9h+99s77P9O9X8LbYP2/569Sh/zzGA\n1nBElBew10haExF7bZ8l6V8kbZT0G5L+KyLurFk/pC3j6hfA0LYqIrxQpfYGnog4IulINX3M9n5J\n51blBZ8UQLst6hzfdkfSOklfq2bdbHuv7ftsnz3m3gBMyNDBrw7zvyzplog4JukeST8REevUOyIo\nHvIDaI+h7tW3vUK90D8QETslKSKO9i1yr6SvDH6G2b7pTvUAMF7d6lFv2F/S+Yykb0bEXSdm2F5T\nnf9L0vskPTt49Q1DbgbA0nU0f6e6a+CStcG3vV7StZL22X5GUki6TdI1ttdJek29t5kPLrVdANM1\nzKf6T0o6fYHSo+NvB8A0cOcekBDBBxIi+EBCBB9IiOADCRF8ICGCDyRE8IGECD6QEMEHEiL4QEIE\nH0iogeB3p7/JRek23UCNbtMN1Og23UBBt+kGanSntiWC/ybdphuo0W26gRrdphso6DbdQI3u1LbE\noT6QEMEHEqr9Xv2RN2BPdgMABhr0vfoTDz6A9uFQH0iI4AMJTS34tq+0fcD2Qdu3Tmu7w7Ldtf0N\n28/YfroF/Wy3PWf7X/vmnWP7MdvP2f77JkcvGtBfawZSXWCw19+t5rfiNWx6MNqpnOPbPk3SQUlX\nSPqupD2Sro6IAxPf+JBs/7ukiyPi5aZ7kSTbl0k6JulzEXFRNW+bpJci4o+rN89zImJzi/rboiEG\nUp2GwmCvN6gFr+Gog9GOalp7/EslfSsiDkXEcUkPqfeXbBOrRac+EbFb0slvQhsl7aimd0i6aqpN\n9RnQn9SSgVQj4khE7K2mj0naL2mtWvIaDuhvaoPRTus/+rmSnu/7+bDe+Eu2RUh63PYe2zc13cwA\nqyJiTnp9FONVDfezkNYNpNo32OtTkla37TVsYjDa1uzhWmB9RLxT0q9K+nB1KNt2bbsW27qBVBcY\n7PXk16zR17CpwWinFfzvSHp7389rq3mtEREvVH8elfSweqcnbTNne7X0+jniiw33M09EHI03PjS6\nV9IvNNnPQoO9qkWv4aDBaKfxGk4r+Hsk/ZTt822fIelqSY9Madu1bL+leueV7bdKereKg4BOjTX/\nfO8RSddX09dJ2nnyClM2r78qSCfUDKQ6FW8a7FXteg0XHIy2rz6x13Bqd+5VlyXuUu/NZntE3DGV\nDQ/B9o+rt5cP9cYT/ELT/dl+UL1hhldKmpO0RdLfSPpLSedJOiRpU0R8v0X9Xa7euerrA6meOJ9u\noL/1kv5B0j71/l1PDPb6tKQvqeHXsNDfNZrCa8gtu0BCfLgHJETwgYQIPpAQwQcSIvhAQgQfSIjg\nAwkRfCCh/wdQmldCg0aXywAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xbb22cc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def print_data_point(image, label):\n",
    "    print \"The below image shows a\", label\n",
    "    # Taken from http://stackoverflow.com/questions/2659312/how-do-i-convert-a-numpy-array-to-and-display-an-image\n",
    "    plt.imshow(image.reshape(28,28), interpolation='nearest')\n",
    "    plt.show()\n",
    "\n",
    "for image, out in training_data[:3]:\n",
    "    print_data_point(image, np.argmax(out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a `Classifier` from `scikit-neuralnetwork`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're ready to use `scikit-neuralnetwork`. The following code prepares the MNIST data as input matracies and vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "[[5]\n",
      " [0]\n",
      " [4]\n",
      " ..., \n",
      " [8]\n",
      " [4]\n",
      " [8]]\n",
      "[[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "[[7]\n",
      " [2]\n",
      " [1]\n",
      " ..., \n",
      " [4]\n",
      " [5]\n",
      " [6]]\n"
     ]
    }
   ],
   "source": [
    "# Number of samples to use for training.\n",
    "# You can adjust this if you like. But you really need all the data you can get when training a Neural network\n",
    "samples_to_use = len(training_data)\n",
    "\n",
    "# Matrix of inputs. Each row is an example image.\n",
    "X_train = np.array([image.ravel() for image, out in training_data[:samples_to_use]])\n",
    "X_test = np.array([image.ravel() for image, out in test_data])\n",
    "\n",
    "# Matrix of labels. Each row is a label for the corresponding input row\n",
    "y_train = np.array([[np.argmax(out)] for image,out in training_data[:samples_to_use]])\n",
    "y_test = np.array([[out] for image, out in test_data])\n",
    "\n",
    "print X_train\n",
    "print y_train\n",
    "\n",
    "print X_test\n",
    "print y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, instatiate a `Classifier` neural network from `scikit-neuralnetwork`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add GPU support (beyond the scope of this tutorial)\n",
    "# If not properly configured, does nothing\n",
    "from sknn.platform import gpu32\n",
    "\n",
    "# Instantiate the Classifier\n",
    "nn = Classifier(\n",
    "    layers=[\n",
    "        Layer(\"Sigmoid\", units=100),      # \"Hidden Layer\" of 100 \"neurons\" which use the \"Sigmoid\" as the \"activation function\"\n",
    "        Layer(\"Softmax\")                  # \"Output Layer\" using the Softmax function for classification\n",
    "    ],                \n",
    "    learning_rate=.1,                     # Learning Rate alpha for Stochastic Gradient Descent (SGD)\n",
    "    n_iter=30,                            # Number of iterations of SGD\n",
    "    batch_size=10,                        # \"Mini-batch\" size of SGD\n",
    "    verbose=True)                         # Toggles a progress bar during training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The components in the neural network are explained [later in this tutorial](#The-Theory)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A single function call will train the net. This took approximately 30 seconds on my Intel i5-6600K computer. If you want to skip training and use an example network instead, load the example network in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda2\\lib\\site-packages\\theano\\tensor\\signal\\downsample.py:6: UserWarning: downsample module has been moved to the theano.tensor.signal.pool module.\n",
      "  \"downsample module has been moved to the theano.tensor.signal.pool module.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "text/plain": [
       "Classifier(batch_size=10, callback=None, debug=False, dropout_rate=None,\n",
       "      f_stable=0.001,\n",
       "      hidden0=<sknn.nn.Layer `Sigmoid`: units=100, name=u'hidden0', frozen=False>,\n",
       "      layers=[<sknn.nn.Layer `Sigmoid`: units=100, name=u'hidden0', frozen=False>, <sknn.nn.Layer `Softmax`: units=10L, name=u'output', frozen=False>],\n",
       "      learning_momentum=0.9, learning_rate=0.1, learning_rule=u'sgd',\n",
       "      loss_type=None, n_iter=30, n_stable=10, normalize=None,\n",
       "      output=<sknn.nn.Layer `Softmax`: units=10L, name=u'output', frozen=False>,\n",
       "      parameters=None, random_state=None, regularize=None, valid_set=None,\n",
       "      valid_size=0.0, verbose=True, warning=None, weight_decay=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving and Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have finished training, you can save the network and its weights (always a good practice)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# These functions let you save and load a network.\n",
    "\n",
    "def save_net(net, filename):\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(net, f)\n",
    "            \n",
    "def load_net(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        net = pickle.load(f)\n",
    "        return net\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Use them like such:\n",
    "# save_net(nn, \"my_network.pkl\")\n",
    "# nn = load_net(\"my_network.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### If you skipped training, use this code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Loads an example of a trained scikit-neuralnetwork Classifier\n",
    "# nn = load_net(\"example_network.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get a taste of our trained neural net."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(10000L, 10L)]\n"
     ]
    }
   ],
   "source": [
    "####################################################\n",
    "# Runs the Trained Neural Network on the test data\n",
    "####################################################\n",
    "nn_pred_test = nn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The below image shows a 7\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n+n+hOG8O0VrVwgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xf116b70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neural net prediction: [7]\n",
      "\n",
      "========================\n",
      "\n",
      "The below image shows a 2\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAADbpJREFUeJzt3X/sXXV9x/HXC8gysRtDZ9uEAlczxUVDKm4kS/dHDawi\n6VLmsg6LhqIyY2TDsMQicfZbsyV8t6UZi2PLoEJ1oiimFJdYgZBvtSxCnXS2s6Uu20VA+qUzHaNk\nS2B97497Cvf77b3n3H7P/XHa9/OR3PR8z/t8z3n3tq/vOef7ufd+HBECkMsZk24AwPgRfCAhgg8k\nRPCBhAg+kBDBBxKqFXzbV9g+YPug7Q3DagrAaHmh4/i2z5B0UNJlkn4qabekqyPiwLzteKEAMCER\n4V7rz6qxz0sl/TginpIk21+VtEbSgRM33di1PCNpZY3DjtqM6K+OGTW3vxk1tzdp+P1t6lupc6l/\nnqSnu75+plgHoOH45R6QUJ1L/WclXdD19bJiXQ8zXcs/X+OQ49CadAMVWpNuoEJr0g2UaE26gQqt\nmt/fLh7V6vxy70xJT6rzy73nJD0u6QMRsX/edjH3Hh/AeGwa/i/3IuL/bN8g6UF1bhm2zA89gGaq\nc6mviNgh6aIh9QJgTPjlHpAQwQcSIvhAQgQfSIjgAwkRfCAhgg8kRPCBhAg+kBDBBxIi+EBCBB9I\niOADCRF8ICGCDyRU6/34GL218ebS+vlzPu/0RH/59J+U1qcuKC1XujwuKa2/76UdpfWji/6mXgNY\nEM74QEIEH0iI4AMJEXwgIYIPJETwgYQIPpAQ4/gTFrP9ZzSVpOme86AMbrqi/rp6u9ej/kFp/cVf\nW1xat6pmcpo6uYYwEM74QEIEH0iI4AMJEXwgIYIPJETwgYQIPpBQrXF8221JL0g6JunliLh0GE2d\nTirH6ZeM9vgbVpXXv/7t1aX139vzj6X16XeV73/6++X1j8fm0vrf1nwdA3qr+wKeY5JWRsSRYTQD\nYDzqXup7CPsAMGZ1QxuSHrK92/b1w2gIwOjVvdRfERHP2X6TOj8A9kfErhM3m+labhUPAMPVLh7V\nagU/Ip4r/jxse5ukSyX1CP7KOocBMJCW5p5Ud/bdcsGX+rbPtr2oWH69pFWS9i10fwDGp84Zf4mk\nbbaj2M+XI+LB4bQFYJQcUfV+6JoHsEPaONJjTNRVU6Xl2+8vH4j+74rdb/id8rq3Vf37faui/lhF\n/bzSaqz/g9L69N0Ve4/fLa1/yO8s3wFKbFJE9PwPyFAckBDBBxIi+EBCBB9IiOADCRF8ICGCDyTE\n5+rX9dHy8sv3l9erx+lfqGhgqqJez8fjxdL63TXfL/+hP7uvYoupegdAT5zxgYQIPpAQwQcSIvhA\nQgQfSIjgAwkRfCAhxvHrWj1VWr6xYv73G7f9sOIA5Z87P2q3r/3j0vr0mPrAcHHGBxIi+EBCBB9I\niOADCRF8ICGCDyRE8IGEGMcfualJN1DqA3FBaf0far7ffsNny+s3f+Yb9Q6ABeGMDyRE8IGECD6Q\nEMEHEiL4QEIEH0iI4AMJVY7j294iabWk2Yi4uFh3rqR7JV0oqS1pbURUfQA8JuH+qdLylS4fqH+2\nYvcfPbO87mPln0fQ9Nc5nK4GOePfJem989bdLOnhiLhI0iOSPj3sxgCMTmXwI2KXpCPzVq+RtLVY\n3irpqiH3BWCEFnqPvzgiZiUpIg5JWjy8lgCM2rBeq19xIzfTtdwqHgCGq108qi00+LO2l0TErO2l\nkp4v33zlAg8DYHAtzT2p7uy75aCX+i4exz0gaX2xfK2k7YO2BmDyKoNv+x5J/yTpbbZ/Yvs6SbdK\n+i3bT0q6rPgawCmi8lI/Itb1KV0+5F4wAp9Zc0tpvWqcvsquV1aVb+CpmkfAKPDKPSAhgg8kRPCB\nhAg+kBDBBxIi+EBCBB9IiM/VP8XFE5tK6/dWfC5+u2L/V8ebSustf7JiD49V1DEJnPGBhAg+kBDB\nBxIi+EBCBB9IiOADCRF8ICHG8RvvptLqf7yrfBy/XbH3ayrq5/9Cxaeq8bn4pyTO+EBCBB9IiOAD\nCRF8ICGCDyRE8IGECD6QEOP4DRefPae0Pv25evv/bqwp34DPxT8tccYHEiL4QEIEH0iI4AMJEXwg\nIYIPJETwgYQqx/Ftb5G0WtJsRFxcrNso6XpJx9+sfUtE7BhZl6ezHVOl5buvKH+/fZUNd5XX7Y9V\n7IHPxT8dDXLGv0vSe3us3xwRlxQPQg+cQiqDHxG7JB3pUaqYowVAU9W5x7/B9h7bd9ouf10pgEZZ\n6Gv1b5f0uYgI238qabOkj/TffKZruVU8AAxXW9WfstixoOBHxOGuL++Q9M3y71i5kMMAOCktzT2p\n7uy75aCX+lbXPb3tpV2190vaN3BvACZukOG8e9Q5Zb/R9k8kbZT0HtvLJR1T59qiakwIQINUBj8i\n1vVYXTE6jNesLa3GI+WDI9M1j/6V9RXvt7+OcfqMeOUekBDBBxIi+EBCBB9IiOADCRF8ICGCDyTE\n5+qP2F/FbaX16ZrvcdxwsLzO++3RC2d8ICGCDyRE8IGECD6QEMEHEiL4QEIEH0iIcfwRO8d/X1r/\n35r799teqNhic80j4HTEGR9IiOADCRF8ICGCDyRE8IGECD6QEMEHEmIc/1T3zl8sr++7Zjx99PVw\nRX22or6kon75SfTSwy+/tbT83cPvrrf/Cv+js0vrq/zJij3sXdBxOeMDCRF8ICGCDyRE8IGECD6Q\nEMEHEiL4QEKV4/i2l0n6ojoDqsck3RERf237XEn3SrpQUlvS2oioenM4huzWfTU/mH/EPvWz8vq2\nN7yvtH7lS98qrd+26GQ7muc/y8uPTvjpvSF+u7T++QX2N8gZ/xVJN0XEOyT9hqRP2H67pJslPRwR\nF0l6RNKnF9YCgHGrDH5EHIqIPcXyUUn7JS2TtEbS1mKzrZKuGlWTAIbrpO7xbbckLZf0PUlLImJW\n6vxwkLR42M0BGI2BX6tve5Gk+yTdGBFHbce8TeZ/3WWma7lVPAAMV7t4VBso+LbPUif0X4qI7cXq\nWdtLImLW9lJJz/ffw8qBmgFQR0tzT6o7+2456KX+FyT9KGLO1K8PSFpfLF8rafv8bwLQTIMM562Q\ndI2kvbafUOeS/hZJ05K+ZvvDkp6StHaUjQIYHkeU3JoP4wB2SBtHeowmi/2bSuvTvzqmRpJ6Q0X9\ndTX3/8GKjxNYt3hLrf1/5foPl29w51RJcZMioudIP6/cAxIi+EBCBB9IiOADCRF8ICGCDyRE8IGE\nGMefsA/GeaX1X9KRkR7/L17aUFqv/X73CqvjLaX1v9PHau3/82/9VPkG/zZVa//Nxjg+gC4EH0iI\n4AMJEXwgIYIPJETwgYQIPpAQ4/jAaYtxfABdCD6QEMEHEiL4QEIEH0iI4AMJEXwgIYIPJETwgYQI\nPpAQwQcSIvhAQgQfSIjgAwlVBt/2MtuP2P5X23tt/2GxfqPtZ2z/oHhcMfp2AQzDWQNs84qkmyJi\nj+1Fkv7Z9kNFbXNEbB5dewBGoTL4EXFI0qFi+ajt/ZKOzwLR803+AJrtpO7xbbckLZf0WLHqBtt7\nbN9p+5wh9wZgRAYOfnGZf5+kGyPiqKTbJb0lIparc0XAJT9wihjkHl+2z1In9F+KiO2SFBGHuza5\nQ9I3++9hpmu5VTwADFe7eFQbKPiSviDpRxFx2/EVtpcW9/+S9H5J+/p/+8oBDwNg4Vqae1Ld2XfL\nyuDbXiHpGkl7bT8hKSTdImmd7eWSjqnzY6betKYAxmaQ3+o/KunMHqUdw28HwDjwyj0gIYIPJETw\ngYQIPpAQwQcSIvhAQgQfSIjgAwkRfCAhgg8kRPCBhAg+kNAEgt8e/yFPSnvSDVRoT7qBCu1JN1Ci\nPekGKrTHdiSCf4L2pBuo0J50AxXak26gRHvSDVRoj+1IXOoDCRF8ICFHxGgPYI/2AAD6ioieH4E/\n8uADaB4u9YGECD6Q0NiCb/sK2wdsH7S9YVzHHZTttu1/sf2E7ccb0M8W27O2f9i17lzbD9p+0va3\nJzl7UZ/+GjORao/JXv+oWN+I53DSk9GO5R7f9hmSDkq6TNJPJe2WdHVEHBj5wQdk+98lvTsijky6\nF0my/ZuSjkr6YkRcXKyblvSziPjz4ofnuRFxc4P62yjpxSZMpGp7qaSl3ZO9Sloj6To14Dks6e/3\nNYbncFxn/Esl/TginoqIlyV9VZ2/ZJNYDbr1iYhdkub/EFojaWuxvFXSVWNtqkuf/qSGTKQaEYci\nYk+xfFTSfknL1JDnsE9/Y5uMdlz/0c+T9HTX18/otb9kU4Skh2zvtn39pJvpY3FEzEqvzmK8eML9\n9NK4iVS7Jnv9nqQlTXsOJzEZbWPOcA2wIiIukXSlpE8Ul7JN17Sx2MZNpNpjstf5z9lEn8NJTUY7\nruA/K+mCrq+XFesaIyKeK/48LGmbOrcnTTNre4n06j3i8xPuZ46IOByv/dLoDkm/Psl+ek32qgY9\nh/0mox3Hcziu4O+W9Cu2L7T9c5KulvTAmI5dyfbZxU9e2X69pFUqnQR0bKy593sPSFpfLF8rafv8\nbxizOf0VQTquYiLVsThhslc16znsORltV31kz+HYXrlXDEvcps4Pmy0RcetYDjwA229W5ywf6swn\n+OVJ92f7HnWmGX6jpFlJGyXdL+nrks6X9JSktRHxXw3q7z3q3Ku+OpHq8fvpCfS3QtJ3JO1V59/1\n+GSvj0v6mib8HJb0t05jeA55yS6QEL/cAxIi+EBCBB9IiOADCRF8ICGCDyRE8IGECD6Q0P8DpbJ/\nkSrVPDsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xf670e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neural net prediction: [2]\n",
      "\n",
      "========================\n",
      "\n",
      "The below image shows a 1\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwZcKMvhSQQZfKuj/ARk4OtrWahK6AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xf733358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neural net prediction: [1]\n",
      "\n",
      "========================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#########################################\n",
    "#  Visually examine some of the results\n",
    "#########################################\n",
    "index = 0             # You can skim through the test data with this\n",
    "num_tests = 3\n",
    "for i, (image, out) in enumerate(test_data[index:index+num_tests]):\n",
    "    print_data_point(image, out)\n",
    "    pred = nn_pred_test[index + i]\n",
    "    print \"neural net prediction:\", pred\n",
    "    print \"\\n========================\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num incorrect: 212\n",
      "The below image shows a 5\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEXwgIYIPJETwgYQIPpAQwQcS+n8W0YomYCb59gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x204617f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neural net prediction: 6\n",
      "\n",
      "========================\n",
      "\n",
      "The below image shows a 2\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x204a0b00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neural net prediction: 4\n",
      "\n",
      "========================\n",
      "\n",
      "The below image shows a 4\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBB9IiOADCf0/Yplu6LkPTfkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x207f2400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neural net prediction: 6\n",
      "\n",
      "========================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#######################################################\n",
    "#  Visually examine some of the incorrect predictions\n",
    "#     (Do they seem difficult to you?)\n",
    "#######################################################\n",
    "nn_incorrect = [(image, pred, actual) for image, pred, actual in zip(X_test, nn_pred_test.ravel(), y_test.ravel()) if pred != actual]\n",
    "print \"Num incorrect:\", len(nn_incorrect)\n",
    "\n",
    "index = 0\n",
    "num_to_show = 3\n",
    "for image, pred, actual in nn_incorrect[index:min(len(nn_incorrect), index+num_to_show)]:\n",
    "    print_data_point(image, actual)\n",
    "    print \"neural net prediction:\", pred\n",
    "    print \"\\n========================\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 0.9788\n"
     ]
    }
   ],
   "source": [
    "####################################################\n",
    "#  The \"accuraccy\" of this trained neural network\n",
    "####################################################\n",
    "nn_accuracy = 1 - (len(nn_incorrect) / float(X_test.shape[0]))\n",
    "print \"Accuracy on test set:\", nn_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next section explains all of the components and math in a neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Theory\n",
    "\n",
    "![](img/network.png \"Diagram of a Neural Network\")\n",
    "\n",
    "A neural network is comprised of multiple layers of nodes. Values are fed from one layer of nodes to the next. The first layer is the **input layer** which produces the input $x$, and the last layer is the **ouput layer** which produces the final computation. In between, we have **hidden layers** whose outputs remain within the network.\n",
    "\n",
    "A neural network is primarily identified by the number of hidden layers. Typically, a $L$-layer Neural Network has $L-1$ hidden layers. The $L$-th layer is the output layer. The $0$-th layer is the input layer. This tutorial denotes layer number by the variable $k$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neurons\n",
    "\n",
    "Nodes are called **neurons**, or **units**. A neuron receives the all of output values of the previous layer and produces a single output.\n",
    "\n",
    "![](img/neuron.png \"Concept of a neuron.\")\n",
    "\n",
    "The $output$ of a neuron is created in two steps:\n",
    "\n",
    "First, a **weighted input** or **hidden layer pre-activation** is computed. We do a weighted sum the inputs according to some **weights** $w_i$ and add a **bias** $b_i$. For the $i$th neuron in a layer, we call this $z_i$. So for example:\n",
    "\n",
    "$$z_i=w_{i,1}x_i+w_{i,2}x_2+w_{i,3}x_3+b_i$$\n",
    "\n",
    "Using vectors notation, we can simplify it as:\n",
    "\n",
    "$$z_i=w_ix+b_i$$\n",
    "\n",
    "where $w_i$ is a row vector, and $x$ is a column vector.\n",
    "\n",
    "Second, a **activation function** $g$ is applied to the weighted input $z_i$. The strength of a neural network comes from this step, because the activation function is usually a *non-linear function*, such as the [sigmoid function](https://en.wikipedia.org/wiki/Sigmoid_function) $\\sigma$. We call the output of this step the **output activation** or **hidden layer activation** $a_i$. Following the previous example:\n",
    "\n",
    "$$output_i=a_i=g(z_i)=\\sigma(w_{i,1}x_i+w_{i,2}x_2+w_{i,3}x_3+b_i)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a Layer\n",
    "\n",
    "So far, we have only considered a single neuron. We can easily expand our notation to a layer of neurons using matracies. Before, for each neuron, we had a row vector of weights $w_i$ and a bias $b_i$ which produced weighted input $z_i$. Now, for the $k$th layer of neurons, we use a matrix $W^k$ whose rows are the $w_i$ row vectors, a column vector $b^k$ whose elements are the $b_i$'s, and a column vector $z^k$ for the $z_i$'s. We represent the whole layer's weighted inputs as:\n",
    "\n",
    "$$z^k=W^kx+b^k$$\n",
    "\n",
    "Similarly, for output activations:\n",
    "\n",
    "$$a^k=g_k(z^k)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This translates very nicely to python using `numpy` arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input vector: [ 0.21758967  0.52502138  0.45868448  0.20453271  0.33132335  0.64778998\n",
      "  0.30865316  0.14240111  0.04716551  0.86088911]\n",
      "Output Activations: [ 0.58228037  0.77312927  0.45611445  0.08043548  0.52312299]\n"
     ]
    }
   ],
   "source": [
    "# Here's the non-linear sigmoid function.\n",
    "# x here can be a numpy array\n",
    "def sigmoid(x):\n",
    "    return 1.0 / (1.0 + np.exp(-x))\n",
    "\n",
    "# The input x to our layer of neurons\n",
    "num_inputs = 10\n",
    "x = np.random.rand(num_inputs)\n",
    "\n",
    "# Number of neurons in layer k\n",
    "num_neurons = 5\n",
    "\n",
    "# Weights of layer k\n",
    "W_k = np.random.randn(num_neurons, num_inputs)\n",
    "\n",
    "# Biases of layer k\n",
    "b_k = np.random.randn(num_neurons)\n",
    "\n",
    "# Weighted input of layer k\n",
    "z_k = W_k.dot(x) + b_k\n",
    "\n",
    "# The activation function\n",
    "g_k = sigmoid\n",
    "\n",
    "# The output activation of layer k\n",
    "a_k = g_k(z_k)\n",
    "\n",
    "print \"Input vector:\", x\n",
    "print \"Output Activations:\", a_k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing a Network\n",
    "\n",
    "In the last section, we denoted the input to a layer as $x$. In a network, the input to layer $k$ is the output of layer $k-1$. To compute a network, we just successively apply layers one after another, feeding the output of one into the next. So, the algorithm for computing a network looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: [ 0.88074506  0.55887648  0.59841642  0.8844166   0.93387852  0.4510958\n",
      "  0.51661283  0.83135754  0.09290896  0.4360341 ]\n",
      "y: [ 0.49483959  0.15120296]\n"
     ]
    }
   ],
   "source": [
    "def identity(x):\n",
    "    return x\n",
    "\n",
    "# Number of inputs to the network\n",
    "num_inputs = 10\n",
    "# Number of outputs of the network (it's not just a scalar!)\n",
    "num_outputs = 2 \n",
    "\n",
    "# Number of neurons/nodes at each layer.\n",
    "# We have 2 hidden layers here: layers 1 and 2\n",
    "# Layer 0 is the input layer\n",
    "# Layer 1 is a hidden layer with 7 neurons\n",
    "# Layer 2 is a hidden layer with 5 neurons\n",
    "# Layer 3 is the output layer\n",
    "N = [num_inputs, 7, 5, num_outputs]\n",
    "\n",
    "# Weights for each layer. None for index 0 to preserve our indexing notation\n",
    "W = [None] + [np.random.randn(n_out, n_in) for n_in, n_out in zip(N[:-1], N[1:])]\n",
    "\n",
    "# Biases for each layer\n",
    "b = [None] + [np.random.randn(n) for n in N[1:]]\n",
    "\n",
    "# The Activation function at each layer.\n",
    "# This can vary for each layer, but we'll do Sigmoid for all of them.\n",
    "g = [identity] + [sigmoid for n in N[1:]]\n",
    "\n",
    "# k is a number from 1 ... len(N) - 1\n",
    "# x is a vector of length N[k-1]\n",
    "def apply_layer((N, W, b, g), k, x):\n",
    "    z_k = W[k].dot(x) + b[k]    # Weighted input\n",
    "    a_k = g[k](z_k)             # Output activation\n",
    "    return (z_k, a_k)\n",
    "\n",
    "def compute((N, W, b, g), x):\n",
    "    z = None\n",
    "    a = x\n",
    "    for k in range(1, len(N)):\n",
    "        z, a = apply_layer((N, W, b, g), k, a)\n",
    "    return a\n",
    "        \n",
    "x = np.random.rand(num_inputs)\n",
    "y = compute((N, W, b, g), x)\n",
    "print \"x:\", x\n",
    "print \"y:\", y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning: Minimizing Loss\n",
    "\n",
    "Like other ML algorithms, a neural network learn by selecting parameters that minimize a total loss over the training data. The parameters are the weights $W^k$ and biases $b^k$. The total loss measures the difference between the network's prediction and the training data output.\n",
    "\n",
    "For notation, our training data consists of $m$ data points of the form $(x^{(i)},y^{(i)})$. $x^{(i)}$ is an input vector and $y^{(i)}$ is the labelled output. \n",
    "\n",
    "For some loss function $l$, we call the total loss $C$ (for \"cost\") and it looks like:\n",
    "\n",
    "$$C=\\frac{1}{m}\\sum_{i=1}^{m}l(compute(x^{(i)}),y^{(i)})$$\n",
    "\n",
    "We will be using **stochastic gradient descent** to adjust the network's parameters in a direction that lowers the loss. (Disclaimer: this optimization problem is not *convex*, so we may not get the optimal weights.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backpropogation\n",
    "\n",
    "To perform gradient descent, we need gradients with respect to each training parameter.\n",
    "\n",
    "We start with the cost gradient with respect to $z^L$, i.e. $\\nabla{}C_{z^L}$. This is how much the cost would change if we could somehow vary the weighted inputs $z^L$ in final layer of the neural net.\n",
    "\n",
    "We label this vector $\\delta^L=\\nabla{}C_{z^L}$, which is sometimes referred to as the **error**. Using the **chain rule** from calculus, we get that element $i$ is:\n",
    "\n",
    "$$\\delta^L_i=\\frac{\\partial{}C}{\\partial{}z^L_i}=\\frac{\\partial{}C}{\\partial{}g_L(z^L_i)}\\frac{\\partial{}g_L(z^L_i)}{\\partial{}z^L_i}$$\n",
    "\n",
    "The reason for this factorization is because it is often easy to compute $\\frac{\\partial{}C}{\\partial{}g_L(z^L_i)}$ and $\\frac{\\partial{}g_L(z^L_i)}{\\partial{}z^L_i}$ individually.\n",
    "\n",
    "$\\delta^L$ gives us the gradient with respect to the final layer, but not with respect to the hidden layers. It turns out, with more calculus, we can inductively compute the errors of hidden layers from $\\delta^L$. Suppose we know the error for layer $k+1$. We can get the error for layer $k$ with the following equation:\n",
    "\n",
    "$$\\delta^k=(W^{k+1})^T\\delta^{k+1}*\\frac{\\partial{}g_k(z^k)}{\\partial{}z^k}$$\n",
    "<center><sub>The $*$ here is the [Hadamard Product](https://en.wikipedia.org/wiki/Hadamard_product_%28matrices%29), or element-wise multiplication</sub></center>\n",
    "\n",
    "This formula is the core of **backpropogation**, which is the most crucial part of training a neural network. This lets us compute the errors of hidden layers *backwards* from the final layer. Knowing the error is important, because if we know the error for a layer, we can compute the gradient with respect to each weight and bias. And if we have the gradient, we can fix the weights and biases in gradient descent.\n",
    "\n",
    "Knowing the errors, the gradient with respect to a bias parameter is:\n",
    "\n",
    "$$\\frac{\\partial{}C}{\\partial{}b_i^k}=\\delta_i^k$$\n",
    "\n",
    "For weights:\n",
    "\n",
    "$$\\frac{\\partial{}C}{\\partial{}w^k_{ij}}=a^{k-1}_j\\delta_i^k$$\n",
    "\n",
    "See [Michael Nielsen's page](http://neuralnetworksanddeeplearning.com/chap2.html#proof_of_the_four_fundamental_equations_%28optional%29) for how to derive these equations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Sigmoid and Mean Squared Error\n",
    "\n",
    "The sigmoid function and mean squared error are fairly good as demonstrations of this math. Assume that every layer uses the sigmoid function as its activation function.\n",
    "\n",
    "For the mean squared error, $C$ looks like:\n",
    "\n",
    "$$C=\\frac{1}{m}\\sum_{i=1}^m\\frac{1}{2}||compute(x^{(i)})-y^{(i)}||_2^2$$\n",
    "\n",
    "First, we compute the error of the final layer $\\delta^L_i=\\frac{\\partial{}C}{\\partial{}g_L(z^L_i)}\\frac{\\partial{}g_L(z^L_i)}{\\partial{}z^L_i}$\n",
    "\n",
    "Mean Squared Error is nice because the partial $\\frac{\\partial{}C}{\\partial{}g_L(z^L_i)}$ is:\n",
    "\n",
    "$$\\frac{\\partial{}C}{\\partial{}g_L(z^L_i)}=g_L(z^L_i)-y^{(i)}_i$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, the sigmoid function $\\sigma$ is nice because the derivative is just:\n",
    "\n",
    "$$\\frac{\\partial{}g_L(z^L_i)}{\\partial{}z^L_i}=\\sigma(z^L_i)(1-\\sigma(z^L_i))$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Together, these two give us:\n",
    "\n",
    "$$\\delta^L=(g_L(z^L)-y^{(i)})*\\sigma(z^L)(1-\\sigma(z^L))$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, as an example, here is one step of backpropagation:\n",
    "\n",
    "$$\\delta^{L-1}=(W^{L})^T\\delta^{L}*\\frac{\\partial{}g_{L-1}(z^{L-1})}{\\partial{}z^{L-1}}=(W^{L})^T\\delta^{L}*\\sigma(z^{L-1})(1-\\sigma(z^{L-1}))$$\n",
    "\n",
    "This sets up very nicely for an algorithmic approach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mse_derivative(g_of_z, y):\n",
    "    return g_of_z - y\n",
    "\n",
    "def sigmoid_prime(x):\n",
    "    return sigmoid(x) * (1.0 - sigmoid(x))\n",
    "\n",
    "def backpropagation((N, W, b, g), x_train, y_train):\n",
    "    # L as we defined it\n",
    "    L = len(N) - 1\n",
    "    \n",
    "    # Keep track of all weighted inputs z_k as we perform the \"forward\" computation\n",
    "    z = [None for n in N]\n",
    "    \n",
    "    # Also keep track of all activation outputs a_k as we perform the forward computation\n",
    "    a = [None for n in N]\n",
    "    \n",
    "    # Perform the forward computation\n",
    "    a[0] = x_train\n",
    "    for k in range(1, len(N)):\n",
    "        z[k], a[k] = apply_layer((N, W, b, g), k, a[k-1]) \n",
    "    # a[L] == compute(x_train) == g[L](z[L])\n",
    "    \n",
    "    # Compute all the errors\n",
    "    error = [None for n in N]\n",
    "    error[L] = mse_derivative(a[L], y_train) * sigmoid_prime(z[L])\n",
    "    for k in range(L-1, 0, -1):\n",
    "        error[k] = W[k+1].T.dot(error[k+1]) * sigmoid_prime(z[k])\n",
    "    \n",
    "    # Compute the gradient of the cost function with respect to every weight\n",
    "    dC_dW = [None] + [error[k].reshape((-1, 1)).dot(a[k-1].reshape((1, -1))) for k in range(1, len(N))]\n",
    "    \n",
    "    # Compute the gradient of the cost function with respect to every bias\n",
    "    dC_db = [None] + [delta for delta in error[1:]]\n",
    "    \n",
    "    return dC_dW, dC_db\n",
    "\n",
    "# Arbitrary test of back propagation\n",
    "x_t = np.random.rand(num_inputs)\n",
    "y_t = np.array([1,2])\n",
    "dC_dW, dC_db = backpropagation((N, W, b, g), x_t, y_t)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Putting it together\n",
    "\n",
    "Now that we have a method of computing gradients, we can run stochastic gradient descent to tune the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Run stochastic gradient descent on the training data with learning rate alpha.\n",
    "def sgd((N, W, b, g), X_train, y_train, alpha, mb_size):\n",
    "    indicies = np.random.permutation(X_train.shape[0])\n",
    "    batches = [indicies[mb_size*k:mb_size*(k+1)] for k in xrange((X_train.shape[0] - 1) / mb_size + 1)]\n",
    "    for batch in batches:\n",
    "        X_train_random = X_train[batch]\n",
    "        y_train_random = y_train[batch]\n",
    "        dC_dW = [np.zeros(weights.shape) for weights in W[1:]]\n",
    "        dC_db = [np.zeros(biases.shape) for biases in b[1:]]\n",
    "        for x, y in zip(X_train_random, y_train_random):\n",
    "            new_dC_dW, new_dC_db = backpropagation((N, W, b, g), x,y)\n",
    "            dC_dW = [old+new for old, new in zip(dC_dW, new_dC_dW[1:])]\n",
    "            dC_dW = [old+new for old, new in zip(dC_dW, new_dC_dW[1:])]\n",
    "        W = [None] + [weights - (alpha/len(batch)) * grad for weights, grad in zip(W[1:], dC_dW)]\n",
    "        b = [None] + [biases - (alpha/len(batch)) * grad for biases, grad in zip(b[1:], dC_db)]\n",
    "    return W, b\n",
    "\n",
    "# Mean Squared Error loss function\n",
    "def loss((N, W, b, g), X, y):\n",
    "    losses = np.array([(np.linalg.norm(compute((N, W, b, g), image) - label)**2.0) / 2.0 for image,label in zip(X, y)])\n",
    "    return losses.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done epoch 0 Loss: 0.071482152149\n",
      "Done epoch 1 Loss: 0.0597220659951\n",
      "Done epoch 2 Loss: 0.0551451912823\n",
      "Done epoch 3 Loss: 0.0496413456085\n",
      "Done epoch 4 Loss: 0.0502638287601\n",
      "Done epoch 5 Loss: 0.0451315821297\n",
      "Done epoch 6 Loss: 0.0440403059401\n",
      "Done epoch 7 Loss: 0.0428243786228\n",
      "Done epoch 8 Loss: 0.0410503783072\n",
      "Done epoch 9 Loss: 0.039160789021\n",
      "Done epoch 10 Loss: 0.0416287915944\n",
      "Done epoch 11 Loss: 0.0381820592988\n",
      "Done epoch 12 Loss: 0.0402847903024\n",
      "Done epoch 13 Loss: 0.0359816119123\n",
      "Done epoch 14 Loss: 0.0364463006606\n",
      "Done epoch 15 Loss: 0.0349671776116\n",
      "Done epoch 16 Loss: 0.0348937847801\n",
      "Done epoch 17 Loss: 0.0322658508608\n",
      "Done epoch 18 Loss: 0.0352194403989\n",
      "Done epoch 19 Loss: 0.0326031901867\n",
      "Done epoch 20 Loss: 0.0319920227311\n",
      "Done epoch 21 Loss: 0.0320847679992\n",
      "Done epoch 22 Loss: 0.0316743708141\n",
      "Done epoch 23 Loss: 0.029329952143\n",
      "Done epoch 24 Loss: 0.0307336826967\n",
      "Done epoch 25 Loss: 0.0293898390603\n",
      "Done epoch 26 Loss: 0.0288235638422\n",
      "Done epoch 27 Loss: 0.031554283789\n",
      "Done epoch 28 Loss: 0.0287318430086\n",
      "Done epoch 29 Loss: 0.0279859812089\n"
     ]
    }
   ],
   "source": [
    "# Our network needs one-hot encoding of the y-labels.\n",
    "# Luckily the training data already comes in that form.\n",
    "y_train_onehot = np.array([out.ravel() for image,out in training_data[:samples_to_use]])\n",
    "\n",
    "# The input is the 28x28 image as a 1d array.\n",
    "num_inputs = 28*28\n",
    "# one-hot encoding output. 10 possible digits.\n",
    "num_outputs = 10\n",
    "\n",
    "# Layers of the neural network. We have a hidden layer of 30 neurons here.\n",
    "N = [num_inputs, 30, num_outputs]\n",
    "\n",
    "# Randomized initial weights for each layer.\n",
    "# None for index 0 to follow our indexing notation.\n",
    "W = [None] + [np.random.randn(n_out, n_in) for n_in, n_out in zip(N[:-1], N[1:])]\n",
    "\n",
    "# Randomized initial biases for each layer\n",
    "b = [None] + [np.random.randn(n) for n in N[1:]]\n",
    "\n",
    "# The Activation function at each layer.\n",
    "# This can vary for each layer, but we'll do Sigmoid for all of them.\n",
    "# g[0] is not used, but it should make sense why it would be identity.\n",
    "# (Recall layer 0 is the input layer)\n",
    "g = [identity] + [sigmoid for n in N[1:]]\n",
    "\n",
    "def train_net((N, W, b, g), X, y):\n",
    "    alpha = 3.0      # Learning rate of Stochastic Gradient Descent (SGD)\n",
    "    mb_size = 10     # Mini-batch size of SGD\n",
    "    epochs = 30      # Number of iterations of SGD\n",
    "    for i in xrange(epochs):\n",
    "        W, b = sgd((N, W, b, g), X, y, alpha, mb_size)\n",
    "        print \"Done epoch\", i, \"Loss:\", loss((N, W, b, g), X, y)\n",
    "    return (N, W, b, g)\n",
    "\n",
    "N, W, b, g = train_net((N, W, b, g), X_train, y_train_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The below image shows a 7\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAADU1JREFUeJzt3XHMXfVdx/HPB9CYQVwqWduMCo+LEZcpaRiSLPWPZ0EH\nMZiyxSFjmsIUSQSdMiMdNfbpQpPOOAzq8A8orGPDbeBYu38YW/DpwsxsVYqwtUCy3Q5G+9AYINZo\nMuXrH/cU7vPw3N+5fc6995z2+34lNz3P+Z17zre3/Ty/c+7v3PtzRAhALme0XQCA6SP4QEIEH0iI\n4AMJEXwgIYIPJNQo+LavsH3I9rO2bx1XUQAmyysdx7d9hqRnJV0m6UVJ+yVdExGHlmzHjQJASyLC\ny60/q8E+L5X0XEQcliTbX5C0UdKhN2+6dWB5XtJsg8NO2ryor4l5dbe+eXW3Nmn89W0b2tLkVP88\nSc8P/PxCtQ5Ax/HmHpBQk1P9H0o6f+DnddW6ZcwPLP9Eg0NOw0zbBdSYabuAGjNtF1Aw03YBNWYa\nPr9XPeo1eXPvTEnPqP/m3hFJ+yR9KCIOLtkuFl/jA5iObeN/cy8i/s/2zZIeVf+SYefS0APopian\n+oqIRyRdOKZaAEwJb+4BCRF8ICGCDyRE8IGECD6QEMEHEiL4QEIEH0iI4AMJEXwgIYIPJETwgYQI\nPpAQwQcSIvhAQgQfSIjgAwkRfCAhgg8kRPCBhAg+kBDBBxIi+EBCBB9IiOADCRF8ICGCDyRE8IGE\nCD6QEMEHEiL4QEJnNXmy7Z6kVyW9JulHEXHpOIoCMFmNgq9+4Gcj4uVxFANgOpqe6nsM+wAwZU1D\nG5K+bnu/7RvGURCAyWt6qr8hIo7Yfpv6vwAORsTjb95sfmB5pnoAGK9e9ajXKPgRcaT685jthyVd\nKmmZ4M82OQyAkcxocae6d+iWKz7Vt/0W2+dUy2dLep+kp1e6PwDT06THXyPpYdtR7efzEfHoeMoC\nMEkrDn5EfF/S+jHWAmBKGIoDEiL4QEIEH0iI4AMJEXwgIYIPJETwgYSa3qt/+jswV2yO77nYfvj9\nbyu2H9Hbi+3v+eMDxXZ9ptysV+ZqNkBG9PhAQgQfSIjgAwkRfCAhgg8kRPCBhAg+kBDj+DXig+Vx\n+u3P1e3hWKP221U+/oaavc/+ec0Gp7sby82+KcobfGVubKV0CT0+kBDBBxIi+EBCBB9IiOADCRF8\nICGCDyTEOH4N31ge5934sb8vtu/e9aHy8zeVn3+vPlJsX3Xu/xTbt3+i2Kwt5a8D0PYXy+1N/VRN\n+6azy+1/9V81O6j5+98fv1Fs/23/Qs0BTk30+EBCBB9IiOADCRF8ICGCDyRE8IGECD6QkCPK49S2\nd0q6UtJCRFxUrVsl6YuSLpDUk3R1RLw65PkhbR1nzVjk18vNO95dbt88X27/y9mTKebk9Wra//b7\nxebv6B3F9odrdr8n5ovt+/yPNXvosm2KiGW/0GGUHv8+SZcvWbdZ0jci4kJJj0n6eLMCAUxTbfAj\n4nFJLy9ZvVHSrmp5l6SrxlwXgAla6TX+6ohYkKSIOCpp9fhKAjBp47pXv+aLy+YHlmeqB4Dx6qn+\nTZO+lQZ/wfaaiFiwvVbSS+XNZ1d4GACjm9HiTnXv0C1HPdV39Thhj6TrquVNknaPWhqA9tUG3/YD\nkv5J0s/Z/oHt6yXtkPSrtp+RdFn1M4BTRO04fuMDMI6PJv5lrti845LyvAO3frC8ez/4ZE0BX65p\n77Jm4/gATjMEH0iI4AMJEXwgIYIPJETwgYQIPpAQ36uPlv1usfX5mnH6e2r27ltr7lN5cK5mD6cn\nenwgIYIPJETwgYQIPpAQwQcSIvhAQgQfSIhxfLRqLv6m2L6rPIxfN6uAtpVvE0iLHh9IiOADCRF8\nICGCDyRE8IGECD6QEMEHEmIcH5N181yx+e0uD9TXzM2mSzbXfN5+R/n4WdHjAwkRfCAhgg8kRPCB\nhAg+kBDBBxIi+EBCjiiPg9reKelKSQsRcVG1bqukG/TGMOttEfHIkOeHtHV8FeOU8qkoj8T/t/+u\n2L7lgfL+fe1dNRUs1LSfzrYpIpa9UWKUHv8+SZcvs/6OiLi4eiwbegDdVBv8iHhc0svLNNV8NwqA\nrmpyjX+z7QO277H91rFVBGDiVnqv/l2SPhERYft2SXdI+p3hm88PLM9UDwDj1ase9VYU/Ig4NvDj\n3ZK+Wn7G7EoOA+CkzGhxp7p36JajnupbA9f0ttcOtH1A0tMj1wagdbU9vu0H1O+yz7X9A/XH5t5r\ne72k19Q/t7hxgjUCGLPa4EfEtcusvm8CteCU9M5i6y03bCu2f6Zm7/5mzeftNVfTjuVw5x6QEMEH\nEiL4QEIEH0iI4AMJEXwgIYIPJMT36qORP41DxfbtNZ/h3PK1cvv1l8+dXEEYCT0+kBDBBxIi+EBC\nBB9IiOADCRF8ICGCDyTEOD7KHporNp9XM7/9xTW794N83r4N9PhAQgQfSIjgAwkRfCAhgg8kRPCB\nhAg+kBDj+OldXWyNPyuP02+v2fslx2s2OGeuZgNMAj0+kBDBBxIi+EBCBB9IiOADCRF8ICGCDyRU\nO45ve52kz0paI+k1SXdHxF/bXiXpi5IukNSTdHVEvDrBWrEiP1lsjZveVWzf/uny3resL7d7LZ+3\n76JRevz/lXRLRLxL0nsk3WT75yVtlvSNiLhQ0mOSPj65MgGMU23wI+JoRByolo9LOihpnaSNknZV\nm+2SdNWkigQwXid1jW97RtJ6Sd+WtCYiFqT+LwdJq8ddHIDJGPlefdvnSHpI0kcj4rjtpRdvhYu5\n+YHlmeoBYLx61aPeSMG3fZb6ob8/InZXqxdsr4mIBdtrJb00fA+zIxUDoIkZLe5U9w7dctRT/Xsl\nfTci7hxYt0fSddXyJkm7lz4JQDeNMpy3QdKHJT1l+wn1T+lvk/RJSV+y/RFJh1X3+U4AnVEb/Ij4\nlqQzhzT/ynjLwditvaXYvP3TH2u0e99eM05/5Vyj/WMyuHMPSIjgAwkRfCAhgg8kRPCBhAg+kBDB\nBxLie/VPeXPF1vixZt+L/0TcX97AdXtAF9HjAwkRfCAhgg8kRPCBhAg+kBDBBxIi+EBCjOOf4j4V\nv19s314exq/1D+//rZot5podAK2gxwcSIvhAQgQfSIjgAwkRfCAhgg8kRPCBhBjH77o/mSs2/6LL\nA/X7xlgKTh/0+EBCBB9IiOADCRF8ICGCDyRE8IGEaoNve53tx2x/x/ZTtv+gWr/V9gu2/616XDH5\ncgGMgyPK85vbXitpbUQcsH2OpH+VtFHSb0r6z4i4o+b5IW0dV73p/F6sKraf7z9qtP8t68vtfqX8\n/0O9uUbHxyRtU0Qse6NH7Q08EXFU0tFq+bjtg5LOq5obfs0DgDac1DW+7RlJ6yX9c7XqZtsHbN9j\n+61jrg3AhIwc/Oo0/yFJH42I45LukvSOiFiv/hlB8ZQfQHeMdK++7bPUD/39EbFbkiLi2MAmd0v6\n6vA9zA8sz1QPAOPVqx71Rv2Qzr2SvhsRd55YYXttdf0vSR+Q9PTwp8+OeBgAKzejxZ3q3qFb1gbf\n9gZJH5b0lO0nJIWk2yRda3u9pNfU/zVz40rLBTBdo7yr/y1JZy7T9Mj4ywEwDXwe/zS3peZr8f25\nJ2v2MDeuUtAh3LILJETwgYQIPpAQwQcSIvhAQgQfSIjgAwnVfh6/8QH4PD7QkuGfx6fHBxIi+EBC\nBB9IqIXg96Z/yJPSa7uAGr22C6jRa7uAgl7bBdToTe1IBP9Nem0XUKPXdgE1em0XUNBru4Aavakd\niVN9ICGCDyQ0pXF8AG0YNo4/8eAD6B5O9YGECD6Q0NSCb/sK24dsP2v71mkdd1S2e7aftP2E7X0d\nqGen7QXb/z6wbpXtR20/Y/trbc5eNKS+zkykusxkr39Yre/Ea9j2ZLRTuca3fYakZyVdJulFSfsl\nXRMRhyZ+8BHZ/p6kd0fEy23XIkm2f1nScUmfjYiLqnWflPQfEfEX1S/PVRGxuUP1bdUIE6lOQ2Gy\n1+vVgdew6WS0TU2rx79U0nMRcTgifiTpC+r/JbvE6tClT0Q8LmnpL6GNknZVy7skXTXVogYMqU/q\nyESqEXE0Ig5Uy8clHZS0Th15DYfUN7XJaKf1H/08Sc8P/PyC3vhLdkVI+rrt/bZvaLuYIVZHxIL0\n+izGq1uuZzmdm0h1YLLXb0ta07XXsI3JaDvTw3XAhoi4WNKvSbqpOpXtuq6NxXZuItVlJntd+pq1\n+hq2NRnttIL/Q0nnD/y8rlrXGRFxpPrzmKSH1b886ZoF22uk168RX2q5nkUi4li88abR3ZJ+qc16\nlpvsVR16DYdNRjuN13Bawd8v6WdtX2D7xyVdI2nPlI5dy/Zbqt+8sn22pPepOAno1FiLr/f2SLqu\nWt4kaffSJ0zZovqqIJ1QM5HqVLxpsld16zVcdjLagfaJvYZTu3OvGpa4U/1fNjsjYsdUDjwC2z+j\nfi8f6k8r9vm267P9gPrTDJ8raUH97y/7iqQHJf20pMOSro6IVzpU33vVv1Z9fSLVE9fTLdS3QdI3\nJT2l/r/ricle90n6klp+DQv1XaspvIbcsgskxJt7QEIEH0iI4AMJEXwgIYIPJETwgYQIPpAQwQcS\n+n+hOG8O0VrVwgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x20c74400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My net: 7\n",
      "\n",
      "===========================\n",
      "\n",
      "The below image shows a 2\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkSrVPDsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2066f2b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My net: 2\n",
      "\n",
      "===========================\n",
      "\n",
      "The below image shows a 1\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwZcKMvhSQQZfKuj/ARk4OtrWahK6AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xf546c18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My net: 1\n",
      "\n",
      "===========================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Visually inspect the results of the trained neural network\n",
    "for image, out in test_data[0:3]:\n",
    "    print_data_point(image, out)\n",
    "    print \"My net:\", compute((N, W, b, g), image.ravel()).argmax()\n",
    "    print \"\\n===========================\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num correct: 9503 of 10000 images\n",
      "Accuraccy: 0.9503\n"
     ]
    }
   ],
   "source": [
    "# Compute how well the network does on the test set.\n",
    "my_correct = [(image, pred, actual) for image, actual in zip(X_test, y_test.ravel()) if compute((N, W, b, g), image).argmax() == actual]\n",
    "print \"Num correct:\", len(my_correct), \"of\", X_test.shape[0], \"images\"\n",
    "print \"Accuraccy:\", float(len(my_correct)) / float(X_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The neural net that we have programmed here is defined by `N`, `W`, `b`, and `g`. We can save and load it with the earlier functions like such:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save_net((N, W, b, g), \"theory_net.pkl\")\n",
    "# N, W, b, g = load_net(\"theory_net.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Reading\n",
    "\n",
    "This tutorial covers chapters 1 and 2 of [Michael Nielsen's free online book](http://neuralnetworksanddeeplearning.com/index.html). Following this tutorial, you can start reading from [chatper 3](http://neuralnetworksanddeeplearning.com/chap3.html).\n",
    "\n",
    "### References\n",
    "\n",
    "* \"10-807 Neural Network I\" PowerPoint, by Russ Salakhutdinov, CMU Machine Learning Department\n",
    "* [A Neural Network in 11 lines of Python (Part 1)](http://iamtrask.github.io/2015/07/12/basic-python-network/), by iamtrask\n",
    "* \"15-381 Deep Learning\" PowerPoint, by Emma Brunskill, CMU CS Department"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
