{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PredictionIO\n",
    "This tutorial will introduce you to a machine learning framework that allows you to rapidly deploy multiple engines - PredictionIO. Say for instance you were a data scientist trying to deploy multiple algorithms \"into the wild\" in order to test their performance - you would have to set up multiple endpoints for incoming data points, and then needlessly rewrite a lot of boilerplate code in processing data, setting up engines, and evaluating performance. PredictionIO aims to get all of this functionality into the same place, allowing you to remove the non-trivial obstacles when it comes to deployment. It is generally used with Scala, which combines Java's object-oriented paradigm with characteristics of a functional language - in this tutorial, however, we cover usage with a Python SDK.\n",
    "\n",
    "## Setup\n",
    "Installing the library consists of two parts: installing the PredictionIO application, and installing the Python SDK.\n",
    "\n",
    "### Manual Setup\n",
    "Currently, automatic setup using a package manager (such as Homebrew on Mac OS) is a little buggy and doesn't seem to work. Thus, manual setup is preferred, and is detailed [here](http://predictionio.incubator.apache.org/install/install-sourcecode/). A note that I personally prefer using HBase and Elasticsearch (as opposed to PostgreSQL), as I have observed PostgreSQL to be slightly glitchy. In order to make the change, navigate to the directory where you installed PredictionIO, and navigate to the `conf/pio-env.sh` file and change the properties labeled `PIO_STORAGE_REPOSITORIES_<REPO_TYPE>_SOURCE` - where `REPO_TYPE` is any of `METADATA`,`EVENTDATA`, or `MODELDATA` - to `ELASTICSEARCH`, `HBASE`, and `LOCALFS` respectively. For your convenience, a sample `pio-env.sh` file has been included with this tutorial, which should require very few (if any) changes in order to work. \n",
    "\n",
    "After installing PredictionIO, test that your setup works by navigating to the `bin/` directory of your PredictionIO installation (or adding it to your `PATH`) and typing\n",
    "\n",
    "`$ pio-start-all`\n",
    "\n",
    "After your prompt appears again, you can check the status of PredictionIO by typing\n",
    "\n",
    "`$ pio status`\n",
    "\n",
    "If everything is OK, the output should indicate that your system is all ready to go; otherwise, troubleshoot using the [FAQ page](http://predictionio.incubator.apache.org/resources/faq/)\n",
    "\n",
    "### Python SDK\n",
    "Installing the Python SDK is a much shorter process, and just requires using Python's built in package manager, `pip`. To install the module, you can use\n",
    "\n",
    "`$ pip install predictionio`\n",
    "\n",
    "This should install the package for Python, but in case you want to do it manually, you can also access the Github repository for the Python SDK [here](https://github.com/apache/incubator-predictionio-sdk-python). After cloning the repo, navigate to the project root and run \n",
    "\n",
    "`$ python setup.py install`\n",
    "\n",
    "After installation, you can check that you've successfully added the module to your Python distribution by running the following code (which should throw an exception otherwise):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Related to the code, but not to PredictionIO\n",
    "import json\n",
    "import numpy as np\n",
    "import pprint\n",
    "import pytz\n",
    "import random\n",
    "from datetime import datetime\n",
    "\n",
    "# PredictionIO-specific; Client classes imported for brevity\n",
    "import predictionio as pio\n",
    "from predictionio import EventClient, EngineClient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommendation Engine Template\n",
    "We will demo PredictionIO using a ready-made recommendation engine (referred to PIO as \"templates\"). Navigate to a directory where you would want to place the engine, and type\n",
    "\n",
    "`$ pio template get apache/incubator-predictionio-template test`\n",
    "\n",
    "This creates a new directory called `test`, containing the engine template. Navigate to this new directory, and run \n",
    "\n",
    "`pio app new test`\n",
    "\n",
    "This should output something along the lines of "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "...\n",
    "[INFO] [App$] Initialized Event Store for this app ID: 1.\n",
    "[INFO] [App$] Created new app:\n",
    "[INFO] [App$]       Name: test\n",
    "[INFO] [App$]         ID: 1\n",
    "[INFO] [App$] Access Key: aM0e6FtMBN6FA0xgI_9_2LXUIEjV5aBqMAQ9A_Y889MeIHxZE1qMUR4rVLNCy3Qf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procedure \n",
    "### Importing data using Python\n",
    "PredictionIO represents data using two concepts: \"entities\" and \"events\". Entities are abstractions for real-world objects (e.g., users), and events are the actions that they perform (e.g., liking/rating a post, or signing in). We first create an EventClient to our app.\n",
    "\n",
    "For data representation, PredictionIO has as its core the concepts of \"events\" and \"entities\". Entities are abstractions for real-world objects such as users, and entities are the actions that they perform (e.g., liking a post, giving a post a rating, or signing in). Events come in two different flavors: generic events, which are performed by an entity (potentially on a target entity) and special events which record changes to an entity's properties. In order for us to access this functionality in Python, we first create an EventClient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# replace with your own access key that you got from running 'pio app new test'\n",
    "event_client = pio.EventClient(access_key='aM0e6FtMBN6FA0xgI_9_2LXUIEjV5aBqMAQ9A_Y889MeIHxZE1qMUR4rVLNCy3Qf', threads=5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This allows us to start adding events, which take on two forms: generic events, which are performed by an entity (potentially on a target entity), and special events which record changes to an entity's properties. These special events also allow us to create entities - this is why there is no `EntityClient`.\n",
    "\n",
    "We now add entities (i.e., users) to our event server. Each entity has a set of properties - to keep it simple, \n",
    "\n",
    "We then want to add entities (in this case, users) to our event server in order to act as entities for the events that we want to create. \n",
    "\n",
    "Additionally, we would like a set of properties to be associated with each user. In order to set this in our Python program, we can simply create a special dictionary where the keys are our entity property names, and set them to the values that we wish.\n",
    "\n",
    "In order to communicate with the server, our client can make two types of requests: synchronous and asynchronous. Asynchronous calls are much faster, but give back a slightly different result (of type `predictionio.AsyncRequest`). Synchronous calls will simply block until they are completed - as expected. For comparison, we add a million users with a property named `popularity` to our event server, given some random integer value from 0 to 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'creationTime': u'2016-11-04T17:15:18.562Z',\n",
      " u'entityId': u'u1',\n",
      " u'entityType': u'user',\n",
      " u'event': u'$set',\n",
      " u'eventId': u'Z0813DMQIKz7N4VGxZhmngAAAVgwVmaRi7wMA2LBwQI',\n",
      " u'eventTime': u'2016-11-04T17:15:18.545Z',\n",
      " u'properties': {u'popularity': 89}}\n",
      "\n",
      "{u'creationTime': u'2016-11-04T17:15:18.886Z',\n",
      " u'entityId': u'u28',\n",
      " u'entityType': u'user',\n",
      " u'event': u'$set',\n",
      " u'eventId': u'1UisRWSy-wCp-lStTgdKbAAAAVgwVmfklr6M8VFQ5AI',\n",
      " u'eventTime': u'2016-11-04T17:15:18.884Z',\n",
      " u'properties': {u'popularity': 94}}\n"
     ]
    }
   ],
   "source": [
    "# capture the results of calling set_user so that we can find the IDs later.\n",
    "async_event_results = []\n",
    "event_results = []\n",
    "\n",
    "# asynchronous requests\n",
    "for i in xrange(30):\n",
    "    user_id = 'u' + str(i)\n",
    "    user_properties = {}\n",
    "    user_properties['popularity'] = random.randint(0, 100)\n",
    "    async_event_result = event_client.aset_user(user_id, properties=user_properties)\n",
    "    async_event_results.append(async_event_result)\n",
    "# event_client.close() # this line will cause asynchronous requests to block until they are completed.\n",
    "\n",
    "# check an asynchronous result\n",
    "event_result = random.choice(async_event_results)\n",
    "\n",
    "try:\n",
    "    async_response = event_result.get_response() # blocks until complete\n",
    "    json_body = json.loads(async_response.__dict__['body']) \n",
    "    event_id = json_body['eventId']\n",
    "    pprint.pprint(event_client.get_event(event_id))\n",
    "except:\n",
    "    print('Encountered an error while trying to get the asynchronous response.')\n",
    "\n",
    "print\n",
    "    \n",
    "# synchronous requests\n",
    "for i in xrange(30):\n",
    "    user_id = 'u' + str(i)\n",
    "    user_properties = {}\n",
    "    user_properties['popularity'] = random.randint(0, 100)\n",
    "    try:\n",
    "        event_result = event_client.set_user(user_id, properties=user_properties)\n",
    "        event_results.append(event_result)\n",
    "    except: \n",
    "        # can log the error here\n",
    "        print('Encountered an error making a synchronous request to the event server.')\n",
    "\n",
    "# check a random user to ensure correctness\n",
    "event_result = random.choice(event_results)\n",
    "json_body = json.loads(event_result.__dict__['body'])\n",
    "event_id = json_body['eventId']\n",
    "pprint.pprint(event_client.get_event(event_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to re-set any user's properties at a later time, we can re-use our `set_user` method. Suppose there were a user who rated 100/100 in popularity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_properties = {}\n",
    "user_properties['popularity'] = 100\n",
    "\n",
    "try:\n",
    "    event_result = event_client.set_user(user_id, properties=user_properties)\n",
    "    json_body = json.loads(event_result.__dict__['body'])\n",
    "except:\n",
    "    print('Error when trying to set user on event server.')\n",
    "\n",
    "user_id = json_body['eventId']\n",
    "user = event_client.get_event(user_id) \n",
    "pprint.pprint(user)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can proceed with adding events to PredictionIO. Each event has a custom name (continuing with our users example, suppose we want to represent a user signing up, with some given source. Events can also take a timestamp, which we can extract from our data (here we just set it equal to the current time).\n",
    "\n",
    "The engine template that we are currently using can take in two different types of events: **rate** and **buy**, which represent a user rating an item and a user buying an item, respectively. \n",
    "\n",
    "Similar to user creation, event creation takes places asynchronously or synchronously. To keep it simple, we use the synchronous method in order to add events. Here, we create two events representing a user giving an item a rating of 5, and subsequently purchasing it.\n",
    "\n",
    "We would then create an event using the `acreate_event` and `create_event` methods in our `EventClient` (asynchronous and synchronous calls as before; for brevity's sake we won't repeat the same tests for creating events). As with entities, events can have properties too, but they also require identification for the associated entity, which would consist of the entity id (from our previous code, some value between 0 and 1000000), as well as the entity type (which we implicitly set to `user` with our `set_user` calls). Here we create a single event representing a random user signing up. For every event we create, we also want to record the event id, so that we can get the event "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "timestamp = datetime.utcnow().replace(tzinfo=pytz.UTC) # need to add timezone info\n",
    "event_result = event_client.create_event(event='rate', entity_type='user', entity_id=user['entityId'],\n",
    "                                         target_entity_type='item', target_entity_id='i0', \n",
    "                                         properties={ 'rating': float(5) }, event_time = timestamp).__dict__\n",
    "\n",
    "# sanity check \n",
    "json_body = json.loads(event_result['body'])\n",
    "event_id = json_body['eventId']\n",
    "pprint.pprint(event_client.get_event(event_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the process is clear, we want to speed up the process of importing data into our event server. As sample data for our engine template, we use our provided `sample_data.txt`, where each line is of the format `<user_id>::<item_id>::<rating>`. For demo purposes, we also include randomly introduced `buy` events mixed in with our sample data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "event_results = []\n",
    "\n",
    "def import_events(file_name):\n",
    "    with open(file_name) as f:\n",
    "        for line in f:\n",
    "            data = line.split('::')\n",
    "            if (random.choice([True, False])): # randomly introduce buy events\n",
    "                event_results.append(event_client.create_event(event='buy', entity_type='user', entity_id=data[0],\n",
    "                                                               target_entity_type='item', \n",
    "                                                               target_entity_id=data[1]).__dict__)\n",
    "            else:\n",
    "                event_results.append(event_client.create_event(event='rate', entity_type='user', entity_id=data[0],\n",
    "                                                               target_entity_type='item', target_entity_id=data[1],\n",
    "                                                               properties={ 'rating': float(data[2]) }).__dict__)\n",
    "\n",
    "import_events('sample_data.txt')\n",
    "print(len(event_results))\n",
    "pprint.pprint(event_results[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interfacing with our engine template\n",
    "\n",
    "Now that we have successfully imported all of our data, we can now interface with our engine template. First we setup our engine template as a local server, modifying a line in the `engine.json` file that is in our engine template directory.\n",
    "\n",
    "```\n",
    "...\n",
    "\"datasource\": {\n",
    "  \"params\": {\n",
    "    \"appName\": \"test\"\n",
    "  }\n",
    "},\n",
    "...\n",
    "```\n",
    "\n",
    "Now, we deploy our server with a series of shell commands (make sure that you are still in the `test` directory)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "$ pio build --verbose\n",
    "...\n",
    "[INFO] [RegisterEngine$] Registering engine re70zzSVWbXjZ1Zk5dy4PDQWksgn9SYV 5e406419fc85bdfc00e9eaebd83b658fa6b35062\n",
    "[INFO] [Console$] Your engine is ready for training.\n",
    "\n",
    "$ pio train \n",
    "...\n",
    "[INFO] [CoreWorkflow$] Inserting persistent model\n",
    "[INFO] [CoreWorkflow$] Updating engine instance\n",
    "[INFO] [CoreWorkflow$] Training completed successfully.\n",
    "\n",
    "$ pio deploy\n",
    "...\n",
    "[INFO] [MasterActor] Undeploying any existing engine instance at http://0.0.0.0:8000\n",
    "[WARN] [MasterActor] Nothing at http://0.0.0.0:8000\n",
    "[INFO] [HttpListener] Bound to /0.0.0.0:8000\n",
    "[INFO] [MasterActor] Engine is deployed and running. Engine API is live at http://0.0.0.0:8000."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create a client to our engine, using the default url for the engine (this parameter is more important when we deploy multiple engines simultaneously)."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "engine_client = EngineClient(url='http://localhost:8000')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now send a request to the server in order to retrieve recommendations for items for a single user, ranked by the score that the engine gives them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query_properties = { 'user': str(random.choice(range(30))), 'num': random.randint(1,5)}\n",
    "query_result = engine_client.send_query(query_properties)\n",
    "pprint(query_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, we can access a web interface for our server at http://localhost:8000, which gives you server information along with engine information.\n",
    "\n",
    "## Census Data\n",
    "\n",
    "We now look at sample data provided to us in class. In the previous homework, we looked at publicly available census data when implementing a Naive Bayes classifier. We look at the same data, except with only three extracted features (for brevity's sake). There is another engine template, titled `classification`, available [here](https://www.dropbox.com/sh/gfalmgeky5ubtlo/AACA04uErXZxNsq8CcFgga_9a?dl=0). Copy this into a directory of your choice; the rest of the tutorial takes place within this directory. We first read in the data, as with the previous assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age        work_class  final_weight  education  education_num  \\\n",
      "0   39         State-gov         77516  Bachelors             13   \n",
      "1   50  Self-emp-not-inc         83311  Bachelors             13   \n",
      "2   38           Private        215646    HS-grad              9   \n",
      "3   53           Private        234721       11th              7   \n",
      "4   28           Private        338409  Bachelors             13   \n",
      "\n",
      "       marital_status         occupation   relationship   race     sex  \\\n",
      "0       Never-married       Adm-clerical  Not-in-family  White    Male   \n",
      "1  Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
      "2            Divorced  Handlers-cleaners  Not-in-family  White    Male   \n",
      "3  Married-civ-spouse  Handlers-cleaners        Husband  Black    Male   \n",
      "4  Married-civ-spouse     Prof-specialty           Wife  Black  Female   \n",
      "\n",
      "   capital_gain  capital_loss  hours_per_week native_country  label  \n",
      "0          2174             0              40  United-States      0  \n",
      "1             0             0              13  United-States      0  \n",
      "2             0             0              40  United-States      0  \n",
      "3             0             0              40  United-States      0  \n",
      "4             0             0              40           Cuba      0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('census.csv')\n",
    "df = df[(df.occupation!='?') & (df.native_country!='?') & (df.work_class!='?')]\n",
    "df['label'] = df['income'].map({'<=50K': 0, '>50K': 1})\n",
    "del df['income']\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "# replace this with your own access key!\n",
    "event_client = EventClient(access_key='Tjbr4B3_O0hmZxLdHARhOgTA9gXBKWXiKxxcBshILruTUxF7qibOcsejgqo4v4Yl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use age, final_weight, and education_num as our features to our naive Bayes classifier. With each person representing a single data point, we create entities on our event server of type \"person\" - thus adding entirely different data points without touching our previous \"users\". Note that this also allows us to re-use data with a different engine (one that we wrote, for instance). Our method calls are also slightly different from the previous example - for custom entity types, we need to set the event type as `$set`, a special value that PredictionIO uses for the (implicit) creation of entities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "event_results = []\n",
    "count = 1\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    person_properties = { 'age': row.age, 'finalWeight': row.final_weight, \n",
    "                         'educationNum': row.education_num, 'label': row.label }\n",
    "    event_result = event_client.acreate_event(event='$set', entity_type='person', \n",
    "                                              entity_id=count, properties=person_properties)\n",
    "    event_results.append(event_result)\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'eventId': u'aOXP92IPt8aN_f82z-CNtgAAAVgwXMc1gCqFk97Uykw', u'eventTime': u'2016-11-04T17:22:16.501Z', u'entityType': u'person', u'creationTime': u'2016-11-04T17:22:45.473Z', u'properties': {u'age': 39, u'finalWeight': 124090, u'educationNum': 5, u'label': 0}, u'entityId': u'4725', u'event': u'$set'}\n"
     ]
    }
   ],
   "source": [
    "# sanity check, as usual\n",
    "event_result = random.choice(event_results)\n",
    "async_response = event_result.get_response()\n",
    "json_body = json.loads(async_response.__dict__['body'])\n",
    "print(event_client.get_event(json_body['eventId']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it! We can now run `pio train` as before, and run `pio deploy` in the following manner:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "$ pio deploy --port 8001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This deploys the PredictionIO server on a different port, allowing for multiple servers to be deployed at the same time. We can now make requests to our engine using a different engine client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'label': 1.0}\n"
     ]
    }
   ],
   "source": [
    "engine_client = EngineClient(url='http://localhost:8001')\n",
    "\n",
    "# sample query result\n",
    "query_result = engine_client.send_query({ 'age': 24.0, 'finalWeight': 10.0, 'educationNum': 9.0 })\n",
    "print(query_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now test the accuracy of the engine on the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  1.  0. ...,  1.  0.  0.]\n",
      "0.412273721902\n"
     ]
    }
   ],
   "source": [
    "predictions = np.array([])\n",
    "# testing accuracy on training set\n",
    "for _, row in df.iterrows():\n",
    "    prediction = engine_client.send_query({'age': row.age, \n",
    "                                           'finalWeight': row.final_weight, \n",
    "                                           'educationNum': row.education_num})\n",
    "    predictions = np.append(predictions, prediction['label'])\n",
    "\n",
    "print(predictions)\n",
    "print(float(sum(predictions != df['label'])) / len(df['label']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it seems that our engine needs a bit of tweaking, or needs to use different features. However, hopefully this has demonstrated how easily and quickly servers can be deployed using PredictionIO."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
