{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pattern\n",
    "Pattern is a python web mining module with tools for data mining, natural language processing, machine learning and network analysis. In the whole process of web mining, data scientists usually first collect data, then parse and store data, then extract information and apply machine learning techniques to gain insights. Pattern contains several modules each of which takes care one of those processes in the web mining pipeline. You can view **pattern** as a collection of commonly used tools in web mining packed together into a library. Basically, **pattern** is more user-friendly in the sense that it provides a more high-level api for doing the usual tasks in web mining than existing libraries.\n",
    "\n",
    "This tutorial will introduce you some basic usage of **pattern** on collecting data from the web and storing data.\n",
    "Due the length restriction, this tutorial is only involved with modules listed below.\n",
    "## Modules\n",
    "- [pattern.web](http://www.clips.ua.ac.be/pages/pattern-web)\n",
    "- [pattern.db](http://www.clips.ua.ac.be/pages/pattern-db)\n",
    "\n",
    "The following topics will be covered in the tutorial.\n",
    "- [Installation](#Installation)\n",
    "- [Collect Data](#Collect-Data) with **pattern**\n",
    "- [Store Data](#Store-Data) with **pattern**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pattern can be easily installed with **pip**:\n",
    "\n",
    "    $ pip install pattern\n",
    "    \n",
    "Note that **pattern** is only available in Python 2.5+ (no support for Python 3 yet)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect Data\n",
    "This section involves several basic usages of **pattern** web module for collecting data on the web.\n",
    "\n",
    "- [API call](#API-call)\n",
    "- [HTML DOM Parser](#HTML-DOM-Parser)\n",
    "- [Crawler](#Crawler)\n",
    "\n",
    "## API call\n",
    "The **pattern** web module provides API calls that can invoke asynchronuous requests to API of useful sources of data on the web: Twitter, Google, Facebook, Wikipedia, and etc, and it also contains APIs for the web services from those data sources, such as Google search, Google translate, and etc. Also, after receiving data from the data sources, **pattern** web module automatically parses and stores the data into *result* objects that are easy to use. Basically, a *result* object contains the following attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "From the official site:\n",
    "```Python\n",
    "result.url                  # URL of content associated with the given query.\n",
    "result.title                # Content title.\n",
    "result.text                 # Content summary.\n",
    "result.language             # Content language.\n",
    "result.author               # Content author. (if there is one)\n",
    "result.date                 # Content date. (if there is one)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will see several examples of using the **pattern** web module below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Twitter\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pattern.web import Twitter, hashtags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the most recent tweets based on some keywords from Twitter, we first initialize a *Twitter* object, which contains a useful method called *search*. The *search* function takes several argument:\n",
    "- *query* (str): the keyword for querying\n",
    "- *start* (int): the id of tweet started on\n",
    "- *count* (int): number of results to be returned\n",
    "- *cached* (bool): whether to cache the results or not\n",
    "\n",
    "The results return from calling *search* will be a list of *result* objects mentioned above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://twitter.com/WhiteStorm14ws/status/794676621345050624\n",
      "WhiteStorm14ws\n",
      "#Trump  #Trump2016 #MAGA  #BuildTheWall #MakeAmericaGreatAgain https://t.co/Hsl3vHIsGT\n",
      "\n",
      "Fri Nov 04 23:04:05 +0000 2016\n",
      "[u'#Trump', u'#Trump2016', u'#MAGA', u'#BuildTheWall', u'#MakeAmericaGreatAgain']\n",
      "https://twitter.com/Outofnames/status/794676615200591872\n",
      "Outofnames\n",
      "RT @SandraTXAS: 'Hillary Clinton &amp; ISIS funded by same money' - Assange \n",
      "#WikiLeaks\n",
      "#SpiritCooking\n",
      "#Hillary #ImWithHer not!  \n",
      "#MAGA #Trump…\n",
      "\n",
      "Fri Nov 04 23:04:04 +0000 2016\n",
      "[u'#WikiLeaks', u'#SpiritCooking', u'#Hillary', u'#ImWithHer', u'#MAGA', u'#Trump']\n",
      "https://twitter.com/hopefulfornow/status/794676614319796226\n",
      "hopefulfornow\n",
      "RT @_AnimalAdvocate: #Retweet if this gives you that #FridayFeeling!\n",
      "We've got to land a knockout blow to #Trump on #VotingDay\n",
      "or he'll be…\n",
      "\n",
      "Fri Nov 04 23:04:03 +0000 2016\n",
      "[u'#Retweet', u'#FridayFeeling', u'#Trump', u'#VotingDay']\n",
      "https://twitter.com/KnucklDraginSam/status/794676613132722177\n",
      "KnucklDraginSam\n",
      "RT @WDFx2EU7: #SpiritCooking and so, #WW3 begins. @POTUS needs this to stop a #Trump win otherwise the #NWO will ax him &amp; @HillaryClinton h…\n",
      "\n",
      "Fri Nov 04 23:04:03 +0000 2016\n",
      "[u'#SpiritCooking', u'#WW3', u'#Trump', u'#NWO']\n",
      "https://twitter.com/cp2austin/status/794676612537192448\n",
      "cp2austin\n",
      "FBI examining fake documents targeting #Hillary.\n",
      "Russia probable authors for #Trump.\n",
      "Where's #Comey now?\n",
      "#hardball… https://t.co/HMd37FXR0b\n",
      "\n",
      "Fri Nov 04 23:04:03 +0000 2016\n",
      "[u'#Hillary', u'#Trump', u'#Comey', u'#hardball']\n",
      "https://twitter.com/occtoys/status/794676612335865856\n",
      "occtoys\n",
      "RT @JacloPac: Another #Trump success story, 4yrs aft opening, Trump International Hotel, Toronto is in bankruptcy ct. America can't afford…\n",
      "\n",
      "Fri Nov 04 23:04:03 +0000 2016\n",
      "[u'#Trump']\n",
      "https://twitter.com/akalayci34/status/794676608267329536\n",
      "akalayci34\n",
      "RT @dwnews: What would a #Trump or #Clinton presidency mean for #Iran? https://t.co/6nKLI8fYNU https://t.co/2BzQOc9cN5\n",
      "\n",
      "Fri Nov 04 23:04:02 +0000 2016\n",
      "[u'#Trump', u'#Clinton', u'#Iran']\n",
      "https://twitter.com/SOLZem1234/status/794676604664512512\n",
      "SOLZem1234\n",
      "RT @Mike_Beacham: Eisenhower warned about them. \n",
      "Kennedy attempted to dismantle them. \n",
      "Johnson thru Obama bowed to them.\n",
      "#TRUMP has now vow…\n",
      "\n",
      "Fri Nov 04 23:04:01 +0000 2016\n",
      "[u'#TRUMP']\n",
      "https://twitter.com/YZeducatesU/status/794676604463153157\n",
      "YZeducatesU\n",
      "RT @KitDaniels1776: The same media that fakes crime scenes with fake police tape wants you to believe #Trump is losing. #tcot #AltRight #Dr…\n",
      "\n",
      "Fri Nov 04 23:04:01 +0000 2016\n",
      "[u'#Trump', u'#tcot', u'#AltRight', u'#Dr']\n"
     ]
    }
   ],
   "source": [
    "tweets = []\n",
    "\n",
    "for tweet in Twitter().search(\"#Trump OR #Clinton\", start=prev, count=10, cached=False):\n",
    "    print tweet.url\n",
    "    print tweet.author\n",
    "    print tweet.text\n",
    "    print tweet.like\n",
    "    print tweet.date\n",
    "    print hashtags(tweet.text) # get the list of # keywords in a tweet\n",
    "    tweets.append(tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pattern.web import Google"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may also use the Google search engine directly, in a way similar to using Twitter above. Note that to perform unlimited search using Google requires a license, otherwise the daily allowed number of queries is 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.donaldjtrump.com/\n",
      "Official campaign site of the Republican nominee in 2016 for U.S. President.\n",
      "https://twitter.com/realdonaldtrump?lang=en\n",
      "33.9K tweets • 1859 photos/videos • 12.9M followers. Check out the latest Tweets <br>\n",
      "from Donald J. <b>Trump</b> (@realDonaldTrump)\n",
      "https://en.wikipedia.org/wiki/Donald_Trump\n",
      "Donald John <b>Trump</b> (born June 14, 1946) is an American businessman, <br>\n",
      "television producer, and politician who is the Republican Party nominee for <br>\n",
      "President of&nbsp;...\n",
      "https://www.facebook.com/DonaldTrump/?fref=ts\n",
      "This is the official Facebook page for Donald J. <b>Trump</b>.\n",
      "http://www.trump.com/\n",
      "<b>Trump</b> Luxury Real Estate redefines what is meant by luxury living, built to be the <br>\n",
      "absolute best in the world.\n"
     ]
    }
   ],
   "source": [
    "engine = Google(license=None, language='en')\n",
    "\n",
    "for result in engine.search('Trump', count=5, cached=False):\n",
    "    print result.url\n",
    "    print result.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HTML DOM Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pattern.web import URL, DOM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The HTML DOM parser  is helpful and user-friendly to get data in a html string. First, we initialize a *URL* object with a url string, which contains a *download* method. By invoking the *download* method, **pattern** sends a GET request to the given url and download the whole html file in the form of a string. Then, we take the html string and initialize a *Element* object by calling the *DOM* function. An *Element* object represents the current hierarchy of the html string, and it contains several useful attributes and methods:\n",
    "\n",
    "From the official website:\n",
    "```Python\n",
    "element.tag                 # Tag name.\n",
    "element.attrs               # Dictionary of attributes, e.g. {'class':'comment'}.\n",
    "element.id                  # Value for id attribute (or None).\n",
    "element.source              # HTML source code in string\n",
    "element.content             # HTML source minus open and close tag.\n",
    "element.by_id(str)          # First nested Element with given id.\n",
    "element.by_tag(str)         # List of nested Elements with given tag name.\n",
    "element.by_class(str)       # List of nested Elements with given class.\n",
    "element.by_attr(**kwargs)   # List of nested Elements with given attribute.\n",
    "element(selector)           # List of nested Elements matching a CSS selector.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sadly, there are some information that the results from *Twitter search* do not record. For example, the full name of a twitter user is not recorded in a *result* object. Now, we try to extract the full name of a twitter user. Actually, the html file of a twitter page is quite complex. For simplicity, we extract the fullname of the last user appear in the page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brook Harty is IronWolve\n",
      "Derinda simpson is noseygirl63\n",
      "KMA is KMA0111\n",
      "Correct The Record is CorrectRecord\n",
      "Correct The Record is CorrectRecord\n",
      "KMA is KMA0111\n",
      "BbayBop is BbayBop\n",
      "Thersa is Thersas1\n",
      "Thersa is Thersas1\n",
      "JanneW10_Messi is _JanneW10\n"
     ]
    }
   ],
   "source": [
    "twitters = []\n",
    "\n",
    "def extract_fullname(url):\n",
    "    dom = DOM(URL(url).download()) # download the html string\n",
    "    fullname = dom.body.by_class(\"fullname\")[-1].content # the last element with class \"fullname\"\n",
    "    username = dom.body.by_class(\"username\")[-1].by_tag(\"b\")[0].content # the last element with class \"username\"\n",
    "    return username, fullname\n",
    "    \n",
    "for tweet in tweets:\n",
    "    username, fullname = extract_fullname(tweet.url)\n",
    "    twitters.append((username, fullname))\n",
    "    print fullname, \"is\", username"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crawler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pattern.web import Crawler, LIFO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A web crawler is program that systematically visit web pages. Basically, it starts from certain web pages, looks for url links inside those web pages and then go to those web pages behind the links, and repeat this process. The **pattern** web package contains the *Crawler* class that allows us to write crawler programs.\n",
    "\n",
    "A *crawler* object maintains a list of url links to be visited. When the *crawl* function is called, it will visit the first link in the list. When a link is visited, the function *visit* will be called, otherwise *fail* will be called, both of which a *link* object is passed as an argument. \n",
    "\n",
    "A *link* object describes the url it is linked to and the referrer url it is from.\n",
    "\n",
    "from the official site:\n",
    "```\n",
    "crawler = Crawler(links=[], domains=[], delay=20.0, sort=FIFO)\n",
    "```\n",
    "\n",
    "```Python\n",
    "crawler.history                       # Dictionary of (domain, time last visited)-items.\n",
    "crawler.visited                       # Dictionary of URLs visited.\n",
    "crawler.crawl(method=DEPTH)           # DEPTH (depth first search) | BREADTH (breath first search) | None.\n",
    "crawler.visit(link, source=None)\n",
    "crawler.fail(link)\n",
    "```\n",
    "\n",
    "```Python\n",
    "link.url                    # Parsed from <a href=''> attribute.\n",
    "link.referrer               # Parent web page URL.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "For illustration purpose, we create a simple crawler that can crawl tweet pages and print out the username of that page. To do so, we create a subclass of *Crawler* and rewrite the *visit* and *fail* function. Note that the url of a tweet page looks like https://twitter.com/username/status/tweet_id, so we need to extract the *username* inside. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class TwitterCrawler(Crawler):\n",
    "    \n",
    "    def visit(self, link, source=None):\n",
    "        if \"status\" in link.url and \"status\" in link.referrer:\n",
    "            visiting_id = link.url.split('/')[3] # extract username\n",
    "            if link.referrer:\n",
    "                from_id = link.referrer.split('/')[3]\n",
    "            else:\n",
    "                from_id = ''\n",
    "            print \"in user:\", visiting_id, \", from user:\", from_id\n",
    "            print \"in url:\", link.url, \", from url:\", link.referrer\n",
    "    \n",
    "    def fail(self, link):\n",
    "        print \"failed:\", link.url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRAWLing --------------------------------------------------\n",
      "in user: imcosta1 , from user: IngridBush\n",
      "in url: https://twitter.com/imcosta1/status/794533506739224576 , from url: https://twitter.com/IngridBush/status/794401601368760320\n",
      "in user: imcosta1 , from user: imcosta1\n",
      "in url: https://twitter.com/imcosta1/status/794532866319417344 , from url: https://twitter.com/imcosta1/status/794533506739224576\n",
      "in user: MaddowBlog , from user: imcosta1\n",
      "in url: https://twitter.com/MaddowBlog/status/794353514080190464 , from url: https://twitter.com/imcosta1/status/794532866319417344\n",
      "in user: Angel5202006 , from user: MaddowBlog\n",
      "in url: https://twitter.com/Angel5202006/status/794543373654822913 , from url: https://twitter.com/MaddowBlog/status/794353514080190464\n",
      "{u'https://twitter.com/Angel5202006/status/794543373654822913': True, u'https://twitter.com/IngridBush/status/794401601368760320': True, u'https://twitter.com/MaddowBlog/status/794353514080190464': True, u'https://twitter.com/imcosta1/status/794533506739224576': True, u'https://twitter.com/imcosta1/status/794532866319417344': True}\n",
      "{u'twitter.com': 1478301090.255352}\n",
      "CRAWLing --------------------------------------------------\n",
      "{u'https://twitter.com/hashtag/FAZ?src=hash': True, u'https://twitter.com/hashtag/spiegelonline?src=hash': True, u'https://twitter.com/DieNachrichten/status/794401601209434113': True, u'https://twitter.com/hashtag/artistic?src=hash': True, u'https://twitter.com/hashtag/staircase?src=hash': True}\n",
      "{u'twitter.com': 1478301099.680371}\n",
      "CRAWLing --------------------------------------------------\n",
      "in user: Orbit_CH3MISTRY , from user: conservtivegurl\n",
      "in url: https://twitter.com/Orbit_CH3MISTRY/status/794344007572852736 , from url: https://twitter.com/conservtivegurl/status/794401601054117888\n",
      "{u'https://twitter.com/Orbit_CH3MISTRY/status/794344007572852736': True, u'https://twitter.com/conservtivegurl/status/794401601054117888': True, u'https://twitter.com/OliviaDougan/status/790621958358511616': True, u'https://twitter.com/OliviaDougan': True, u'https://twitter.com/TrIpLeBeEeE': True}\n",
      "{u'twitter.com': 1478301108.098373}\n",
      "CRAWLing --------------------------------------------------\n",
      "in user: gatascasa , from user: ninetyniners\n",
      "in url: https://twitter.com/gatascasa/status/794322440327294977 , from url: https://twitter.com/ninetyniners/status/794401600680837120\n",
      "{u'https://twitter.com/ninetyniners/status/794401600680837120': True, u'https://twitter.com/bannelee1': True, u'https://twitter.com/blearnedh/status/794613199198973952': True, u'https://twitter.com/gatascasa/status/794322440327294977': True, u'https://twitter.com/TheFix': True}\n",
      "{u'twitter.com': 1478301115.679692}\n",
      "CRAWLing --------------------------------------------------\n",
      "in user: Tehsupercow , from user: connzillaa\n",
      "in url: https://twitter.com/Tehsupercow/status/794408570745929728 , from url: https://twitter.com/connzillaa/status/794401600496402432\n",
      "in user: Tehsupercow , from user: Tehsupercow\n",
      "in url: https://twitter.com/Tehsupercow/status/794410821375954944 , from url: https://twitter.com/Tehsupercow/status/794408570745929728\n",
      "in user: Tehsupercow , from user: Tehsupercow\n",
      "in url: https://twitter.com/Tehsupercow/status/794410821375954944?lang=zh-tw , from url: https://twitter.com/Tehsupercow/status/794410821375954944\n",
      "in user: Tehsupercow , from user: Tehsupercow\n",
      "in url: https://twitter.com/Tehsupercow/status/794410821375954944?lang=en , from url: https://twitter.com/Tehsupercow/status/794410821375954944?lang=zh-tw\n",
      "{u'https://twitter.com/Tehsupercow/status/794410821375954944?lang=zh-tw': True, u'https://twitter.com/Tehsupercow/status/794408570745929728': True, u'https://twitter.com/Tehsupercow/status/794410821375954944': True, u'https://twitter.com/Tehsupercow/status/794410821375954944?lang=en': True, u'https://twitter.com/connzillaa/status/794401600496402432': True}\n",
      "{u'twitter.com': 1478301122.484982}\n"
     ]
    }
   ],
   "source": [
    "for tweet_url in tweet_urls[:5]: # just crawl from first 5 urls\n",
    "    crawler = TwitterCrawler(links=[tweet_url], delay=0.0, sort=LIFO) \n",
    "    # LIFO: the new links are visited in the order of last-in-first-out\n",
    "\n",
    "    print \"CRAWLing \" + \"-\" * 50\n",
    "    while len(crawler.visited) < 5: # crawl 5 pages\n",
    "        crawler.crawl(cached=False)\n",
    "\n",
    "    print crawler.visited\n",
    "    print crawler.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store Data\n",
    "This section involves some basic method of storing data with **pattern**:\n",
    "\n",
    "- [Create Database](#Create-Database)\n",
    "- [Create Table](#Create-Table)\n",
    "- [Insert Data](#Insert-Data)\n",
    "- [Data Query](#Data-Query)\n",
    "\n",
    "The pattern.db module contains wrappers for databases (SQLite, MySQL). It is convenient to work with tabular data, collected from **pattern** web module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pattern.db import Database, SQLITE, pd, assoc, INNER\n",
    "from pattern.db import field, pk, STRING, INTEGER, rel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create or access a SQLite very easily by calling *Database*, where the first argument is the directory of the database. If there is already a database, then **pattern** will connect to the database, otherwise it will create one. The function *pd* stands for parent directory of the script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "db = Database(pd(\"tweet.db\"), type=SQLITE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Table\n",
    "\n",
    "We can define the schema of a table in an expressive way using *pk*, and *field*. We create two tables for the twitter data collected from above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if not \"tweet\" in db:\n",
    "    schema = (\n",
    "        pk(), # Auto-incremental id.\n",
    "        field(\"author\", STRING(50)), # name, type\n",
    "        field(\"text\", STRING(256)),\n",
    "        field(\"like\", INTEGER)\n",
    "    )\n",
    "    db.create(\"tweet\", schema) # create the table\n",
    "    \n",
    "if not \"twitter\" in db:\n",
    "    schema = (\n",
    "        pk(),\n",
    "        field(\"username\", STRING(50)),\n",
    "        field(\"fullname\", STRING(50))\n",
    "    )\n",
    "    db.create(\"twitter\", schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the table is created, we can access the table with *db.table_name*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insert Data\n",
    "The *append* function allows easy insertion of a data row, in which the argument names correspond to the field names of the table. We insert the tweet data collected from *Twitter.search* and twitter data collected using the HTML DOM parser above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tweet_set = set()\n",
    "\n",
    "for tweet in tweets:\n",
    "    if tweet.id not in tweet_set:\n",
    "        if tweet.like:\n",
    "            db.tweet.append(author=tweet.author, text=tweet.text, like=tweet.like)\n",
    "        else:\n",
    "            db.tweet.append(author=tweet.author, text=tweet.text, like=0)\n",
    "        tweet_set.add(tweet.id)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "twitter_set = set()\n",
    "\n",
    "for username, fullname in twitters:\n",
    "    if username not in twitter_set:\n",
    "        db.twitter.append(username=username, fullname=fullname)\n",
    "        twitter_set.add(username)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function *assoc* will convert a data table into a generator of each row represent as a Python dictionary. Let's print the first 10 rows of the tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweet table:--------------------------------------------------\n",
      "{u'text': u'This is America. NO ONE \"ALLOWS\" US ANYTHING! With #Trump leading us #WeThePeople WILL #DrainTheSwamp! @realfirearms @jorgenseptember', u'like': 0, u'id': 1, u'author': u'WalkingSeaWater'}\n",
      "{u'text': u'RT @balleryna: .@heuteshow&lt;=Staatsfunk wei\\xdf von Verstrickung der kriminellen #Clinton in #Epstein- &amp; #Weiner-Verbrechen=Mitschuld!:( #Wikil\\u2026', u'like': 0, u'id': 2, u'author': u'AndrewRoussak'}\n",
      "{u'text': u\"#Trump\\n\\nOh. And he hasn't paid any #federaltax in  20 years.\\nZero contribution. That is sick. When millions of poor people with 2 jobs+ pay!\", u'like': 0, u'id': 3, u'author': u'DubaiDiaries'}\n",
      "{u'text': u'#trump likes attachment beneficial awesome benevolent', u'like': 0, u'id': 4, u'author': u'nicolasabanner2'}\n",
      "{u'text': u'RT @joelpollak: Panoramic shot of crowded #Trump rally in #Atkinson #NewHampshire - at least 1,000 packed into hall, wall to wall https://t\\u2026', u'like': 0, u'id': 5, u'author': u'bibifl59'}\n",
      "{u'text': u'RT @GOPFIB: Melania #Trump is upset by people who bully others on the internet.\\nYou know, like her husband. https://t.co/C6oCUs52UY', u'like': 0, u'id': 6, u'author': u'mzz_faithy'}\n",
      "{u'text': u'RT @CorrectRecord: #Trump\\'s closing message is built on lies.\\n@KatyTurNBC: \"He is still dwelling on things that are not factually true.\"\\n#T\\u2026', u'like': 0, u'id': 7, u'author': u'peevee24'}\n",
      "{u'text': u'RT @PeterKellyBC: I made my election predictions on Vox https://t.co/VieaRAjZ2i #Trump #HillaryClinton', u'like': 0, u'id': 8, u'author': u'charlierichmond'}\n",
      "{u'text': u'The latest A Look Down the Rabbit Hole! https://t.co/BdoLuGvclq Thanks to @AnonBruja @PupperJ @SensiblySecular #nevertrump #trump', u'like': 0, u'id': 9, u'author': u'WildChild69'}\n",
      "{u'text': u'@LindaSuhler @RSBNetwork my sister is there with her boyfriend #Lucky \\u2728Both in PA &amp;  voted for #Trump \\u2728Trump signs all over PA \\u2728#VoteTrump', u'like': 0, u'id': 10, u'author': u'Love_America__'}\n",
      "\n",
      "twitter table:--------------------------------------------------\n",
      "{u'username': u'WalkingSeaWater', u'fullname': u'WalkingSeaWater', u'id': 1}\n",
      "{u'username': u'elchicano270', u'fullname': u'Jose J. Alonso', u'id': 2}\n",
      "{u'username': u'DubaiDiaries', u'fullname': u'Bibi', u'id': 3}\n",
      "{u'username': u'nicolasabanner2', u'fullname': u'Nicolasa Bannerman', u'id': 4}\n",
      "{u'username': u'HearlCathy', u'fullname': u'Cathy Hearl', u'id': 5}\n",
      "{u'username': u'WLD01', u'fullname': u'Willie Lee Davis', u'id': 6}\n",
      "{u'username': u'karindann', u'fullname': u'Karindann', u'id': 7}\n",
      "{u'username': u'PeterKellyBC', u'fullname': u'Peter Kelly <span class=\"Emoji Emoji--forLinks\" style=\"background-image:url(\\'https://abs.twimg.com/emoji/v2/72x72/1f1e8-1f1e6.png\\')\" title=\"Flag of Canada\" aria-label=\"Emoji: Flag of Canada\">&nbsp;</span><span class=\"visuallyhidden\" aria-hidden=\"true\">\\U0001f1e8\\U0001f1e6</span>', u'id': 8}\n",
      "{u'username': u'WildChild69', u'fullname': u'Alice King', u'id': 9}\n",
      "{u'username': u'Love_America__', u'fullname': u'Deplorable Jen', u'id': 10}\n"
     ]
    }
   ],
   "source": [
    "print \"tweet table:\" + \"-\" * 50\n",
    "for index, row in enumerate(assoc(db.tweet)):\n",
    "    if index < 10:\n",
    "        print row # represented by a dictionary {'name': 'value'}\n",
    "    else:\n",
    "        break\n",
    "print\n",
    "\n",
    "print \"twitter table:\" + \"-\" * 50\n",
    "for index, row in enumerate(assoc(db.twitter)):\n",
    "    if index < 10:\n",
    "        print row\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Query\n",
    "The **pattern** db module contains a high level function for executing SQL data query. Suppose we want to search from the 'tweet' table for the tweet of the twitter recorded in the 'tweeter' table and list them with the full name instead of the user name. The *relations* attribute is a collection of *rel* object which defines the relations between tables. Specifically,\n",
    "```Python\n",
    "rel(\"fieldname1\", \"fieldname2\", \"tablename\", join=LEFT)  # LEFT or INNER\n",
    "```\n",
    "where 'fieldname2' of 'tablename' table is join with 'fieldname1' of the current table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select tweet.text, twitter.fullname from `twitter` inner join `tweet` on twitter.username=tweet.author;\n"
     ]
    }
   ],
   "source": [
    "q = db.twitter.search( # search from the \"twitter\" table\n",
    "    fields = (\n",
    "       \"tweet.text\",\n",
    "       \"twitter.fullname\"\n",
    "    ),\n",
    "    relations = (\n",
    "      rel(\"username\", \"tweet.author\", \"tweet\", join=INNER) # inner join from the tweet table\n",
    "    )\n",
    ")\n",
    "print q.sql() # print out the query in SQL "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We print out the result of the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tweet.text': u'This is America. NO ONE \"ALLOWS\" US ANYTHING! With #Trump leading us #WeThePeople WILL #DrainTheSwamp! @realfirearms @jorgenseptember', 'twitter.fullname': u'WalkingSeaWater'}\n",
      "{'tweet.text': u\"#Trump\\n\\nOh. And he hasn't paid any #federaltax in  20 years.\\nZero contribution. That is sick. When millions of poor people with 2 jobs+ pay!\", 'twitter.fullname': u'Bibi'}\n",
      "{'tweet.text': u'#trump likes attachment beneficial awesome benevolent', 'twitter.fullname': u'Nicolasa Bannerman'}\n",
      "{'tweet.text': u'The latest A Look Down the Rabbit Hole! https://t.co/BdoLuGvclq Thanks to @AnonBruja @PupperJ @SensiblySecular #nevertrump #trump', 'twitter.fullname': u'Alice King'}\n",
      "{'tweet.text': u'@LindaSuhler @RSBNetwork my sister is there with her boyfriend #Lucky \\u2728Both in PA &amp;  voted for #Trump \\u2728Trump signs all over PA \\u2728#VoteTrump', 'twitter.fullname': u'Deplorable Jen'}\n",
      "{'tweet.text': u'#trump treat benevolent yays agreeable ok', 'twitter.fullname': u'Nannette Markowitz'}\n"
     ]
    }
   ],
   "source": [
    "for row in assoc(q):\n",
    "    print row "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary and Referrence\n",
    "Basically, as mentioned in the introduction, **pattern** is useful in the sense that it is a bundle of a lot of common used tools in web mining. Besides the web and db modules, there are other useful modules that deal with other common tasks in data science. If you are interested, take a look at the official site.\n",
    "\n",
    "- The official site: http://www.clips.ua.ac.be/pages/pattern\n",
    "- The **pattern.web** package: http://www.clips.ua.ac.be/pages/pattern-web\n",
    "- The **pattern.db** package: http://www.clips.ua.ac.be/pages/pattern-db\n",
    "- The Github directory: https://github.com/clips/pattern\n",
    "- A Case Study: http://www.clips.ua.ac.be/sites/default/files/modeling-creativity.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
