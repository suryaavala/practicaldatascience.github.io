{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This tutorial will introduce you to one of the Natural Langrage Processing approaches called Speech Analytics Model by VERINT. In the class we've learned several useful libraries and algorithms that can help us to do specific tasks. You may also find some of them in this tutorial but the goal is to understand the whole model structure and different role each part plays and how does it contributes to the process of solving business issue. We will apply this model to solve a call driver analysis problem in this tutorial.\n",
    "\n",
    "**Please do not share this notebook or the data with others.**\n",
    "\n",
    "## Natural Langrage Processing and Speech Analytics Model\n",
    "According to the Wikipedia, the definition of the NLP is \"A field of computer science, artificial intelligence, and computational linguistics concerned with the interactions between computers and human (natural) languages.\" https://en.wikipedia.org/wiki/Natural_language_processing. \n",
    "\n",
    "Processing natrual language is hard. The same word can express different meanings in different contents. (Think about the subtle irony). Apart from sentiment analysis, translation is another common application of NLP practice. Recently, Google announced a breakthough in Neural Machine Translation which reduces the translation errors by an average of 60% compared to Google's phrase-based production system. You can find more details about NMT here: https://arxiv.org/pdf/1609.08144v2.pdf\n",
    "\n",
    "In practise, when we want to analysis speech data, the Speech Analytics Model would be a handy framwork to follow. It includes three levels: Keyword Spotting, Content Categorization and Root Cause Analytics. (please refer to the graph below) Of course in real business problem we need to taylor the model to make it more suitable for the case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](speech.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background Introduction\n",
    "Nowadays almost all the companies have their call centers. The customer service team over the phone are supposed to solve the enquiries and problems from the customers. Company A receives increasing incoming call as well as lots of complains about increasing waiting time. (shows below)\n",
    "\n",
    "The company wants to know why people are calling so that they can optimize their business practice to reduce the call volumn as well as the calling time. In this tutorial we are going to do a small call driver analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](background.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial content\n",
    "\n",
    "In this tutorial, we will follow the basic speech analytics model's structure, optimize it and apply the apporach on the call driver analysis case.\n",
    "\n",
    "We will be working on a small interaction sample data (a small fraction of monthly data) from a telecom company. The general apporach could be apply to different business cases with corresponding adjustments.\n",
    "\n",
    "We will cover the folowing topics in this tutorial:\n",
    "* Installing the libraries\n",
    "* Loading and understand the data\n",
    "* Keyword spotting (Named-entity recognition, topic modeling)\n",
    "* Content categorization (SVM, RNN-LSTMs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installing the libraries\n",
    "\n",
    "Before getting started, you'll need to install the various libraries that we will use. You can install lda, nltk, scikit-learn, Keras and TensorFlow using pip:\n",
    "\n",
    "    $ pip install lda\n",
    "$ sudo pip install -U nltk\n",
    "    $ pip install -U scikit-learn\n",
    "$ sudo pip install keras\n",
    "\n",
    "if you have anaconda installed, please visit the link https://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/get_started/os_setup.md#pip-installation and\n",
    "https://www.tensorflow.org/versions/r0.10/get_started/os_setup.html#anaconda-installation to\n",
    "choose the right install method of keras and TensorFlow for your system.\n",
    "Here I use\n",
    "\n",
    "    $ export TF_BINARY_URL=https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-0.11.0rc1-py2-none-any.whl\n",
    "$ sudo pip install --upgrade $TF_BINARY_URL\n",
    "    \n",
    "sudo pip will not install the packages into local anaconda site-packages so that it cannot be found.\n",
    "\n",
    "    $ export TF_BINARY_URL=https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-0.10.0-py2-none-any.whl\n",
    "$ sudo pip install --ignore-installed --upgrade $TF_BINARY_URL\n",
    "\n",
    "\n",
    "    LDA: https://pypi.python.org/pypi/lda\n",
    "    NLTK: http://www.nltk.org/install.html\n",
    "    Scikit-learn: http://scikit-learn.org/stable/install.html\n",
    "    Keras: https://keras.io/#installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import csv\n",
    "import lda\n",
    "import time\n",
    "import nltk\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import keras.preprocessing.text as pre\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn import preprocessing\n",
    "from nltk.corpus import stopwords\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing import sequence\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "from keras.utils.np_utils import to_categorical\n",
    "# from keras.layers.recurrent import GRU as GRU\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from keras.layers import Activation, Embedding, Dense, LSTM, Dropout\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and understand the data\n",
    "\n",
    "Now that we've installed and loaded the libraries, let's loat the data example to see how's the data looks like. The data is stored in csv format so we can load it into data frame for further process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   iInteractionId    iContactId  \\\n",
      "0    6.280000e+18  6.280000e+18   \n",
      "1    6.280000e+18  6.280000e+18   \n",
      "2    6.280000e+18  6.280000e+18   \n",
      "3    6.280000e+18  6.280000e+18   \n",
      "4    6.280000e+18  6.280000e+18   \n",
      "\n",
      "                                             Content  \n",
      "0    i used to get mine i'm speaking with a sound...  \n",
      "1    hello the payments that sort of them speakin...  \n",
      "2    so i just need them you here overgrown about...  \n",
      "3    so i usually david since right how are you s...  \n",
      "4    the money once it's not come on the phone th...  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('sampleData.csv')\n",
    "print df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table has three columns, iInteractionID, iContactId and Content. The first two are mainly used as primary key that helps to find the specific interaction. The conversation content that is converted from the voice record stores in content column.\n",
    "Let's find one conversation record to look in to the details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  i used to get mine else we can look hello yes a c yes yeah okay oh really oh i thought i know you know saddam open unfortunately what's your name sorry misspoke into most of and you're looking at getting building connected so rights no i don't know yeah what was your mother sorry what was your hollywood trace right are you calling from phone in the same rights okay i understand let me look i'll go see society juices for a total of march which really hard why is that correct all what's the street interest cold now do you have a number on this i said what you want to sorry yes really slow yeah yeah they typically don't update please number is which doesn't surprise me limited cookbooks okay no it doesn't work on this issue is so i need to see if i can check what the what i'm interested it's probably so he said he saw it's the main road reachable i used to check what's your address and so i'm okay one sec i'll just see what options it has you know what he is you know that's good so well that's promising at least some off the check i said you ninety four keisha because when i was online before i tell you what what church only highlight which is a fortune beyond the interest rate also some forty at least you do it isolate the full address so you you're saying oh you made this is for appliance it'll sorry it's it's like to listen around you that same area like i right alright excellence ah and it's actually rolled then is available so you have you had told him before all you have a computer of course you like he seems that oh really i understand oh okay no you go you recently go template is that right okay well we can do for you had a look at the proposal things great so it was gonna check rochelle like up a a matter just see if i could when you were you off you'd also hit didn't spoke should go there when oh you to go to you both of us on to if you mostly kinda on to jump should i can see anything yet so ron it doesn't like your the address book page because rickles out those it'll take a look and it's like a plot for broadway connections for you but we need to watch itself guarantee tools connected it was like shouldn't she rolled and i'm oh i ask you got a couple of month also be accounts they could be a deal where it would be at the ball x and we can get in the month discounts it'll systems give off the skills and date free connection for dogs public what do you contract so i guess to let you know the overall policy creeks for the parole but you'll be looking at so it's a yes about twenty fold old's more month for the broadband i think in just a from there and i don't like icons guarantee until toppling say do you want us to fly and see if we can get broken to you so you because records a bill thank you give me should but it's no longer for each other one much we could only highlight i'll put you on the cheek overnight as a trace maybe situations seems it's dialer pull up yep yep but it because my mother you directly george or so i have to tell you reattach guaranteed at all but double click working but if you're happy to give it a gallon okay to trouble pliable see if we can't do you connect it's do you want to apply for connection oh really what's your mobile number the smoking for oh right yeah i'll check to see it double two four button doesn't look like it's a w well it's like i get the interest of that for me so i it's yeah exactly what you you know apologies of that's alright thank you and i think i might as complex recycles robbing it takes about twenty six almost a few more monthly when you call it typing land line so you got from dollars a month and that's the full to get about plan and we do that with a bottle quick that's the month for the first twelve months kevin c hong kong and broke and all that you'll be a cell phone separately because it doesn't look like it's on the account minus yeah get yes yep yes six will six is yes all rights and you should be caught up that's on the oh right so you so the same religion is about the phone mobile is that right yep oh right right so you're you're paying full the hard for your mobile is slowly but it's like prepaid doctor connection please up right okay how much you spending a mobile for the most of the at the moment it's so it says office in the month hold on so you take twenty dollars a month to cool yep yep yep oh yeah i mean you're paying extra twenty dollars to close relative i'm synching we could do it because deals because all the accounts i'm just gonna have a quick look at equals options are available to los do you think two hundred minutes was truly a h months would cos because okay what we could do is you can leave your mobile number two hundred meg child's you mentioned you mobile phone is probably doing around c fossils a month okay and what we could do is you put me calculate sixty dollars a month you would you want a hundred minutes in new zealand to a hundred minutes to australia plus other countries one hundred six to stroll with i'm limited new zealand six and also some doctor to use on your mobile phone if you want to well but they cheat that box thinking about you you have a lot your location and you've got a comedian sometimes open up because it just charged horse account so the tablets would connect to the holding both parents and if you wanted to call spoke to temple from your mobile phone number i'll check for you so do you see into on your mobile floating loan do you see it on your mobile phone okay do you have they look up mobile phone do you have yes yes how much so that you get what about the phone for your templates yes oh really yeah yes and it's for a lot of the six months of it yes yeah so where do shopping that this do we can do if you did your mother coverage could only remove boris it's six one four yes yeah that's good that's good so yes oh so you'll see we can yep mark martin intentionally as soon as we get the mobile of the accounts with you shortly plan because it seems it's gonna give you more but what we apply for probably connection a holiday we sure what what was connected to a king before you cancel the bonus on top let's just so they can also so that's just because it's a but i see i see about where you are you happy for me to give us some place where you let me give a number is oh well okay g t mostly use a couple of the hard okay so it we'd we installed a broadband off on the ceiling that there's a couple of sitting you'll be able to use a couple of hartford and your connection we do for you it was still people different connection but i i mean she in the recognition wants to keep it but if i place you going to see if we can make it was awesome cool thank you so you got any accounts hard if you want me to send one of the season social but it'll look at the only real cold should can you tell right yeah it does look should be about one to see the monthly rolls and it's sent to me it sounds like you're condos at that level you i think it's pretty costs with the bosses because you're doing yes and the mobile phone ok huh i guess okay see any extras because you've got the instrument calling so that's going to the call in but if you are speaking with jill smoking if you don't find steve is your who's probably do that for you can get to a tremendous undertaking surrounded in your account you're right you thought about money one six one that's all been six six so it again you see a lot more but okay but the only thing is a weekly karen we can't we can't had a c build so the one for the hold for the bold spreads up the phone roger this one for raleigh okay yeah so we can't keep the mobile six from the hard part of the broadband will be on the old on floating so so you're paying fifty dollars a consultant yeah you said exit falsely hong kong and that will go up to the a t for the month because it broke i will be clearing that as well and so i guess we could look at it deals those ah is raj colts around the country oh not this week physical around easy ones with the books well would you like to servers okay if you just look to phone i want to do is if you know we don't give you a land line for you cool stool a month and you see one for the first twelve months so that if you could help you live on floating cool you as long as you know the what it was cold stopped you know spoke all and that will be the free for the for this year if you want to keep it off to the first twelve months it is fourteen dollars a month well she can't stop it if you can wish you can take it off to what is i don't know this will be including the broadband so it gives the total cost of the both ends with the a t for the month which includes the land line forty department snakes plus free cool scenes he'd for the first twelve months at this we want to keep your mobile as separate account the secret from roger land line we can do that at the citadel some uncle the and okay that's what i can find great so you can yeah that would be replace you'll like a phone connection so what's up and running do you could smoke because the connections you know i thought that as well so you great you full to divorce yeah that's i'm sorry so well because actually i'll just so i'm just thinking or could actually do a little client award and be able to give you the screen six colin but it will take off another ten dollars and i'll give you changing the box amounts do you think that would be enough for you okay so you can see the old being well say fobel's cheaper actually yeah it's not a technical those successfully you'd be looking at girls a month and i'll give you ticket box where is you go to at fall in and that will give you forty people x plus three cools to live on c. d. fields would you rather save you should fossil is full yeah well that's still too much of okay well this guy full that signed in yep let's see what you could always get roger to use your mobile phones culturally and see if he doesn't it wouldn't be a little because you play some money to the thing with the broadband is he your old old applying for the moment what you get street dollar cold so strong wind and if we do to change it it would actually go to free to local so sterling so you need to slow down towards the it's like if she can make up savings when you cold what sure i can bring them yes please on the line what do you watch cool maybe not hello people seem and y you so you can you give them something they at follow it is the one eight nine cents yeah so the the you follow the c land line i'm limited cold swollen launching easy loans correct to and once you need to influence twelve months the one you make sense of this that's correct yep he's no it's not it's it's it's weekly in the process underscore you could type also yeah yeah something stupid i was wondering if i click what you'll get on my system and the forty gig about ten to teach on the template multiples yeah we do a free connection that are free modem as part of the one year contract so once you know the money to you if you wanted to keep being c colon the in the bank it's about fourteen a month plus we cellphone almost credit obviously collings fourteen dollars a month so the we don't including c colon sending us about twelve dollars a week it would be in c colon so it goes up to date eighty four oh sorry no i'm i'm gonna put a woman's because i don't use the phone bills won't because what michael swelled also monthly get off this is she'll go off my local is if you go rudolph easy pulling yep no it goes out of your existing call for phone lines no it so you want to hold the line for me to online which is what you funds with your so defective like a tree that's it for your system checkpoints and social so i think so you just like the modem into a check points what's your phone and that the same one two four months yeah yeah we we we we see that the modem that comes with that what that which means you put your following any modem into the same point please enter the points if it's like coming up on the connection type of to that will swallow swing so i i'm sorry yes of course it just seems like the it charge is your phone i'm awfully sorry yep yeah you can you click on it's like it's the only thing you do you like the you see what i needed to holland so much for calling the campbell's window okay can to answer your back on again yeah like a people's won't bother double click on think us a call oh right right same you sure you going to put all three is the account so that you get a bill for and get the extra calling it cheaper right did you say your secret guilt monthly strongly all done this yes you see kills chicks mister ellis jeez that's close load that i'm okay but you know for the moment to do all the month you okay that's month fulfill between feels a month and he's like what do you think okay but do you think you speak with all the month going is not sixteen strolling rule no that that's fine would you what we can mobile phone l the it's it will just be the broadband something so it's like i must admit some sleeping correctly go for you also okay that's like what we'll do is we'll get it probably takes you don't mind looking at we don't guarantee on to look up and running the modem movies fees two hundred so what's the post okay sorry this is just already too like field it'll it did take your key i d for the month oh really sometimes yep because of the month dial here yeah well you do you take a look you contract if it does work oh that's cool so if we consul right i still be a trace we will see what people trying to okay what i'll do you what was your full postal address please spoken to took the weird i need to like field in the region yeah is that correct site forty eight ball x is oh eight you'll land he might have to just which adults not enough people to the very speedy usable but no okay so we don't see so no watching videos pretty full season downloading and play games it's not sure if that's that's what phone or like so you will apply for about connection okay the modem six okay hundreds of so used to couple of days because i guess it's real delivery somewhat booked a broadband connection the full monday next week you don't have to be a hard for it because i'll just be connected foreign exchange okay so can you talk to receive the modem no no just because you don't see fourth line for you but it's pretty straight for to school it's gold the instructions and it's it's just like a place i come to kill by default it is it's like not even possible the back of the modem right yeah absolutely who does not pretty quickly no you get that will take long hopefully so you will your holiday and you'll templates will join the loss on c. gotta pick you could possibly connect it it just cracks a wall sticks with hollywood treat you can take you've had looks around hard will sell thinks it's t yeah correct yep that's like okay so weekly isn't line oh yeah instead it's what i'll do is all seem to call question takes me see trusted told details you'll get a four six message contending be all bank to make sure enough almost existed with something running and when you get the modem you've got to look at it may be still okay if you have any problems among give you all full contact number just go to the she's you know dollars here enter that way so i might them can okay so this will apply also you take especially shortly it is yes oh sorry oh eight hundred twenty two fifty four no it's yeah it's excellent all right you know what's like you get paid for because you don't at all but so they can help you oh yeah well just click it takes yep you'll get templates yeah you just have to go to law fine cities you know do more funny clicks yep yep okay in a loop right okay when you go into the back oh really like on well so you do you want me to go back in extra monday next week would you replace but it still monday okay that's like for so this little place up a corporation tasteless interested details and it will just follow both another takes me situation for running that's we can put in your modem and you think it's just another card right no that's an automatic system so it's if you could take since it doesn't get your new one i i'll do what you need to try we do you have the card rockabilly system which means you charge for the day of connection to the into that pulling months also multiple instances bills once a month and a partial month ah yeah if you look at a bill you build up to the twenty second of my favorite cleats we get connected almost sixty yeah so it would you connected with it seems to be charged at sixteen such we can see the partial charge oh six nine okay level always schedule that for twenty seconds it sounds like a blank sounds like a plan alright sorry this is all played do you have any other question for me in the smoking so alright when you awfully up and running just a minute you can't feel temple looks like a final cancel the the the one of the connection i have is it just pretty quiet is what do you call a month detail like in a monthly invoices a prepaid okay doesn't connect oh you mean you a few quick i'll do anything about that i got a small place okay so because on my system i guess when you run helpful money on that'll just all working so you yeah yeah so what we do a lot of the yeah up to you could have but probably in the main card yes of course right yeah yeah the total mouldy connected by the twenty second of my right no you're doing a what sorry so you'll tell them i don't want to send one four nine and possibly yeah so you just ah doing that system and they'll be connected it's correct you in the possible it is on the back of the modem a second so you can just copy those costs on your template it's it's pretty stressful that's awful structural that so yeah i'm i'm i'm talking to you you know if you get yourself yeah it's on the phone just retry you'd be swayed i hello yes correct yes all right now probably say talking to the that's correct yes alright look i'll put a bank fee but\n"
     ]
    }
   ],
   "source": [
    "content = list(df.ix[:,2])\n",
    "print content[10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "We can tell from the text above that it does not make much sense. There are many oral words as well as mis-interpreted words. These chaos make it very diffecult to identify the main topic of the conversation. Although we can still make mostly correct judgement on the topic after reading the test above but there're tens of thousands of transactions per month and the company want to analysis one year's data. \n",
    "\n",
    "The call drive analysis is actually a classification on natural language test without any predifined classes. So our first step is to find thouse potential classes. Before that, we need to pre-process the data and remove those noise as possible.\n",
    "The noise could be mis-interpreted words, stopwords, oral words or in this case: words that has no business meaning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def _getWordList(content):\n",
    "    docs = []\n",
    "    rep = {r\"phone number\": \"phonenumber\",\n",
    "           r\"line number\": \"linenumber\",\n",
    "           r\"call back\": \"callback\",\n",
    "           r\"ring back\": \"callback\",\n",
    "           r\"cell phone\": \"phonenumber\",\n",
    "           r\"mobil number\": \"phonenumber\",\n",
    "           r\"mobile number\": \"phonenumber\",\n",
    "           r\"ticket number\": \"ticketnumber\",\n",
    "           r\"account number\": \"accountnumber\",\n",
    "           r\"number account\": \"accountnumber\",\n",
    "           r\"email address\": \"email\",\n",
    "           r\"late payment\": \"latepayment\",\n",
    "           r\"make payment\": \"makepayment\",\n",
    "           r\"put payment\": \"makepayment\",\n",
    "           r\"made payment\": \"madepayment\",\n",
    "           r\"bill payment\": \"billpayment\",\n",
    "           r\"land line\": \"landline\",\n",
    "           r\" talk \": \" speak \",\n",
    "           r\" thank \": \" thanks \",\n",
    "           r\"calling\": \"call\",\n",
    "           r\"paying\" : \"pay\",\n",
    "           r\"trying\" : \"try\",\n",
    "           r\"anything\" : \"something\"\n",
    "           }\n",
    "    rep = dict((re.escape(k), v) for k, v in rep.iteritems())\n",
    "    pattern = re.compile(\"|\".join(rep.keys()))\n",
    "    for i in range(len(content)):\n",
    "        line = pattern.sub(lambda m: rep[re.escape(m.group(0))], content[i])   \n",
    "        line = re.sub(r'[^\\w\\s]','',line)            \n",
    "        docs.append(line)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    stop_words.update(['~','.', ',', '\"', \"'\", '?', '!', ':', ';', '(', ')', '[', ']', '{', '}', 'anyway', 'hold', 'make', 'zero', 'first', 'hi', 'much', 'still', 'sort', 'alright', 'take', 'name', 'sure', 'would', 'look', 'got', 'six', 'back', 'put', 'give', 'nine', 'want', 'let', 'got', 'oh', 'yeah', 'yeh', 'yep', 'ah', 'like', 'know', 'right', 'think', 'okay', 'get', 'see', 'okay','well','three','two'])\n",
    "    stop_words.update(['else','sorry','said','going','thanks','hundr', 'id','seventeen','cant', 'pop', 'sorri','im', 'dont', 'ill', 'went', 'long','help', 'richard','youll', 'set','full', 'old', 'thank', 'call', 'shall', 'put', 'speak','bit','one', 'need','say','five','go','might','four','tell','told','us','around','mom','either','use','me','five','bye','mind','keep'])        \n",
    "    stop_words.update(['also', 'ive', 'youve', \"yes\", 'thats', 'im', 'dont', 'already', 'cant', 'us', 'ill', 'youre', 'could',\n",
    "                       'go', 'actually', 'anyway', 'hold', 'make', 'zero', 'first', 'hi', 'much', \n",
    "                       'still', 'sort', 'alright', 'take', 'name', 'sure', 'would', 'look', \n",
    "                       'got', 'six', 'back', 'put', 'give', 'nine', 'want', 'let', 'got', 'oh', \n",
    "                       'yeah', 'yeh', 'yep', 'ah', 'like', 'know', 'right', 'think', 'okay', \n",
    "                       'get', 'see', 'okay','well','three','two', 'put', 'speak', 'four', 'five', 'litle',\n",
    "                       'ok', 'gonna', 'whats', 'nine', 'eight', 'one', 'theres', 'please', 'good',\n",
    "                       'able', 'forty', 'youll', 'hundred' ])               \n",
    "    # Prepare docs an vocabulary removing stop words that we defined  \n",
    "    ndocs = []\n",
    "    word_list = []\n",
    "    for doc in docs:\n",
    "        tokens = wordpunct_tokenize(doc)\n",
    "        wl = [i for i in tokens if i.lower() not in stop_words]\n",
    "        ndocs.append(\" \".join(wl))\n",
    "        word_list += wl\n",
    "    return list(set(word_list)), ndocs, stop_words\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a customized lexicon, and preprocessed document list as well as the defined stop_words. This is a unigram methond. From the regular expression above you can find out that we join two words together. Why don't do a bigram analysis instead? You can try yourself and explore the reason.\n",
    "\n",
    "## NER\n",
    "The simplest key word spotting is Named-entity recognition. There are many ways to implement, I find that the nltk.pos_tag and nltk.FreqDist can be a good choice. We've learned pos in the class, the FreqDist will return a distribution with frequency.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ner_process(document, stopword):\n",
    "    text = nltk.word_tokenize(document)\n",
    "    tagged = nltk.pos_tag(text)\n",
    "    word_tag_fd = nltk.FreqDist(tagged)\n",
    "    entity_names = []\n",
    "    for (wt, _) in word_tag_fd.most_common():\n",
    "        word = wt[0].replace(\" \", \"\").strip()\n",
    "        if (wt[1] == 'NN' or 'NNS' or 'VBN') and (len(word) > 1):\n",
    "            if stopword.count(word) == 0:\n",
    "                entity_names.append(word)\n",
    "    counts = Counter(entity_names)\n",
    "    return counts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('modem', 17), ('mean', 12), ('phonenumber', 12), ('twelve', 12), ('ask', 11)]\n"
     ]
    }
   ],
   "source": [
    "vocab, docs, stop_words = _getWordList(content)\n",
    "document = ' '.join(str(e) for e in docs)\n",
    "counts = ner_process(document, list(stop_words))\n",
    "print sorted(counts.iteritems(), key=lambda (k, v): (-v, k))[:5]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The individual keyword with frequency is not enough for us to interpret the topics. It only provides the infomation of the most frequent words that people are mentioned. So it's natural for us to find a way to generate the most frequent topic of the interactions.\n",
    "\n",
    "\n",
    "## LDA\n",
    "\n",
    "\n",
    "\n",
    "In natural language processing, Latent Dirichlet Allocation (LDA) is a generative probabilistic model of a corpus that allows sets of observations to be explained by unobserved groups that explain why some parts of the data are similar. The basic idea is that documents are represented as random mixtures over latent topics, where each topic is characterized by a distribution over words.\n",
    "\n",
    "The generative process is as follows:\n",
    "Documents are represented as random mixtures over latent topics, where each topic is characterized by a distribution over words. LDA assumes the following generative process for a corpus **D** consisting of **M** documents each of length **N**i:\n",
    "\n",
    "\n",
    "LDA assumes the following generative process for each document w in a corpus D:\n",
    "1. Choose N ∼ Poisson(ξ).\n",
    "2. Choose θ ∼ Dir(α) where Dir(α) is the Dirichlet distribution for parameter α.\n",
    "3. For each of the N words wn:\n",
    "    (a) Choose a topic zn ∼ Multinomial(θ).\n",
    "    (b) Choose a word wn from p(wn |zn,β), a multinomial probability conditioned on the topic zn.\n",
    "\n",
    "\n",
    "\n",
    "Find more here: https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation\n",
    "\n",
    "Now we can perform a topic modeling on the docs, we are using lda (Latent Dirichlet Allocation ) package here.\n",
    "This process can be regarded as unsupervised classification.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Topic modeling function.\n",
    "def _topicModels(vocab, docs, n_topics, g_num_top_words):\n",
    "    cv = CountVectorizer(vocabulary = vocab)\n",
    "    X = cv.fit_transform(docs).toarray();\n",
    "    X.shape\n",
    "    model = lda.LDA(n_topics=n_topics, n_iter=200, random_state=1)\n",
    "    model.fit(X)\n",
    "    topic_word = model.topic_word_\n",
    "    \n",
    "    num_top_words = g_num_top_words\n",
    "    for i, topic_dist in enumerate(topic_word):\n",
    "        topic_words = np.array(vocab)[np.argsort(topic_dist)][:-num_top_words:-1]\n",
    "        print \"Topic {}: {}\".format(i, ' '.join(topic_words))\n",
    "    return X, model    \n",
    "\n",
    "def _plotTopics(x, vocab, model, n_topics, g_num_top_words):        \n",
    "    #\n",
    "    # Plotting and visualizing\n",
    "    num_top_words = g_num_top_words\n",
    "    num_topics = n_topics\n",
    "    fontsize_base = 100 / np.max(x)\n",
    "    topic_word = model.topic_word_\n",
    "    \n",
    "    for t, topic_dist in enumerate(topic_word):\n",
    "        plt.subplot(1, num_topics, t + 1)\n",
    "        plt.ylim(0, num_top_words + 0.5)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.title('Topic #{}'.format(t))\n",
    "        top_words_idx = np.argsort(x[:,t])[::-1] \n",
    "        #print top_words_idx\n",
    "        top_words_idx = top_words_idx[:num_top_words]\n",
    "        #print top_words_idx\n",
    "        #top_words = vocab[top_words_idx]\n",
    "        top_words = np.array(vocab)[np.argsort(topic_dist)][:-num_top_words:-1] \n",
    "        top_words_shares = x[top_words_idx, t]\n",
    "        for i, (word, share) in enumerate(zip(top_words, top_words_shares)):\n",
    "            fontsize = (fontsize_base*share) if (fontsize_base*share) > 12 else 12\n",
    "            fontsize = 18 if fontsize > 18 else fontsize\n",
    "            plt.text(0.3, num_top_words-i-0.5, word, fontsize=fontsize)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: something check try mean time phone broadband thing problem card yet maybe didnt moment great may different find connected read\n",
      "Topic 1: modem connection check working internet connected broadband cable getting box problem next using lets connect technician line correct point tried\n",
      "Topic 2: number account something new send address phone seven system phonenumber wanted supposed double since correct speaking minute accounts ahead problem\n",
      "Topic 3: really moment phone working mobile interest work different local second landline lot understand home itll details possible used reason phonenumber\n",
      "Topic 4: cool come looking today people things probably stuff little pretty speaking time contract double twenty place takes couple kind basically\n",
      "Topic 5: broadband connection landline address line connected order property done course thing work accountnumber house people modem installation customer speed questions\n",
      "Topic 6: something try mean come find fine thing time doesnt point even money sign sometimes guys talking done pay course probably\n",
      "Topic 7: connection time line change email information mean means send looking getting things way fine every provide case message account side\n",
      "Topic 8: dollars ninety month fifty credit account twenty thirty cents mobile dollar number months pay next free sixty ten dot twelve\n",
      "Topic 9: computer try people click change using wife since password reset connect life check things box nothing something dot thing double\n"
     ]
    }
   ],
   "source": [
    "n_topics = 10\n",
    "n_words = 21\n",
    "# Build the model\n",
    "topic, model = _topicModels(vocab, docs, n_topics, n_words)\n",
    "\n",
    "# _plotTopics(topic, vocab, model, n_topics, n_words)\n",
    "# print \"finished\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Now we have a clearer picture of what's going on here. For example, the topic 1 may be conversations about broadband internet modem connection.  Topic 8 maybe something about the payment. Taking business domain knowledge into account, we can draw a issue tree for this problem. \n",
    "\n",
    "My attempts lead me to the structure like this:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](issueTree.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can certainly have different version of issue tree based on your understanding. Have a try.\n",
    "\n",
    "Based on the issue tree we developed, now we have the tags that we need for the supervised classification. We can perform structured classification method. Here I choose to devide the problem into small parts and solve them seperately. \n",
    "\n",
    "\n",
    "## Dynamic Learning\n",
    "\n",
    "We now have the tags, but without any training data. How do we get the training set for further classifications? \n",
    "First I examed the result from unsupervised classification by manually go through the content of the conversation and to check if the tag is correct. Then I use the sample (about 50 interactions for each class) to predict on larger dataset using SVM. Manually check the correctness of the tag and put those with high confidence into the training set.\n",
    "And then we keep training on more unseen dataset and continually add samples with high confidence into training set. The process is called active(dynamic) learning.\n",
    "\n",
    "You can try to generate your own training set. Here I provide mine training sample for the broadband class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         iInteractionId           iContactId  \\\n",
      "0   6280185542163380000  6280185542163380000   \n",
      "1   6280199883101110000  6280199883101110000   \n",
      "2   6280207102876130000  6280207102876130000   \n",
      "3   6280208284040360000  6280208284040360000   \n",
      "4   6280213798738520000  6280213798738520000   \n",
      "5   6280216255459810000  6280216255459810000   \n",
      "6   6281409350169860000  6281409350169860000   \n",
      "7   6281422432600400000  6281422432600400000   \n",
      "8   6281432392669410000  6281432392669410000   \n",
      "9   6281432981054750000  6281432981054750000   \n",
      "10  6283515662236180000  6283515662236180000   \n",
      "11  6283518934986590000  6283518934986590000   \n",
      "12  6283521370247720000  6283521370247720000   \n",
      "13  6283526129071490000  6283526129071490000   \n",
      "14  6280197061242590000  6280197061242590000   \n",
      "15  6281413456133420000  6281413456133420000   \n",
      "16  6281416020254070000  6281416020254070000   \n",
      "17  6281430657477450000  6281430657477450000   \n",
      "18  6281431937377700000  6281431937377700000   \n",
      "19  6288744213730370854  6288743560895341846   \n",
      "\n",
      "                                              Content        Category  \n",
      "0     i used to get mine i'm speaking with a sound...          Buying  \n",
      "1     hello the payments that sort of them speakin...          Buying  \n",
      "2     so i just need them you here overgrown about...          Buying  \n",
      "3     so i usually david since right how are you s...          Buying  \n",
      "4     the money once it's not come on the phone th...          Buying  \n",
      "5     hi you're speaking to richard very about a n...          Buying  \n",
      "6     putting a speaking with cameron i understand...          Buying  \n",
      "7     oh you're speaking to rich i'm in san you ha...          Buying  \n",
      "8     good afternoon days paid policy from spot an...          Buying  \n",
      "9     hi good evening every how are you my name is...          Buying  \n",
      "10    i used to get mine else we can look hello ye...          Buying  \n",
      "11    good morning you're speaking with karen and ...          Buying  \n",
      "12    you're speaking with jane how can i help sin...          Buying  \n",
      "13    hi you're speaking with casey and i'm speaki...          Buying  \n",
      "14    in albany static on here to help are you cal...  Cable_Location  \n",
      "15    i like i can help i know yes i am oh i think...  Cable_Location  \n",
      "16    you'd have to have been just the other and y...  Cable_Location  \n",
      "17    hello yes thinking that they had one of my m...  Cable_Location  \n",
      "18    hello and it's hard to hear calling from spo...  Cable_Location  \n",
      "19    you're speaking with countries how may i hel...  Cable_Location  \n"
     ]
    }
   ],
   "source": [
    "BBtraining = pd.read_csv('sampleWithID.csv')\n",
    "print BBtraining.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used SVM for the classification and get the result as follows:\n",
    "\n",
    "    Fold 1 Out of Sample Accuracy = 0.8406755\n",
    "    Fold 2 Out of Sample Accuracy = 0.8759399\n",
    "\n",
    "![title](SVM.png)\n",
    "\n",
    "Since we've already learned SVM in the class, I'll leave this part to yourself to try it out.\n",
    "\n",
    "# RNN-LSTMs (alternative attempt)\n",
    "\n",
    "Basic neural network assume all inputs and outputs are independent. Recurrent neural network's basic idea is to make use of sequential information.\n",
    "\n",
    "![title](RNN.png)\n",
    "\n",
    "    X: A token (word) as a vector\n",
    "    O: Output label\n",
    "    S : Memory, computed from the past memory and current word\n",
    "\n",
    "However it still have issues like vanishing gradients when working on natural language problems since the meaning is heavily rely on the context.\n",
    "    \n",
    "LSTMs (Long Short Term Memories) have a different formula which add \"residual information\" to the next state instead of just transforming each state. The key idea of LSTMs is a \"constant stream\" flows through the entire chain. \n",
    "\n",
    "![title](LSTM.png)\n",
    "\n",
    "The basic LSTMs also has input gate, forget/update gate and output gate. These gates together decide how the latest input will affect the model and to drop what information and what should be the output.\n",
    "\n",
    "If you want to expolore more about RNN and LSTM, CS224D-Deep Learning for Natural Language Processing offered by Stanford NLP group would be a nice resource. You can find the lecture notes here:\n",
    "http://cs224d.stanford.edu/syllabus.html\n",
    "\n",
    "Here I will provide a rough version of LSTMs code application. This may take long time! (around 15 minutes for each epoch)\n",
    "Try to write your own code and improve the accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def base_filter():\n",
    "    f = string.punctuation\n",
    "    f = f.replace(\"'\", '')\n",
    "    f += '\\t\\n'\n",
    "    return f\n",
    "    \n",
    "    \n",
    "# extract data and format them as the input to the model\n",
    "def load_data(filepath):\n",
    "    data = []\n",
    "    classes = []\n",
    "    rep = {r\"phone number\": \"phonenumber\",\n",
    "           r\"line number\": \"linenumber\",\n",
    "           r\"call back\": \"callback\",\n",
    "           r\"ring back\": \"callback\",\n",
    "           r\"cell phone\": \"phonenumber\",\n",
    "           r\"mobil number\": \"phonenumber\",\n",
    "           r\"mobile number\": \"phonenumber\",\n",
    "           r\"ticket number\": \"ticketnumber\",\n",
    "           r\"account number\": \"accountnumber\",\n",
    "           r\"number account\": \"accountnumber\",\n",
    "           r\"email address\": \"email\",\n",
    "           r\"late payment\": \"latepayment\",\n",
    "           r\"make payment\": \"makepayment\",\n",
    "           r\"put payment\": \"makepayment\",\n",
    "           r\"made payment\": \"madepayment\",\n",
    "           r\"bill payment\": \"billpayment\",\n",
    "           r\"land line\": \"landline\",\n",
    "           r\" talk \": \" speak \",\n",
    "           r\" thank \": \" thanks \",\n",
    "           r\"calling\": \"call\",\n",
    "           r\"paying\" : \"pay\",\n",
    "           r\"trying\" : \"try\",\n",
    "           r\"anything\" : \"something\"\n",
    "           }\n",
    "    rep = dict((re.escape(k), v) for k, v in rep.iteritems())\n",
    "    pattern = re.compile(\"|\".join(rep.keys()))\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    stop_words.update(['also', 'ive', 'youve', \"yes\", 'thats', 'im', 'dont', 'already', 'cant', 'us', 'ill', 'youre', 'could',\n",
    "                       'go', 'actually', 'anyway', 'hold', 'make',  'first', 'hi', 'much', \n",
    "                       'still', 'sort', 'alright', 'take', 'name', 'sure', 'would', 'look', \n",
    "                       'got', 'back', 'put', 'give', 'want', 'let', 'got', 'oh', \n",
    "                       'yeah', 'yeh', 'yep', 'ah', 'like', 'know', 'right', 'think', 'okay', \n",
    "                       'get', 'see', 'okay','well','three','two', 'put', 'speak', 'four', 'five', 'litle',\n",
    "                       'ok', 'gonna', 'whats', 'nine', 'eight', 'one', 'theres', 'please', 'good',\n",
    "                       'able', 'forty', 'youll', 'hundred'])    \n",
    "    token = pre.Tokenizer(nb_words= None, filters=base_filter(), lower=True, split=\" \")\n",
    "    with open (filepath, 'rb') as f:\n",
    "        reader = csv.reader(f)\n",
    "        next(reader) #ignore first row\n",
    "        for row in reader:\n",
    "            line = pattern.sub(lambda m: rep[re.escape(m.group(0))], row[2])\n",
    "            line = re.sub(r'[^\\w\\s]','',line)\n",
    "            tokens = wordpunct_tokenize(line)\n",
    "            wl = [i for i in tokens if i.lower() not in stop_words]\n",
    "            wl = ' '.join(wl)\n",
    "            token.fit_on_texts(wl)\n",
    "            list_of_lists = token.texts_to_sequences(wl)\n",
    "            flattened = [val for sublist in list_of_lists for val in sublist]\n",
    "            classes.append(row[3])\n",
    "            data.append(flattened)\n",
    "    array = np.asarray(data)\n",
    "    array = sequence.pad_sequences(array)\n",
    "    labeler = preprocessing.LabelEncoder()\n",
    "    labels = set(classes)\n",
    "    labeler.fit(list(labels))\n",
    "    nb_classes = len(set(labels))\n",
    "    label = labeler.transform(classes)\n",
    "    label = to_categorical(label, nb_classes)\n",
    "    return array, label, nb_classes\n",
    "\n",
    "def run_model(Xtrain, xtrain, Xtest, xtest, nb_classes):\n",
    "    results = []\n",
    "    max_features = 1500\n",
    "    embedding_dim = 32\n",
    "    batch_size = 32\n",
    "    epochs = 1 # to save time I set it to 1\n",
    "    #modes = ['cpu', 'mem', 'gpu']\n",
    "    modes = ['cpu']\n",
    "    for mode in modes:\n",
    "        print('Testing mode: consume_less=\"{}\"'.format(mode))\n",
    "    \n",
    "        model = Sequential()  \n",
    "        model.add(Embedding(max_features, embedding_dim, dropout=0.2))\n",
    "        model.add(LSTM(embedding_dim, dropout_W=0.2, dropout_U=0.2, return_sequences=True))\n",
    "        model.add(LSTM(16, return_sequences=True))\n",
    "        model.add(LSTM(8))\n",
    "        model.add(Dense(16, activation = 'tanh'))\n",
    "        model.add(Dense(nb_classes, activation='sigmoid'))\n",
    "        model.compile(loss='categorical_crossentropy',\n",
    "                      optimizer='adam',\n",
    "                      metrics=['accuracy'])\n",
    "        start_time = time.time()\n",
    "        history = model.fit(Xtrain, xtrain,\n",
    "                            batch_size=batch_size,\n",
    "                            nb_epoch=epochs,\n",
    "                            validation_data=(Xtest, xtest))\n",
    "        average_time_per_epoch = (time.time() - start_time) / epochs\n",
    "        results.append((history, average_time_per_epoch))\n",
    "    return results, modes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing mode: consume_less=\"cpu\"\n",
      "Train on 208 samples, validate on 408 samples\n",
      "Epoch 1/1\n",
      "208/208 [==============================] - 899s - loss: 0.2728 - acc: 0.1490 - val_loss: 1.1921e-07 - val_acc: 0.1397\n"
     ]
    }
   ],
   "source": [
    "base_filter()\n",
    "Xtrain, xtrain, nb_classes = load_data(\"BBXtrain.csv\")\n",
    "Xtest, xtest, nb_classes = load_data(\"SampleWithID.csv\")\n",
    "results, modes = run_model(Xtrain, xtrain, Xtest, xtest, nb_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Is the result good enough? \n",
    "    Why is that? \n",
    "    Could do provide a better solution?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# try it out here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "As long as we get the model (either SVM or LSTM) with high performance, we can then apply it on all interaction data set. Thus it's much easier for the company to understand why customer are calling and which part of their business need to be optimized for higher efficiency.\n",
    "This is one way to perform the data driven business strategy developing. The algorithm that we chose could be replaced in different application domain, but the logic remains the same. We also need to know how to chose between different algorithms to better fit the business case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference\n",
    "\n",
    "[1] Blei, David M. \"Latent Dirichlet Allocation - Definitions.\" Machine Learning. N.p., Jan. 2003. Web. 30 Oct. 2016.\n",
    "    https://www.cs.princeton.edu/~blei/papers/BleiNgJordan2003.pdf\n",
    "    \n",
    "[2] By Unrolling We Simply Mean That We Write out the Network for the Complete Sequence. For Example, If the Sequence We Care about Is a Sentence Of 5 Words, the Network Would Be Unrolled into a 5-layer Neural Network, One Layer for Each Word. The Formulas That Govern the Computation Happening in A RNN Are as Follows:. \"Recurrent Neural Networks Tutorial, Part 1 – Introduction to RNNs.\" WildML. N.p., 17 Sept. 2015. Web. 30 Oct. 2016.\n",
    "    http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/\n",
    "    \n",
    "[3] Olah, Christopher. \"Understanding LSTM Networks.\" -- Colah's Blog. August 27, 2015. Accessed October 30, 2016. \n",
    "        http://colah.github.io/posts/2015-08-Understanding-LSTMs/\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
