{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Introduction\n",
    "\n",
    "This tutorial will introduce you to some basic knowledge about implementing a collaborative filtering recommender system on a Netflix dataset.\n",
    "\n",
    "Recommender systems has been playing a key part in many data science application scenarios. In a nutshell, the goal of recommender systems is to maximize the profit (or user happiness) by recommending items that users want, and the biggest challenge in achieving this goal is to estimate ratings for the items that have not been seen by a user. \n",
    "\n",
    "An example of recommender systems - Amazon:\n",
    "[<img src=\"https://cdn-images-1.medium.com/max/2000/1*UEIb9b7VT0u5NMBeZajxjg.png\">](https://cdn-images-1.medium.com/max/2000/1*UEIb9b7VT0u5NMBeZajxjg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It adds to the complexity of the problem that the items can vary from movies to songs, posts, ads, products... While the companies or researchers collect millions of ratings from users of their chosen items, we need to know how to get insights out of the data and form computational models in order to achieve the goal. \n",
    "\n",
    "There are generally two high-level approaches in modeling the recommender system problem - content filtering and collaborative filtering:\n",
    "\n",
    "<img src=\"https://www.bizofit.com/blog/wp-content/uploads/2017/03/Picture1.png\">\n",
    "\n",
    "While content filtering requires side information (or attributes) of the items, the item attributes are usually not available or insufficient in most of the real-world problems. Therefore, a big perk of the collaborative filtering algorithm is that it does not need side information (or attributes) of the items other than the user preferences over them. The essence of collaborative filtering algorithm is the assumption that personal tastes are correlated, i.e. we would be able to predict the target user's preferences by looking at preferences of a group of user who are \"similar\" to this user. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So here comes the motivation of this tutorial - to demonstrate the effectiveness of collaborative filtering algorithms in tackling the challenges in building recommender systems. \n",
    "\n",
    "In this tutorial, we compare the performance of several rating algorithms and understand their differences. In particular, we will focus on the comparison between the two nearest neighbor approaches: the memory-based approach (or the nearest neighbor approach based on user-user similarity) and the model-based approach (or the nearest neighbor approach based on item-item similarity). \n",
    "\n",
    "Here's an illustration of the two approaches:\n",
    "[<img src=\"http://www.salemmarafi.com/wp-content/uploads/2014/04/collaborativeFiltering-960x540.jpg\">](http://www.salemmarafi.com/wp-content/uploads/2014/04/collaborativeFiltering-960x540.jpg)\n",
    "\n",
    "This tutorial will also introduce a few parameter tuning tricks in the implementation of the algorithms, including tuning the number of neighbors and the similarity metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tutorial content\n",
    "\n",
    "The Netflix dataset used in this tutorial can be downloaded from [here](https://drive.google.com/file/d/1GYL2Uy7XEX6-ziGNRxTwdMyyAcHXVLdG/view?usp=sharing).  \n",
    "\n",
    "We will cover the following topics in this tutorial:\n",
    "- Dataset Description\n",
    "\n",
    "- Corpus Exploration\n",
    "\n",
    "- User-User Similarity: The memory-based Collaborative Filtering approach\n",
    "\n",
    "- Item-Item Similarity: The model-based Collaborative Filtering approach\n",
    "\n",
    "- Pearson's Correlation Coefficient (PCC): The bias-reduced Collaborative Filtering approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Dataset Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset has 3 components: train/development/test.  The development and testing sets were created by sampling points from the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Training set:\n",
    "\n",
    "The training set is the input to the Collaborative Filtering system. The format of the data is as follows:\n",
    "\n",
    "\"MovieID\",\"UserID\",\"Rating\",\"RatingDate\"\n",
    "MovieID1,UserID11,rating_score_for_UserID11_to_MovieID1,the_date_of_rating\n",
    "MovieID1,UserID12,rating_score_for_UserID12_to_MovieID1,the_date_of_rating\n",
    "\n",
    "where rating_score_for_UserID*_to_MovieID* are decimal values between 1.0 and 5.0 and dates have the format YYYY-MM-DD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieid</th>\n",
       "      <th>userid</th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2001-03-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2001-02-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2000-01-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2001-02-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2000-01-21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieid  userid  rating        date\n",
       "0        0       0       3  2001-03-05\n",
       "1        0       1       3  2001-02-15\n",
       "2        1       2       3  2000-01-22\n",
       "3        1       3       4  2001-02-15\n",
       "4        1       5       3  2000-01-21"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train_data = pd.read_csv('train.csv',header=None)\n",
    "train_data.columns = ['movieid', 'userid', 'rating', 'date']\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Development set:\n",
    "\n",
    "The development set consists of movie-user pairs without a rating.  The format of the data is as follows:\n",
    "\n",
    "\"MovieID\",\"UserID\"\n",
    "MovieID1,UserID11\n",
    "MovieID1,UserID12\n",
    "\n",
    "Our task is to predict the ratings of these pairs given the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieid</th>\n",
       "      <th>userid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieid  userid\n",
       "0        2      23\n",
       "1        3     108\n",
       "2        3      29\n",
       "3        3      80\n",
       "4        4     137"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_data = pd.read_csv('dev.csv',header=None)\n",
    "dev_data.columns = ['movieid', 'userid']\n",
    "dev_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Development set queries:\n",
    " \n",
    "The user vectors from the training data corresponding to the users in the development set are in the format:\n",
    "\n",
    "\"UserID\" \"MovieID:Rating\" \"MovieID:Rating\" ... \"MovieID:Rating\"\n",
    "\n",
    "Note: when finding the k-nearest neighbors for a query of User_i, User_i does not count as one of the k-nearest neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0 0:3 134:5 153:3 159:5 175:3 178:3 191:4 239:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1 0:3 955:4 1092:4 1532:5 2168:4 2396:4 2987:4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2 1:3 88:2 304:3 338:5 347:4 404:5 451:3 466:3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4 18:4 19:4 32:2 62:5 66:3 70:5 80:5 85:2 89:3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5 1:3 4:2 19:4 32:4 48:4 52:2 54:1 74:1 116:2 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0  0 0:3 134:5 153:3 159:5 175:3 178:3 191:4 239:...\n",
       "1  1 0:3 955:4 1092:4 1532:5 2168:4 2396:4 2987:4...\n",
       "2  2 1:3 88:2 304:3 338:5 347:4 404:5 451:3 466:3...\n",
       "3  4 18:4 19:4 32:2 62:5 66:3 70:5 80:5 85:2 89:3...\n",
       "4  5 1:3 4:2 19:4 32:4 48:4 52:2 54:1 74:1 116:2 ..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_queries = pd.read_csv('dev.queries',header=None)\n",
    "dev_queries.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Test set format:\n",
    "\n",
    "The test set and test queries are given in the same format as the development set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corpus Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin the corpus exploration with a few basic statistics: \n",
    "- the total number of users\n",
    "- the total number of movies\n",
    "- the number of times any movie was rated '1'\n",
    "- the number of times any movie was rated '3'\n",
    "- the number of times any movie was rated '5'\n",
    "- the average movie rating across all users and movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys, math\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse import coo_matrix\n",
    "from scipy.sparse.linalg import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readTrain(file):\n",
    "    user = []\n",
    "    movie = []\n",
    "    rating = []\n",
    "    with open(file, 'r') as tr:\n",
    "        for line in tr:\n",
    "            t = line.split(\",\")\n",
    "            user.append(int(t[1]))\n",
    "            movie.append(int(t[0]))\n",
    "            rating.append(int(t[2])) # pre-process here, option 2\n",
    "\n",
    "    m = coo_matrix((rating, (user, movie)), dtype = float)\n",
    "    m = m.tocsr()\n",
    "    return m, rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of nonzero entries: 820367\n",
      "The total number of users: 10916\n",
      "The total number of movies: 5392\n"
     ]
    }
   ],
   "source": [
    "m, rating = readTrain('train.csv')\n",
    "print(\"The total number of nonzero entries:\", m.nnz)\n",
    "print(\"The total number of users:\", m.shape[0]) \n",
    "print(\"The total number of movies:\",  m.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since 820367 << 10916 * 5392, we know that the matrix is very sparse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of times any movie was rated '1': 53852\n",
      "the number of times any movie was rated '3': 260055\n",
      "the number of times any movie was rated '5': 139429\n",
      "the average movie rating across all users and movies: 3.3805674777264323\n"
     ]
    }
   ],
   "source": [
    "r = np.array(rating)\n",
    "print(\"the number of times any movie was rated '1':\", np.where(r == 1)[0].shape[0])\n",
    "print(\"the number of times any movie was rated '3':\", np.where(r == 3)[0].shape[0])\n",
    "print(\"the number of times any movie was rated '5':\", np.where(r == 5)[0].shape[0])\n",
    "print(\"the average movie rating across all users and movies:\", np.average(r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User-User Similarity\n",
    "\n",
    "We then proceed to the memory-based Collaborative Filtering approach. We start with reading in the queries from the dev.csv file. Note that for memory-based and model-based CF, there are subtle differences in the calculation of similarity as well as reading the queries, as shown in the similarity/similarityPair functions and the readQuery function below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the memory-based Collaborative Filtering approach, for each query, the similarity betwen the user in this query and all the users is computed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def similarity(m, q, func):\n",
    "    # m is the CSR matrix and q is the query row index\n",
    "    if func == 'cosine':\n",
    "        m = normalize(m)\n",
    "    res = np.dot(m, m[q].transpose()).toarray().flatten()\n",
    "    res[q] = 0 # exclude query itself\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, the queries in nature come in a random manner, which means a same user could appear in different queries several times with different movies. Therefore, in order to avoid repetitive similarity computation for the same user, a dictionary is implemented to group the queries by user.\n",
    "\n",
    "In addition, a list of tuple is implemented to keep track of the original order of the queries, which is important in the evaluation step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# read query file into a user-movies dictionary\n",
    "def readQuery(file, model):\n",
    "    output = None\n",
    "    tuples = [] # input order maintenance\n",
    "    with open(file, 'r') as f:\n",
    "        if model == \"memory\":\n",
    "            query = defaultdict(list) # user as key, list of movies as value\n",
    "            for line in f:\n",
    "                t = line.split(\",\")\n",
    "                tuples.append((int(t[1]), int(t[0])))\n",
    "                query[int(t[1])].append(int(t[0]))\n",
    "            output = (query, tuples)\n",
    "        if model == \"model\":\n",
    "            for line in f:\n",
    "                t = line.split(\",\")\n",
    "                tuples.append((int(t[0]),int(t[1])))\n",
    "            output = tuples\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item-Item Similarity\n",
    "\n",
    "\n",
    "On the other hand, the model-based Collaborative Filtering approach derives a model for pairwise similarity for further computation, as shown in the similarityPair function below. \n",
    "\n",
    "Therefore, we maintain only a tuple list to keep track of the queries, as shown in the readQuery function above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def similarityPair(m, func):\n",
    "    # m is the matrix\n",
    "    if func == 'cosine':\n",
    "        m = normalize(m)\n",
    "    res = m.transpose().dot(m)\n",
    "     # exclude query itself\n",
    "    np.fill_diagonal(res,0)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the model argument in the readQuery function has two different values, indicating the two different approaches (memory-based, model-based). \n",
    "\n",
    "Below is a list of all arguments we will be experimenting in this tutorial:\n",
    "\n",
    "- model (memory-based or model collaborative filtering): \n",
    "    \"memory\", \"model\"\n",
    "\n",
    "\n",
    "- k (number of k nearest neighbor): \n",
    "    10,100,500\n",
    "    \n",
    "    \n",
    "- similarity (similarity metric used for knn): \n",
    "    \"dotproduct\", \"cosine\"\n",
    "    \n",
    "    \n",
    "- weighing (approach for combining prediction given knn):\n",
    "    \"mean\",\"weight\"\n",
    "    \n",
    "    \n",
    "- pcc (if standardization used):\n",
    "    \"True\", \"False\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize\n",
    "from numpy.linalg import norm\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The knn and knnWeight functions can be shared in the two approaches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def knn(similarity, k):\n",
    "    return np.argpartition(-similarity, k)[:k]\n",
    "\n",
    "def knnWeight(similarity, knn):\n",
    "    return (similarity[[knn]]+1.)/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predict function for the two approaches are essentially different in the row or column slicing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(m, knn, similarity, func, model):\n",
    "    if model == \"memory\":\n",
    "        # row slicing and average\n",
    "        if (func == 'weight') and (np.sum(knnWeight(similarity,knn)) != 0):\n",
    "            res = np.average(m[knn].toarray(), axis = 0, weights = knnWeight(similarity, knn))\n",
    "        else:\n",
    "            res = np.mean(m[knn].toarray(), axis = 0)\n",
    "    if model == \"model\":\n",
    "        # column slicing and average\n",
    "        if (func == 'weight') and (np.sum(knnWeight(similarity,knn)) != 0):\n",
    "            res = np.average(m[:,knn], axis = 1, weights = knnWeight(similarity, knn))\n",
    "        else:\n",
    "            res = np.mean(m[:,knn], axis = 1)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the helper functions ready, we are now ready to implement the two collaborative filtering algorithms!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def memoryCF(m, query, k, func, func_w):\n",
    "    res = {} # return the dictionary {u,m} = prediction for all the queries\n",
    "    for user in query.keys():\n",
    "        sim = similarity(m, user, func) #(1, #user)\n",
    "        temp = knn(sim, k)\n",
    "        prediction = predict(m, temp, sim, func_w, \"memory\") #(1, #movies)\n",
    "        for movie in query[user]:\n",
    "            pred = prediction[movie] + 3 # plus 3\n",
    "            if pred > 5:\n",
    "                pred = 5\n",
    "            elif pred < 1:\n",
    "                pred = 1\n",
    "            res[user, movie] = pred\n",
    "    return res\n",
    "\n",
    "def modelCF(m, tuples, k, func, func_w):\n",
    "    res = [] # return the list of predictions given the query tuples\n",
    "    m = np.asarray(m, order = 'F') # column-major order\n",
    "    simPair = similarityPair(m, func)\n",
    "    for pair in tuples:\n",
    "        #print pair[0]\n",
    "        sim = simPair[pair[0]]\n",
    "        temp = knn(sim, k)\n",
    "        prediction = predict(m, temp, sim, func_w, \"model\")\n",
    "        pred = prediction[pair[1]] + 3\n",
    "        if pred > 5:\n",
    "            pred = 5\n",
    "        elif pred < 1:\n",
    "            pred = 1\n",
    "        res.append(pred)# plus 3\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getPrediction(model, trainFile, devFile, k, similarity, weighing):\n",
    "    if model == 'memory':\n",
    "        M, _ = readTrain(trainFile)\n",
    "        query, tuples = readQuery(devFile, model)\n",
    "        pred = memoryCF(M, query, k, similarity, weighing)\n",
    "    elif model == 'model':\n",
    "        M, _ = readTrain(trainFile)\n",
    "        tuples = readQuery(devFile, model)\n",
    "        pred = modelCF(M, tuples, k, similarity, weighing)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: We left out the weighing=\"weight\" option due to the limitation of space in this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "getPrediction('memory', 'train.csv', 'dev.csv', 10, \"dotproduct\", \"mean\")\n",
    "getPrediction('memory', 'train.csv', 'dev.csv', 100, \"dotproduct\", \"mean\")\n",
    "getPrediction('memory', 'train.csv', 'dev.csv', 500, \"dotproduct\", \"mean\")\n",
    "\n",
    "getPrediction('memory', 'train.csv', 'dev.csv', 10, \"cosine\", \"mean\")\n",
    "getPrediction('memory', 'train.csv', 'dev.csv', 100, \"cosine\", \"mean\")\n",
    "getPrediction('memory', 'train.csv', 'dev.csv', 500, \"cosine\", \"mean\")\n",
    "\n",
    "getPrediction('model', 'train.csv', 'dev.csv', 10, \"dotproduct\", \"mean\")\n",
    "getPrediction('model', 'train.csv', 'dev.csv', 100, \"dotproduct\", \"mean\")\n",
    "getPrediction('model', 'train.csv', 'dev.csv', 500, \"dotproduct\", \"mean\")\n",
    "\n",
    "getPrediction('model', 'train.csv', 'dev.csv', 10, \"cosine\", \"mean\")\n",
    "getPrediction('model', 'train.csv', 'dev.csv', 100, \"cosine\", \"mean\")\n",
    "getPrediction('model', 'train.csv', 'dev.csv', 500, \"cosine\", \"mean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the evaluation step, we will use one single evaluation metric typically used in collaborative filtering, Root Mean Squared Error (RMSE). RMSE is calculated as follows:\n",
    "\n",
    "    E = 0\n",
    "\n",
    "    For each rating\n",
    "\n",
    "        E = E + (true_rating - rating)^2\n",
    "    \n",
    "    RMSE = sqrt(E / num_ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the limitation of space in the tutorial, we leave out the output of the getPredictions function, which we use along with the gold standards behind the scenes to calculate the RMSE. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "\n",
    "A few conclusions about the choices of k, similarity metric, and the two approaches themselves:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion 1: Value of k\n",
    "\n",
    "In our experiment, for all the similarity metrics and all the weighting schemes, k = 10 always give the best RMSE. When k grows, the RMSE also grows, indicating a decrease in the performance. It is not dificult to understand, for example, given a query user, it's easier to find 10 similar users than to find 500 similar users. Getting a large set of similar users is not very reasonable, as a large subset of it might not be really similar to the query user. They are selected because of an overly large value of k. This is also true when it comes to movies. Therefore, a reasonable k for k nearest neighborhood on user-user similarity and item-item similarity is important. With some experiments, we find that when k falls into [25,30], the algorithm could achieve a relatively low RMSE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion 2: Similaity metric: dot product vs. cosine similarity\n",
    "\n",
    "Given the same value of k, the same similarity metric, for user-user similarity and item-item similarity, either choosing the dot product or choosing cosine similarity does not differ a lot. Cosine similarity only differs from dot product that it goes through a normalization process. For the dataset given, it's so sparse that such normalization does little work to help us revise the prediction. Thereforem, these two metrics are both good indicators for measuring similarity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion 3: Feature: user similarity vs. movie similarity\n",
    "\n",
    "User simialrity is a little better than the movie similarity. This is not difficult to find given the same similairty metric and the value of k. As we understand, there are not a large group of users being so generous(always give high ratings) while others being so strict(always give low ratings). On the other hand, movies differ a lot more than users. There are movies that are highly rated and there are movies that are not liked by users. As a result, for the dataset, user similarity is a better indicator than movie similarity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## References and Further Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Koren Y, Bell R, Volinsky C. Matrix factorization techniques for recommender systems[J]. Computer, 2009, 42(8). \n",
    "\n",
    "2. Ricci F, Rokach L, Shapira B. Introduction to recommender systems handbook[M]//Recommender systems handbook. springer US, 2011: 1-35.\n",
    "\n",
    "3. Resnick P, Varian H R. Recommender systems[J]. Communications of the ACM, 1997, 40(3): 56-58.\n",
    "\n",
    "4. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
 }
