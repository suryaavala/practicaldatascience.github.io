{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This tutorial aims to explain you what word embeddings are, how to create the word embeddings and how to use the created embeddings to perform sentiment analysis on tweets. The tutorial uses keras, a neural network library built on TensorFlow, Theano, Microsoft Cognitive Toolkit and MXNet.\n",
    "\n",
    "Word embeddings are numerical representations of text which would be able to closely represent the usage of a word in the text. If our training text (the text used to obtain the word embeddings) is large enough, we might get close to a generic representation of the words. \n",
    "\n",
    "\n",
    "A Word Embedding format generally tries to map a word using a dictionary to a vector. Each word is represented as a vector of real numbers forming the embedding.\n",
    "\n",
    "### Different type of word embeddings:\n",
    "#### Frequency based Embedding\n",
    "Frequent based embeddings as the term suggests, represent the frequency of the words in the documents in the form of a vector.\n",
    "Each vector has 'n' real numbers representing the frequency of the word in some form for 'n' documents.\n",
    "\n",
    "Some of the popularly used frequency based embeddings:\n",
    "\n",
    "1.Count Vector:\n",
    "It is a simple counter on the given document. The word frequencies are taken into a vector in order to be used for various operations like genreating ranks, finding PMI, etc.\n",
    "\n",
    "A popular way to do this would be to use count vectorizers.\n",
    "\n",
    "2.TF-IDF Vector: tf–idf or TFIDF, short for term frequency–inverse document frequency, is a numerical statistic that is intended to reflect how important a word is to a document in a collection or corpus. It is often used as a weighting factor in searches of information retrieval, text mining, and user modeling.\n",
    "\n",
    "3.Co-Occurrence Vector: It provides information about the occurance of given two words in various documents. This is useful find relationsips among various words.\n",
    "\n",
    "A co-occurrence matrix of size V X V. Now, for even a decent corpus V gets very large and difficult to handle. So generally, this architecture is never preferred in practice.\n",
    "\n",
    "A co-occurrence matrix of size V X N where N is a subset of V and can be obtained by removing irrelevant words like stopwords etc. for example. This is still very large and presents computational difficulties.\n",
    "\n",
    "#### Prediction based Embedding\n",
    "A Prediciton based embedding usually represents the probablity of a word occuring given a preset of words. These embeddings are largely based on nueral nets and popularly used in generating embeddings like word2vec, GloVe.\n",
    "\n",
    "1.Continuous Bag of words: We use CBOW to get the probability of a word given the context.\n",
    "\n",
    "2.Skip – Gram model: Skip-gram is the reverse of CBOW, here we try to predict the context given a word.\n",
    "\n",
    "## Word embedding use-cases:\n",
    "\n",
    "Since words embeddings are representations of words in numerical forms, we can use these to find similarities among words, find the odd words, perform sentiment analysis, find similar users based on their review texts, and whole lot of other things.\n",
    "\n",
    "\n",
    "## How to generate a word embedding:\n",
    "\n",
    "There are many different forms of embeddings and many different ways to generate them, in this tutorial, we'll be using keras to generate the word embedding and we'll be using the same embedding to perform sentiment analysis on tweets.\n",
    "\n",
    "### Installing the librarires:\n",
    "\n",
    "#### Keras:\n",
    "\n",
    "##### First, clone the library using git:\n",
    "\n",
    "git clone https://github.com/keras-team/keras.git\n",
    "\n",
    "##### Install the library using python:\n",
    "\n",
    "cd keras\n",
    "sudo python setup.py install\n",
    "\n",
    "#### For Anaconda users on Windows:\n",
    "\n",
    "\n",
    "conda install mingw libpython\n",
    "pip install git+git://github.com/Theano/Theano.git\n",
    "pip install git+git://github.com/fchollet/keras.git\n",
    "\n",
    "\n",
    "referred from: https://stackoverflow.com/questions/34097988/how-do-i-install-keras-and-theano-in-anaconda-python-on-windows\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's get started on learning the word embeddings for tweets:\n",
    "\n",
    "### First, let's download our data for the tweets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('data.zip', <http.client.HTTPMessage at 0x210653c1470>)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request\n",
    "urllib.request.urlretrieve(\"https://dl.dropboxusercontent.com/s/jdu7t8gof9gdbir/data.zip?dl=0\", \"data.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### extracting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "with zipfile.ZipFile(\"data.zip\",\"r\") as zip_ref:\n",
    "    zip_ref.extractall(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sentiment                                               text\n",
      "0          1  @stellargirl I loooooooovvvvvveee my Kindle2. ...\n",
      "1          1  Reading my kindle2...  Love it... Lee childs i...\n",
      "2          1  Ok, first assesment of the #kindle2 ...it fuck...\n",
      "3          1  @kenburbary You'll love your Kindle2. I've had...\n",
      "4          1  @mikefish  Fair enough. But i have the Kindle2...\n"
     ]
    }
   ],
   "source": [
    "#importing the datasets:\n",
    "import pandas as pd\n",
    "datafram = pd.read_csv(\"./data/train.csv\", sep=\",\", encoding=\"latin-1\", header = None)\n",
    "datafram = datafram[[0, 5]]\n",
    "datafram = datafram.dropna(axis = 0, how = \"any\")\n",
    "datafram.columns = ['sentiment', 'text']\n",
    "\n",
    "datafram1 = pd.read_csv(\"./data/test.csv\", sep=\",\", encoding=\"latin-1\", header = None)\n",
    "datafram1 = datafram1[[0, 5]]\n",
    "datafram1 = datafram1.dropna(axis = 0, how = \"any\")\n",
    "datafram1.columns = ['sentiment', 'text']\n",
    "\n",
    "print(datafram1.head())\n",
    "\n",
    "\n",
    "list_of_tweets = [string for string in datafram[\"text\"].head(n=5000)]\n",
    "sentiments_train = [sentiment for sentiment in datafram[\"sentiment\"].head(n=5000)]\n",
    "list_of_tweets_test = [string for string in datafram1[\"text\"].head(n=5000)]\n",
    "sentiments_test = [sentiment for sentiment in datafram1[\"sentiment\"].head(n=5000)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "498\n"
     ]
    }
   ],
   "source": [
    "print(len(list_of_tweets_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### let's consider the top(most frequent) 10000 words for our word embedding, the tokenizer get's the frequency of the words and puts in a matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The document 1 would be encoded to look like this:\n",
      "[3691, 68, 241, 87, 3692, 390, 161, 4, 1243, 12, 2350, 46, 807, 3693, 11, 1099, 39, 2, 37, 9, 454]\n",
      "The document 2 would be encoded to look like this:\n",
      "[7, 421, 19, 122, 44, 455, 216, 533, 132, 3694, 9, 6, 253, 339, 74, 4, 1449, 121, 35, 340, 971]\n",
      "The document 3 would be encoded to look like this:\n",
      "[3695, 1, 3696, 230, 348, 10, 3, 1450, 872, 2, 1451, 1452, 3, 407, 32, 34, 11, 3697]\n",
      "The document 4 would be encoded to look like this:\n",
      "[5, 559, 534, 358, 1100, 6, 38, 65, 17, 1244]\n",
      "The document 5 would be encoded to look like this:\n",
      "[3698, 30, 40, 16, 3699, 21, 33, 20, 619, 69, 55, 1, 102, 213, 1, 44, 94, 12, 33, 126, 98]\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "nb_words = 10000\n",
    "tokenizer = Tokenizer(num_words=nb_words)\n",
    "tokenizer.fit_on_texts(list_of_tweets)\n",
    "sequences = tokenizer.texts_to_sequences(list_of_tweets)\n",
    "sequences_test = tokenizer.texts_to_sequences(list_of_tweets_test)\n",
    "sequences = tokenizer.texts_to_sequences(list_of_tweets)\n",
    "\n",
    "for i,item in enumerate(sequences[:5]):\n",
    "    print(\"The document\", i+1,\"would be encoded to look like this:\")\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding a padding to the tweets because not all tweets may of full length(each tweet can contain a max of 120 words(newer standard is 240 but our data contains a max of 120))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "max_len = 120\n",
    "padded_sequences_train = pad_sequences(sequences, maxlen=max_len)\n",
    "padded_sequences_test = pad_sequences(sequences_test, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's build a model to obtain the embeddings and use it to classify the tweets\n",
    "We'll be using LSTM to build the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import SimpleRNN\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The entire set of words will be brought down to an emdedding of 25 dimensions\n",
    "### this is our embedding layer which would create word embeddings required for our classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Embedding(nb_words, 25))\n",
    "model.add(LSTM(25))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### this would be our final activation layer which would classify the tweet's sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_15 (Embedding)     (None, None, 25)          250000    \n",
      "_________________________________________________________________\n",
      "lstm_14 (LSTM)               (None, 25)                5100      \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 26        \n",
      "=================================================================\n",
      "Total params: 255,126\n",
      "Trainable params: 255,126\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now that we have defined our model, let's train and validate on the data we have\n",
    "\n",
    "#### We'll be using an rmsprop optimizer which is a gradient descent optimization algorithm used to reach to an optimal solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### spitting the data into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5000 samples, validate on 498 samples\n",
      "Epoch 1/3\n",
      "5000/5000 [==============================] - 28s 6ms/step - loss: 4.7220e-06 - acc: 1.0000 - val_loss: 5.2298 - val_acc: 0.6345\n",
      "Epoch 2/3\n",
      "5000/5000 [==============================] - 28s 6ms/step - loss: 2.2370e-07 - acc: 1.0000 - val_loss: 5.8905 - val_acc: 0.6345\n",
      "Epoch 3/3\n",
      "5000/5000 [==============================] - 26s 5ms/step - loss: 1.0000e-07 - acc: 1.0000 - val_loss: 5.8905 - val_acc: 0.6345\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#let's fit our data and validate it\n",
    "history = model.fit(padded_sequences_train, sentiments_train, epochs = 3,\n",
    "                    validation_data=(padded_sequences_test,sentiments_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now that we have trained our model, let's have a look as to how the embedding looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "intermediate_layer_model = Model(inputs=model.layers[0].input, outputs=model.layers[0].output)\n",
    "intermediate_output = intermediate_layer_model.predict(padded_sequences_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is what the matrix of word generated by the embedding layer looks like. In our neural net, this is the output of the first layer. This matrix contains of vector representations of each word across different documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.04162078 -0.03348149  0.03786346 ... -0.04674438 -0.06014031\n",
      "    0.00024746]\n",
      "  [ 0.04162078 -0.03348149  0.03786346 ... -0.04674438 -0.06014031\n",
      "    0.00024746]\n",
      "  [ 0.04162078 -0.03348149  0.03786346 ... -0.04674438 -0.06014031\n",
      "    0.00024746]\n",
      "  ...\n",
      "  [-0.00582225 -0.01026675  0.02723275 ... -0.0675716  -0.03286002\n",
      "   -0.01973963]\n",
      "  [-0.00969476 -0.04095811 -0.00980223 ... -0.02640022 -0.01141983\n",
      "   -0.04310979]\n",
      "  [ 0.03945119 -0.01108055  0.0396351  ... -0.02955022  0.03476034\n",
      "    0.01253241]]\n",
      "\n",
      " [[ 0.04162078 -0.03348149  0.03786346 ... -0.04674438 -0.06014031\n",
      "    0.00024746]\n",
      "  [ 0.04162078 -0.03348149  0.03786346 ... -0.04674438 -0.06014031\n",
      "    0.00024746]\n",
      "  [ 0.04162078 -0.03348149  0.03786346 ... -0.04674438 -0.06014031\n",
      "    0.00024746]\n",
      "  ...\n",
      "  [-0.00194294  0.00193267  0.01482169 ... -0.02822047 -0.05402488\n",
      "   -0.05006673]\n",
      "  [-0.00144253 -0.06722535  0.05305618 ... -0.06403372 -0.04306626\n",
      "    0.01246735]\n",
      "  [ 0.04671446  0.01487343  0.03778696 ... -0.01028239  0.02608524\n",
      "    0.0301709 ]]\n",
      "\n",
      " [[ 0.04162078 -0.03348149  0.03786346 ... -0.04674438 -0.06014031\n",
      "    0.00024746]\n",
      "  [ 0.04162078 -0.03348149  0.03786346 ... -0.04674438 -0.06014031\n",
      "    0.00024746]\n",
      "  [ 0.04162078 -0.03348149  0.03786346 ... -0.04674438 -0.06014031\n",
      "    0.00024746]\n",
      "  ...\n",
      "  [ 0.10012779 -0.06341252  0.01646713 ... -0.0662342  -0.01344566\n",
      "   -0.04054141]\n",
      "  [ 0.01273019  0.01372518  0.04350451 ... -0.02280546  0.01531036\n",
      "   -0.03933141]\n",
      "  [ 0.0293779  -0.01074352  0.02476607 ... -0.01702261 -0.01435005\n",
      "   -0.00822318]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 0.04162078 -0.03348149  0.03786346 ... -0.04674438 -0.06014031\n",
      "    0.00024746]\n",
      "  [ 0.04162078 -0.03348149  0.03786346 ... -0.04674438 -0.06014031\n",
      "    0.00024746]\n",
      "  [ 0.04162078 -0.03348149  0.03786346 ... -0.04674438 -0.06014031\n",
      "    0.00024746]\n",
      "  ...\n",
      "  [ 0.0601103  -0.06140871  0.03430462 ... -0.06618682  0.00923611\n",
      "   -0.00302633]\n",
      "  [ 0.03477598 -0.04985327  0.05956572 ... -0.03583379 -0.02891656\n",
      "   -0.06111253]\n",
      "  [ 0.04776362 -0.04833873  0.04136449 ... -0.02471089 -0.01688262\n",
      "    0.03201168]]\n",
      "\n",
      " [[ 0.04162078 -0.03348149  0.03786346 ... -0.04674438 -0.06014031\n",
      "    0.00024746]\n",
      "  [ 0.04162078 -0.03348149  0.03786346 ... -0.04674438 -0.06014031\n",
      "    0.00024746]\n",
      "  [ 0.04162078 -0.03348149  0.03786346 ... -0.04674438 -0.06014031\n",
      "    0.00024746]\n",
      "  ...\n",
      "  [ 0.02366696 -0.07015848  0.03525355 ... -0.00204991 -0.0427664\n",
      "   -0.02159615]\n",
      "  [ 0.04393804 -0.03637139 -0.01158868 ... -0.04493895 -0.03275845\n",
      "   -0.05108397]\n",
      "  [-0.0196682  -0.04964047 -0.00128552 ...  0.00941113 -0.01683521\n",
      "    0.01156454]]\n",
      "\n",
      " [[ 0.04162078 -0.03348149  0.03786346 ... -0.04674438 -0.06014031\n",
      "    0.00024746]\n",
      "  [ 0.04162078 -0.03348149  0.03786346 ... -0.04674438 -0.06014031\n",
      "    0.00024746]\n",
      "  [ 0.04162078 -0.03348149  0.03786346 ... -0.04674438 -0.06014031\n",
      "    0.00024746]\n",
      "  ...\n",
      "  [ 0.07702358  0.01832387  0.02729563 ... -0.03437546 -0.04901461\n",
      "   -0.02019781]\n",
      "  [ 0.0048205   0.01443387 -0.00697982 ... -0.01124056 -0.00573027\n",
      "   -0.04957398]\n",
      "  [ 0.04235768 -0.05357802  0.0772208  ... -0.1003823   0.00453435\n",
      "   -0.01746259]]]\n"
     ]
    }
   ],
   "source": [
    "print(intermediate_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's bring down the word representaions of all the words in the first document to a 2-D to help us visualize how they are spread across.\n",
    "\n",
    "We'll be using TSNE to perform this dimensionality reduction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computing 119 nearest neighbors...\n",
      "[t-SNE] Indexed 120 samples in 0.000s...\n",
      "[t-SNE] Computed neighbors for 120 samples in 0.012s...\n",
      "[t-SNE] Computed conditional probabilities for sample 120 / 120\n",
      "[t-SNE] Mean sigma: 0.000000\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: -42.567875\n",
      "[t-SNE] Error after 1000 iterations: -11.514710\n"
     ]
    }
   ],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "tsne = TSNE(n_components=2, verbose=1, perplexity=45,angle=0.99,init = 'pca',learning_rate=500.0)\n",
    "tsne_sample = tsne.fit_transform(intermediate_output[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's plot the spread of these words, which would result in something looking like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(tsne_sample[:, 0], tsne_sample[:, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a pre-trained model to train your neural net:\n",
    "\n",
    "You can use a pre-trained word embedding model like word2vec or GloVe to understand how words are being used and feed this as an input to your model.\n",
    "\n",
    "Following is a demonstration as to how we can do that.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### let's download the pre-trianed model for tweets from GloVe, the following file has a size of around 1.3GB, so it might take a while to download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "urllib.request.urlretrieve(\"http://nlp.stanford.edu/data/glove.twitter.27B.zip\", \"file.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the files have been downloaded, let's unzip them into the folder and load the unzipped files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "with zipfile.ZipFile(\"file.zip\",\"r\") as zip_ref:\n",
    "    zip_ref.extractall(\".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the 25 dimensional vector GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1193514 word vectors.\n"
     ]
    }
   ],
   "source": [
    "from numpy import asarray\n",
    "import numpy as np\n",
    "embeddings_index = dict()\n",
    "f = open('./glove.twitter.27B.25d.txt', encoding=\"utf-8\")\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Loaded %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create a weight matrix for words in training docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vocab_size = 1000000\n",
    "embedding_matrix = np.zeros((vocab_size, 25))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_16 (Embedding)     (None, None, 25)          25000000  \n",
      "_________________________________________________________________\n",
      "lstm_15 (LSTM)               (None, 25)                5100      \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1)                 26        \n",
      "=================================================================\n",
      "Total params: 25,005,126\n",
      "Trainable params: 5,126\n",
      "Non-trainable params: 25,000,000\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "embedding_layer_2 = Embedding(vocab_size, 25, weights=[embedding_matrix], trainable=False)\n",
    "model = Sequential()\n",
    "model.add(embedding_layer_2)\n",
    "model.add(LSTM(25))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### spitting the data into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5000 samples, validate on 498 samples\n",
      "Epoch 1/3\n",
      "5000/5000 [==============================] - 26s 5ms/step - loss: 0.0465 - acc: 0.9996 - val_loss: 2.9684 - val_acc: 0.6345\n",
      "Epoch 2/3\n",
      "5000/5000 [==============================] - 25s 5ms/step - loss: 8.2583e-05 - acc: 1.0000 - val_loss: 4.1717 - val_acc: 0.6345\n",
      "Epoch 3/3\n",
      "5000/5000 [==============================] - 24s 5ms/step - loss: 3.4631e-06 - acc: 1.0000 - val_loss: 5.2728 - val_acc: 0.6345\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#let's fit our data and validate it\n",
    "history = model.fit(padded_sequences_train, sentiments_train, epochs = 3,\n",
    "                    validation_data=(padded_sequences_test,sentiments_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "intermediate_layer_model = Model(inputs=model.layers[0].input, outputs=model.layers[0].output)\n",
    "intermediate_output = intermediate_layer_model.predict(padded_sequences_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computing 119 nearest neighbors...\n",
      "[t-SNE] Indexed 120 samples in 0.000s...\n",
      "[t-SNE] Computed neighbors for 120 samples in 0.002s...\n",
      "[t-SNE] Computed conditional probabilities for sample 120 / 120\n",
      "[t-SNE] Mean sigma: 0.000000\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: -67.600555\n",
      "[t-SNE] Error after 1000 iterations: -15.036423\n"
     ]
    }
   ],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "tsne = TSNE(n_components=2, verbose=1, perplexity=45,angle=0.99,init = 'pca',learning_rate=500.0)\n",
    "tsne_sample = tsne.fit_transform(intermediate_output[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(tsne_sample[:, 0], tsne_sample[:, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References:\n",
    "https://machinelearningmastery.com/use-word-embedding-layers-deep-learning-keras/\n",
    "\n",
    "https://nlp.stanford.edu/projects/glove/\n",
    "\n",
    "https://blog.keras.io/using-pre-trained-word-embeddings-in-a-keras-model.html\n",
    "\n",
    "https://www.quora.com/How-is-GloVe-different-from-word2vec\n",
    "\n",
    "https://en.wikipedia.org/wiki/Word_embedding\n",
    "\n",
    "https://www.analyticsvidhya.com/blog/2017/06/word-embeddings-count-word2veec/\n",
    "\n",
    "https://machinelearningmastery.com/what-are-word-embeddings/\n",
    "\n",
    "https://www.tensorflow.org/tutorials/word2vec\n",
    "\n",
    "https://en.wikipedia.org/wiki/Tf%E2%80%93idf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
