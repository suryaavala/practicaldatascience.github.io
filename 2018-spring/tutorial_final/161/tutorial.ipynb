{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This tutorial is going to introduce you to the basics of TensorFlow and walk you through a simple example using TensorFlow to classify handwritten digits from the MNIST dataset.\n",
    "\n",
    "### What is TensorFlow?\n",
    "TensorFlow is a software framework that was developed at Google and is used for numerical computation using data flow graphs. It facilitates the process of constructing, training, and deploying deep neural networks and has enabled people to make progress on various tasks such as cancer detection, language translation, and preventing blindness in people with diabetes among many others. TensorFlow is popular because it is flexible and allows user to easily create different kinds of models. One of the most common uses of tensorflow is image classification.\n",
    "\n",
    "### What is a Tensor?\n",
    "The data used in computations with TensorFlow are stored in multidimensional arrays called tensors. The name TensorFlow comes from the fact that we are designing computational graphs that define how the tensors will \"flow\" through the system. The number of dimensions a tensor has is referred to as its rank."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing TensorFlow\n",
    "\n",
    "In order to install the TensorFlow library you should first install pip then issue the following command: \n",
    "\n",
    "    $ pip install --upgrade tensorflow\n",
    "    \n",
    "This will install TensorFlow as well as all the packages that TensorFlow requires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to validate that the installation ran correctly, I'm going to run a short TensorFlow program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, TensorFlow!\n"
     ]
    }
   ],
   "source": [
    "hello = tf.constant('Hello, TensorFlow!')\n",
    "sess = tf.Session()\n",
    "print(sess.run(hello).decode())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above should print \"Hello, TensorFlow!\" which means we are now ready to run TensorFlow programs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Computational Graph\n",
    "\n",
    "### Simple Linear Model\n",
    "In order to get started with the basics of constructing a computational graph we will first start by creating a simple linear model and training this model.\n",
    "\n",
    "A computational graph is made up of nodes. These nodes can be constants which do not take in any arguments as seen below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0\n",
      "[1 2 3 4]\n",
      "[[4. 4.]\n",
      " [4. 4.]]\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant(2.0, tf.float32)\n",
    "b = tf.constant([1, 2, 3, 4])\n",
    "c = tf.constant(4.0, shape=[2, 2])\n",
    "\n",
    "sess = tf.Session()\n",
    "print(sess.run(a))\n",
    "print(sess.run(b))\n",
    "print(sess.run(c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variable a is a float with a value of 2.0, b is a 1D array, and c is a 2D array with two rows and two columns. In order to evaluate nodes and print out their values we must run them within a session which is created using tf.Session().\n",
    "\n",
    "Nodes can also be operations which take in tensors and return tensors as output. The code below shows how to create a node that returns the result of dividing two tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2. 2.]\n",
      " [2. 2.]]\n"
     ]
    }
   ],
   "source": [
    "div_node = tf.divide(c, a)\n",
    "print(sess.run(div_node))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nodes can also be defined to take in variable parameters as seen below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.0\n"
     ]
    }
   ],
   "source": [
    "d = tf.placeholder(tf.float32)\n",
    "e = tf.placeholder(tf.float32)\n",
    "mult_node = tf.multiply(d, e)\n",
    "print(sess.run(mult_node, feed_dict = {d: 10.0, e: 5.0}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables d and e are placeholders indicating that they will be given values later. When running the graph, the values are passed in through the argument feed_dict and the resulting tensor contains the result of multiplying nodes d and e together.\n",
    "\n",
    "Now we will create and train a linear model. First we must define the model parameters as shown below. We use tf.Variable to create the parameters. The method tf.Variable is similar to tf.constant however it allows for modifiable inputs as the model is being trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W = tf.Variable(1.0, tf.float32)\n",
    "b = tf.Variable(1.0, tf.float32)\n",
    "x = tf.placeholder(tf.float32)\n",
    "y = tf.placeholder(tf.float32)\n",
    "model = W * x + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above defines the model parameters and constructs the graph. Next, we must define the loss function and how to optimize the loss function. We will use a squared loss function and gradient descent with a step size of 0.01 as our optimization function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "squared_loss = tf.square(model - y)\n",
    "loss = tf.reduce_sum(squared_loss)\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.01)\n",
    "train = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to create example training data and feed it to the model. We will then train the function and evaluate our accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W: 2.0000064 b: 4.999981 loss: 2.3101165e-10\n"
     ]
    }
   ],
   "source": [
    "x_train = [1, 2, 3, 4]\n",
    "y_train = [7, 9, 11, 13]\n",
    "\n",
    "# must run the following line in order to initialize the variables\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "for i in range(2000):\n",
    "  sess.run(train, {x: x_train, y: y_train})\n",
    "\n",
    "W_, b_, loss_  = sess.run([W, b, loss], {x:x_train, y:y_train})\n",
    "print(\"W: %s b: %s loss: %s\" % (W_, b_, loss_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final coefficient estimates are printed above along with the loss. The true values of the coefficients are 2 and 5 so as we can see the model came pretty close to the correct values and our loss is very low.\n",
    "\n",
    "Next we are ready to work with a real example using TensorFlow to classify images.\n",
    "\n",
    "## Example: Classifying Images\n",
    "\n",
    "Now we are going to train a model to classify digits from the MNIST dataset. The dataset can be found at this website: http://yann.lecun.com/exdb/mnist/. This dataset has 60,000 examples and a test set of 10,000 examples. The images in the dataset are all normalized and centered within a fixed size. Each image is 28 by 28 pixels and is flattened to produce a vector of length 784 in order to make the computation easier.\n",
    "\n",
    "The first step is to download the data by running the following two lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The one_hot parameter ensures that the labels are represented as one hot vectors. For example, to represent the label 1, all indices in the vector would be 0 except for the value at index 1 which would be 1. This format will make it easier for us to predict labels as you will see later on.\n",
    "\n",
    "Next, we will want to define our model and its parameters. The model we are going to use for the classification is the softmax regression model. Softmax regression is a good model for our purposes as it returns a number between 0 and 1 which allows us to assign probabilities to each label and determine which label is most likely the correct one.\n",
    "\n",
    "Below, we define x as a placeholder which we will provide a value for later. W is the coefficient which is defined using tf.Variable so its value can be modified during the training of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "length = 28 * 28 # length of flattened image\n",
    "x = tf.placeholder(tf.float32, [None, length])\n",
    "W = tf.Variable(tf.ones([length, 10]))\n",
    "y = tf.nn.softmax(tf.matmul(x, W))\n",
    "y_train = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to define our loss function and how we are going to optimize it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cross_entropy = -1 * tf.reduce_sum(y_train * tf.log(y))\n",
    "cross_entropy = tf.reduce_mean(cross_entropy)\n",
    "opt = tf.train.GradientDescentOptimizer(0.01)\n",
    "train = opt.minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to initialize our variables and then train the model. We are going to run the training step 5000 times and for each step we are going to use a batch of 150 training examples. We use a smaller batch size because using the whole dataset for each training step would be expensive and take much longer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialize all variables\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "for batch in range(5000):\n",
    "  x_batch, y_batch = mnist.train.next_batch(150)\n",
    "  sess.run(train, feed_dict={x: x_batch, y_train: y_batch})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we are going to measure how well our model classified the digits. Since the labels are one-hot vectors we will compare the indices of the vectors with the highest probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9088\n"
     ]
    }
   ],
   "source": [
    "num_correct = tf.equal(tf.argmax(y, axis=1), tf.argmax(y_train, axis=1))\n",
    "num_correct = tf.cast(num_correct, tf.float32) # cast from boolean to float\n",
    "acc = tf.reduce_mean(num_correct)\n",
    "print(sess.run(acc, feed_dict={x: mnist.test.images, y_train: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we got an accuracy rate of roughly 91%. This is not a very good rate and small changes to our model could improve it. However, this example shows the easiness of creating and training a model with TensorFlow and the flexibility with which it allows us to define models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Resources\n",
    "This tutorial is meant to introduce you to the basics. For learning more about TensorFlow and information about how to use it to accomplish a variety of tasks the links below may be helpful.\n",
    "\n",
    "1. https://www.tensorflow.org/tutorials/\n",
    "2. https://github.com/tensorflow\n",
    "3. http://amygdala.github.io/ml/2017/02/03/transfer_learning.html\n",
    "4. https://www.tensorflow.org/tutorials/deep_cnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Citations\n",
    "https://www.tensorflow.org/versions/r1.1/get_started/get_started\n",
    "\n",
    "https://www.tensorflow.org/versions/r1.1/get_started/mnist/beginners\n",
    "\n",
    "https://www.lynda.com/Google-TensorFlow-tutorials/What-TensorFlow/601800/647721-4.html\n",
    "\n",
    "https://www.computerworlduk.com/open-source/what-is-tensorflow-how-are-businesses-using-it-3658374/\n",
    "\n",
    "https://research.googleblog.com/2017/02/announcing-tensorflow-10.html\n",
    "\n",
    "https://dataplatform.ibm.com/analytics/notebooks/91440c8b-0bfb-471e-b04e-235e4d9f510d/view?access_token=fb4380415a903111e26cec3bd95d8ba91a04746185c866fecde9d36643fa5585\n",
    "\n",
    "Data from: http://yann.lecun.com/exdb/mnist/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
