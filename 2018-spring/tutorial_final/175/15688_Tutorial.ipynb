{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONVOLUTIONAL NEURAL NETWORKS IN TENSORFLOW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Tensorflow](Tensorflow.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial will introduce you to convolutional neural networks. The primary role of any data science professional is to extract hidden patterns from data. While general machine learning techniques are sufficient for majority of the tasks,neural networks are particularly useful when the data is composed of images,speech or video. Convolutional neural network is a specific type of neural network which is primarily used for computer vision tasks (i.e image recognition).\n",
    "\n",
    "Recently a company called iSono Health used convolutional neural networks to develop a cost efficient automated ultrasound imaging platform to help women detect breast cancer early. The person who built the deep learning model for iSono Health is a data scientist. In this [article](https://blog.insightdatascience.com/automating-breast-cancer-detection-with-deep-learning-d8b49da17950) he talks about how he used several data science techniques such as data preprocessing and preparation to build the final model.\n",
    "\n",
    "Researchers at the University of Bonn are attempting to use convolutional neural networks in agricultural robots to monitor crop health so as to promote sustainable farming, thereby reducing the dependence on fertilizers, herbicides and pesticides. For further information please refer to this [article](https://www.kdnuggets.com/2017/11/real-world-deep-learning-neural-networks-smart-crops.html).\n",
    "\n",
    "Convolutional neural network is the choice of tool for nearly all image related tasks and this tutorial will introduce you to the basics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Convolutional Neural Network](cnn.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial Topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial a convolutional neural network is built using [tensorflow](https://www.tensorflow.org/). If you haven't come across tensorflow before please go through this link [Basics of tensorflow](https://medium.com/@curiousily/tensorflow-for-hackers-part-i-basics-2c46bc99c930) before you proceed.\n",
    "\n",
    "The following topics are covered in this tutorial:\n",
    "- [Installing tensorflow](#Installing-tensorflow)\n",
    "- [Loading data and visualization](#Loading-data-and-visualization)\n",
    "- [Creating layers of the network](#Creating-layers-of-the-network)\n",
    "- [Setting up the images](#Setting-up-the-images)\n",
    "- [Running the session](#Running-the-session)\n",
    "- [Summary and References](#Summary-and-References)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please run the following command in your jupyter notebook.\n",
    "\n",
    "!pip install tensorflow==1.3.0\n",
    "\n",
    "After you run the above command please make sure the following libraries work for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data and visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset used in this tutorial is the [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html). The dataset consists of 60000 32 x 32 color images in ten possible classes. 50000 images are use to train the model and 10000 images are used to test the model. There are five training batches and one test batch and each batch contains 10000 images. The training batches contain random images whereas the test batch contains exactly 1000 images from each posible class.\n",
    "\n",
    "Once you download the dataset please save it in the same directory as this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the data and check if it has been loaded properly\n",
    "Directory_name='cifar-10-batches-py/'\n",
    "files_name=['batches.meta','data_batch_1','data_batch_2','data_batch_3','data_batch_4','data_batch_5','test_batch']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The creators of the CIFAR-10 dataset provided the below function to extract the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        cifar_dict = pickle.load(fo, encoding='bytes')\n",
    "    return cifar_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now create the various training batches and the test batch.There are five training batches and one test batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Batches_meta=unpickle(Directory_name + files_name[0])\n",
    "Data_batch_1=unpickle(Directory_name + files_name[1])\n",
    "Data_batch_2=unpickle(Directory_name + files_name[2])\n",
    "Data_batch_3=unpickle(Directory_name + files_name[3])\n",
    "Data_batch_4=unpickle(Directory_name + files_name[4])\n",
    "Data_batch_5=unpickle(Directory_name + files_name[5])\n",
    "Test_batch=unpickle(Directory_name + files_name[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([b'batch_label', b'labels', b'data', b'filenames'])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keys of the various data batches and test batch\n",
    "Data_batch_1.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data-10000 x 3072 numpy array. Each row stores a 32x32 image. The 3072 value is split as follows: first 1024 values correspond to the red channel,next 1024 values to green channel and last 1024 values to blue channel. \n",
    "\n",
    "labels-10000 numbers in the range 0-9. These represent the possible class values of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{b'label_names': [b'airplane',\n",
       "  b'automobile',\n",
       "  b'bird',\n",
       "  b'cat',\n",
       "  b'deer',\n",
       "  b'dog',\n",
       "  b'frog',\n",
       "  b'horse',\n",
       "  b'ship',\n",
       "  b'truck'],\n",
       " b'num_cases_per_batch': 10000,\n",
       " b'num_vis': 3072}"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The various possible classes\n",
    "Batches_meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Classes](pic.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2f4e80f0>"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ntb5MPAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1b27c240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualizing a single image\n",
    "image=Data_batch_1[b'data']\n",
    "image=image.reshape(10000,3,32,32).transpose(0,2,3,1)\n",
    "plt.imshow(image[105],interpolation='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x18a2fc50>"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x18a64080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(image[369],interpolation='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating layers of the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the Convolutional neural network architectures used in practice consists of three main layers: Convolutional layer,Max pooling layer and the Fully connected layer. Description of the layers in detail:\n",
    "\n",
    "Input [32X32X3]- The input to the CNN is an image of height and width equal to 32 pixels and with three color channels (red,green,blue). \n",
    "\n",
    "Convolutional Layer  [32x32xnumber of filters]- each neuron will compute the dot product between their weights and a small region in the input. This layer is used to identify the various features in the input such as straight edges,curves,colors et cetera.\n",
    "\n",
    "Relu [32x32xnumber of filters]- this layer will apply an activation function to each element ( max(0,element) thresholding at zero).The output is the same size as the input. Note there can be other activation functions, such as sigmoid(rarely used), hyperbolic tangent function (tanh) et cetera.\n",
    "\n",
    "Pool [16x16xnumber of filters]- this operation will reduce the size along the height and width. In addition this operation controls the number of parameters, thereby controlling overfitting. There are several pooling operations that can be used such as max-pooling, average pooling, L2 norm pooling et cetera. In this tutorial I've used max pooling operation.\n",
    "\n",
    "Fully Connected Layer [1x1x10]- this layer will compute the final scores of each class. Each neuron in this layer will be connected to all the neurons in the previous layer. The activation of this layer is calculated with a matrix multiplication and a bias value.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameters\n",
    "\n",
    "Stride- we use this hyperparameter to slide over the input. For example when the stride is two then we move the filter two pixels at a time.\n",
    "\n",
    "Zero-padding - this hyperparameter is used to preserve information from the original input so that we can extract the low level features.\n",
    "\n",
    "If you require additional clarity on some of the terminologies mentioned, please refer to this [paper](http://cs231n.github.io/convolutional-networks/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Helper Functions for the various layers\n",
    "\n",
    "# Initialization of weights and bias\n",
    "def weights(size):\n",
    "    stddev_truncated_normal=0.1\n",
    "    Weights=tf.truncated_normal(shape=size,stddev=stddev_truncated_normal)\n",
    "    return tf.Variable(Weights)\n",
    "\n",
    "def bias(size):\n",
    "    value_bias=0.1\n",
    "    Bias=tf.constant(value=value_bias,shape=size)\n",
    "    return tf.Variable(Bias)\n",
    "\n",
    "def conv2D(input_x,m):\n",
    "    return tf.nn.conv2d(input_x,m,strides=[1,1,1,1],padding='SAME')\n",
    "\n",
    "def max_pool(conv_output):\n",
    "    stride_length=2\n",
    "    return tf.nn.max_pool(conv_output,ksize=[1,stride_length,stride_length,1],strides=[1,2,2,1],padding='SAME')\n",
    "\n",
    "def conv_layer(input_x,size):\n",
    "    w=weights(size)\n",
    "    b=bias([size[3]])\n",
    "    conv_output=conv2D(input_x,w)+b\n",
    "    return tf.nn.relu(conv_output)\n",
    "\n",
    "def fully_connected_layer(input_layer,user_size):\n",
    "    Shape=int(input_layer.get_shape()[1])\n",
    "    w=weights([Shape,user_size])\n",
    "    b=bias([user_size])\n",
    "    matrix_multiplication=tf.matmul(input_layer,w)\n",
    "    return  (matrix_multiplication + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Place holders [None] since we assign the size of the batch later\n",
    "x=tf.placeholder(tf.float32,shape=[None,32,32,3]) \n",
    "ytrue=tf.placeholder(tf.float32,shape=[None,10])\n",
    "\n",
    "holdout_prob=tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Various Layers 2 convolutional layers 2 max pool layers and 1 fully connected layer\n",
    "conv_layer1=conv_layer(x,[5,5,3,32])\n",
    "max_pool1=max_pool(conv_layer1)\n",
    "\n",
    "# Filter size can vary I've used 5X5 filter\n",
    "conv_layer2=conv_layer(max_pool1,[5,5,32,64])\n",
    "max_pool2=max_pool(conv_layer2)\n",
    "\n",
    "# we have used 2 max pool layers so 32/2/2=8 \n",
    "reshaped_layer=tf.reshape(max_pool2,[-1,8*8*64])\n",
    "full_layer=tf.nn.relu(fully_connected_layer(reshaped_layer,1024))\n",
    "\n",
    "random_dropout=tf.nn.dropout(full_layer,keep_prob=holdout_prob)\n",
    "ypred=fully_connected_layer(random_dropout,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Dropout and Optimizer\n",
    "\n",
    "Dropout - this is a technique to combat overfitting in neural networks. In this technique half the neurons are deactivated from a specific layer during training. In this tutorial I have used dropout only on the fully connected layer. When we are testing the model the dropout is deactivated.\n",
    "\n",
    "Optimizer- there are several optimizers that can be used such as Gradient Descent, Gradient Descent with momentum, RMSprop and Adam optimizer. This tutorial uses the Adam optimizer since it is a mixture of Gradient Descent with momentum and RMSprop, therefore gives better performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loss function\n",
    "loss_function=tf.nn.softmax_cross_entropy_with_logits(labels=ytrue,logits=ypred)\n",
    "loss=tf.reduce_mean(loss_function)\n",
    "\n",
    "#Optimizer\n",
    "optimizer=tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "train_var=optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create session\n",
    "sess=tf.InteractiveSession()\n",
    "\n",
    "# Initialize all the variables created and run\n",
    "var_init=tf.global_variables_initializer()\n",
    "sess.run(var_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The images are present in the 5 training batches. Each individual batch contains 10000 images, since we are using mini-batches during training, we need to combine all the 5 training batches into one large batch before we can obtain the mini batches. \n",
    "\n",
    "Moreover, the actual labels of the images are not one-hot encoded (process of converting categorical variables into it's own array, where value is 1 if the particular category is encountered and zero everywhere else). One hot encoding helps the neural network perform better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_batches=[Data_batch_1,Data_batch_2,Data_batch_3,Data_batch_4,Data_batch_5]\n",
    "\n",
    "# To vertically stack all the training images \n",
    "training_images=[dta[b'data'] for dta in training_batches]\n",
    "training_images=np.vstack(training_images)\n",
    "\n",
    "# Reshape images to correct size and normalize it\n",
    "training_images=training_images.reshape(len(training_images),3,32,32).transpose(0,2,3,1)\n",
    "training_images=training_images/training_images.max()\n",
    "\n",
    "# Horizontally stacking all the labels of the images and performing one hot encoding on them (there are 10 classes)\n",
    "training_labels=[label[b'labels'] for label in training_batches]\n",
    "training_labels=np.hstack(training_labels)\n",
    "one_hot_encoded=tf.one_hot(training_labels,10)\n",
    "\n",
    "training_labels=sess.run(one_hot_encoded)\n",
    "\n",
    "# Doing the same as above for test Labels\n",
    "testing_images=np.vstack(Test_batch[b'data'])\n",
    "testing_images=testing_images.reshape(len(testing_images),3,32,32).transpose(0,2,3,1)\n",
    "testing_images=testing_images/testing_images.max()\n",
    "\n",
    "testing_labels=np.hstack(Test_batch[b'labels'])\n",
    "test_one_hot_encoded=tf.one_hot(testing_labels,10)\n",
    "\n",
    "testing_labels=sess.run(test_one_hot_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To get next batches\n",
    "class Next_batch():\n",
    "    def __init__(self):\n",
    "        self.counter=0\n",
    "    def next_batch(self,batch_size):\n",
    "        x=training_images[self.counter:batch_size+self.counter].reshape(batch_size,32,32,3)\n",
    "        y=training_labels[self.counter:batch_size+self.counter]\n",
    "        self.counter=(self.counter+batch_size)% len(training_images) \n",
    "        return x,y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we run the session. There are two operations going on in the session. In the first part we train the convolutional neural network for 5000 epochs using a batch size of 100. The training operation takes a long time to finsh even for just 5000 epochs. To get higher accuracy we need to run the model for more number of epochs (there are other modifications that we can make, however they are not considered in this tutorial). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training is complete\n"
     ]
    }
   ],
   "source": [
    "batch_class=Next_batch()\n",
    "epochs=5000\n",
    "# GRAPH SESSION\n",
    "\n",
    "# Training the CNN\n",
    "for step in range(epochs):\n",
    "    x_value,y_value=batch_class.next_batch(100)\n",
    "    sess.run(train_var,feed_dict={x:x_value,ytrue:y_value,holdout_prob:0.5})\n",
    "    \n",
    "print('Training is complete')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the training is complete we test the model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Testing Accuacy\n",
      "67.5800025463 %\n"
     ]
    }
   ],
   "source": [
    "# Testing the model\n",
    "correct_prediction=tf.equal(tf.argmax(ypred,1),tf.argmax(ytrue,1))\n",
    "casting_to_float=tf.cast(correct_prediction,'float')\n",
    "casting=tf.reduce_mean(casting_to_float)\n",
    "\n",
    "print('Final Testing Accuacy')\n",
    "accuracy=sess.run(casting,feed_dict={x:testing_images,ytrue:testing_labels,holdout_prob:1.0})\n",
    "print(str(accuracy*100)+' %')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial covers the basics of convolutional neural networks. To better illustrate the concepts a basic model was developed in tensorflow. The hyperparameters have not been tuned using a cross validation set. To improve this model please refer to the following sources:\n",
    "\n",
    "- [introduction to visual recognition](http://cs231n.stanford.edu/syllabus.html)\n",
    "- [introduction to tensorflow](http://web.stanford.edu/class/cs20si/syllabus.html)\n",
    "- [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html)\n",
    "\n",
    "- [tensorflow for deep learning with python- udemy](https://www.udemy.com/courses/search/?q=tensorflow%20deep%20learning&src=sac&kw=tensorflow)\n",
    "\n",
    "Pictures are from [google](https://www.google.com/search?q=cnn+picture+for+cifar+10&source=lnms&tbm=isch&sa=X&ved=0ahUKEwiOtJXs_5TaAhXmt1kKHUISBTIQ_AUICigB&biw=1536&bih=711#imgrc=olX_OEK8LUkzmM:)\n",
    "\n",
    "The last link is from an online course and is paid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
