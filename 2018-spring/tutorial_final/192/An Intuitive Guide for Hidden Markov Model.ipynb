{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An Intuitive Guide to Hidden Markov Model (HMM)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an intuitive tutorial for the Hidden Markov Model. The tutorial aims to give readers a basic understanding of HMM, without using too much mathematical formula to mess a beginner's mind. The focus (scope) of the tutorial is mainly on what HMM is and how it works, so that the algorithm's proving part and the application part will be relatively brief. \n",
    "\n",
    "The tutorial is organized as below:\n",
    "\n",
    "0. **Why does it matter**,\n",
    "\n",
    "1. **What is the HMM**,\n",
    "\n",
    "2. **The three basic problems** for HMM,\n",
    "\n",
    "3. \\*Brief **Examples**.\n",
    "\n",
    "Have fun reading!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 1. Introduction\n",
    "\n",
    "In our daily life, the following scenarios can always be found:\n",
    "\n",
    "> *A foreigner is trying to say something in a language we don’t understand. We do hear the changing sounds and tones, but we cannot figure out the **hidden meaning** of each sound piece because we don’t know the language at all.*\n",
    "\n",
    "\n",
    "> *The stock price for a certain company is going up and down for some reasons. We only observe that the price is changing from day to day, but typically we don’t know the **hidden market forces** that caused all these changes.*\n",
    "\n",
    "In both of the above cases, there are some **hidden factors** (*meaning of sounds*, *market forces*) that lead to the events we observed (*sounds of speaking*, *price movement*). However, we don’t know **what the factors are** and **how they are affecting the observable results**. \n",
    "\n",
    "We really want to know though, because the hidden factors **is of great interests** (*we want to understand the speech*) and **is crucial for predicting** (*we want guess tomorrow's stock price*).\n",
    "\n",
    "**Hidden Markov Model (HMM)** is such a model to deal with this kind of problem. It is widely used in data science and machine learning, including areas such as price predicting, time-series analysis, and speech & image & gesture recognition. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. What is Hidden Markov Model\n",
    "\n",
    "### 2.1. An Intuitive Example\n",
    "\n",
    "To begin with, let's consider a super easy situation where we are playing with three different dice. Let's name them as `D6`, `D4`, and `D8`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/dice_detail.png\" width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> As you can see, `D6` has six possible results `[1,2,3,4,5,6]`, with a probability of getting each result equals to `1/6`. `D4` and `D8` are similarly defined.\n",
    "\n",
    "We are playing sequentially: we pick up one of the dice, roll it to get a number. Then we put it back, and do the process again.\n",
    "\n",
    "We pick up the first die randomly (`Pr=1/3` for each). **After that, there is a special \"transition setting\"**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/transition.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> If we are holding `D6` right now, next time we are most likely to pick up `D4` ($P(D6\\rightarrow D4)=0.7$), and less likely to pick up `D6` ($P(D6\\rightarrow D6)=0.2$) or `D8` ($P(D6\\rightarrow D8)=0.1$). Similarly, the probability of pick up a certain die will change regarding to which die (`D6`|`D4`|`D8`) we are holding right now.\n",
    " \n",
    "In this manner, we will pick up and roll the die one by one. For example we may pick up a sequence of dice `D4,D6,D4,D6,D6,D8`, and get a sequence of numbers, let's say, `4,1,2,5,3,8`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/possible_result.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, what if we write down the result numbers, and show **ONLY** the result to one of our friend? \n",
    "\n",
    "To give him a sense of the whole picture, we can tell him about every part of our process:\n",
    "1. there are **`three dice`**,\n",
    "2. there are **`eight unique numbers`** generated by the dice,\n",
    "3. there is a **probabilistic `“transition setting”`** between current die and the next pick up,\n",
    "4. each **die has a `probability distribution`** to generate certain result values, and\n",
    "5. we **`initialize the process`** by randomly choosing a die.\n",
    "\n",
    "For our dear friend, only the **result sequence is observable**, although he knows that it is generated by a **dice sequence that is hidden** from him. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/possible_result_2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "> Can he make a good guess on **what the dice sequence is**?\n",
    "\n",
    "**What we have done can already be modeled by a HMM.** In another word, if our friend has read this tutorial before, he can make a pretty good guess about the hidden dice sequence, and even predict the next result number."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Definition of Hidden Markov Model\n",
    "\n",
    "#### 2.2.1. Five Elements of a Hidden Markov Model\n",
    "\n",
    "Corresponding to the five pieces of information we gave to our friend (shown within parathesis in below definitions), a Hidden Markov Model is characterized by the following **five elements**:\n",
    "\n",
    "1. **The number of hidden `states` in the model.** $N$. (`three dice`). The hidden states are something we cannot observe. They can result in some of the observable events, and can transite from one to another.<br><br>\n",
    "2. **The number of distinct `observation symbols` in the model.** $M$. (`eight unique numbers`). The observation symbols correspond to the observed output of the system being modeled. Unlike hiddent state, they can be observed by us.<br><br>\n",
    "3. **The `state transition` probability distribution.** $A$. (`transition setting`). State transition transiting from one state (current) to another state (next time). This can be denoted as `transition matrix` $A$. For example, we can denote the \"transition setting\" in the previous example as:<br><br>$$A=\\left\\lgroup\\matrix{~&D6&D4&D8\\cr D6&0.2&0.7&0.1\\cr D4&0.5&0.3&0.2\\cr D8&0.3&0.1&0.6}\\right\\rgroup$$<br>where $A_{ij}$ means the probability to pick up die $j$ in the next time when currently holding die $i$.<br><br>\n",
    "4. **The `observation symbol transition` probability distribution in each state.** $B$. (`die's probability distribution`). For each state (die), there will be a probability distribution about which observation symbol may be generated. This can also be denoted as a matrix - `emission matrix` $B$. For the previous example:<br><br>$$B=\\left\\lgroup\\matrix{~&1&2&3&4&5&6&7&8&9\\cr D6&1/6&1/6&1/6&1/6&1/6&1/6&0&0&0\\cr D4&1/4&1/4&1/4&1/4&0&0&0&0&0\\cr D8&1/8&1/8&1/8&1/8&1/8&1/8&1/8&1/8&1/8}\\right\\rgroup$$<br>where $B_{ij}$ means the probability to roll a $j$ with die $i$.<br><br>\n",
    "5. **The `initial state` distribution** $\\pi$. (`start by randomly pick`). In the previous example, our initial state $\\pi=[\\frac{1}{3},\\frac{1}{3},\\frac{1}{3}]$, as we randomly pick one of the three dice.\n",
    "\n",
    "Just like that our friend cannot see the hidden dice, the hidden states are always unobservable. That's why this is a **HIDDEN** Markov Model.\n",
    "\n",
    "#### 2.2.2. Markov Process\n",
    "\n",
    "Then why hidden **MARKOV**? The answer is in the state transition assumption. \n",
    "\n",
    "An essential feature of a HMM is that the **hidden states** are performing a **`markov process`**. In a conceptual level, this means that the future state is only determined by the current state, and is irrelevant to the previous states. **In another word, the future state is conditionally independent from the previous states given the current state.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/markov_process.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> In our dicing example, according to our setting, the probability of each die to be picked in the next round **depends only on which die we are holding right now**. This is exactly an example of `markov process`.\n",
    "\n",
    "Ref: \n",
    "[CMU-stat-lecture-note](http://www.stat.cmu.edu/~cshalizi/754/notes/lecture-09.pdf), [wikipedia](https://en.wikipedia.org/wiki/Markov_chain)\n",
    "\n",
    "### 2.3. A Practical Definition\n",
    "\n",
    "Given all conceptual definition above, we can define a HMM model in Python as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class HMM:\n",
    "    def __init__(self, Ann, Bnm, pi1n):\n",
    "        self.A = np.array(Ann) # A, transition matrix (N * N)\n",
    "        self.B = np.array(Bnm) # B, emisson matrix (N * M)\n",
    "        self.pi = np.array(pi1n) # pi, initial state (1 * N)\n",
    "        self.N = self.A.shape[0] # N, number of hidden states\n",
    "        self.M = self.B.shape[1] # M, number of observation symbols\n",
    "\n",
    "        \n",
    "    # print out the HMM model.\n",
    "    def printhmm(self):\n",
    "        print(\"========================================\")\n",
    "        print(\"HMM content: \")\n",
    "        print(\"N = \", self.N)\n",
    "        print(\"M = \", self.M)\n",
    "        print(\"hmm.A = \", self.A)\n",
    "        print(\"hmm.B = \", self.B)\n",
    "        print(\"hmm.pi = \", self.pi)\n",
    "        print(\"========================================\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Three Basic Problems for HMMs\n",
    "\n",
    "Then what can a HMM do? \n",
    "\n",
    "> **Generally speaking, you can generate a HMM based only on your observation, and perform prediction based on this model.**\n",
    "\n",
    "To achieve this, there are **three problems** of interest that must be solved for a HMM model to be useful. \n",
    "\n",
    "1. **Evaluation**: Given the model ($A,B,\\pi$), what is the probability of getting a given observation sequence $O=o_1\\dots o_t$?\n",
    "2. **Decoding**: Given the model ($A,B,\\pi$) and the observation sequence $O$, what is the most likely state sequence $P=p_1\\dots p_t$?\n",
    "3. **Learning**: Given the observation sequence $O$, the # states $N$, and # observations $M$, how to learn a model?\n",
    "\n",
    "In the following sections, we will continue using the rolling dice example. Assume we roll dice for three times and get a observation sequence $O=[4,1,2]$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='images/example_observation.png' width = 650/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Evaluation - Forward algorithm\n",
    "\n",
    "> Given the model ($A,B,\\pi$), what is the probability of getting a given observation sequence $O=o_1\\dots o_t$?\n",
    "\n",
    "The most intuitive solution is to exhaust every possible dice sequence to generate the given ovservation sequence, calculate each probability, and sum them up. However this can be super computational costly.\n",
    "\n",
    "Alternative solution is the `forward algorithm`. Below is a simple illustration.\n",
    "\n",
    "Assume that we roll a die first, and get the observation $o_1=4$. We can calculate **the probability of rolling that die and get the observed $o_1$** for each possible die (`D6`|`D4`|`D8`). e.g., for `D6`, \n",
    "\n",
    "$$Pr(p_1=D6,o_1=4)=Pr(p_1=D6)*Pr(o_1=4|p_1=D6)=\\frac{1}{3}*\\frac{1}{6}=\\frac{1}{18}$$\n",
    "\n",
    "In this way, we can generate a table:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/forward_1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each cell represents **the probability of getting the observation sequence when a certain die is picked at this step.** (a formal definition can be found in the code below). For convenient, we denote the computed value of each cell as `val(D*, o*)`.\n",
    "\n",
    "Similarly, we can pick and roll a die again (and get 1), and we can calculate the second column:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/forward_2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that to calculate each cell in $o_2$, we need value in each cell in $o_1$ (`Val(Di, o1)`).\n",
    "\n",
    "Again, calculate the third column:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/forward_3.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notice that to calculate each cell in $o_3$, we need value of each cell in $o_2$ (`Val(Di, o1)`). However, we DO NOT need information in $o_1$!**\n",
    "\n",
    "In this manner (in fact, `dynamic programming`), we can calculate total probability at any step, without worrying about computational cost issue.\n",
    "\n",
    "Below is a simple implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An Intuitive Guide to Hidden Markov Model (HMM)\n",
    "# Forward Algorithm\n",
    "# @author author\n",
    "# @params O       the observation sequence\n",
    "# @return alphas  a sequence of alpha generated when doing the algorithm\n",
    "# @return prob    the probability of generating this observation sequence\n",
    "def Forward(self, O):\n",
    "    # T: length of the observation sequence\n",
    "    T = len(O) \n",
    "\n",
    "    # alphas: an empty table to store middle results (value of each cell in the table)\n",
    "    alphas = np.zeros((T, self.N), np.float) \n",
    "    # the alphas(t, i) can be formally defined as:\n",
    "    # at time t, given that the hidden state is i, \n",
    "    # the probability of generating the observation sub-sequence (o1, o2, ..., ot)\n",
    "\n",
    "    # first calculate the initial situation\n",
    "    for i in range(self.N):\n",
    "        alphas[0, i] = self.pi[i] * self.B[i, O[0]]\n",
    "\n",
    "    # then for each step, calculate the next step alpha value based on the current alpha value\n",
    "    # according to the table shown above, for ot+1, if the hidden state is j,\n",
    "    # alphas(t+1, j) = sum(i = 1...N){alpha(t, i) * A(i, j) * B(j, ot+1)}\n",
    "    #               = sum(i = 1...N){alpha(t, i) * A(i, j)} * B(j, ot+1)\n",
    "    for t in range(T - 1):\n",
    "        for j in range(self.N):\n",
    "            sum = 0.0\n",
    "            for i in range(self.N):\n",
    "                sum += alphas[t, i] * self.A[i, j] # A is the transition matrix\n",
    "            alphas[t + 1, j] = sum * self.B[j, O[t + 1]] # B is the emission matrix\n",
    "\n",
    "    # the final probability is the sum of the alphas of the current step\n",
    "    prob = 0.0\n",
    "    for i in range(self.N):\n",
    "        prob += alphas[T - 1, i]\n",
    "\n",
    "    return alphas, prob\n",
    "\n",
    "# add this function to the customized HMM class\n",
    "HMM.Forward = Forward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Decoding - Viterbi algorithm\n",
    "\n",
    "> Given the model ($A,B,\\pi$) and the observation sequence $O$, what is the most likely state sequence $P=p_1\\dots p_t$?\n",
    "\n",
    "Again, as the model is given, we can exhaust every possible dice sequence. This can be super computational costly.\n",
    "\n",
    "Alternative solution is the `Viterbi algorithm`. Below is a simple illustration.\n",
    "\n",
    "Again, let's assume that we roll a die first, and get the observation $o_1=4$. For each possible die (`D6`|`D4`|`D8`), the **probability of rolling that die and get $o_1=4$** can be generated in the same way as in Forward algorithm.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/viterbi_1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's take a look at each cell in the table. In each column (step), we want to record **the highest probability to generate the given observation for a dice sequence**. e.g., for the cell (D6,$o_2$), it records the highest probability to generate `[4,1]` when the dice sequence's second die ($p_2$) is `D6`. i.e.\n",
    "\n",
    "$$Val(D6,o_2)=max\\{Var(D6,o_1)*Pr(p_2=D6|p_1=D6)*Pr(o_2=1|p_2=D6),\\\\\\quad \\quad \\quad \\quad \\quad \\quad \\quad Var(D4,o_1)*Pr(p_2=D6|p_1=D4)*Pr(o_2=1|p_2=D6),\\\\\\quad \\quad \\quad \\quad \\quad \\quad \\quad Var(D8,o_1)*Pr(p_2=D6|p_1=D8)*Pr(o_2=1|p_2=D6)\\}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/viterbi_2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar for the third column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/viterbi_3.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is easy to find out again that **to calculate current cell, we only need to use computed values in the previous column!** Step by step, when we reach the final step, we can find out the sequence of hidden states that has the highest probability to generate the given observation.\n",
    "\n",
    "Below is a simple implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An Intuitive Guide to Hidden Markov Model (HMM)\n",
    "# Viterbi Algorithm\n",
    "# @author author\n",
    "# @params O             the observation sequence\n",
    "# @return hiddenStates  the predicted hidden states sequence\n",
    "# @return prob          the probability that the hidden states sequence generate this observation sequence\n",
    "def viterbi(self, O):\n",
    "    # T: length of the observation sequence\n",
    "    T = len(O)\n",
    "    # deltas: an empty table to store middle results (value of each cell in the table)\n",
    "    deltas = np.zeros((T, self.N), np.float)\n",
    "    # phi: an empty table to store which state is chosen at each cell\n",
    "    phi = np.zeros((T, self.N), np.float)\n",
    "    # hiddenStates: the result hiddenStates that most likely generates such an observation\n",
    "    hiddenStates = np.zeros(T)\n",
    "    \n",
    "    # first calculate the initial situation\n",
    "    for i in range(self.N):\n",
    "        deltas[0, i] = self.pi[i] * self.B[i, O[0]]\n",
    "        phi[0, i] = 0\n",
    "\n",
    "    # then for each step, calculate the current step delta value based on the previous delta value\n",
    "    # according to the table shown above, for ot, if the hidden state is j,\n",
    "    # delta(t, j) = max(i = 1...N){delta(t-1, i) * A(i, j) * B(j, ot)}\n",
    "    #             = max(i = 1...N){delta(t-1, i) * A(i, j)} * B(j, ot)\n",
    "    for t in range(1, T):\n",
    "        for i in range(self.N):\n",
    "            # calculate each product first to make it easier to choose max\n",
    "            tmp = np.array([deltas[t - 1, j] * self.A[j, i] for j in range(self.N)])\n",
    "            deltas[t, i] = self.B[i, O[t]] * tmp.max() # calculate new delta\n",
    "            phi[t, i] = tmp.argmax() # record which state is chosen to reach the max delta\n",
    "\n",
    "    # the max probability in the last column is the final probability\n",
    "    prob = deltas[T - 1, :].max()\n",
    "    # restore the sequence of hidden states\n",
    "    hiddenStates[T - 1] = deltas[T - 1, :].argmax()\n",
    "    for t in range(T - 2, -1, -1):\n",
    "        # notice that each time we choose a previous state to reach the highest prob for current cell\n",
    "        # so the t-th hiddenstates is actually chosen in the (t+1)-th step\n",
    "        hiddenStates[t] = phi[t + 1, int(hiddenStates[t + 1])]\n",
    "    return hiddenStates, prob\n",
    "\n",
    "# add this function to the customized HMM class\n",
    "HMM.viterbi = viterbi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Learning - Baum-Welch Algorithm\n",
    "\n",
    "> Given the observation sequence $O$, the # states $N$, and # observations $M$, how to learn a model?\n",
    "\n",
    "For most of the time, we don't know the model in advance. What we have is the observation sequence(s). Thus, learning the model is an extreme important task.\n",
    "\n",
    "The Baum-Welch Algorithm is one of the EM algorithm. **In general, the algorithm initializes the model ($A,B,\\pi$) randomly, and calculates the probability of generating the given observation sequence by this model (`E-step` in the following code). Then the algorithm try to update the model based on the calculation result (`M-step` in the following code).**\n",
    "\n",
    "As this algorithm is much more difficult to explain in detail, here we'll simply take a look at a straight-forward example code, hopefully we can get a sense of what the algorithm is trying to achieve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An Intuitive Guide to Hidden Markov Model (HMM)\n",
    "# Backward Algorithm\n",
    "# Similar to forward algorithm. we need the betas to do the Baum-Welch Algorithm.\n",
    "# @author author\n",
    "# @params O      the observation sequence\n",
    "# @return betas  middle variables storing information used for model update in Baum-Welch Algorithm\n",
    "def Backward(self, O):\n",
    "    # T: length of the observation sequence\n",
    "    T = len(O)\n",
    "    # betas: an empty table to store middle calculation results\n",
    "    betas = np.zeros((T, self.N), np.float)\n",
    "    # note: the true definition of beta can be found in reference documents\n",
    "\n",
    "    # first calculate the initial situation\n",
    "    for i in range(self.N):\n",
    "        betas[T - 1, i] = 1.0\n",
    "\n",
    "    # then for each step, calculate the current step beta value based on the next beta value\n",
    "    for t in range(T - 2, -1, -1):\n",
    "        for i in range(self.N):\n",
    "            sum = 0.0\n",
    "            for j in range(self.N):\n",
    "                sum += self.A[i, j] * self.B[j, O[t + 1]] * betas[t + 1, j]\n",
    "            betas[t, i] = sum # update beta, so the next iteration can use previous results\n",
    "    return betas\n",
    "\n",
    "HMM.Backward = Backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An Intuitive Guide to Hidden Markov Model (HMM)\n",
    "# Compute Xi - an important middle calculation result to do the Baum-Welch Algorithm.\n",
    "# @author author\n",
    "# @params O      the observation sequence\n",
    "# @params alpha  alpha in forward algorithm\n",
    "# @params beta   beta in backward algorithm\n",
    "# @params gamma  gamma generated by ComputeGamma\n",
    "# @return xi     middle variables used for model update in Baum-Welch Algorithm\n",
    "def ComputeXi(self, O, alpha, beta, gamma):\n",
    "    # T: length of the observation sequence\n",
    "    T = len(O)\n",
    "    # xi: an empty table to store middle calculation results\n",
    "    xi = np.zeros((T, self.N, self.N))\n",
    "\n",
    "    # calculate xi based on current observation and current model\n",
    "    # this implementation is based on lecture slides of 04831230-Theory of Automatic Control, Peking University\n",
    "    for t in range(T - 1):\n",
    "        sum = 0.0\n",
    "        for i in range(self.N):\n",
    "            for j in range(self.N):\n",
    "                xi[t, i, j] = alpha[t, i] * beta[t + 1, j] * self.A[i, j] * self.B[j, O[t + 1]]\n",
    "                sum += xi[t, i, j]\n",
    "        for i in range(self.N):\n",
    "            for j in range(self.N):\n",
    "                xi[t, i, j] /= sum # normalized\n",
    "    return xi\n",
    "\n",
    "HMM.ComputeXi = ComputeXi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An Intuitive Guide to Hidden Markov Model (HMM)\n",
    "# Compute Gamma - another important middle calculation result to do the Baum-Welch Algorithm.\n",
    "# @author author\n",
    "# @params T      the length of observation sequence\n",
    "# @params alpha  alpha in forward algorithm\n",
    "# @params beta   beta in backward algorithm\n",
    "# @return gamma  middle variables used for model update in Baum-Welch Algorithm\n",
    "def ComputeGamma(self, T, alpha, beta):\n",
    "\n",
    "    gamma = np.zeros((T, self.N), np.float)\n",
    "\n",
    "    # calculate gamma based on current observation and current model\n",
    "    # this implementation is based on lecture slides of 04831230-Theory of Automatic Control, Peking University\n",
    "    for t in range(T):\n",
    "        denominator = 0.0\n",
    "        for j in range(self.N):\n",
    "            gamma[t, j] = alpha[t, j] * beta[t, j]\n",
    "            denominator += gamma[t, j]\n",
    "        for i in range(self.N):\n",
    "            gamma[t, i] = gamma[t, i] / denominator\n",
    "    \n",
    "    return gamma\n",
    "\n",
    "HMM.ComputeGamma = ComputeGamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An Intuitive Guide to Hidden Markov Model (HMM)\n",
    "# Baum-Welch Algorithm\n",
    "# this implementation is based on lecture slides of 04831230-Theory of Automatic Control, Peking University\n",
    "# @author author\n",
    "# @params O      the observation sequences (list of list). multiple observations as training data\n",
    "def BaumWelch(self, O):\n",
    "\n",
    "    # initial params\n",
    "    L = len(O) # number of training data (observations)\n",
    "    T = len(O[0]) # length of observation\n",
    "    stopThreshold = 0.01 # threshold to stop\n",
    "    iterCount = 0 # number of iterations\n",
    "    isInit = 1 # check if it is the first time\n",
    "    prob = 0.0 # current model's highest probability in the current round of EM algorithm\n",
    "    prevProb = 0.0 # last model's highest probability\n",
    "    delta = 0.0 # difference between current probability and previous probability\n",
    "    prevDelta = 10e-20 # previosu delta\n",
    "    ratio = 0.0 # delta / prevdelta\n",
    "    # middle variables to store calculation results\n",
    "    alpha = np.zeros((T, self.N), np.float)\n",
    "    beta = np.zeros((T, self.N), np.float)\n",
    "    gamma = np.zeros((T, self.N), np.float)\n",
    "    xi = np.zeros((T, self.N, self.N))\n",
    "    pi = np.zeros((T), np.float)\n",
    "    # sub middle variables to store calculation results based on above variables\n",
    "    denominatorA = np.zeros((self.N), np.float)\n",
    "    denominatorB = np.zeros((self.N), np.float)\n",
    "    numeratorA = np.zeros((self.N, self.N), np.float)\n",
    "    numeratorB = np.zeros((self.N, self.M), np.float)\n",
    "    \n",
    "    # begin iteration\n",
    "    # Generally speaking, the E-step is calculating all the needed variables \n",
    "    # by using the current model to avaluate the current observation.\n",
    "    # Then in the M-step, we will update the model parameter (A, B, pi) based on\n",
    "    # our calculation result in E-step.\n",
    "    # The detail about all formulas and why this works should be found in reference resources\n",
    "    while True:\n",
    "        iterCount += 1 # count the number of iterations\n",
    "        \n",
    "        # E-step: calculate all the middle variables based on current observation sequence and current model\n",
    "        for l in range(L):\n",
    "            # first, calculate different middle variables defined above (alpha, beta, gamma, xi)\n",
    "            alpha, curprob = self.Forward(O[l])\n",
    "            beta = self.Backward(O[l])\n",
    "            gamma = self.ComputeGamma(T, alpha, beta)\n",
    "            xi = self.ComputeXi(O[l], alpha, beta, gamma)\n",
    "            # then, store the current probability, later on this will be used to judge if the iteration should stop\n",
    "            prob += curprob\n",
    "            # finally, pre-calculate some middle calculation results to make it more clear in M-step\n",
    "            for i in range(self.N):\n",
    "                pi[i] += gamma[0, i]\n",
    "                for t in range(T - 1):\n",
    "                    denominatorA[i] += gamma[t, i]\n",
    "                    denominatorB[i] += gamma[t, i]\n",
    "                denominatorB[i] += gamma[T - 1, i]\n",
    "\n",
    "                for j in range(self.N):\n",
    "                    for t in range(T - 1):\n",
    "                        numeratorA[i, j] += xi[t, i, j]\n",
    "                for k in range(self.M):\n",
    "                    for t in range(T):\n",
    "                        if O[l][t] == k:\n",
    "                            numeratorB[i, k] += gamma[t, i]\n",
    "\n",
    "        # M-step: use all pre-computed middle result in E-step to update model parameter (A, B, pi)\n",
    "        for i in range(self.N):\n",
    "            self.pi[i] = 0.001 / self.N + 0.999 * pi[i] / L # update pi\n",
    "            for j in range(self.N):\n",
    "                self.A[i, j] = 0.001 / self.N + 0.999 * numeratorA[i, j] / denominatorA[i] # update A\n",
    "                numeratorA[i, j] = 0.0 # initialize the middle varibles for next iteration\n",
    "            for k in range(self.M):\n",
    "                self.B[i, k] = 0.001 / self.M + 0.999 * numeratorB[i, k] / denominatorB[i] # update B\n",
    "                numeratorB[i, k] = 0.0 # initialize the middle varibles for next iteration\n",
    "\n",
    "            pi[i] = denominatorA[i] = denominatorB[i] = 0.0 # initialize the middle varibles for next iteration\n",
    "\n",
    "        # after each training observation has been taken into account, check if we should break the iteration\n",
    "        if isInit == 1: # first iteration, there is no prevProb, so handle separately\n",
    "            isInit = 0\n",
    "            prevProb = prob\n",
    "            ratio = 1\n",
    "            continue\n",
    "        # check how much the probability has been improved\n",
    "        delta = prob - prevProb\n",
    "        # the improve ratio compared to last time\n",
    "        ratio = delta / prevDelta\n",
    "        prevProb = prob\n",
    "        prevDelta = delta\n",
    "        prob = 0\n",
    "        \n",
    "        # if there is not much improvement, stop the EM algorithm\n",
    "        if ratio <= stopThreshold:\n",
    "            print(\"# iteration:\", round)\n",
    "            break\n",
    "            \n",
    "HMM.BaumWelch = BaumWelch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Applications\n",
    "\n",
    "Given the three algorithms above, we can use HMM to train and predict different kind of datasets. In the beginning of this tutorial, we talked about the stock price data and speech sounds data. Both of them can be modeled by a HMM.\n",
    "\n",
    "For simplicity purpose, let's take a look back at the rolling dice example. For our friend, he need to make a guess on what the hidden dice sequence is. Here is how he can achieve:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden dice sequence:\n",
      "['D4', 'D6', 'D4', 'D6', 'D6', 'D8']\n",
      "Observation:\n",
      "['4', '1', '2', '5', '3', '8']\n",
      "\n",
      "Our friend's guess:\n",
      "['D4', 'D6', 'D4', 'D6', 'D4', 'D8']\n"
     ]
    }
   ],
   "source": [
    "# Rolling dice example - prediction\n",
    "# Observation: 4, 1, 2, 5, 8, 3\n",
    "# True dice sequence (hidden from our friend): D4, D6, D4, D6, D6, D8\n",
    "\n",
    "diceNames = ['D6', 'D4', 'D8']\n",
    "diceNumber = ['1', '2', '3', '4', '5', '6', '7', '8']\n",
    "\n",
    "A = [[0.2, 0.7, 0.1],\n",
    "     [0.5, 0.3, 0.2],\n",
    "     [0.3, 0.1, 0.6]]\n",
    "B = [[0.167, 0.167, 0.167, 0.167, 0.167, 0.167, 0, 0],\n",
    "     [0.25, 0.25, 0.25, 0.25, 0, 0, 0, 0],\n",
    "     [0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125]]\n",
    "Pi = [0.333, 0.333, 0.334]\n",
    "\n",
    "O = [3, 0, 1, 4, 2, 7]\n",
    "\n",
    "print(\"Hidden dice sequence:\")\n",
    "print([\"D4\", \"D6\", \"D4\", \"D6\", \"D6\", \"D8\"])\n",
    "\n",
    "print(\"Observation:\")\n",
    "print([diceNumber[i] for i in O])\n",
    "\n",
    "# our friend will guess what's the possible hidden dice sequence is by using the viterbi algorithm\n",
    "hmm1 = HMM(A, B, Pi)\n",
    "guess, _ = hmm1.viterbi(O)\n",
    "\n",
    "print(\"\\nOur friend's guess:\")\n",
    "print([diceNames[int(i)] for i in guess])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A pretty much good guess!\n",
    "\n",
    "He can also learn the model by himself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# iteration: <built-in function round>\n"
     ]
    }
   ],
   "source": [
    "# Rolling dice example - learning\n",
    "\n",
    "# random guess\n",
    "randA = [[0.3, 0.3, 0.4],\n",
    "         [0.3, 0.4, 0.3],\n",
    "         [0.4, 0.3, 0.3]]\n",
    "randB = [[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125],\n",
    "         [0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125],\n",
    "         [0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125]]\n",
    "randPi = [0.333, 0.333, 0.334]\n",
    "\n",
    "O = [3, 0, 1, 4, 2, 7]\n",
    "\n",
    "# our friend can learn the model in this way\n",
    "hmm2 = HMM(randA, randB, randPi)\n",
    "hmm2.BaumWelch([O])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**More concrete examples can be found here: [wikipedia-example](https://en.wikipedia.org/wiki/Hidden_Markov_model#A_concrete_example), [using-sklearn-for-the-wiki-problem](http://sujitpal.blogspot.com/2013/03/the-wikipedia-bob-alice-hmm-example.html).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Further Resources\n",
    "\n",
    "[A-simple-explanation-of-the-Hidden-Markov-Model](https://www.quora.com/What-is-a-simple-explanation-of-the-Hidden-Markov-Model-algorithm)\n",
    "\n",
    "[A-tutorial-on-hidden-Markov-models-by-Rabiner](http://www.cs.ubc.ca/~murphyk/Bayes/rabiner.pdf) (recommended)\n",
    "\n",
    "[What-are-some-good-resources-for-learning-about-Hidden-Markov-Models](https://www.quora.com/What-are-some-good-resources-for-learning-about-Hidden-Markov-Models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
