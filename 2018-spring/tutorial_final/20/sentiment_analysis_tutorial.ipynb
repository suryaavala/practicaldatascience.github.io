{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\"Sentiment analysis refers to the use of natural language processing, text analysis, computational linguistics, and biometrics to systematically identify, extract, quantify, and study affective states and subjective information.\" ([wiki](https://en.wikipedia.org/wiki/Sentiment_analysis)) <br>\n",
    "Sentiment analysis allows us to detect the attitude of an opinion, a review...   <br>\n",
    "Take product reviews for example, by analyzing the reviews, we can know what attitudes to consumers hold toward a product; take tweets as an example, we may be able to discover the political attitude of a person by analyzing his/her tweets. <br>\n",
    "\n",
    "This can be widely applied, while in this tutorial we will take classifying positive/negative product reviews for example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial content\n",
    "\n",
    "In this tutorial, I will show some ways to do sentiment analysis in Python, specifically using [NLTK](http://www.nltk.org/), [spaCy](https://spacy.io/) and [scikit-learn](http://scikit-learn.org/stable/).\n",
    "\n",
    "We'll be using product reviews data in the [nltk corpus](http://www.nltk.org/nltk_data/): \n",
    "> _53. Product Reviews(9 Products)_<br>\n",
    "   id: `product_reviews_2`\n",
    "\n",
    "There are reviews of 9 products in this dataset.  The data is from Amazon.com.  Though the data is a bit out of date(2007), we can still use it to do sentiment analysis.\n",
    "\n",
    "Each review is classified as positive or negative.  We will use them to train a model that is able to classify whether a review is positive or negative.\n",
    "\n",
    "\n",
    "We will cover the following topics in this tutorial:\n",
    "- [Installing the libraries](#Installing-the-libraries)\n",
    "- [Loading and preprocessing data](#Loading-and-preprocessing-data)\n",
    "\n",
    "- [Lemmatizing words](#Lemmatizing-words)\n",
    "  1. [Using spaCy](#Using-spaCy)\n",
    "  2. [Using NLTK WordNetLemmatizer](#Using-NLTK-WordNetLemmatizer)\n",
    "\n",
    "- [Training classifiers](#Training-classifiers)\n",
    "  1. [Using NLTK NaiveBayesClassifier](#Using-NLTK-NaiveBayesClassifier)\n",
    "  2. [Using sklearn BernoulliNB](#Using-sklearn-BernoulliNB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing the libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__1. Install spaCy__\n",
    "\n",
    "Open the terminal in jupyter notebook, type the following commands:<br>\n",
    "\n",
    "`conda config --add channels\n",
    "conda-forge conda install spacy\n",
    "python -m spacy download en`\n",
    "\n",
    "\n",
    "\n",
    "__2. Install NLTK__\n",
    "\n",
    "If using anaconda, nltk should be installed with anaconda.<br>\n",
    "Simply run `import nltk` in the terminal.<br>\n",
    "In case that didn't work, run the following command to install NLTK:<br>\n",
    "`\n",
    "conda install -c anaconda nltk \n",
    "`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and preprocessing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Press [here](https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/packages/corpora/product_reviews_2.zip) to download the data__ _Product Reviews(9 Products)_ __"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package product_reviews_2 to\n",
      "[nltk_data]     /Users/Amyhuang/nltk_data...\n",
      "[nltk_data]   Package product_reviews_2 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('product_reviews_2')\n",
    "# http://www.nltk.org/_modules/nltk/corpus/reader/reviews.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product Reviews (9 products)\n",
      "\n",
      "Available as ‘Additional Review Datasets (9 products)’ from\n",
      "http://www.cs.uic.edu/~liub/FBS/FBS.html\n",
      "\n",
      "Source:\n",
      "http://www.cs.uic.edu/~liub/FBS/Reviews-9-products.rar\n",
      "\n",
      "NB: Line-endings have been converted from DOS to Unix, and some\n",
      "control characters and extended ASCII characters have been converted\n",
      "to UTF-8.\n",
      "\n",
      "\n",
      "*****************************************************************************\n",
      "* Contact: Bing Liu, liub@cs.uic.edu \n",
      "*          http://www.cs.uic.edu/~liub\n",
      "*****************************************************************************\n",
      "\n",
      "                            README file\n",
      "\n",
      "This folder contains annotated customer reviews of 9 products. \n",
      "\n",
      "\n",
      "All the reviews were from amazon.com. The data was used in the following \n",
      "paper:\n",
      "\n",
      "Xiaowen Ding, Bing Liu and Philip S. Yu. \n",
      "\t“A Holistic Lexicon-Based Approach to Opinion Mining.\" \n",
      "\tProceedings of First ACM International Conference on Web Search and Data Mining \n",
      "\t(WSDM-2008), Feb 11-12, 2008, Stanford University, Stanford, California, USA.\n",
      "\n",
      "\n",
      "\n",
      "Symbols used in the annotated reviews: \n",
      "\n",
      "  [t]: the title of the review: Each [t] tag starts a review. \n",
      "       We did not use the title information in our papers.\n",
      "  xxxx[+|-n]: xxxx is a product feature. \n",
      "      [+n]: Positive opinion, n is the opinion strength: 3 strongest, \n",
      "            and 1 weakest. Note that the strength is quite subjective. \n",
      "            You may want ignore it, but only considering + and -\n",
      "      [-n]: Negative opinion\n",
      "  ##  : start of each sentence. Each line is a sentence. \n",
      "  [u] : feature not appeared in the sentence.\n",
      "  [p] : feature not appeared in the sentence. Pronoun resolution is needed.\n",
      "  [s] : suggestion or recommendation.\n",
      "  [cc]: comparison with a competing product from a different brand.\n",
      "  [cs]: comparison with a competing product from the same brand.\n",
      "\n",
      "\n",
      "Finally, tagging is a hard task. Errors and inconsistencies are inevitable.\n",
      "If you see some problems, please let us know. We also welcome your comments.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import product_reviews_2\n",
    "read_me = product_reviews_2.readme()\n",
    "for i in read_me.splitlines():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By looking at the README file, we get to understand the dataset.<br>\n",
    "We will only be looking at '+' and '-' in [+n]/[-n] since the README file mentioned 'the strength is quite subjective'.<br>\n",
    "Therefore, the information we will extract include '+', '-' and the content of reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following are 9 files with the reviews of each product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Canon_PowerShot_SD500.txt',\n",
       " 'Canon_S100.txt',\n",
       " 'Diaper_Champ.txt',\n",
       " 'Hitachi_router.txt',\n",
       " 'Linksys_Router.txt',\n",
       " 'MicroMP3.txt',\n",
       " 'Nokia_6600.txt',\n",
       " 'README.txt',\n",
       " 'ipod.txt',\n",
       " 'norton.txt']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_reviews_2_fileids = product_reviews_2.fileids()\n",
    "product_reviews_2_fileids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the raw data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t]\n",
      "\n",
      "SD500[+2]##We really enjoyed shooting with the Canon PowerShot SD500. \n",
      "\n",
      "design[+2]##It has an exterior design that combines form and function more elegantly than any point-and-shoot we've ever tested. \n",
      "\n",
      "image-processing system[+1]##A Digic II-powered image-processing system enables the SD500 to snap a limitless stream of 7-megapixel photos at a respectable clip, its start-up time is tops in its class, and it delivers decent photos when compared to its competition. \n",
      "\n",
      "image[+2]##The SD500 rivals the Canon G6 in image quality. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = product_reviews_2.raw(product_reviews_2_fileids[0]).splitlines()\n",
    "for r in data[:5]:\n",
    "    print(r + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the label('+' or '-') and the content of the review. \n",
    "Save these info in `reviews`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "reviews = []\n",
    "pre_label = []\n",
    "pre_content = []\n",
    "for field in product_reviews_2_fileids:\n",
    "    data = product_reviews_2.raw(field).splitlines()\n",
    "    for r in data:\n",
    "        label_finder = re.compile(r'\\[([+-])[123]\\]')\n",
    "        content_finder = re.compile('##(.+)')\n",
    "        label = label_finder.findall(r)\n",
    "        content = content_finder.findall(r)\n",
    "        \n",
    "        if len(pre_label) >= 1 and len(pre_content) == 0 and len(label) == 0 and len(content) == 1:\n",
    "            label = pre_label\n",
    "        if len(label) >= 1 and len(content) == 1:\n",
    "            reviews.append([label, content[0]])\n",
    "        if len(label) == 0 and len(content) == 1:\n",
    "            if len(reviews) > 0:\n",
    "                reviews[-1][1] += (content[0])\n",
    "        pre_label = label\n",
    "        pre_content = content\n",
    "# print(len(reviews))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['+'], 'We really enjoyed shooting with the Canon PowerShot SD500. ']\n"
     ]
    }
   ],
   "source": [
    "print(reviews[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reviews can be tagged with more than one feature(which means more than one label)<br>\n",
    "Some may have both '+' and '-' labels.  It will be hard to classify whether the review is positive or negative.<br> Therefore, we only preserve reviews that have only one of the labels.<br>\n",
    "This way, it will be much clearer whether the review is positive or negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for review in reviews:\n",
    "    if len(review[0]) > 1:\n",
    "        if (all(l== '+' for l in label) or all(l== '-' for l in label)):\n",
    "            review[0] = [review[0][-1]]\n",
    "        else:\n",
    "            del reviews[reviews.index(review)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save label of reviews separately.\n",
    "'+' is saved as 1 in `label`; '-' is saved as 0.\n",
    "The following is an overview of the number of reviews we have; how many are positive; how many are negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of positive reviews: 1336\n",
      "# of negative reviews: 751\n",
      "                Total: 2087\n"
     ]
    }
   ],
   "source": [
    "num_pos = 0\n",
    "num_neg = 0\n",
    "label = []\n",
    "for review in reviews:\n",
    "    if review[0][0] == '+':\n",
    "        num_pos += 1\n",
    "        label.append(1)\n",
    "    else:\n",
    "        num_neg += 1\n",
    "        label.append(0)\n",
    "print('# of positive reviews:', num_pos)\n",
    "print('# of negative reviews:', num_neg)\n",
    "print('                Total:', num_pos + num_neg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatizing words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The base form of a word, that one might look up in a dictionary, is called the __lemma__ or __dictionary form__ for the word.([wikipedia](https://en.wikipedia.org/wiki/Lemmatisation))<br>\n",
    "For example, 'walked', 'walks' and 'walking' all have the same base form 'walk'(verb).  In other words, the verb 'walk' is the lemma of 'walked', 'walks' and 'walking'. <br>\n",
    "\n",
    "By lemmatizing the words, which means we will be able to analyze the reviews better.<br>\n",
    "Otherwise, words like 'shooting' and 'shoot' will be treated as different words though they are basically the same.<br>\n",
    "\n",
    "In the following, we will go through two ways to lemmatize words.\n",
    "1. spaCy\n",
    "2. NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using spaCy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method `make_lemmatized_word_list` will do the following using spaCy:<br>\n",
    "* First, we can tokenize words in a sentence by calling `nlp(sentence)`.<br>\n",
    "* Next, we can access the `lemma_` (Base form of the [token](https://spacy.io/api/token)) of each token.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import spacy\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_lemmatized_word_list(text):\n",
    "    #tokenize the cotent of reviews\n",
    "    #i.e. each review will be a spacy.tokens.doc.Doc, each word will be a spacy.tokens.token.Token\n",
    "    tokenized_text = nlp(text.lower())\n",
    "    lemmatized = []\n",
    "    for token in tokenized_text:\n",
    "        lemma = token.lemma_\n",
    "        if re.match('[a-zA-Z]+$', lemma) and (lemma not in stopwords.words(\"english\")) and (not (token.is_stop)):\n",
    "            lemmatized.append(lemma)\n",
    "    return lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lemma_spacy = [make_lemmatized_word_list(i[1]) for i in reviews]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the lemmatized word list of reviews(using spaCy):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['enjoy', 'shoot', 'canon', 'powershot'],\n",
       " ['exterior',\n",
       "  'design',\n",
       "  'combine',\n",
       "  'form',\n",
       "  'function',\n",
       "  'elegantly',\n",
       "  'point',\n",
       "  'shoot',\n",
       "  'test']]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemma_spacy[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using NLTK WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nltk also has WordNetLemmatizer which can lemmatize words. <br>\n",
    "We should provide `pos` while using `WordNetLemmatizer.lemmatize()` to get a more accurate outcome (the default is `pos = NOUN`)<br>\n",
    "(From the [documentation](http://www.nltk.org/_modules/nltk/corpus/reader/wordnet.html), we can see that `POS_LIST = [NOUN, VERB, ADJ, ADV]`)\n",
    "\n",
    "By using `pos_tag(word_tokenize(word))`(see this [link](http://www.nltk.org/_modules/nltk/tag.html) for ducumentation), we can get the [Penn Treebank tag](https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html) of the word.<br>\n",
    "\n",
    "The following method `get_wordnet_pos` can map Penn Treebank tag to `pos`.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/Amyhuang/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk import pos_tag, word_tokenize\n",
    "#map Penn Treebank tag to wornet pos\n",
    "def get_wordnet_pos(tag):\n",
    "    if tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return None\n",
    "#transform a sentence into a list of lemmatized words\n",
    "def make_word_list(sent):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_word_list = []\n",
    "    for word, tag in pos_tag(word_tokenize(sent.lower())):\n",
    "        wntag = get_wordnet_pos(tag)\n",
    "        if not wntag:\n",
    "            lemma = word\n",
    "        else:\n",
    "            lemma = lemmatizer.lemmatize(word, wntag)\n",
    "\n",
    "        if re.match('[a-zA-Z]+$', lemma) and (lemma not in stopwords.words(\"english\")):\n",
    "            lemmatized_word_list.append(lemma)\n",
    "    return lemmatized_word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lemma_nltk = [make_word_list(i[1]) for i in reviews]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the lemmatized word list of reviews(using NLTK):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['really', 'enjoy', 'shoot', 'canon', 'powershot'],\n",
       " ['exterior',\n",
       "  'design',\n",
       "  'combine',\n",
       "  'form',\n",
       "  'function',\n",
       "  'elegantly',\n",
       "  'ever',\n",
       "  'test']]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemma_nltk[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lemmatizing outcome using spaCy and using NLTK is different.  This is pretty clear by looking at the first review.\n",
    "One has the word 'really' and the other doesn't.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before training the model, we use train_test_split in sklearn to generate train set and test set. <br>\n",
    "Note: we will use `lemma_nltk`, the lemmatized outcome using nltk, in the following part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(lemma_nltk, label, test_size=0.25, random_state=15688)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of reviews in train set and test set\n",
      "X_train: 1565\n",
      "y_train: 1565\n",
      "X_test : 522\n",
      "y_test : 522\n"
     ]
    }
   ],
   "source": [
    "print('Number of reviews in train set and test set')\n",
    "print('X_train:', len(X_train))\n",
    "print('y_train:', len(y_train))\n",
    "print('X_test :', len(X_test))\n",
    "print('y_test :', len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 1565 samples as the train set and 522 samples as the test set.\n",
    "Next, we will go through two ways of training a classifier:\n",
    "1. NLTK NaiveBayesClassifier\n",
    "2. sklearn BernoulliNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using NLTK NaiveBayesClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's use [NaiveBayesClassifier](http://www.nltk.org/_modules/nltk/classify/naivebayes.html) in nltk.<br>\n",
    "There is a specific format for the input of NaiveBayesClassifier.<br>\n",
    "The documentation of nltk says, 'The first step in creating a classifier is deciding what features of the input are relevant, and how to encode those features.' <br>\n",
    "Next, 'we need to prepare a list of examples and corresponding class labels.' Which means transferring each data into the following format: <br>\n",
    "(encoded features, class label) <br>\n",
    "Please look at the examples given in this [document](http://www.nltk.org/book/ch06.html) for further details.\n",
    "\n",
    "In our case, the feature we are using will be whether a word(lemma) exists in the review.\n",
    "Each review will be transformed to a tuple with the following format: <br>\n",
    "( a dictionary of lemma, positive/negative ) <br>\n",
    "\n",
    "Let's take a review as example:<br>\n",
    "\n",
    "> The original review:<br>\n",
    "> `We really enjoyed shooting with the Canon PowerShot SD500. `<br>\n",
    "> The lemmatized word list of this sentence:<br>\n",
    "> `['enjoy', 'shoot', 'canon', 'powershot']`<br>\n",
    "> The input of NaiveBayesClassifier:<br>\n",
    "> `({'enjoy': True, 'shoot': True, 'canon': True, 'powershot': True}, 'positive')`<br>\n",
    "\n",
    "The following is transforming the reviews to the specific format for training the NaiveBayesClassifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_word_dic(X):\n",
    "    dictionary = {}\n",
    "    for word in X:        \n",
    "        dictionary[word] = True\n",
    "    return dictionary\n",
    "def make_nb_input(X, y):\n",
    "    annote_reviews = []\n",
    "    for words, sign in zip(X, y):\n",
    "        if sign == 1:\n",
    "            annote_reviews.append((make_word_dic(words), 'positive'))\n",
    "        else:\n",
    "            annote_reviews.append((make_word_dic(words), 'negative'))\n",
    "    return annote_reviews\n",
    "\n",
    "annote_X_train = make_nb_input(X_train, y_train)\n",
    "annote_X_test = make_nb_input(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train the classifier by calling `NaiveBayesClassifier.train(annoted_X_train)`, and get the accuracy by calling `util.accuracy(classifier, annote_X_test)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6475095785440613\n"
     ]
    }
   ],
   "source": [
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.classify import util\n",
    "\n",
    "classifier = NaiveBayesClassifier.train(annote_X_train)\n",
    "accuracy = util.accuracy(classifier, annote_X_test)\n",
    "print('Accuracy:' , accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By calling `show_most_informative_features()`, we can see what lemmas are most informative while classifying whether the review is positive or negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                 scratch = True           negati : positi =     12.3 : 1.0\n",
      "                    pain = True           negati : positi =     12.3 : 1.0\n",
      "                customer = True           negati : positi =     11.6 : 1.0\n",
      "                    flaw = True           negati : positi =     10.0 : 1.0\n",
      "                     fix = True           negati : positi =      9.5 : 1.0\n",
      "                    site = True           negati : positi =      8.3 : 1.0\n",
      "              completely = True           negati : positi =      8.1 : 1.0\n",
      "               sometimes = True           negati : positi =      8.1 : 1.0\n",
      "                   audio = True           positi : negati =      7.8 : 1.0\n",
      "                    pull = True           negati : positi =      7.6 : 1.0\n",
      "                  damage = True           negati : positi =      7.6 : 1.0\n",
      "                   later = True           negati : positi =      6.7 : 1.0\n",
      "                    stay = True           negati : positi =      6.4 : 1.0\n",
      "                  repair = True           negati : positi =      6.4 : 1.0\n",
      "                security = True           negati : positi =      6.4 : 1.0\n",
      "                   annoy = True           negati : positi =      6.4 : 1.0\n",
      "           unfortunately = True           negati : positi =      6.4 : 1.0\n",
      "                  reboot = True           negati : positi =      6.4 : 1.0\n",
      "                 promise = True           negati : positi =      6.4 : 1.0\n",
      "                  norton = True           negati : positi =      6.4 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(n = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If 'pain' appears in the review, the chance that it is a negative review is 12.3 times more than the chance that it is a positive review. <br>\n",
    "It is reasonable when words like 'pain', 'scratch', 'damage', 'annoy'... appear in the review, it's more likely that it is a negative review. <br>\n",
    "\n",
    "The classifier can also test other reviews by using `classifier.classify(review)`<br>\n",
    "The input should be encoded features, a dictionary of lemma in our case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this is a 1-star review I got on Amazon (https://www.amazon.com/VicTsing-Wireless-Portable-Receiver-Adjustable/product-reviews/B013WC0P2A/ref=cm_cr_dp_d_hist_1?ie=UTF8&filterByStar=one_star&reviewerType=all_reviews#reviews-filter-bar)\n",
    "testing_rev = '''The mouse pauses every couple seconds. Tested this on a few computers and it does the same thing. Not sure if this is a common problem but i wanted it to be known that this does happen.\n",
    "\n",
    "The scroll wheel on mine seems to be misshaped and gets caught on something when scrolling.\n",
    "\n",
    "Overall, the build quality of the mouse is sub par. I have bought sub-$20 mice in the past and this is honestly one of the worst ones i've used. Will be requesting a return and refund.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'negative'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.classify(make_word_dic(make_word_list(testing_rev)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This 1-star review is classified as a negative review.  Though this doesn't mean everything, at least for this example the classifier seems to be working ok."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using sklearn BernoulliNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's use sklearn to train a classifier. <br>\n",
    "First, we transform reviews into the proper format. <br>\n",
    "We use [CountVecotizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer) to make a sparse matrix with size `nxw`. <br>\n",
    "`n` is the number of reviews; `w` is the number of words. <br>\n",
    "The `(i, j)` value will be the number of times `jth` word appeared in `ith` review. <br>\n",
    "\n",
    "\n",
    "Note: The input should be a sentence not a list of words; therefore, we transform the list of words back to a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "context_text = [\" \".join(i) for i in X_train]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can set max_df and min_df to give a threshold of the frequency(float) or absolute counts(integer) vocabulary appear in the documents.\n",
    "Also, we can specify stop_words = 'english' to exclude stopwords from the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of vocabulary(lemma): 800\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vector = CountVectorizer(min_df = 5, stop_words = \"english\", max_df = 0.9)\n",
    "\n",
    "X = count_vector.fit_transform(context_text)\n",
    "\n",
    "print('Size of vocabulary(lemma):', X.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part of vocabulary lists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ability', 'able', 'absolutely', 'access', 'accessory', 'actual', 'actually', 'adapter', 'add', 'addition']\n",
      "['wrench', 'write', 'wrong', 'xp', 'yahoo', 'yeah', 'year', 'yes', 'zen', 'zoom']\n"
     ]
    }
   ],
   "source": [
    "print(count_vector.get_feature_names()[:10])\n",
    "print(count_vector.get_feature_names()[-10:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we use [BernoulliNB](http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.BernoulliNB.html#sklearn.naive_bayes.BernoulliNB.score) as the classifier. <br>\n",
    "BernoulliNB has some parameters that we can decide its value. <br>\n",
    "By using cross-validation, the best hyperparameter for the test set can be chosen.  In our case, alpha, additive (Laplace/Lidstone) smoothing parameter, is the hyperparameter we can choose. <br>\n",
    "\n",
    "The following is splitting train set into 5 folds and assign one file as the validation set each time and iterate 5 times.<br>\n",
    "The validation set is used to evaluate the performance. <br>\n",
    "The alpha that has the best performance(in this case we use f1_score) on average is the best alpha.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "label_np = np.asarray(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_alpha: 2.1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "num_folds = 5\n",
    "k_fold = KFold(num_folds, shuffle = True, random_state = 15688)\n",
    "max_score = 0\n",
    "best_alpha = 0\n",
    "for a in range(1,51):\n",
    "    alpha_test = a/10\n",
    "    nb = BernoulliNB(alpha = alpha_test)\n",
    "    \n",
    "    total_score = 0\n",
    "    for train, test in k_fold.split(X, label_np):\n",
    "        nb.fit(X[train], label_np[train])\n",
    "        label_predict = nb.predict(X[test])\n",
    "        score = f1_score(label_np[test], label_predict)\n",
    "        total_score += score\n",
    "    mean_score = total_score/num_folds\n",
    "    if mean_score > max_score:\n",
    "        max_score = mean_score\n",
    "        best_alpha = alpha_test\n",
    "print(\"best_alpha:\", best_alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After getting the best alpha, train the model using best alpha as the parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.683908045977\n"
     ]
    }
   ],
   "source": [
    "nb = BernoulliNB(alpha = best_alpha)\n",
    "nb.fit(X, np.asarray(y_train))\n",
    "X_test_join = [\" \".join(i) for i in X_test]\n",
    "X_testing = count_vector.transform(X_test_join)\n",
    "print('Accuracy:', nb.score(X_testing, np.asarray(y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sklearn` gives us more flexibility in choosing hyperparameters; this may be the reason why it is performing better on accuracy comparing to `nltk`. <br>\n",
    "However, accuracy isn't the only way to evaluate a model; we can choose to use different classifiers due to needs or preference. <br>\n",
    "While nltk has `show_most_informative_features()` which can show features that are most informative in classification, sklearn doesn't have a similar method. <br>\n",
    "The following method can manually extract and print the top 10 informative features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_top10(vectorizer, clf, class_labels):\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    top10 = np.argsort(clf.coef_[0])[-10:]\n",
    "    print([feature_names[j] for j in top10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['player', 'ipod', 'like', 'phone', 'router', 'work', 'camera', 'great', 'good', 'use']\n"
     ]
    }
   ],
   "source": [
    "print_top10(count_vector, nb, nb.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Words 'like', 'great', 'good' seems to be reasonable while words like 'ipod', 'player' don't seem important in classifying whether the review is positive or negative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another pro of sklearn is the metrics it has that are easy to approach. <br>\n",
    "Let's take roc curve as example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmcAAAJhCAYAAAAE6xcMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ne+LcHXQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x128748eb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "matplotlib.style.use('ggplot')\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "X_test_trans = count_vector.transform(X_test_join)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "#draw ROC of Bernoulli Naive Bayes\n",
    "y_score = nb.predict_proba(X_test_trans)[:,1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_score, pos_label=1)\n",
    "auc = np.trapz(tpr, fpr)\n",
    "plt.plot(fpr, tpr, label=\"Bernoulli Naive Bayes AUC=\" + str(auc), lw=3, color='C1')\n",
    "plt.title('ROC Curve')\n",
    "plt.xlabel(\"FPR\")\n",
    "plt.ylabel(\"TPR\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial used product reviews(9 products) from nltk.corpus to do sentiment analysis. <br>\n",
    "Two different ways to lemmatize the words - using __spaCy__ and __NLTK WordNetLemmatizer__ - and two ways to train the classifier - __NLTK NaiveBayesClassifier__ and __sklearn BernoulliNB__- are included in the tutorial. <br>\n",
    "They all have pros and cons; no one is significantly better than the other.  The choice can be made base on needs or preferences. <br>\n",
    "This tutorial is an introduction to sentiment analysis, and hope you get a basic idea of classifying positive and negative reviews."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
