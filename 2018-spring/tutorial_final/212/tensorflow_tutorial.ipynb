{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Simple TensorFlow Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction - What & Why\n",
    "\n",
    "TensorFlow is a tool for machine learning with optional GPU support. It highly abstracts the models and hides details underneath so that users can concentrate more on figuring out suitable machine learning model for analyzing data science problems. One or two lines of code would be enough to train and evaluate a model so that users can test on all different models quickly. It also opens low level structures and model components for users to flexibly assemble their own customized models. Consequently, TensorFlow makes data analysis easier to implement and faster to see a result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Installation and Verification\n",
    "\n",
    "In this section, I will introduce how to install TensorFlow on your computer and how to test if your installation works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Installation\n",
    "\n",
    "[This link](https://www.tensorflow.org/install/) gives a detailed installation guide for different operating systems (Ubuntu, MacOS, Window). Here is the simplest one using pip from command line without GPU support:\n",
    "\n",
    "$ pip install tensorflow\n",
    "\n",
    "It is recommended to use the non-GPU version of TensorFlow first for exploring the basics easier. If you want to install the GPU one, please refer to the above link as well for detailed steps and notices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Validate your installation\n",
    "\n",
    "Use the short program below to validate if tensorflow is ready to run on your machine. It should print out \"Hello, TensorFlow\" on your console.\n",
    "\n",
    "(Citation: https://www.tensorflow.org/install/install_linux#ValidateYourInstallation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shuqih/ENTER/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Hello, TensorFlow!'\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "hello = tf.constant('Hello, TensorFlow!')\n",
    "sess = tf.Session()\n",
    "print(sess.run(hello))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. TensorFlow Big Picture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](images/TensorFlowProgrammingEnvironment.png)\n",
    "\n",
    "(Citation: https://www.tensorflow.org/get_started/get_started_for_beginners)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This picture shows the hierarchical structure of TensorFlow framework. Basically, it provides the high level OOP APIs called Estimators which are complete machine learning models. You can use them in really simple ways to run a fairly complicated machine learning task, especially neural network tasks. What's more, you can also use the middle level APIs which are major and common model components, for example Layers to build layers of network and Datasets to pre-process raw data into usable forms and feed data to the model, to customize your own implementations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Main Components of TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Intuition\n",
    "\n",
    "Using TensorFlow to do computation follows a slight different structure from traditional procedures programming using C, Java or Python. Instead of doing calculation along the execution of lines of programs, **TensorFlow is mainly composed of two parts: **\n",
    "\n",
    "1. **building computaion steps, i.e. the graph**\n",
    "2. **take in input values into the graph and generate results**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, if I have the python code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 24 38\n"
     ]
    }
   ],
   "source": [
    "def formula1(a, b):\n",
    "    return a * b * 2\n",
    "\n",
    "def formula2(a, b):\n",
    "    return a + b + 10\n",
    "\n",
    "a = 1\n",
    "b = 2\n",
    "c = 3\n",
    "d = 4\n",
    "\n",
    "x = formula1(a, b)\n",
    "y = formula1(c, d)\n",
    "z = formula2(x, y)\n",
    "\n",
    "print(x, y, z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then when running, this program will perform the operations line by line. Specifically, when running at line 7, the variable \"a\" is assigned value 1, when running at line 12, the calculation of \"formula1(a,b)\" is computed and the variable \"x\" is assigned value 4. However in TensorFlow, all the calculation and value assignments will not be executed unless explicitly asked to. Otherwise only the calculation process will be formed, but values won't be passed in and calculation will not happen. Thus, I think a likely analog could be merging all the formulas into a big one and wait to be explicitly asked to do the computation. And the above program can be rewritten as follows to mimic TensorFlow structure: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\n"
     ]
    }
   ],
   "source": [
    "def formula1(a, b):\n",
    "    return a * b * 2\n",
    "\n",
    "def formula2(a, b):\n",
    "    return a + b + 10\n",
    "\n",
    "# this is to mimic the explicit call to execute the calculation\n",
    "def calculate(z):\n",
    "    print(z)\n",
    "\n",
    "# merge seperate formulas together to be one big complete formula\n",
    "z = formula2(formula1(a, b), formula1(c, d))\n",
    "# ==>\n",
    "z = formula1(a,b) + formula1(c,d) + 10\n",
    "# ==>\n",
    "z = a * b * 2 + c * d * 2 + 10\n",
    "\n",
    "a = 1\n",
    "b = 2\n",
    "c = 3\n",
    "d = 4\n",
    "\n",
    "# all the value assignments and calculations wait here to be executed\n",
    "\n",
    "# ======================================================================\n",
    "\n",
    "# explicitly issue to execution command, all the needed value assignments \n",
    "# and calculations in order to calculate \"z\" are traced back to and done.\n",
    "# specifically, \"z\" traces back to how it is formed, and that calls the \n",
    "# \"formula2\" function. And since in this calculation \"formula2\" needs two \n",
    "# parameters which are \"formula1(a,b)\" and \"formula1(c,d)\", these two \n",
    "# calculations are traced to and executed before \"formula2\" got executed \n",
    "# to generate value of \"z\". And in order to calculate \"formula1(a,b)\" and \n",
    "# \"formula1(c,d)\", variable \"a\", \"b\", \"c\" and \"d\" are traced to and assigned \n",
    "# the values 1, 2, 3 and 4 before calculations are down.\n",
    "calculate(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The name TensorFlow is a great concise and accurate description of its internal core structure of this framework. That is Tensors (any dimension of arrays) flowing within Graphs (a composition of nodes and edges where nodes represent computation operations and edges represent data flow) in order to realize certain computations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.1 Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensors, as roughly mentioned above, are the n-dimensional arrays flowing in the edges of a Graph. And it is worthwhile to mention that most TensorFlow functions return tf.Tensors.\n",
    "\n",
    "Here is an example of how to create simple constant Tensors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = tf.constant(1.0, dtype=tf.float32)\n",
    "b = tf.constant(2.0) # dtype=tf.float32 implicitly\n",
    "c = tf.constant(3, dtype=tf.int32)\n",
    "d = tf.constant(4) # dtype=tf.int32 implicitly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned above, Tensors are not given values yet until being explicitly asked to. Thus, the are all empty values at this moment, which can be shown as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const_1:0\", shape=(), dtype=float32)\n",
      "Tensor(\"Const_2:0\", shape=(), dtype=float32)\n",
      "Tensor(\"Const_3:0\", shape=(), dtype=int32)\n",
      "Tensor(\"Const_4:0\", shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(a)\n",
    "print(b)\n",
    "print(c)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows that all the Tensors have value 0 instead of seemingly given values 1.0, 2.0, 3 and 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, Tensors can have any dimensions or ranks. See the following example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const_5:0\", shape=(4,), dtype=int32)\n",
      "Tensor(\"Const_6:0\", shape=(2, 2), dtype=int32)\n",
      "Tensor(\"Const_7:0\", shape=(4, 1), dtype=int32)\n",
      "Tensor(\"Const_8:0\", shape=(2, 2, 1), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "e = tf.constant([1, 2, 3, 4]) # rank 1\n",
    "f = tf.constant([[1, 2], [3, 4]]) # rank 2\n",
    "g = tf.constant([[1], [2], [3], [4]]) # rank 2\n",
    "h = tf.constant([[[1], [2]], [[3], [4]]]) # rank 3\n",
    "print(e)\n",
    "print(f)\n",
    "print(g)\n",
    "print(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the \"shape\" parameter shown here, Tensors can be built very flexibly. Actually TensorFlow uses numpy arrays to represent Tensor values in Python. This enhances its convenience to use in large scale mathematical computations or machine learning tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously constant is far from enough to represent all the Tensors. So besides constants, TnesorFlow also provides other types of Tensors. Specifically they are:\n",
    "- tf.Variable\n",
    "- tf.constant\n",
    "- tf.placeholder\n",
    "- tf.SparseTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specifically, placeholders are used to wait for external input which will be fed in later. Usage examples are shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us one placeholder waiting for a floating point number."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.Variable is the only one among them whose value can be changed during the program running. In other word, all the other three types are immutable once assigned. To create a tf.Variable, it is recommended to use tf.get_variable method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "var = tf.get_variable(\"var\", [1, 2, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where the name and shape of the Variable is specified. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.2 Operation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Operations take Tensors as inputs, doing calculations with them and output results as Tensors. They make up the nodes of a graph. Common operations are like addition and multiplication, which are the most basic and widely used operations for machine learning tasks, especially in neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"add:0\", shape=(), dtype=float32)\n",
      "Tensor(\"mul:0\", shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "add = a + b\n",
    "mul = c * d\n",
    "print(add)\n",
    "print(mul)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since not explicitly asked to run yet, the operations are just built and ready to run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are finally here to explicit run the value assignments and computations. A Session object encapsulates the environment in which Operation objects are executed, and Tensor objects are evaluated. First of all, let's build a simple tf.Session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try to use this session, an encapsulation in which Tensors flow through the Operations, to run the Operations built above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(add))\n",
    "print(sess.run(mul))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is worthwhile to mention that in order to calculate value for \"add\", only the \"add\" itself needs to be passed into tf.Session().run() and all the value assignments and calculations which are prerequisite for this \"add\" will be automatically figured out and get calculated beforehand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Realize Machine Learning using TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we already have a basic understanding about how TensorFlow works essencially. In this section let's try to use the basic components we have presented to build a realization of a simple machine learning algorithm - linear regression - as well as TensorFlow's straight-forward high level methods directly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Low Level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's realize it using low level model components. See if the model can guess the mathmatical relation between my features and labels, i.e. y=x+1\n",
    "\n",
    "(Citation: https://www.tensorflow.org/programmers_guide/low_level_intro#training_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict before training:\n",
      "[[0.        ]\n",
      " [0.84737074]\n",
      " [1.6947415 ]\n",
      " [2.5421124 ]\n",
      " [3.389483  ]\n",
      " [4.2368536 ]]\n",
      "predict after training:\n",
      "[[0.9999988]\n",
      " [1.9999992]\n",
      " [2.9999995]\n",
      " [3.9999998]\n",
      " [5.       ]\n",
      " [6.000001 ]]\n"
     ]
    }
   ],
   "source": [
    "# First of all, let's build some constants as the data features \n",
    "# and labels used for training the model later.\n",
    "x = tf.constant([[0], [1], [2], [3], [4], [5]], dtype=tf.float32)\n",
    "y = tf.constant([[1], [2], [3], [4], [5], [6]], dtype=tf.float32)\n",
    "\n",
    "# Then we employ the Layers, which is the interface of TensorFlow\n",
    "# to build computing relations or nodes and edges. The tf.layers.Dense() \n",
    "# we use here is a densely connected layer class which takes in \n",
    "# input vectors and output a single value.\n",
    "regressor = tf.layers.Dense(units=1)\n",
    "\n",
    "# pass in features\n",
    "predictions = regressor(x)\n",
    "\n",
    "# choose loss function as MSE \n",
    "loss_function = tf.losses.mean_squared_error(labels=y, predictions=predictions)\n",
    "\n",
    "# choose optimization method as gradient descent\n",
    "# with learning rate 0.05\n",
    "optimization = tf.train.GradientDescentOptimizer(0.05)\n",
    "\n",
    "# build training process\n",
    "training = optimization.minimize(loss_function)\n",
    "\n",
    "# before running, simply run the internal initializer to initialize\n",
    "# all the variables which cannot run otherwise\n",
    "initialization = tf.global_variables_initializer()\n",
    "\n",
    "# run TensorFlow Graph\n",
    "sess = tf.Session()\n",
    "sess.run(initialization)\n",
    "\n",
    "# show prediction before training\n",
    "# which is very much like random number\n",
    "print(\"predict before training:\")\n",
    "print(sess.run(predictions))\n",
    "\n",
    "# training with 1000 steps\n",
    "for i in range(1000):\n",
    "    sess.run((training, loss_function))\n",
    "\n",
    "# show the final prediction after training\n",
    "# which is very much the same as expected\n",
    "print(\"predict after training:\")\n",
    "print(sess.run(predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 High Level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, let's realize the linear regression model using [tf.estimator.LinearRegressor](https://www.tensorflow.org/api_docs/python/tf/estimator/LinearRegressor) with exactly the same linear relation as the previous model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp6y6c_8hh\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmp6y6c_8hh', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f5d283b2a90>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/tmp6y6c_8hh/model.ckpt.\n",
      "INFO:tensorflow:loss = 84.0, step = 1\n",
      "INFO:tensorflow:global_step/sec: 792.426\n",
      "INFO:tensorflow:loss = 6.582644e-05, step = 101 (0.132 sec)\n",
      "INFO:tensorflow:global_step/sec: 1251.04\n",
      "INFO:tensorflow:loss = 2.2742472e-05, step = 201 (0.076 sec)\n",
      "INFO:tensorflow:global_step/sec: 1173.41\n",
      "INFO:tensorflow:loss = 1.581072e-05, step = 301 (0.088 sec)\n",
      "INFO:tensorflow:global_step/sec: 1329.9\n",
      "INFO:tensorflow:loss = 3.1305924e-06, step = 401 (0.076 sec)\n",
      "INFO:tensorflow:global_step/sec: 1196.29\n",
      "INFO:tensorflow:loss = 3.716324e-06, step = 501 (0.079 sec)\n",
      "INFO:tensorflow:global_step/sec: 1438.58\n",
      "INFO:tensorflow:loss = 1.8468259e-06, step = 601 (0.070 sec)\n",
      "INFO:tensorflow:global_step/sec: 1459.98\n",
      "INFO:tensorflow:loss = 3.864452e-07, step = 701 (0.068 sec)\n",
      "INFO:tensorflow:global_step/sec: 1310.31\n",
      "INFO:tensorflow:loss = 3.949226e-07, step = 801 (0.077 sec)\n",
      "INFO:tensorflow:global_step/sec: 1230.85\n",
      "INFO:tensorflow:loss = 1.1407337e-07, step = 901 (0.081 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into /tmp/tmp6y6c_8hh/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 1.4161969e-08.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-04-01-01:50:45\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmp6y6c_8hh/model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-04-01-01:50:45\n",
      "INFO:tensorflow:Saving dict for global step 1000: average_loss = 3.2378446e-07, global_step = 1000, loss = 6.475689e-07\n",
      "loss: 6.475689e-07\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmp6y6c_8hh/model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "\n",
      "Prediction is \"17.00074005126953\", expected \"17\"\n",
      "\n",
      "Prediction is \"18.000810623168945\", expected \"18\"\n",
      "\n",
      "Prediction is \"19.00088119506836\", expected \"19\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Specify data for train, evaluate and predict new\n",
    "train_x = {'x': np.array([1, 2, 3, 4, 5, 6, 7, 8])}\n",
    "train_y = np.array([2, 3, 4, 5, 6, 7, 8, 9])\n",
    "test_x = {'x': np.array([-1, -2, -3, -4])}\n",
    "test_y = np.array([0, -1, -2, -3])\n",
    "predict_x = {'x': np.array([16, 17, 18])}\n",
    "predict_y = np.array([17, 18, 19])\n",
    "\n",
    "# Create input functions.\n",
    "def input_fn_train(features, labels, batch_size): \n",
    "    # Convert the inputs to a Dataset.\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((features, labels))\n",
    "    # Shuffle, repeat, and batch the examples.\n",
    "    return dataset.shuffle(10).repeat().batch(batch_size)\n",
    "\n",
    "def input_fn_evaluate(features, labels, batch_size): \n",
    "    # Convert the inputs to a Dataset.\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((features, labels))\n",
    "    # Batch the examples.\n",
    "    return dataset.batch(batch_size)\n",
    "\n",
    "def input_fn_predict(features, batch_size):\n",
    "    # Convert the inputs to a Dataset.\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(features)\n",
    "    # Batch the examples.\n",
    "    return dataset.batch(batch_size)\n",
    "   \n",
    "\n",
    "# Build feature columns.\n",
    "feature_columns = [tf.feature_column.numeric_column(key='x')]\n",
    "\n",
    "# Build BaselineRegressor.\n",
    "regressor = tf.estimator.LinearRegressor(feature_columns=feature_columns)\n",
    "\n",
    "# Fit model.\n",
    "regressor.train(input_fn=lambda:input_fn_train(train_x, train_y, 3), steps=1000)\n",
    "\n",
    "# Evaluate squared-loss between the test and train targets.\n",
    "loss = regressor.evaluate(input_fn=lambda:input_fn_evaluate(test_x, test_y, 3))[\"loss\"]\n",
    "\n",
    "# Show evaluation result.\n",
    "print(\"loss:\", loss)\n",
    "\n",
    "# Predict outputs the mean value seen during training.\n",
    "predictions = regressor.predict(input_fn=lambda:input_fn_predict(predict_x, 3))\n",
    "\n",
    "# Show prediction results.\n",
    "template = ('\\nPrediction is \"{}\", expected \"{}\"')\n",
    "for pred, pred_y in zip(predictions, predict_y):\n",
    "    print(template.format(pred[\"predictions\"][0], pred_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Summary\n",
    "\n",
    "Comparing the above two realizations, we can easily find that the high level Estimator is more structured. The steps are almost the same for different Estimators, hiding the complicated and variant details underneath. So the usage are more universal. \n",
    "\n",
    "**Generally speaking, using an Estimator follows these four steps:**\n",
    "\n",
    "1. **Write one or more dataset importing functions.**\n",
    "2. **Define the feature columns.**\n",
    "3. **Instantiate the relevant pre-made Estimator.**\n",
    "4. **Call a training, evaluation, or inference method.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Analysis of Real Dataset\n",
    "\n",
    "Having known how to build machine learning models with TensorFlow, now let's go a little further to analyze a real world dataset, called [\"Pima Indians Diabetes Database\"](https://www.kaggle.com/uciml/pima-indians-diabetes-database/data) from Kaggle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Dataset overview\n",
    "\n",
    "This dataset gives eight attributes of features together with the outcome whether this person has diabetes or not. All columns are numerical and there is no empty row anywhere. Now let's load this data in and have a look of it generally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.845052</td>\n",
       "      <td>120.894531</td>\n",
       "      <td>69.105469</td>\n",
       "      <td>20.536458</td>\n",
       "      <td>79.799479</td>\n",
       "      <td>31.992578</td>\n",
       "      <td>0.471876</td>\n",
       "      <td>33.240885</td>\n",
       "      <td>0.348958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.369578</td>\n",
       "      <td>31.972618</td>\n",
       "      <td>19.355807</td>\n",
       "      <td>15.952218</td>\n",
       "      <td>115.244002</td>\n",
       "      <td>7.884160</td>\n",
       "      <td>0.331329</td>\n",
       "      <td>11.760232</td>\n",
       "      <td>0.476951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.300000</td>\n",
       "      <td>0.243750</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>30.500000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.372500</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>140.250000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>127.250000</td>\n",
       "      <td>36.600000</td>\n",
       "      <td>0.626250</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>846.000000</td>\n",
       "      <td>67.100000</td>\n",
       "      <td>2.420000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Pregnancies     Glucose  BloodPressure  SkinThickness     Insulin  \\\n",
       "count   768.000000  768.000000     768.000000     768.000000  768.000000   \n",
       "mean      3.845052  120.894531      69.105469      20.536458   79.799479   \n",
       "std       3.369578   31.972618      19.355807      15.952218  115.244002   \n",
       "min       0.000000    0.000000       0.000000       0.000000    0.000000   \n",
       "25%       1.000000   99.000000      62.000000       0.000000    0.000000   \n",
       "50%       3.000000  117.000000      72.000000      23.000000   30.500000   \n",
       "75%       6.000000  140.250000      80.000000      32.000000  127.250000   \n",
       "max      17.000000  199.000000     122.000000      99.000000  846.000000   \n",
       "\n",
       "              BMI  DiabetesPedigreeFunction         Age     Outcome  \n",
       "count  768.000000                768.000000  768.000000  768.000000  \n",
       "mean    31.992578                  0.471876   33.240885    0.348958  \n",
       "std      7.884160                  0.331329   11.760232    0.476951  \n",
       "min      0.000000                  0.078000   21.000000    0.000000  \n",
       "25%     27.300000                  0.243750   24.000000    0.000000  \n",
       "50%     32.000000                  0.372500   29.000000    0.000000  \n",
       "75%     36.600000                  0.626250   41.000000    1.000000  \n",
       "max     67.100000                  2.420000   81.000000    1.000000  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read data from csv file\n",
    "diabetes = pd.read_csv(\"datasets/diabetes.csv\")\n",
    "\n",
    "# Show feature information\n",
    "diabetes.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Generate features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.2.1 Generate features\n",
    "\n",
    "Let's split this dataset into training set and test set for later use. In order to spliting dataset propotionally to labels, i.e. to have generally identical percent of positive and negative labels in both sets, I will use the \"train_test_split\" function from scikit-learn library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Stratify dataset into training set and test set\n",
    "train,test=train_test_split(diabetes,test_size=0.25,random_state=0,stratify=diabetes['Outcome'])\n",
    "\n",
    "# Generate features and labels\n",
    "train_x, train_y = train, train.pop(\"Outcome\")\n",
    "test_x, test_y = test, test.pop(\"Outcome\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.2.2 Normalization\n",
    "\n",
    "Before we can start to apply different machine learning models on the data, we should first normalize the dataset, which would be greatly benefitial for increasing the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shuqih/ENTER/lib/python3.6/site-packages/pandas/core/indexing.py:537: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Pregnancies   Glucose  BloodPressure  SkinThickness   Insulin       BMI  \\\n",
      "432    -0.844335 -1.279049       0.252871      -0.597814 -0.171805 -0.252732   \n",
      "453    -0.547562 -0.059255      -3.570271      -1.287373 -0.692439 -1.571832   \n",
      "706     1.826623 -0.184362      -3.570271      -1.287373 -0.692439 -4.057829   \n",
      "606    -0.844335  1.879904       0.459528       1.345490  1.849992  1.015634   \n",
      "118     0.045984 -0.747344      -0.470426       0.154433 -0.692439 -0.481038   \n",
      "\n",
      "     DiabetesPedigreeFunction       Age  \n",
      "432                  0.166372 -0.955839  \n",
      "453                  1.086908  3.295778  \n",
      "706                 -0.636457 -0.275580  \n",
      "606                  2.372641 -0.955839  \n",
      "118                 -0.087153 -0.955839  \n"
     ]
    }
   ],
   "source": [
    "# Normalize features\n",
    "features = train_x.columns.values\n",
    "for feature in features:\n",
    "    mean, std = diabetes[feature].mean(), diabetes[feature].std()\n",
    "    train_x.loc[:, feature] = (train_x[feature] - mean) / std\n",
    "    test_x.loc[:, feature] = (test_x[feature] - mean) / std\n",
    "    \n",
    "# Display normalized training features\n",
    "print(train_x.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Analyze with Logistic Regression\n",
    "\n",
    "First of all, since this is a binary classification problem and the number of features is not very big, we can try to start with simple linear model which could be a great choice for such a problem. Let's build a linear classifier - [tf.estimator.LinearClassifier](https://www.tensorflow.org/api_docs/python/tf/estimator/LinearClassifier) - step by step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.3.1 Create input function\n",
    "\n",
    "Input functions are used to feed data for the machine learning model. It returns [tf.data.Dataset](https://www.tensorflow.org/api_docs/python/tf/data/Dataset) objects which is TensorFlow's standard interface for building data pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def input_fn_train(features, labels, batch_size): \n",
    "    # Convert the inputs to a Dataset.\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
    "    # Shuffle, repeat, and batch the examples.\n",
    "    return dataset.shuffle(10).repeat().batch(batch_size)\n",
    "\n",
    "def input_fn_evaluate(features, labels, batch_size): \n",
    "    # Convert the inputs to a Dataset.\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
    "    # Batch the examples.\n",
    "    return dataset.batch(batch_size)\n",
    "\n",
    "def input_fn_predict(features, batch_size):\n",
    "    # Convert the inputs to a Dataset.\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(dict(features))\n",
    "    # Batch the examples.\n",
    "    return dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.3.2 Define the feature columns\n",
    "\n",
    "There is actually much more to say about feature columns. Because sttributes of datasets can have many more types than just numerical data in this example. For example categorical data and strings. In order to coping with those data types, more complicated steps are needed to build feature columns which are suitable of inputing into the machine learning model. That is because machine learning models can only compute upon numerical values. Please check [this short introduction](https://www.tensorflow.org/get_started/feature_columns) if you wonder how to change other data types into usable numerical representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[_NumericColumn(key='Pregnancies', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), _NumericColumn(key='Glucose', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), _NumericColumn(key='BloodPressure', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), _NumericColumn(key='SkinThickness', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), _NumericColumn(key='Insulin', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), _NumericColumn(key='BMI', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), _NumericColumn(key='DiabetesPedigreeFunction', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), _NumericColumn(key='Age', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]\n"
     ]
    }
   ],
   "source": [
    "# Generate feature columns\n",
    "feature_columns = []\n",
    "for key in train_x.keys():\n",
    "    feature_columns.append(tf.feature_column.numeric_column(key=key))\n",
    "print(feature_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.3.3 Instantiate an estimator\n",
    "\n",
    "Let's build a logistic regression model by emplying TensorFlow's high level Estimator - tf.estimator.LinearClassifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpxmnftff3\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpxmnftff3', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f5d21de2748>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "# Instantiate a tf.estimator.LinearClassifier\n",
    "classifier = tf.estimator.LinearClassifier(feature_columns=feature_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.3.4 Train, evaluate and predict\n",
    "\n",
    "Now we train the model and evaluate it on the test set, showing you the overall accuracy as well as prediction for some sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/tmpxmnftff3/model.ckpt.\n",
      "INFO:tensorflow:loss = 69.31472, step = 1\n",
      "INFO:tensorflow:global_step/sec: 277.769\n",
      "INFO:tensorflow:loss = 52.925636, step = 101 (0.361 sec)\n",
      "INFO:tensorflow:global_step/sec: 507.502\n",
      "INFO:tensorflow:loss = 46.37968, step = 201 (0.197 sec)\n",
      "INFO:tensorflow:global_step/sec: 490.872\n",
      "INFO:tensorflow:loss = 43.34184, step = 301 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 579.397\n",
      "INFO:tensorflow:loss = 48.30621, step = 401 (0.175 sec)\n",
      "INFO:tensorflow:global_step/sec: 530.207\n",
      "INFO:tensorflow:loss = 49.49308, step = 501 (0.186 sec)\n",
      "INFO:tensorflow:global_step/sec: 689.886\n",
      "INFO:tensorflow:loss = 44.340233, step = 601 (0.145 sec)\n",
      "INFO:tensorflow:global_step/sec: 700.865\n",
      "INFO:tensorflow:loss = 43.63758, step = 701 (0.143 sec)\n",
      "INFO:tensorflow:global_step/sec: 688.921\n",
      "INFO:tensorflow:loss = 54.316948, step = 801 (0.145 sec)\n",
      "INFO:tensorflow:global_step/sec: 561.875\n",
      "INFO:tensorflow:loss = 52.864273, step = 901 (0.178 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into /tmp/tmpxmnftff3/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 44.495712.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-04-01-01:50:52\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpxmnftff3/model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-04-01-01:50:52\n",
      "INFO:tensorflow:Saving dict for global step 1000: accuracy = 0.78125, accuracy_baseline = 0.6510416, auc = 0.8723582, auc_precision_recall = 0.75923324, average_loss = 0.43420967, global_step = 1000, label/mean = 0.34895834, loss = 41.684128, prediction/mean = 0.34609973\n",
      "\n",
      "Test set accuracy: 0.7812\n",
      "\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpxmnftff3/model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "\n",
      "Prediction is \"1\" (87.39%), expectation is \"1\"\n",
      "\n",
      "Prediction is \"0\" (80.96%), expectation is \"0\"\n",
      "\n",
      "Prediction is \"0\" (91.60%), expectation is \"0\"\n",
      "\n",
      "Prediction is \"0\" (95.61%), expectation is \"0\"\n",
      "\n",
      "Prediction is \"1\" (87.96%), expectation is \"1\"\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "classifier.train(input_fn=lambda:input_fn_train(train_x, train_y, 100), steps=1000)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = classifier.evaluate(input_fn=lambda:input_fn_evaluate(test_x, test_y, 100))\n",
    "# Display accuracy on test set\n",
    "print('\\nTest set accuracy: {accuracy:0.4f}\\n'.format(**accuracy))\n",
    "\n",
    "# Predict on test set\n",
    "predictions = classifier.predict(input_fn=lambda:input_fn_predict(test_x.tail(), 100))\n",
    "# Display predictions for some rows in test set\n",
    "template = ('\\nPrediction is \"{}\" ({:.2f}%), expectation is \"{}\"')\n",
    "for prediction, expectation in zip(predictions, test_y.tail()):\n",
    "    predicted_class = prediction['class_ids'][0]\n",
    "    probability = prediction['probabilities'][predicted_class]\n",
    "    print(template.format(predicted_class, 100 * probability, expectation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 Analyze with Neural Network\n",
    "\n",
    "TensorFlow is especially suitable for building neural networks. Let's have a look of what a neural network is and how to build a [Deep Neural Network](https://www.tensorflow.org/api_docs/python/tf/estimator/DNNClassifier) for analyzing this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.4.1 What Is Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural Network has the advantage of fitting a non-linear model without manual adjustment. When the data distribution gets too complex for people to figure out a suitable distribution model intuitively, neural network becomes one of the top solutions here.\n",
    "\n",
    "Specifically, instead of building a set of linear relations from the inputs to the outputs, neural network takes in several hidden layers in the middle that apply extra linear and non-linear mappings, thus using a network of small neurons to form the whole mathemitical model. The following picture show a dense neural network where dense means edges exists among any pair of nodes in the adjecent layers, i.e. the network is fully connected.\n",
    "\n",
    "![title](images/NeuralNetwork.jpg)\n",
    "\n",
    "(Citation: https://www.tutorialspoint.com/artificial_intelligence/artificial_intelligence_neural_networks.htm)\n",
    "\n",
    "For more information about neural network a possible reference could be [Google's machine learning crash course](https://developers.google.com/machine-learning/crash-course/introduction-to-neural-networks/video-lecture)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.4.2 Create input function & Define the feature columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "I will just reuse the input functions and feature columns from the previous section for convenience since they are totally the same actually. This is also to show you how convenient and decoupled it is when building machine learning models with TensorFlow. Other components can be totally seperated from specific models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.4.3 Instantiate an estimator\n",
    "\n",
    "Let's build a logistic regression model by emplying TensorFlow's high level Estimator - tf.estimator.DNNClassifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpd0ebx_i2\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpd0ebx_i2', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f5d214fb2b0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "# Instantiate a tf.estimator.DNNClassifier with two hidden layers, each layer has 10 neurons\n",
    "classifier = tf.estimator.DNNClassifier(feature_columns=feature_columns, hidden_units=[10, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.4.4 Train, evaluate and predict\n",
    "\n",
    "This part is actually exactly the same as in the previous section. I put it here again for rendering the results as well as proving again how abstract Estimators are, i.e. all the processes of running an Estimator for whatever model is almost the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/tmpd0ebx_i2/model.ckpt.\n",
      "INFO:tensorflow:loss = 83.386246, step = 1\n",
      "INFO:tensorflow:global_step/sec: 424.416\n",
      "INFO:tensorflow:loss = 50.0934, step = 101 (0.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 663.729\n",
      "INFO:tensorflow:loss = 39.855835, step = 201 (0.151 sec)\n",
      "INFO:tensorflow:global_step/sec: 667.414\n",
      "INFO:tensorflow:loss = 38.212246, step = 301 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 643.609\n",
      "INFO:tensorflow:loss = 39.552364, step = 401 (0.160 sec)\n",
      "INFO:tensorflow:global_step/sec: 479.062\n",
      "INFO:tensorflow:loss = 38.584087, step = 501 (0.206 sec)\n",
      "INFO:tensorflow:global_step/sec: 474.35\n",
      "INFO:tensorflow:loss = 37.390976, step = 601 (0.209 sec)\n",
      "INFO:tensorflow:global_step/sec: 729.897\n",
      "INFO:tensorflow:loss = 39.288555, step = 701 (0.137 sec)\n",
      "INFO:tensorflow:global_step/sec: 648.762\n",
      "INFO:tensorflow:loss = 43.086643, step = 801 (0.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 677.866\n",
      "INFO:tensorflow:loss = 44.418262, step = 901 (0.148 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into /tmp/tmpd0ebx_i2/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 39.644894.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-04-01-01:50:57\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpd0ebx_i2/model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-04-01-01:50:58\n",
      "INFO:tensorflow:Saving dict for global step 1000: accuracy = 0.8020833, accuracy_baseline = 0.6510416, auc = 0.8575523, auc_precision_recall = 0.7186221, average_loss = 0.45923197, global_step = 1000, label/mean = 0.34895834, loss = 44.08627, prediction/mean = 0.34249595\n",
      "\n",
      "Test set accuracy: 0.8021\n",
      "\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpd0ebx_i2/model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "\n",
      "Prediction is \"1\" (86.89%), expectation is \"1\"\n",
      "\n",
      "Prediction is \"0\" (88.45%), expectation is \"0\"\n",
      "\n",
      "Prediction is \"0\" (85.12%), expectation is \"0\"\n",
      "\n",
      "Prediction is \"0\" (98.56%), expectation is \"0\"\n",
      "\n",
      "Prediction is \"1\" (94.26%), expectation is \"1\"\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "classifier.train(input_fn=lambda:input_fn_train(train_x, train_y, 100), steps=1000)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = classifier.evaluate(input_fn=lambda:input_fn_evaluate(test_x, test_y, 100))\n",
    "# Display accuracy on test set\n",
    "print('\\nTest set accuracy: {accuracy:0.4f}\\n'.format(**accuracy))\n",
    "\n",
    "# Predict on test set\n",
    "predictions = classifier.predict(input_fn=lambda:input_fn_predict(test_x.tail(), 100))\n",
    "# Display predictions for some rows in test set\n",
    "template = ('\\nPrediction is \"{}\" ({:.2f}%), expectation is \"{}\"')\n",
    "for prediction, expectation in zip(predictions, test_y.tail()):\n",
    "    predicted_class = prediction['class_ids'][0]\n",
    "    probability = prediction['probabilities'][predicted_class]\n",
    "    print(template.format(predicted_class, 100 * probability, expectation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5 Summary\n",
    "\n",
    "From the results above, we can find that Logistic Regression performs well on this datasets. Actually this diabetes problem is very much like to breast cancer classification problem shown in calss, which is a calssic problem suitable for solving with linear classification. \n",
    "\n",
    "Neural Network also performs well. But this dataset is relatively too small and thus not very suitable for solving with DNN. Neural Network will perform better if there is more data. And there are a lot more hyperparameters that we can tune on to make both the classifiers better, for example adjusting learning rate, increasing training steps and create polynomial features."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
