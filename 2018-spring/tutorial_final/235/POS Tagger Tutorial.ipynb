{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part of Speech Tagging via various Learning Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is a Part of Speech Tagger\n",
    "\n",
    "The process of part of speech tagging assigns labels to words in a sentence corresponding to their function within that sentence, i.e noun, verb, adjective, etc. While this is often quite simple for humans to go through and annotate, it quite difficult to do automatically, as the meaning of a word may change drastically depending on its position within a sentence. \n",
    "\n",
    "Part of speech tagging is considered an essential component of Natural Language Processing as it plays a significant role in sentiment analysis, data extraction, and syntactic structure among others. Being able to correctly identify the role of a word provides information about the sentence as a whole, as well as the neighbors of that word. Below are short examples using the default tagger provided by NLTK. You will need to download it with the following commands:\n",
    "\n",
    "  ```python\n",
    "  >>>nltk.download('maxent_treebank_pos_tagger')\n",
    "  >>>nltk.download('punkt')\n",
    "  >>>nltk.download('averaged_perceptron_tagger')\n",
    "  ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Part', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('Speech', 'NNP'),\n",
       " ('Tagging', 'NNP'),\n",
       " ('is', 'VBZ'),\n",
       " ('amazing', 'JJ'),\n",
       " ('!', '.')]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import word_tokenize, pos_tag\n",
    "\n",
    "sentence = 'Part of Speech Tagging is amazing!'\n",
    "\n",
    "pos_tag(word_tokenize(sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collecting and Cleaning the Data\n",
    "As you can see, each word has been assigned a specific label. To build our own tagger, let us start by downloading the data set that we will be working with. For the purposes of this tutorial, we will use pre-tagged data obtained from the NLTK Brown corpus. You will need to run the following two commands to obtain the relevant data.\n",
    "\n",
    "  ```python\n",
    "  >>>nltk.download('brown')\n",
    "  >>>nltk.download('universal_tagset')\n",
    "  ```\n",
    "The first line will download the Brown corpus, while the universal tagset will be used to assign standardized part of speech tags to the words. For now, we will use the simplified universal tag set shown below. However, many taggers, such as the default nltk tagger used above, often use tag sets with many times more labels in order to capture information such as plurality, tense, possessiveness, etc. \n",
    "\n",
    "We are now ready to collect the tagged sentences from the Brown Corpus.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=\"//imgur.com/QmMpzGP\">View post on imgur.com</a></blockquote><script async src=\"//s.imgur.com/min/embed.js\" charset=\"utf-8\"></script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML('''<blockquote class=\"imgur-embed-pub\" lang=\"en\" data-id=\"QmMpzGP\"><a href=\"//imgur.com/QmMpzGP\">View post on imgur.com</a></blockquote><script async src=\"//s.imgur.com/min/embed.js\" charset=\"utf-8\"></script>'''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "//imgur.com/QmMpzGP",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import Image, display\n",
    "display(Image('//imgur.com/QmMpzGP'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('The', 'DET'), ('Fulton', 'NOUN'), ('County', 'NOUN'), ('Grand', 'ADJ'), ('Jury', 'NOUN'), ('said', 'VERB'), ('Friday', 'NOUN'), ('an', 'DET'), ('investigation', 'NOUN'), ('of', 'ADP'), (\"Atlanta's\", 'NOUN'), ('recent', 'ADJ'), ('primary', 'NOUN'), ('election', 'NOUN'), ('produced', 'VERB'), ('``', '.'), ('no', 'DET'), ('evidence', 'NOUN'), (\"''\", '.'), ('that', 'ADP'), ('any', 'DET'), ('irregularities', 'NOUN'), ('took', 'VERB'), ('place', 'NOUN'), ('.', '.')], [('The', 'DET'), ('jury', 'NOUN'), ('further', 'ADV'), ('said', 'VERB'), ('in', 'ADP'), ('term-end', 'NOUN'), ('presentments', 'NOUN'), ('that', 'ADP'), ('the', 'DET'), ('City', 'NOUN'), ('Executive', 'ADJ'), ('Committee', 'NOUN'), (',', '.'), ('which', 'DET'), ('had', 'VERB'), ('over-all', 'ADJ'), ('charge', 'NOUN'), ('of', 'ADP'), ('the', 'DET'), ('election', 'NOUN'), (',', '.'), ('``', '.'), ('deserves', 'VERB'), ('the', 'DET'), ('praise', 'NOUN'), ('and', 'CONJ'), ('thanks', 'NOUN'), ('of', 'ADP'), ('the', 'DET'), ('City', 'NOUN'), ('of', 'ADP'), ('Atlanta', 'NOUN'), (\"''\", '.'), ('for', 'ADP'), ('the', 'DET'), ('manner', 'NOUN'), ('in', 'ADP'), ('which', 'DET'), ('the', 'DET'), ('election', 'NOUN'), ('was', 'VERB'), ('conducted', 'VERB'), ('.', '.')], [('The', 'DET'), ('September-October', 'NOUN'), ('term', 'NOUN'), ('jury', 'NOUN'), ('had', 'VERB'), ('been', 'VERB'), ('charged', 'VERB'), ('by', 'ADP'), ('Fulton', 'NOUN'), ('Superior', 'ADJ'), ('Court', 'NOUN'), ('Judge', 'NOUN'), ('Durwood', 'NOUN'), ('Pye', 'NOUN'), ('to', 'PRT'), ('investigate', 'VERB'), ('reports', 'NOUN'), ('of', 'ADP'), ('possible', 'ADJ'), ('``', '.'), ('irregularities', 'NOUN'), (\"''\", '.'), ('in', 'ADP'), ('the', 'DET'), ('hard-fought', 'ADJ'), ('primary', 'NOUN'), ('which', 'DET'), ('was', 'VERB'), ('won', 'VERB'), ('by', 'ADP'), ('Mayor-nominate', 'NOUN'), ('Ivan', 'NOUN'), ('Allen', 'NOUN'), ('Jr.', 'NOUN'), ('.', '.')]]\n",
      "57340\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "taggeddata = nltk.corpus.brown.tagged_sents(tagset='universal')\n",
    "print(taggeddata[:3])\n",
    "print(len(taggeddata))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing out the first few elements in tagged data reveals that the output of tagged sentences is a list of sentences, where each sentence is broken up into tuples containing the word and its tag. For example, the first sentence is \"The Fulton County Grand Jury said Friday an investigation of Atlanta's recent primary election produced \"no evidence\" that any irregularities took place.\"\n",
    "\n",
    "Now that we have a collection of tagged sentences, we will now extract our training and test data and labels. In the previous code block, we were able to determine that the full data set contains 57340 sentences. To make things simple, we will use the first 50,000 sentences as our training set and the rest as our test set. After we have split our data, we can then map all the words in our training data set to a number, as this will help our learning algorithm down the road. We will use a default dict the default value set to -1 in order to handle cases that dont appear in our training set. We will also add mappings to indicate the beginning and end of sentences, where <span>\"@@@\"</span> will represent the beginning and <span>\"###\"</span> will represent the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('@@@', 0),\n",
       " ('###', 1),\n",
       " ('The', 2),\n",
       " ('Fulton', 3),\n",
       " ('County', 4),\n",
       " ('Grand', 5),\n",
       " ('Jury', 6),\n",
       " ('said', 7),\n",
       " ('Friday', 8),\n",
       " ('an', 9),\n",
       " ('investigation', 10),\n",
       " ('of', 11),\n",
       " (\"Atlanta's\", 12),\n",
       " ('recent', 13),\n",
       " ('primary', 14),\n",
       " ('election', 15),\n",
       " ('produced', 16),\n",
       " ('``', 17),\n",
       " ('no', 18),\n",
       " ('evidence', 19)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def createMappings(data):\n",
    "    wordmap = defaultdict(lambda:-1)\n",
    "    wordmap[\"@@@\"] = 0\n",
    "    wordmap[\"###\"] = 1\n",
    "    counter = 2\n",
    "    for sentence in data:\n",
    "        for word, tag in sentence:\n",
    "            if word not in wordmap:\n",
    "                wordmap[word] = counter\n",
    "                counter += 1\n",
    "    return wordmap\n",
    "                \n",
    "trainingset = taggeddata[:50000]\n",
    "testset = taggeddata[50000:]\n",
    "\n",
    "wordmap = createMappings(trainingset)\n",
    "list(wordmap.items())[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the Data and Extracting Features\n",
    "The next step is to prepare our training set so that we can feed into a model. However, instead of just splitting our tuples, we will also create a function that will produce a set of features for each word. For the models in this tutorial, we will specify the following features:\n",
    "\n",
    "| **Features** | **Definition** | \n",
    "|----------|-------------|\n",
    "| prev      | The mapping for the word that appeared previously in the sentence |\n",
    "| next | The mapping for the word that appeared next in the sentence |\n",
    "| lowercase | boolean representing if the word is all lower case |\n",
    "| capitalized | boolean representing if the first letter is capitalized |\n",
    "| isnumber | boolean representing if the current word is all numbers |\n",
    "| word | the word mapping of the current word | \n",
    "| prefix | The first character of the current word | \n",
    "| prefix1 | The first two character of the current word | \n",
    "| prefix2 | The first three character of the current word |\n",
    "| suffix | The last character of the current wordr | \n",
    "| suffix1 | The last two character of the current word |\n",
    "| suffix2 | The last three character of the current word |\n",
    "\n",
    "As you can imagine, this provides our model with a lot more information than just simply using the word as the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def featurify(sentence, mapping):\n",
    "    for i in range(len(sentence)):\n",
    "        word = sentence[i]\n",
    "        feature = {}\n",
    "        # Some features suggested from http://nlpforhackers.io/training-pos-tagger/\n",
    "        if i == 0:\n",
    "            feature['prev'] = mapping['***']\n",
    "        else:\n",
    "            feature['prev'] = mapping[sentence[i-1]]\n",
    "        if i == len(sentence)-1:\n",
    "            feature['next'] = mapping['###']\n",
    "        else:\n",
    "            feature['next'] = mapping[sentence[i+1]]\n",
    "        feature['lowercase'] = word.lower() == word\n",
    "        feature['capitalized'] = word[0].upper() == word[0]\n",
    "        feature['number'] = word.isdigit()\n",
    "        feature['word'] = mapping[word]\n",
    "        feature['prefix'] = word[:1]\n",
    "        feature['prefix1'] = word[:2]\n",
    "        feature['prefix2'] = word[:3]\n",
    "        feature['suffix'] = word[-1:]\n",
    "        feature['suffix1'] = word[-2:]\n",
    "        feature['suffix2'] = word[-3:]\n",
    "        yield feature\n",
    "        \n",
    "def splitData(taggedsentences, mapping):\n",
    "    # taggedsentences: a list of sentences whose words have been tagged\n",
    "    labels = []\n",
    "    words = []\n",
    "    featwords = []\n",
    "    for sentence in taggedsentences:\n",
    "        for word, tag in sentence:\n",
    "            words.append(mapping[word])\n",
    "            labels.append(tag)\n",
    "        featuredsentence = featurify([word for word, tag in sentence], mapping)\n",
    "        featwords += list(featuredsentence)\n",
    "    return featwords, words, labels\n",
    "\n",
    "feattrain, wordtrain, labeltrain = splitData(trainingset, wordmap)\n",
    "feattest, wordtest, labeltest = splitData(testset, wordmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that while the feature values for prev, next, and word are all integers that were mapped to those specific words, the prefix and suffix features are substrings of the original word. While this is not ideal, it would be a pain to enumerate all the possibilities and assign mappings. Instead, we will allow sklearn to create a one hot encoding of the prefix and suffix categories using the sklearn.DictVectorizer class. This is ideal as it handles all the enumerations that show up in our training set automatically while also being represented in the fast SciPy sparse matrix format. In the case that an prefix/suffix shows up in our test set, all those categories will simply be set to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x13583 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 10 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "def getVectorizer(data):\n",
    "    vec = DictVectorizer(sparse=True)\n",
    "    ohdata = vec.fit_transform(data)\n",
    "    return vec, ohdata\n",
    "\n",
    "def onehotEncode(vec, data):\n",
    "    ohdata = vec.transform(data)\n",
    "    return ohdata\n",
    "\n",
    "vectorizer, ohfeattrain = getVectorizer(feattrain)\n",
    "ohfeattest = onehotEncode(vectorizer, feattest)\n",
    "\n",
    "ohfeattrain[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the Models\n",
    "Now that we have finished preparing our data for learning, our next choice is what sort of model should we train on our data. We will implement several classifiers and test their performance on our data. In order to accomplish this, we will use the following classifiers provided by sklearn: \n",
    "\n",
    "1. Logistic Regression - attempts to learn multiple seperating hyperplanes that will be used to distinguish the word's label based on its distance from those hyperplanes. Assumes that the data is linearly seperable. We will use the sag solver as we have a large data set, and we will enable the multi-class labelling.\n",
    "2. KNeighbors Classifier - stores all the examples during training, and then assigns labels to test words by choosing the k closest neighbors. Assumes that the all features of the data are equally important in determining the closest neighbor. We will use the default value of k = 5. \n",
    "3. Decision Tree Classifier - creates a tree where at each node, a feature is selected such that the distribution of the data at that node results in the lowest possible entropy.\n",
    "4. Multi-Layer Perceptron Classifier - creates layers of hidden states whose weights are trained to minimize the loss of the predictions. We will use a simple perceptron with 2 hidden layers that have 50 neurons each.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "def learnLogReg(data, labels):\n",
    "    logreg = sklearn.linear_model.LogisticRegression(solver=\"sag\", multi_class=\"multinomial\")\n",
    "    logreg = logreg.fit(data, labels)\n",
    "    return logreg\n",
    "\n",
    "def learnKNN(data, labels):\n",
    "    knn = sklearn.neighbors.KNeighborsClassifier()\n",
    "    knn = knn.fit(data, labels)\n",
    "    return knn\n",
    "\n",
    "def learnTree(data, labels):\n",
    "    tree = DecisionTreeClassifier()\n",
    "    tree = tree.fit(data, labels)\n",
    "    return tree\n",
    "\n",
    "def learnMLP(data, labels):\n",
    "    mlp = MLPClassifier(hidden_layer_sizes = (50, 50))\n",
    "    mlp = mlp.fit(data, labels)\n",
    "    return mlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we train our models though, lets take a look at how many training examples we have after our preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1039920\n"
     ]
    }
   ],
   "source": [
    "print(len(labeltrain))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With over a million training examples, all of our models will take an extremely long time to train. Therefore, let's reduce the size of our training set just for the purposes of this tutorial and take just the first 100,000 samples. For, we will also time our models on how long they take to train. This can be done by adding the following line at the top of each cell. \n",
    "\n",
    "  ```python\n",
    "  >>>%%time\n",
    "  ```\n",
    "  \n",
    "In addition to using our extracted features, we will also train models using just the words themselves in order to compare and justify the creation of our features. We will need to use numpy to reshape our lists into an acceptable format for the SciKit models, as they are currently in a 1-D list format, but are required to be 2-D arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "simpletrain = np.array(wordtrain[:20000]).reshape(-1,1)\n",
    "simpletest = np.array(wordtest).reshape(-1,1)\n",
    "finalfeattrain = ohfeattrain[:20000]\n",
    "finallabeltrain = labeltrain[:20000]\n",
    "\n",
    "simpleLRModel = learnLogReg(simpletrain, finallabeltrain)\n",
    "simpleKNNModel = learnKNN(simpletrain, finallabeltrain)\n",
    "simpleDecisionModel = learnTree(simpletrain, finallabeltrain)\n",
    "simplePerceptronModel = learnMLP(simpletrain, finallabeltrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.64 s, sys: 4.62 ms, total: 1.65 s\n",
      "Wall time: 1.65 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sunil/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "LRModel = learnLogReg(finalfeattrain, finallabeltrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.65 ms, sys: 1.58 ms, total: 8.23 ms\n",
      "Wall time: 6.21 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "KNNModel = learnKNN(finalfeattrain, finallabeltrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 883 ms, sys: 3.95 ms, total: 887 ms\n",
      "Wall time: 884 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "DecisionModel = learnTree(finalfeattrain, finallabeltrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 39.8 s, sys: 11.5 s, total: 51.3 s\n",
      "Wall time: 51.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "PerceptronModel = learnMLP(finalfeattrain, finallabeltrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To analyze the total time taken to train each model, we want the total time designated under CPU. From these, we can see that of the four, the multi-layer perceptron takes significantly more time than the rest, while the KNN model takes almost no time at all. This is because the KNN Model simply stores all the examples without really doing any processing. On the other hand, the Perceptron model is tuning hundreds of parameters as it looks at each training example, resulting in its two minute run time. However, as of now, none of these timings are very significant as they are all one time costs. The larger issue is determining the accuracy and speed at which the models are able to predict on a test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting and Scoring our Models\n",
    "\n",
    "Evaluating these functions is fairly simple as we can just use the built-in SciKit learn function, score, provided for every model. We will evaluate the scores of both are simple and featured models. In addition, we will also time our featured models using the same method as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sLRScore = simpleLRModel.score(simpletest, labeltest)\n",
    "sKNNScore = simpleKNNModel.score(simpletest, labeltest)\n",
    "sDecisionScore = simpleDecisionModel.score(simpletest, labeltest)\n",
    "sMLPScore = simplePerceptronModel.score(simpletest, labeltest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 55.8 ms, sys: 2.55 ms, total: 58.3 ms\n",
      "Wall time: 57 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "LRScore = LRModel.score(ohfeattest, labeltest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 6s, sys: 5min 34s, total: 7min 40s\n",
      "Wall time: 11min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "KNNScore = KNNModel.score(ohfeattest, labeltest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 96.5 ms, sys: 81.8 ms, total: 178 ms\n",
      "Wall time: 285 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "DecisionScore = DecisionModel.score(ohfeattest, labeltest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 417 ms, sys: 133 ms, total: 550 ms\n",
      "Wall time: 337 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "MLPScore = PerceptronModel.score(ohfeattest, labeltest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you choose to run these models yourself, they should result in values that are fairly similar to those in the table below. To streamline this tutorial, I have purposefully removed the cells that score and time the simple models as they follow the exact format of the other test cells.\n",
    "\n",
    "| **Model** | **Accuracy** | **Time (seconds)** |\n",
    "|----------|-------------|\n",
    "| Simple Logistic Regression | 0.16357444422455308 | 0.0935\n",
    "| Feature Logistic Regression | 0.38214097235965433 | 59\n",
    "| Simple KNN | 0.76062075334784618 | 0.377\n",
    "| Feature KNN | 0.35543000000000002 | 460\n",
    "| Simple Decision Tree | 0.7761478329705126 | 0.0756\n",
    "| Feature Decision Tree | 0.86376904809024346 | 0.217\n",
    "| Simple Perceptron | 0.26882545022758758 | 0.431\n",
    "| Feature Perceptron | 0.80440662312817468 | 0.514\n",
    "\n",
    "Before we compare the models with each other, note that the addition of the features has improved the accuracy of the models across the board by a fairly large amount. The only one that has failed to do so is the KNN model. In fact, although we had noted that KNN's had the lowest training time by far, when it comes to predictions, it is significantly worse than any of the other 3 models. This is due to the fact that for every single training example, the KNN algorithm needs to calculate the distance to every single point provided in the training data. In fact, as an experiment, you can try increasing the size of the training data to include 100,000 examples and then attempting to score the featured test data. Chances are that your kernel will die due to memory overflow. \n",
    "\n",
    "Overall, the decision tree seems to have proved itself as the most effective model, maintaining relatively low prediction times while also holding the highest accuracy of the bunch. This is likely due to the slightly deterministic nature of sentence tagging. If a word ends with 'ly', it is likely an adverb, the word following an article('the', 'a', 'an') is likely either an adjective or a noun, etc. As a result, it makes sense that splitting the dataset based on the feature values results in the highest accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Further Resources\n",
    "\n",
    "To find additional information on Part of Speech tagging as well other methods used in this tutorial, the following links may be helpful:\n",
    "\n",
    "- NLTK Tutorial on POS tags - http://www.nltk.org/book/ch05.html\n",
    "- Information on grammer and popular tag sets - https://web.stanford.edu/~jurafsky/slp3/10.pdf\n",
    "- POS tagging wiki page- http://wiki.apertium.org/wiki/Part-of-speech_tagging\n",
    "- Explanation and list of various supervised learning techniques - http://scikit-learn.org/stable/supervised_learning.html\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
