{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This tutorial will introduce you to the basics of music manipulation in Python, partiularly through the MIDI file format, which is an easily parseable format for analyzing the structure of music files without performing complex tasks such as frequency analysis. We will cover ways of reading in MIDI files and extracting the relevant information regarding the notes in a given song.\n",
    "\n",
    "The next part of the tutorial will be an introduction to Markov chains, a way of modeling stochastic processes. We will model a song as a Markov model, and write a program that will generate musical notes based on the works of a particular composer, with the ultimate goal of generating music in the style of that composer. We will be using some collected works of Mozart as our training set.\n",
    "\n",
    "Finally, we will discuss the results of using Markov chains for generating music, and discuss some of the limitations of the Markov model in this context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing the Libraries\n",
    "\n",
    "We will be using the `mido` library for processing MIDI data. For the Markov models, we will be using numpy arrays and matrices.\n",
    "\n",
    "You can install the libraries with the following command:\n",
    "\n",
    "```\n",
    "pip install mido numpy\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import coo_matrix\n",
    "from mido import Message, MidiFile, MidiTrack\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The MIDI File Format\n",
    "\n",
    "MIDI is a structured file format for encoding electronic music data.\n",
    "\n",
    "As opposed to other music file formats such as mp3 that contain actual audio data, a MIDI file is encoded as a sequence of **events**. Some examples of MIDI events are **note on**, **note off**, **set tempo**, **time signature**, and **key signature**.\n",
    "\n",
    "MIDI files also can contain multiple **tracks**, which are each an independent sequence of events. There are multiple types of MIDI files - *type 0* files have a single track, *type 1* files have multiple synchronous tracks that play at the same time, and *type 2* files have multiple asynchronous tracks that may not be played at the same time. \n",
    "\n",
    "Each MIDI file has a tempo field that encodes the number of microseconds per quarter note. This is the inverse of the common tempo measurement, bpm (beats per minute). The *time* field of each MIDI event is a relative offset from the previous event, in microseconds.\n",
    "\n",
    "Here is an example of a simple song (Twinkle Twinkle Little Star, which interestingly enough, was also composed by Mozart!).\n",
    "\n",
    "![MIDI Example](midi_pianotrack_screenshot.jpg)\n",
    "\n",
    "This is a piece of software called Synthesia that is commonly used for visualizing MIDI files. The bars coming down towards the piano are the notes in the MIDI file. The **blue** and **green** notes are part of two different **tracks**. \n",
    "\n",
    "Each individual bar has two events - a **note on** event which happens when the bottom edge of the bar hits the piano, and a **note off** event which happens when the top edge of the bar hits the piano. The speed of the bars as they descend is controlled by the **tempo** and speed settings of the MIDI file.\n",
    "\n",
    "You can watch the full video [here](https://www.youtube.com/watch?v=KKCsujeeu8o) for a more intuitive visual expression of a MIDI file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data\n",
    "\n",
    "The dataset we will be using is a collection of Mozart Piano Sonatas. The ultimate goal will be to write a program that can generate a sequence of notes that sounds \"Mozart-like\". \n",
    "\n",
    "We will load the MIDI files and store them as lists of notes. There will be two lists per song - the right hand and left hand notes. For our input data, these are encoded in channels 0 and 1 of the MIDI file, respectively. These sequences do not encode any information about time or duration, and we will discuss this assumption in more detail later.\n",
    "\n",
    "Opening a MIDI file is simple - just provide the filename to the library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_midi = MidiFile('Mozart/mozk281a.mid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MidiFile object contains all the events in the file. Metadata such as MIDI file type and number of tracks can be accessed directly from this object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIDI file type: 1\n",
      "Number of tracks: 16\n"
     ]
    }
   ],
   "source": [
    "print(\"MIDI file type: \" + str(test_midi.type))\n",
    "print(\"Number of tracks: \" + str(len(test_midi.tracks)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that this is a *type 1* file, which has multiple synchronous tracks. MIDI files by default have 16 tracks. However, in our case, only two of them are being used - the rest contain basic header data and are otherwise empty.\n",
    "\n",
    "You can access the *type* of a message directly as well, which is helpful for us to find the note events. Iterating over all the messages in a file is equally simple. To prevent large unnecessary output, the example loop here does nothing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for msg in test_midi:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a sequence of notes, we need to look at the **note_on** and **note_off** events. Each event has a *time* attribute that represents a relative time offset to the previous event in the sequence. When *time* is zero, the event occurs at the same time as the most recent note with a non-zero time value, which we will use to determine chords versus single notes. \n",
    "\n",
    "Essentially, to extract a chord from a MIDI file, we take all the events between two events with a nonzero *time* field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A#/Bb \n",
      "C \n",
      "A#/Bb \n",
      "C \n",
      "A#/Bb \n",
      "C \n",
      "A#/Bb \n",
      "C \n",
      "A#/Bb \n",
      "C \n",
      "A \n",
      "A#/Bb \n",
      "C \n",
      "D \n",
      "A#/Bb \n",
      "A \n",
      "C \n",
      "A#/Bb \n",
      "A \n",
      "D#/Eb \n"
     ]
    }
   ],
   "source": [
    "# Construct a dictionary mapping MIDI note numbers into human-readable notes\n",
    "all_notes = [\"C\", \"C#/Db\", \"D\", \"D#/Eb\", \"E\", \"F\", \"F#/Gb\", \"G\", \"G#/Ab\", \"A\", \"A#/Bb\", \"B\"]\n",
    "midi_note_map = {}\n",
    "for i in range(128):\n",
    "    midi_note_map[i] = all_notes[i % 12]\n",
    "\n",
    "# Loads an individual MIDI file into a list of notes\n",
    "def load_midifile(filename):\n",
    "    mid = MidiFile(filename)\n",
    "    \n",
    "    right_hand_notes = []\n",
    "    left_hand_notes = []\n",
    "    \n",
    "    # When parsing MIDI notes into a note sequence:\n",
    "    # 1) We only care about note_on messages to get a sequence of notes\n",
    "    # 2) Treat notes with a time value of 0 as part of the same chord as the most recent note with a non-zero time value\n",
    "    # 3) Use a set to discard duplicate note events (i.e. noisy/faulty MIDI encoding)\n",
    "    \n",
    "    current_note_right = set()\n",
    "    current_note_left = set()\n",
    "    for msg in mid:\n",
    "        if ((msg.type == 'note_on') or (msg.type == 'note_off')):\n",
    "            if (msg.time > 0):\n",
    "                right_hand_notes.append(list(current_note_right))\n",
    "                left_hand_notes.append(list(current_note_left))\n",
    "                \n",
    "                # Time value is zero, reset the current note\n",
    "                current_note_right = set()\n",
    "                current_note_left = set()\n",
    "            \n",
    "            if (msg.type == 'note_on'):\n",
    "                if (msg.channel == 0):\n",
    "                    current_note_right.add(msg.note)\n",
    "                if (msg.channel == 1):\n",
    "                    current_note_left.add(msg.note)\n",
    "\n",
    "    # Clean data of empty notes\n",
    "    # Convert to tuple for immutability later\n",
    "    right_hand_notes = [tuple(x) for x in right_hand_notes if x != [] ]\n",
    "    left_hand_notes = [tuple(x) for x in left_hand_notes if x != [] ]\n",
    "    \n",
    "    return (right_hand_notes, left_hand_notes)\n",
    "    \n",
    "# Process all the songs in the Mozart folder\n",
    "def load_all_midifiles():\n",
    "    right_hand_sequences = []\n",
    "    left_hand_sequences = []\n",
    "    \n",
    "    for filename in os.listdir('Mozart'):\n",
    "        if filename.endswith(\".mid\"):\n",
    "            (right_hand, left_hand) = load_midifile('Mozart/' + filename)\n",
    "            right_hand_sequences.append(right_hand)\n",
    "            left_hand_sequences.append(left_hand)\n",
    "            \n",
    "    return (right_hand_sequences, left_hand_sequences)\n",
    "\n",
    "(all_right_hand, all_left_hand) = load_all_midifiles()\n",
    "\n",
    "# Print out, to verify, the first 20 notes/chords of the first file, right hand\n",
    "# Use the dictionary constructed earlier to map MIDI note numbers into human-readable notes\n",
    "for chord in all_right_hand[0][0:20]:\n",
    "    human_readable = \"\"\n",
    "    for note in chord:\n",
    "        human_readable += midi_note_map[note] + ' '\n",
    "    print(human_readable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This matches the first measure right-hand notes from Mozart's Sonata no. 3 in B-flat Major, which is the first file in the list. If you don't know how to read sheet music, trust me - it matches.\n",
    "\n",
    "![Mozart Sonata](mozart_measure1.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will write a quick function that takes a sequence of notes and generates a MIDI file from it. Each MIDI file needs a track, so we will construct a single track and append all our note messages to it.\n",
    "\n",
    "Earlier, we stated that we were not parsing any timing information from the MIDI file when reading in the note sequences. For outputing a file, we need some timing information - for the sake of this tutorial, we will the default bpm (beats per minute) and speed of the MIDI format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequence_to_MIDI(note_sequence, output_filename):\n",
    "    outfile = MidiFile()\n",
    "    track = MidiTrack()\n",
    "    outfile.tracks.append(track)\n",
    "    \n",
    "    track.append(Message('program_change', program=1, time=0))\n",
    "    \n",
    "    for chord in note_sequence:\n",
    "        if (len(chord) > 1):\n",
    "            # This is a chord - the first note should have a nonzero time, the rest should have a time of zero\n",
    "            # Append all the 'note_on' messages first, then all the 'note_off' messages\n",
    "            for i in range(len(chord)):\n",
    "                if (i == 0):\n",
    "                    noteOnMessage = Message('note_on', note=chord[i], velocity=60, time=100)\n",
    "                    track.append(noteOnMessage)\n",
    "                else:\n",
    "                    noteOnMessage = Message('note_on', note=chord[i], velocity=60, time=0)\n",
    "                    track.append(noteOnMessage)\n",
    "            for i in range(len(chord)):\n",
    "                if (i == 0):\n",
    "                    noteOnMessage = Message('note_off', note=chord[i], velocity=60, time=100)\n",
    "                    track.append(noteOnMessage)\n",
    "                else:\n",
    "                    noteOnMessage = Message('note_off', note=chord[i], velocity=60, time=0)\n",
    "                    track.append(noteOnMessage)\n",
    "        else:\n",
    "            # Single note - play it\n",
    "            noteOnMessage = Message('note_on', note=chord[0], velocity=60, time=100)\n",
    "            noteOffMessage = Message('note_off', note=chord[0], velocity=60, time=100)\n",
    "            track.append(noteOnMessage)\n",
    "            track.append(noteOffMessage)\n",
    "            \n",
    "    outfile.save(output_filename)\n",
    "    \n",
    "# Here, I will generate a MIDI file from the right-hand melody sequence of the first Mozart piece\n",
    "sequence_to_MIDI(all_right_hand[0], 'mozart_rh_midi.mid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use Windows Media Player to directly play the MIDI file, if you are using Windows.\n",
    "\n",
    "VLC Media Player on Mac should have a codec able to play MIDI as well.\n",
    "\n",
    "If not, I have included all the MIDI files generated from this project (this test sequence of the first Mozart piece, as well as a generated test sequence from the end of the tutorial) as .mp3 files in the folder as well, which can be played with any media player."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Markov Models\n",
    "\n",
    "We will now discuss Markov models. \n",
    "\n",
    "A **Markov chain** is a stochastic model that acts as a sort of state machine, with transitions between states behaving according to probabilistic rules. Essentially, it is a system where each state has a certain probability of transitioning to some other state(s), or itself. \n",
    "\n",
    "Here is a simple Markov chain, with four states and various probabilities of transitioning between them.\n",
    "\n",
    "![Markov Chain](markov_chain.png)\n",
    "\n",
    "State 3, for example, has equal probability (0.25) of transitioning to itself or any of the 3 other states.\n",
    "\n",
    "The key property of a Markov model is that the probability of transitioning to a future state depends only on the current state. This means we do not need to maintain a history of state transitions to compute what state we transition to next.\n",
    "\n",
    "Transition probabilities of Markov models can be expressed as a **transition matrix**, which is a matrix containing the probability of transitioning from one state to another. The element *(i,j)* of a transition matrix contains the probability of transitioning from state *i* to state *j*.\n",
    "\n",
    "We can construct the transition matrix as a standard numpy matrix. The transition matrix for the above Markov chain example is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.4   0.6   0.    0.  ]\n",
      " [ 0.6   0.4   0.    0.  ]\n",
      " [ 0.25  0.25  0.25  0.25]\n",
      " [ 0.    0.    0.    1.  ]]\n"
     ]
    }
   ],
   "source": [
    "example_Tmatrix = np.matrix([[0.4, 0.6, 0, 0], [0.6, 0.4, 0, 0], [0.25, 0.25, 0.25, 0.25], [0, 0, 0, 1]])\n",
    "print(example_Tmatrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Markov Models for Music\n",
    "\n",
    "We will now construct a Markov model representing our musical sequence. The states in our model will be the notes and chords that exist in the song. We will compute the transition probabilities using the counts of notes from our training data, in a similar way to computing the counts of words in an n-gram model approach to text classification.\n",
    "\n",
    "In the code, when referring to a \"note\", we are referring to either a note or a chord, since we processed the MIDI file in a way that preserved chord information separately from individual note information.\n",
    "\n",
    "We will create our music model by first constructing the counts of notes following other notes from the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_note_counts(note_sequences):\n",
    "    # Construct a dictionary mapping {note: dictionary of counts of following notes}\n",
    "    note_counts = {}\n",
    "    \n",
    "    # This stores the number of times a note follows any other note, from our training data\n",
    "    for song in note_sequences:\n",
    "        for i in range(len(song) - 1):\n",
    "            current_note = song[i]\n",
    "            next_note = song[i+1]\n",
    "            if current_note in note_counts:\n",
    "                if next_note in note_counts[current_note]:\n",
    "                    note_counts[current_note][next_note] += 1\n",
    "                else:\n",
    "                    note_counts[current_note][next_note] = 1\n",
    "            else:\n",
    "                note_counts[current_note] = {}\n",
    "                note_counts[current_note][next_note] = 1\n",
    "\n",
    "    return note_counts\n",
    "\n",
    "right_hand_counts = compute_note_counts(all_right_hand)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will convert this dictionary of counts into a Markov transition matrix. We do this first by computing a mapping of notes to indices. We will use this mapping for the indices of the transition matrix, so we have a consistent ordering of notes (which our initial counts dictionary does not have)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute maps between notes and indices of the transition matrix\n",
    "def compute_note_idx_maps(note_counts):\n",
    "    # Get a set of all possible unique notes\n",
    "    all_notes = set(note_counts.keys())\n",
    "    for chord, following_notes in note_counts.items():\n",
    "        for note in following_notes.keys():\n",
    "            all_notes.add(note)\n",
    "            \n",
    "    # Compute a mapping from unique notes to indices\n",
    "    # Also compute the inverse mapping - useful when generating notes\n",
    "    note_to_idx = {}\n",
    "    idx_to_note = {}\n",
    "    i = 0\n",
    "    for chord in all_notes:\n",
    "        note_to_idx[chord] = i\n",
    "        idx_to_note[i] = chord\n",
    "        i += 1\n",
    "        \n",
    "    return (note_to_idx, idx_to_note)\n",
    "\n",
    "# Compute the transition matrix in a sparse matrix representation\n",
    "def compute_transition_matrix(note_counts, note_to_idx):\n",
    "    row_idx = []\n",
    "    col_idx = []\n",
    "    mat_data = []\n",
    "    # Using this map, compute the transition matrix\n",
    "    for chord, following_notes in note_counts.items():\n",
    "        next_note_sum = sum([v for v in following_notes.values()])\n",
    "        \n",
    "        # Construct a row of the transition matrix\n",
    "        for next_note, count in following_notes.items():\n",
    "            note_prob = count / next_note_sum\n",
    "            \n",
    "            # Only append nonzero entries to the matrix - construct it sparsely\n",
    "            if (note_prob > 0):\n",
    "                row_idx.append(note_to_idx[chord]) # Row index is the current note\n",
    "                col_idx.append(note_to_idx[next_note]) # Column index is the next note\n",
    "                mat_data.append(note_prob) # Transition probability\n",
    "                \n",
    "    # Construct the transition matrix\n",
    "    T = coo_matrix((mat_data, (row_idx, col_idx)))\n",
    "    \n",
    "    return T\n",
    "\n",
    "(note_to_idx, idx_to_note) = compute_note_idx_maps(right_hand_counts)\n",
    "T = compute_transition_matrix(right_hand_counts, note_to_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will use the Markov transition probability matrix to generate a sequence of notes. We start by selecting a random note using the overall distribution of notes (i.e. the first note we select is based on how often notes appear in general). Then, we will use the transition matrix to select probabilities for the next notes that follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a sequence of notes \n",
    "def generate_note_sequence(num_notes, note_counts, T, note_to_idx, idx_to_note):\n",
    "    # Compute the sums of each note - lets us compute the probabilities easier\n",
    "    note_count_sums = {}\n",
    "    for key, value in note_counts.items():\n",
    "        note_count_sums[key] = sum([v for v in value.values()])\n",
    "        \n",
    "    total_counts = sum([v for v in note_count_sums.values()])\n",
    "    \n",
    "    # Compute the overall probability of any given note being chosen\n",
    "    note_probability = np.array(list(note_count_sums.values())) / total_counts\n",
    "    \n",
    "    # Select the first note to start with\n",
    "    first_note = np.random.choice(np.array(list(note_count_sums.keys())), p=note_probability)\n",
    "    \n",
    "    # Construct a sequence of notes with a random note to start, using the overall probabilities to select the note\n",
    "    new_notes = []\n",
    "    new_notes.append(np.random.choice(np.array(list(note_count_sums.keys())), p=note_probability))\n",
    "    \n",
    "    while(len(new_notes) < num_notes):\n",
    "        last_note = new_notes[-1]\n",
    "        last_note_idx = note_to_idx[last_note]\n",
    "        \n",
    "        # Get the row of the transition matrix corresponding to the last note\n",
    "        next_note_probs = T.todense()[last_note_idx,:]\n",
    "        next_possible_notes = np.linspace(0, T.shape[0]-1, T.shape[0])\n",
    "        \n",
    "        next_possible_notes = np.reshape(next_possible_notes, next_note_probs.shape).flatten()\n",
    "        next_note_probs = np.array(next_note_probs).flatten()\n",
    "        \n",
    "        # Select the next note\n",
    "        next_note_idx = np.random.choice(next_possible_notes, p=next_note_probs)\n",
    "        next_note = idx_to_note[next_note_idx]\n",
    "        \n",
    "        new_notes.append(next_note)\n",
    "            \n",
    "    return new_notes\n",
    "\n",
    "# Generate a test sequence and \n",
    "test_sequence = generate_note_sequence(50, right_hand_counts, T, note_to_idx, idx_to_note)\n",
    "sequence_to_MIDI(test_sequence, 'test_sequence.mid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "After listening to the test sequence generated by our Markov chain generator, we can see that it has some hints of Mozart, but in general, sounds fairly haphazard and random when compared to the original sonatas. There are a few reasons for this, and they involve the limitations of Markov models for processing this kind of data.\n",
    "\n",
    "1. **A Markov model has no notion of 'history'.**\n",
    "\n",
    "    Music inherently has a notion of 'history'. Chord progressions are just one example - specific sequences of chords. A Markov model has no way of encoding this kind of history, since the probability of the next note depends only on the note before it.\n",
    "\n",
    "    A possible solution to this would be to employ a similar approach as the n-gram word model, which uses multiple words (or in this case, notes) to predict the next note to be played. However, this has a tendency to overfit, and whereas it might work with words, would not work as well with music due to the next limitation.\n",
    "\n",
    "2. **Music has structure.**\n",
    "\n",
    "    Just as a story has a beginning, middle, and end, musical pieces have distinct sections. They also have individual themes (short melodic sequences) that are often varied upon and repeated in different ways throughout a piece. This kind of big-picture history cannot be captured by a Markov model, even if it were to use multiple notes to predict the next note.\n",
    "\n",
    "3. **We made no assumptions about timing when parsing our training data.**\n",
    "\n",
    "    This is an assumption we made at the start - that every note has equal duration. Obviously, this is not the case with actual music. However, this becomes a problem of size when encoding our data set. Take, for example, a piano. There are 88 unique keys. Up to 10 of these can be pressed at any given time (as a pianist has ten fingers). Therefore, to uniquely encode all possible chords that can be played on a piano, we require over 4 trillion unique states. This becomes intractable very quickly, and that's still ignoring how long each note is played for! \n",
    "    \n",
    "    In addition, the MIDI file format is limited in recording high-level information about a song, such as overall structure and themes.\n",
    "    \n",
    "Overall, we have found that Markov models are limited in their ability to generate musical sequences. In addition, we have noticed that the MIDI file format is also limited in encoding important information about music. \n",
    "\n",
    "## Possible Further Work\n",
    "\n",
    "Markov models can be very useful for generating themes and shorter sequences, however. Listening to the generated sequences, they do sound reasonably \"Mozart-y\", and with some improvements, a Markov chain-based approach could be used to generate individual themes or shorter melodic sequences of a song.\n",
    "\n",
    "Then, a secondary algorithm could be used to assemble these themes into an actual song, taking into account knowledge of music structure and pacing - as well as coming up with variations on the themes produced by the Markov model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Resources and References\n",
    "\n",
    "* [MIDO - Python MIDI library](https://mido.readthedocs.io/en/latest/)\n",
    "* [The MIDI File Format](https://www.csie.ntu.edu.tw/~r92092/ref/midi/)\n",
    "* [Visual Markov chain explanation](http://setosa.io/ev/markov-chains/)\n",
    "* [Recurrent Neural Networks for Music Generation](https://medium.com/artists-and-machine-intelligence/neural-nets-for-generating-music-f46dffac21c0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
