{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "This tutorial will introduce you to Tensorflow, an open-source machine learning framework for numerical computation using dataflow graphs. We'll learn how to implement multi-layer perceptrons in Tensorflow using a dataset of malicious and benign URLs, creating a classifier for identifying malicious URLs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background\n",
    "\n",
    "We'll use a \"Hidden Fraudulent URLs\" dataset provided by researchers at the University of Trieste, Italy. The dataset includes three kinds of URLs:\n",
    "\n",
    "1. Hidden Fraudulent URLs\n",
    "2. URLs of legitimate pages from trusted, but compromised websites\n",
    "3. URLs of legitimate pages from trusted, uncompromised websites\n",
    "\n",
    "Let's take a closer look at these terms.\n",
    "\n",
    "- __Hidden URL__: a URL not reached by crawling the website within up to the third level of depth.\n",
    "\n",
    "- __Hidden Fraudulent URL__: a URL to an illegitimate webpage that was added to a trusted website. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tutorial content\n",
    "\n",
    "We'll cover the following topics in this tutorial:\n",
    "- [Installing Libraries](#Installing-Libraries)\n",
    "- [Introduction to Tensorflow](#Introduction-to-Tensorflow)\n",
    "- [Exploratory Data Analysis](#Exploratory-Data-Analysis)\n",
    "- [Feature Engineering](#Feature-Engineering)\n",
    "- [Training and Test Data](#Training-and-Test-Data)\n",
    "- [Feature Columns](#Feature-Columns)\n",
    "- [Choosing the Model](#Choosing-the-Model)\n",
    "- [Training and Evaluation](#Training-and-Evaluation)\n",
    "- [Results](#Results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, install Tensorflow and the tld module (for parsing URLs).  You can install them via `pip`:\n",
    "    \n",
    "    $ pip install tensorflow\n",
    "    \n",
    "    $ pip install tld\n",
    "    \n",
    "Next, make sure the following imports work for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vivekshankar/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import collections\n",
    "import tensorflow as tf # need to run pip install tensorflow\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from urllib.parse import urlparse\n",
    "from tld import get_tld # need to run pip install tld\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import precision_recall_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin with a short excursion into the low-level TensorFlow API: Tensorflow Core. For the remainder of the tutorial, we'll be using higher-level Estimator APIs, but it's still good to know the underlying structure of Tensorflow programs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Tensorflow, the main data structure is the **tensor**: an array of values. A **computational graph** contains:\n",
    "\n",
    "1. **Operations**: nodes in the graph. Operations describe calculations that take input tensors and output tensors.\n",
    "\n",
    "2. **Tensors**: edges in the graph. These represent values that flow through the graph.\n",
    "\n",
    "Below is a simple **computational graph** we'll create: [<img src=\"https://github.com/VivekShankar/Tutorial/raw/master/CompGraph.png\">](https://github.com/VivekShankar/Tutorial/raw/master/CompGraph.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can think of a Tensorflow program in two stages: \n",
    "\n",
    "1. Building the graph\n",
    "\n",
    "2. Running the graph\n",
    "\n",
    "Run the following snippet to create a computational graph. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const_2:0\", shape=(), dtype=float32)\n",
      "Tensor(\"Const_3:0\", shape=(), dtype=float32)\n",
      "Tensor(\"mul_1:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Create two floating point constants a and b using tf.constant\n",
    "# tf.constant builds the constant operation from a float.\n",
    "a = tf.constant(1.4) \n",
    "b = tf.constant(4.0)\n",
    "# Apply the \"*\" operation to multiply the two tensors.\n",
    "total = a * b\n",
    "print(a)\n",
    "print(b)\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: printing the tensors does not output the values 1.4, 4.0, and 5.6, as you might expect. The code only builds the graph. To run the graph, create a `tf.Session` object and call its `run` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.6\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "print(sess.run(total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations, you've run your first Tensorflow program! We've come to the end of our short exploration of Tensorflow Core - you should be familiar with basic Tensorflow terminology and how Tensorflow programs work behind the scenes. For more information, check out: https://www.tensorflow.org/programmers_guide/low_level_intro."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've got our feet wet with Tensorflow, check out the following link to load the URLs dataset: http://machinelearning.inginf.units.it/data-and-tools/hidden-fraudulent-urls-dataset. Download the `HiddenFraudulentURLs.zip` file, unzip the file to extract `HiddenFraudulentURLs.csv`, and load the data using Pandas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>compromissionType</th>\n",
       "      <th>isHiddenFraudulent</th>\n",
       "      <th>contentLength</th>\n",
       "      <th>serverType</th>\n",
       "      <th>poweredBy</th>\n",
       "      <th>contentType</th>\n",
       "      <th>lastModified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://www.sinduscongoias.com.br/index.html</td>\n",
       "      <td>defacement</td>\n",
       "      <td>False</td>\n",
       "      <td>2474</td>\n",
       "      <td>Apache/2.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>text/html</td>\n",
       "      <td>Sat, 05 Jan 2013 19:36:29 GMT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://www.sinduscongoias.com.br/index.php/ins...</td>\n",
       "      <td>defacement</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>Apache/2.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>text/html; charset=utf-8</td>\n",
       "      <td>Mon, 21 Jan 2013 19:30:53 GMT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://www.sinduscongoias.com.br/index.php/ins...</td>\n",
       "      <td>defacement</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>Apache/2.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>text/html; charset=utf-8</td>\n",
       "      <td>Mon, 21 Jan 2013 19:30:58 GMT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://www.sinduscongoias.com.br/index.php/ins...</td>\n",
       "      <td>defacement</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>Apache/2.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>text/html; charset=utf-8</td>\n",
       "      <td>Mon, 21 Jan 2013 19:31:01 GMT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://www.sinduscongoias.com.br/index.php/ins...</td>\n",
       "      <td>defacement</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>Apache/2.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>text/html; charset=utf-8</td>\n",
       "      <td>Mon, 21 Jan 2013 19:31:05 GMT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url compromissionType  \\\n",
       "0        http://www.sinduscongoias.com.br/index.html        defacement   \n",
       "1  http://www.sinduscongoias.com.br/index.php/ins...        defacement   \n",
       "2  http://www.sinduscongoias.com.br/index.php/ins...        defacement   \n",
       "3  http://www.sinduscongoias.com.br/index.php/ins...        defacement   \n",
       "4  http://www.sinduscongoias.com.br/index.php/ins...        defacement   \n",
       "\n",
       "   isHiddenFraudulent  contentLength  serverType poweredBy  \\\n",
       "0               False           2474  Apache/2.2       NaN   \n",
       "1               False              0  Apache/2.2       NaN   \n",
       "2               False              0  Apache/2.2       NaN   \n",
       "3               False              0  Apache/2.2       NaN   \n",
       "4               False              0  Apache/2.2       NaN   \n",
       "\n",
       "                contentType                   lastModified  \n",
       "0                 text/html  Sat, 05 Jan 2013 19:36:29 GMT  \n",
       "1  text/html; charset=utf-8  Mon, 21 Jan 2013 19:30:53 GMT  \n",
       "2  text/html; charset=utf-8  Mon, 21 Jan 2013 19:30:58 GMT  \n",
       "3  text/html; charset=utf-8  Mon, 21 Jan 2013 19:31:01 GMT  \n",
       "4  text/html; charset=utf-8  Mon, 21 Jan 2013 19:31:05 GMT  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_urls = pd.read_csv(\"HiddenFraudulentURLs.csv\", sep=\";\")\n",
    "df_urls.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspecting the data, we notice several missing values (NaNs). To avoid errors in Tensorflow, we replace NaNs with empty strings. Our goal is to predict whether the URL is fraudulent (predict the `isHiddenFraudulent` column). For binary classification, Tensorflow expects that the label has values 1 (fraudulent) or 0 (benign): we cast `isHiddenFraudulent` to an integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_urls.fillna('', inplace=True)\n",
    "df_urls[\"isHiddenFraudulent\"] = df_urls[\"isHiddenFraudulent\"].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For EDA, we examine the data and basic **categorical** features we're provided with through bar charts. For example, here's a bar chart showing the distribution of the `isHiddenFraudulent` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 2 artists>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAD8CAYAAACLrvgBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/wGWkqMA2eYxMgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Count the number of URLs in each category: fraudulent or not fraudulent\n",
    "counts = collections.Counter(df_urls[\"isHiddenFraudulent\"])\n",
    "plt.bar(range(len(counts)), list(counts.values()), \n",
    "        tick_label=[\"Not Hidden/Fraudulent\", \"Hidden/Fraudulent\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution is skewed heavily towards non-fraudulent URLs: over 95% are benign! Keep this in mind later, when we're evaluating our Tensorflow model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do feature engineering to augment our dataset. Rather than passing the entire URL as a feature, let's break it into its constituent parts. Here's the general URL structure: `scheme://netloc/path;parameters?query#fragment`. We'll extract some of these features in the function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_url_features(url_series):\n",
    "    '''Takes in a Pandas Series object containing the URLs and returns \n",
    "       a dictionary of new features. For each entry in the result, \n",
    "       the key is the name of the new feature, and the value is a list \n",
    "       containing all the values for that feature.'''\n",
    "    \n",
    "    # Example URL: http://www.google.com/a/b/c/search?q=search&lang=en\n",
    "    features = {\"schema\": [], # http\n",
    "                \"netloc\" : [], # www.google.com\n",
    "                \"path\" : [], # a/b/c/search?q=search&lang=en\n",
    "                \"log_len_path\" : [], # log(len(\"a/b/c/search?q=search&lang=en\")) = 4\n",
    "                \"tld\" : [], # com\n",
    "                \"domain\": []} # google\n",
    "    \n",
    "    for url in url_series:\n",
    "        o = urlparse(url) # parse the URL using urlparse to extract its scheme, netloc, and path\n",
    "        features[\"schema\"].append(o.scheme) \n",
    "        features[\"netloc\"].append(o.netloc)\n",
    "        features[\"path\"].append(o.path)\n",
    "        # Add 1 to the length before taking log to avoid 'log(0)' errors\n",
    "        features[\"log_len_path\"].append(round(math.log(len(o.path) + 1, 2)))\n",
    "        try:\n",
    "            tld_object = get_tld(url, as_object=True) # get the tld and domain using tld.get_tld\n",
    "            features[\"tld\"].append(tld_object.suffix)\n",
    "            features[\"domain\"].append(tld_object.domain)\n",
    "        except: # exception in extracting the TLD\n",
    "            features[\"tld\"].append(\"\")\n",
    "            features[\"domain\"].append(\"\")\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add these features as columns into our dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_features_to_df(df):\n",
    "    '''Calls create_url_features on the list of URLs in the dataframe to \n",
    "       create a dictionary of new features. Adds the new features as new \n",
    "       columns in the original dataframe and returns the modified dataframe'''\n",
    "    \n",
    "    # create the features dictionary\n",
    "    features = create_url_features(df[\"url\"]) \n",
    "    for feature in features: # loop through the dict & add the features as cols\n",
    "        df[feature] = features[feature]\n",
    "    return df\n",
    "\n",
    "df_urls = add_features_to_df(df_urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the `lastModified` timestamp, we'll extract the **year** as another feature. First, we convert the timestamp string into a `datetime` object. However, since the data doesn't follow one specific datetime format string, we cycle through several possibilities. If there's no `lastModified` timestamp for an example, or we're unable to extract a year, we return a default value of 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def extractTime(time):\n",
    "    '''Returns the year (of type: int) from the 'time' timestamp string, \n",
    "       if possible. Returns 0 otherwise'''\n",
    "    \n",
    "    if time == '':\n",
    "        return 0\n",
    "    formats = ['%a, %d %b %Y %H:%M:%S %Z', \n",
    "               '%a, %d %b %Y %H:%M:%S%Z', \n",
    "               '%a, %d %b %Y %H:%M:%S %z', \n",
    "               '%a %d %b %Y %H:%M:%S %Z', \n",
    "               '%a, %d %b %Y %H:%M:%S %Z %z'] # possible datetime format strings\n",
    "    for fmt in formats:\n",
    "        try: # try to convert the lastModified string to a dateTime\n",
    "            d = datetime.strptime(time, fmt)\n",
    "            return d.year\n",
    "        except ValueError: # try a different datetime format string\n",
    "            pass\n",
    "    return 0\n",
    "\n",
    "df_urls[\"year\"] = df_urls[\"lastModified\"].apply(lambda time : extractTime(time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, we've now extracted features from the raw URLs! How can we tell how good our features are? One way of investigating feature quality is by determining whether a feature is **strongly correlated** with the label. For example, suppose the TLD \".ru\" appeared in fraudulent URLs 96.7% of the time. Then, the TLD is good at \"separating\" the data: \".ru\" is strongly correlated with fraudulent URLs. We can visually inspect the correlation of a **categorical** feature with the label by plotting a **heat map** of the label vs. the feature. We present a heat map of the label vs. tld for the first 1000 examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x1a206436a0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAAD8CAYAAADUv3dIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "numExamples = 1000\n",
    "tld, label = df_urls[\"tld\"], df_urls[\"isHiddenFraudulent\"]\n",
    "\n",
    "# Extract the list of unique tlds, assign each tld in the list of tlds\n",
    "# an index\" representing which tld in the list of unique tlds it is\n",
    "unique_tlds, tld_ids = np.unique(tld[:numExamples], return_inverse=True)\n",
    "# Repeat above steps for the label\n",
    "unique_labels, label_ids = np.unique(label[:numExamples], return_inverse=True)\n",
    "\n",
    "# Create the heat map plot\n",
    "_, xt, yt, _ = plt.hist2d(tld_ids, label_ids, bins=(len(unique_tlds), len(unique_labels)))\n",
    "plt.xticks((xt[:-1]+xt[1:])/2, unique_tlds) # Add tick-marks for the x and y axes\n",
    "plt.yticks((yt[:-1]+yt[1:])/2, unique_labels)\n",
    "\n",
    "# Show heat map\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each cell corresponds with a row (1=malicious, 0=benign), and a column (TLD). The cell's color indicates the number of instances of the TLD in a class. For example, \".edu\" appears in malicious URLs <25 times, and in benign URLs around 100 times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Test Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we parse the data into training and test sets. We'll split the `df_urls` dataframe such that 80% of the examples are in the training set, and 20% are in the test set. It's important to randomize the data before splitting between training/test sets so that the distribution of the features and the label in the training and test sets match their overall distribution in the original dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(df, label_name=\"isHiddenFraudulent\", split_ratio=0.8):\n",
    "    '''Shuffles the rows of the data frame and splits the raw input \n",
    "       data into training and testing sets'''\n",
    "    \n",
    "    # Returns two tuples of (feature, label) for the training and test sets.\n",
    "    df = shuffle(df) # shuffle the rows of the data frame randomly\n",
    "    num_rows = df.shape[0]\n",
    "    split_point = int(num_rows*split_ratio)\n",
    "    train, test = df[:split_point], df[split_point:]\n",
    "\n",
    "    # 1. Delete (pop) the labels from the DataFrame, \n",
    "    # and assign the labels to train_y/test_y\n",
    "    # 2. Assign the remainder of the DataFrame to train_x/test_x\n",
    "    train_x, train_y = train, train.pop(\"isHiddenFraudulent\")\n",
    "    test_x, test_y = test, test.pop(\"isHiddenFraudulent\")\n",
    "    \n",
    "    return (train_x, train_y), (test_x, test_y)\n",
    "\n",
    "(train_x, train_y), (test_x, test_y) = load_data(df_urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Columns\n",
    "\n",
    "#### String Features\n",
    "We'll convert our features into **feature columns** (data structure in Tensorflow to describe how to interpret different feature types). For us, most features are strings. Neural Networks work best on numbers (e.g.: `tf.float32`). We use `tf.feature_column.categorical_column_with_vocabulary_list` that takes in a \"vocabulary list\" of all the unique string-values of the feature, and maps each string to an integer. Then, each string will be represented as a one-hot vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "string_features = [\"schema\", \"netloc\", \"path\", \"tld\", \"domain\"]\n",
    "vocab_feature_columns = []\n",
    "for key in string_features:\n",
    "    # Get a list of the unique feature values (vocabulary list)\n",
    "    vocab_list = df_urls[key].unique()\n",
    "    vocab_length = len(vocab_list)\n",
    "    \n",
    "    # create a vocabulary feature column that converts each string \n",
    "    # to a one-hot vector using the index of the string in the vocab_list\n",
    "    vocabulary_feature_column = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "        key=key,\n",
    "        vocabulary_list=vocab_list)\n",
    "    vocab_feature_columns.append((vocabulary_feature_column,vocab_length))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For features like the domain, we have a **lot** of possible classes, (around 10<sup>5</sup>)! It's hard to train neural nets as the number of categories becomes large - the one-hot vectors grow proportionally! Instead of representing the data using large one-hot vectors, we can use **embedding columns**. Embeddings represent data as lower-dimensional, dense vectors. Below, we convert the categorical feature columns into embedding columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_feature_columns = []\n",
    "for (vocabulary_feature_column, vocab_length) in vocab_feature_columns:\n",
    "    my_feature_columns.append(tf.feature_column.embedding_column(\n",
    "        categorical_column=vocabulary_feature_column,\n",
    "        dimension=math.ceil(vocab_length ** 0.25)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do we choose the dimension of our embedding column? We use a rule of thumb: the length of the embedding column is the 4th root of the number of categories. How do we find the concrete values for each embedding vector corresponding to a string? The answer: during training of the neural network. As we train our model, we learn values of our embedding vectors to satisfy amazing properties, such as nearby strings having vectors lying close together in the embedding space!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numerical Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For `log(len(path))` (and other numerical features), we can use `tf.feature_column.numeric_column` and specify the `dtype` argument to differentiate between different numerical datatypes: `int32`, `float64`, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_feature_columns.append(tf.feature_column.numeric_column(key=\"log_len_path\", dtype=tf.float64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For `lastModified`, we'll split the feature into buckets within specific year ranges (e.g.: [before 2000, 2000-2005, 2005-2010, etc]). We can use the `tf.feature_column.bucketized_column` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numeric_feature_column = tf.feature_column.numeric_column(key=\"year\")\n",
    "bucketized_feature_column = tf.feature_column.bucketized_column(\n",
    "    source_column = numeric_feature_column,\n",
    "    boundaries = [2000, 2005, 2010, 2011, 2012, 2013])\n",
    "my_feature_columns.append(bucketized_feature_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing the Model\n",
    "\n",
    "Tensorflow provides many model types, but we'll use a neural network for this exercise. In this tutorial, we assume a working knowledge of neural networks, but for a refresher, we recommend the following chapter from Michael Nielson's online book: http://neuralnetworksanddeeplearning.com/chap1.html "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Tensorflow model is an `Estimator` object. Tensorflow has two major classes: pre-made and custom Estimators, that you'll code yourself. Tensorflow has a premade, fully-connected neural network Estimator. Run the cell below to create a `tf.estimator.DNNClassifier`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/l4/kglg4bbd4y1c4jgqsvgqbs500000gn/T/tmp0en6_hm1\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/l4/kglg4bbd4y1c4jgqsvgqbs500000gn/T/tmp0en6_hm1', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x1a1f6fc668>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "# Pass in the list of feature columns: feature_columns=my_feature_columns\n",
    "# Pass in a list describing the specific neural network architecture: hidden_units=[50,50]\n",
    "classifier = tf.estimator.DNNClassifier( #DNN = deep neural network\n",
    "    feature_columns=my_feature_columns, \n",
    "    # Three hidden layers: 1024 nodes in the 1st layer, 512 in the 2nd, 256 in the 3rd\n",
    "    # (ith element in list = # nodes in ith hidden layer)\n",
    "    hidden_units=[1024, 512, 256],\n",
    "    dropout = 0.05,\n",
    "    optimizer=tf.train.ProximalAdagradOptimizer(\n",
    "        learning_rate=0.1,\n",
    "        l1_regularization_strength=0.001),\n",
    "    # The model must choose between 2 classes.\n",
    "    n_classes=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go over the **tunable hyperparameters** we supplied. \n",
    "1. `hidden_units`: list describing the neural network architecture: # hidden layers, nodes per layer.\n",
    "2. `ProximalAdagradOptimizer` optimizer: method for optimizing the network’s loss function that you can read more about here: https://cs.stanford.edu/~ppasupat/a9online/1107.html.\n",
    "3. `learning_rate=0.1`: indicates how far to move a neuron’s weights in the direction of the gradient during backpropagation.\n",
    "4. `dropout=0.05`: regularization technique for neural networks, represents the probability we remove neurons from the network. Removing neurons allows the network to avoid incorporating every neuron while making classification decisions and helps avoid overfitting in large networks.\n",
    "\n",
    "It's a good idea to run experiments with different hyperparameters on a validation set to determine suitable hyperparameter values for the network. For more information on the parameters you can supply to `DNNClassifier`, check out https://www.tensorflow.org/api_docs/python/tf/estimator/DNNClassifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train the network, we provide an `input_fn` (`train_input_fn` below), to input training data into the model. `train_input_fn` takes in `features`, a Pandas dataframe containing our training data (row=example, column=feature). `labels` is a list of labels for each example. `batch_size` indicates the number of examples to process at a time (before performing a gradient update). Training neural nets works best when the order of examples is randomized - call `tf.data.Dataset.shuffle` to shuffle the training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_input_fn(features, labels, batch_size):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
    "    # Randomize the examples and group them in batches\n",
    "    dataset = dataset.shuffle(buffer_size=1000).repeat().batch(batch_size)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's call the `train` method of the `DNNClassifier` to train the model, passing `train_input_fn` to input the training data and the number of steps to train the model (another hyperparameter)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /var/folders/l4/kglg4bbd4y1c4jgqsvgqbs500000gn/T/tmp0en6_hm1/model.ckpt.\n",
      "INFO:tensorflow:loss = 72.51943, step = 1\n",
      "INFO:tensorflow:global_step/sec: 35.5732\n",
      "INFO:tensorflow:loss = 11.260693, step = 101 (2.812 sec)\n",
      "INFO:tensorflow:global_step/sec: 54.3126\n",
      "INFO:tensorflow:loss = 21.995567, step = 201 (1.841 sec)\n",
      "INFO:tensorflow:global_step/sec: 54.0021\n",
      "INFO:tensorflow:loss = 10.766937, step = 301 (1.852 sec)\n",
      "INFO:tensorflow:global_step/sec: 52.9843\n",
      "INFO:tensorflow:loss = 5.152972, step = 401 (1.888 sec)\n",
      "INFO:tensorflow:global_step/sec: 45.5397\n",
      "INFO:tensorflow:loss = 12.049961, step = 501 (2.195 sec)\n",
      "INFO:tensorflow:global_step/sec: 43.128\n",
      "INFO:tensorflow:loss = 6.913458, step = 601 (2.319 sec)\n",
      "INFO:tensorflow:global_step/sec: 40.2133\n",
      "INFO:tensorflow:loss = 2.2083893, step = 701 (2.487 sec)\n",
      "INFO:tensorflow:global_step/sec: 42.6669\n",
      "INFO:tensorflow:loss = 2.8111935, step = 801 (2.343 sec)\n",
      "INFO:tensorflow:global_step/sec: 45.4688\n",
      "INFO:tensorflow:loss = 5.4695992, step = 901 (2.199 sec)\n",
      "INFO:tensorflow:global_step/sec: 46.3805\n",
      "INFO:tensorflow:loss = 2.2957695, step = 1001 (2.157 sec)\n",
      "INFO:tensorflow:global_step/sec: 46.4172\n",
      "INFO:tensorflow:loss = 0.3205124, step = 1101 (2.153 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.1643\n",
      "INFO:tensorflow:loss = 3.7575848, step = 1201 (2.034 sec)\n",
      "INFO:tensorflow:global_step/sec: 43.0433\n",
      "INFO:tensorflow:loss = 0.33279473, step = 1301 (2.323 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.3749\n",
      "INFO:tensorflow:loss = 0.30636594, step = 1401 (2.025 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.7131\n",
      "INFO:tensorflow:loss = 0.24278273, step = 1501 (1.972 sec)\n",
      "INFO:tensorflow:global_step/sec: 46.0973\n",
      "INFO:tensorflow:loss = 0.60212606, step = 1601 (2.170 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.7138\n",
      "INFO:tensorflow:loss = 0.080047324, step = 1701 (2.011 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.634\n",
      "INFO:tensorflow:loss = 0.30489182, step = 1801 (2.016 sec)\n",
      "INFO:tensorflow:global_step/sec: 39.1983\n",
      "INFO:tensorflow:loss = 3.1499155, step = 1901 (2.551 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.8636\n",
      "INFO:tensorflow:loss = 0.20489246, step = 2001 (1.966 sec)\n",
      "INFO:tensorflow:global_step/sec: 52.9525\n",
      "INFO:tensorflow:loss = 0.019355984, step = 2101 (1.889 sec)\n",
      "INFO:tensorflow:global_step/sec: 46.9963\n",
      "INFO:tensorflow:loss = 0.3062989, step = 2201 (2.127 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.8752\n",
      "INFO:tensorflow:loss = 1.1990522, step = 2301 (2.005 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.6907\n",
      "INFO:tensorflow:loss = 2.6573713, step = 2401 (2.054 sec)\n",
      "INFO:tensorflow:global_step/sec: 47.4933\n",
      "INFO:tensorflow:loss = 0.5266581, step = 2501 (2.106 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.6281\n",
      "INFO:tensorflow:loss = 9.575424, step = 2601 (2.014 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.4967\n",
      "INFO:tensorflow:loss = 0.6876551, step = 2701 (1.980 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.5107\n",
      "INFO:tensorflow:loss = 0.101485506, step = 2801 (2.062 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.5606\n",
      "INFO:tensorflow:loss = 0.89080566, step = 2901 (2.059 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.8857\n",
      "INFO:tensorflow:loss = 0.07780044, step = 3001 (1.965 sec)\n",
      "INFO:tensorflow:global_step/sec: 53.1723\n",
      "INFO:tensorflow:loss = 0.101802126, step = 3101 (1.880 sec)\n",
      "INFO:tensorflow:global_step/sec: 52.6975\n",
      "INFO:tensorflow:loss = 0.052600954, step = 3201 (1.898 sec)\n",
      "INFO:tensorflow:global_step/sec: 47.5073\n",
      "INFO:tensorflow:loss = 0.18057963, step = 3301 (2.105 sec)\n",
      "INFO:tensorflow:global_step/sec: 41.3329\n",
      "INFO:tensorflow:loss = 0.055494707, step = 3401 (2.419 sec)\n",
      "INFO:tensorflow:global_step/sec: 46.7424\n",
      "INFO:tensorflow:loss = 0.41917998, step = 3501 (2.139 sec)\n",
      "INFO:tensorflow:global_step/sec: 45.5184\n",
      "INFO:tensorflow:loss = 0.41990775, step = 3601 (2.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 46.2163\n",
      "INFO:tensorflow:loss = 0.2348056, step = 3701 (2.162 sec)\n",
      "INFO:tensorflow:global_step/sec: 44.725\n",
      "INFO:tensorflow:loss = 0.041345116, step = 3801 (2.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 46.9682\n",
      "INFO:tensorflow:loss = 0.112057805, step = 3901 (2.129 sec)\n",
      "INFO:tensorflow:global_step/sec: 52.0008\n",
      "INFO:tensorflow:loss = 0.07408035, step = 4001 (1.923 sec)\n",
      "INFO:tensorflow:global_step/sec: 52.3583\n",
      "INFO:tensorflow:loss = 2.280766, step = 4101 (1.910 sec)\n",
      "INFO:tensorflow:global_step/sec: 51.8393\n",
      "INFO:tensorflow:loss = 0.18768007, step = 4201 (1.929 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.7625\n",
      "INFO:tensorflow:loss = 0.13290061, step = 4301 (1.970 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.8454\n",
      "INFO:tensorflow:loss = 0.04772886, step = 4401 (1.967 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.8336\n",
      "INFO:tensorflow:loss = 0.05629401, step = 4501 (2.007 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.6187\n",
      "INFO:tensorflow:loss = 0.04766655, step = 4601 (2.015 sec)\n",
      "INFO:tensorflow:global_step/sec: 51.5356\n",
      "INFO:tensorflow:loss = 0.005023988, step = 4701 (1.941 sec)\n",
      "INFO:tensorflow:global_step/sec: 51.9453\n",
      "INFO:tensorflow:loss = 0.03774302, step = 4801 (1.925 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.7669\n",
      "INFO:tensorflow:loss = 0.047759973, step = 4901 (1.971 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.8744\n",
      "INFO:tensorflow:loss = 0.19071469, step = 5001 (1.965 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.9124\n",
      "INFO:tensorflow:loss = 0.0155694, step = 5101 (2.003 sec)\n",
      "INFO:tensorflow:global_step/sec: 53.089\n",
      "INFO:tensorflow:loss = 0.036609974, step = 5201 (1.883 sec)\n",
      "INFO:tensorflow:global_step/sec: 52.1783\n",
      "INFO:tensorflow:loss = 0.27266726, step = 5301 (1.916 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.6249\n",
      "INFO:tensorflow:loss = 0.032677665, step = 5401 (1.976 sec)\n",
      "INFO:tensorflow:global_step/sec: 51.8992\n",
      "INFO:tensorflow:loss = 0.03038904, step = 5501 (1.927 sec)\n",
      "INFO:tensorflow:global_step/sec: 51.8379\n",
      "INFO:tensorflow:loss = 0.014914964, step = 5601 (1.929 sec)\n",
      "INFO:tensorflow:global_step/sec: 52.3619\n",
      "INFO:tensorflow:loss = 0.044147104, step = 5701 (1.909 sec)\n",
      "INFO:tensorflow:global_step/sec: 51.629\n",
      "INFO:tensorflow:loss = 0.3197619, step = 5801 (1.937 sec)\n",
      "INFO:tensorflow:global_step/sec: 51.4732\n",
      "INFO:tensorflow:loss = 0.033410873, step = 5901 (1.943 sec)\n",
      "INFO:tensorflow:global_step/sec: 52.7364\n",
      "INFO:tensorflow:loss = 0.035701774, step = 6001 (1.896 sec)\n",
      "INFO:tensorflow:global_step/sec: 51.554\n",
      "INFO:tensorflow:loss = 0.08737838, step = 6101 (1.940 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.6112\n",
      "INFO:tensorflow:loss = 0.008033576, step = 6201 (1.975 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.9431\n",
      "INFO:tensorflow:loss = 0.019559294, step = 6301 (2.043 sec)\n",
      "INFO:tensorflow:global_step/sec: 45.7185\n",
      "INFO:tensorflow:loss = 0.0239755, step = 6401 (2.187 sec)\n",
      "INFO:tensorflow:global_step/sec: 51.4773\n",
      "INFO:tensorflow:loss = 0.026216637, step = 6501 (1.943 sec)\n",
      "INFO:tensorflow:global_step/sec: 53.6574\n",
      "INFO:tensorflow:loss = 0.035930563, step = 6601 (1.863 sec)\n",
      "INFO:tensorflow:global_step/sec: 53.4658\n",
      "INFO:tensorflow:loss = 0.012211544, step = 6701 (1.870 sec)\n",
      "INFO:tensorflow:global_step/sec: 53.9825\n",
      "INFO:tensorflow:loss = 0.099074095, step = 6801 (1.853 sec)\n",
      "INFO:tensorflow:global_step/sec: 53.6632\n",
      "INFO:tensorflow:loss = 0.012778895, step = 6901 (1.863 sec)\n",
      "INFO:tensorflow:global_step/sec: 54.7908\n",
      "INFO:tensorflow:loss = 0.18353516, step = 7001 (1.825 sec)\n",
      "INFO:tensorflow:global_step/sec: 54.4787\n",
      "INFO:tensorflow:loss = 0.07516977, step = 7101 (1.836 sec)\n",
      "INFO:tensorflow:global_step/sec: 54.245\n",
      "INFO:tensorflow:loss = 0.022360936, step = 7201 (1.844 sec)\n",
      "INFO:tensorflow:global_step/sec: 53.8748\n",
      "INFO:tensorflow:loss = 1.0492541, step = 7301 (1.856 sec)\n",
      "INFO:tensorflow:global_step/sec: 54.6012\n",
      "INFO:tensorflow:loss = 0.02363428, step = 7401 (1.831 sec)\n",
      "INFO:tensorflow:global_step/sec: 54.3875\n",
      "INFO:tensorflow:loss = 0.15925038, step = 7501 (1.839 sec)\n",
      "INFO:tensorflow:global_step/sec: 54.2453\n",
      "INFO:tensorflow:loss = 0.021329965, step = 7601 (1.844 sec)\n",
      "INFO:tensorflow:global_step/sec: 54.3359\n",
      "INFO:tensorflow:loss = 0.024959087, step = 7701 (1.840 sec)\n",
      "INFO:tensorflow:global_step/sec: 53.7246\n",
      "INFO:tensorflow:loss = 0.013364156, step = 7801 (1.861 sec)\n",
      "INFO:tensorflow:global_step/sec: 44.0853\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.033222627, step = 7901 (2.268 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.1806\n",
      "INFO:tensorflow:loss = 0.007316313, step = 8001 (2.033 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.8872\n",
      "INFO:tensorflow:loss = 0.012808415, step = 8101 (2.004 sec)\n",
      "INFO:tensorflow:global_step/sec: 53.5426\n",
      "INFO:tensorflow:loss = 0.009774205, step = 8201 (1.868 sec)\n",
      "INFO:tensorflow:global_step/sec: 53.0887\n",
      "INFO:tensorflow:loss = 0.026046386, step = 8301 (1.884 sec)\n",
      "INFO:tensorflow:global_step/sec: 53.6554\n",
      "INFO:tensorflow:loss = 0.01219924, step = 8401 (1.864 sec)\n",
      "INFO:tensorflow:global_step/sec: 47.8475\n",
      "INFO:tensorflow:loss = 0.06376077, step = 8501 (2.090 sec)\n",
      "INFO:tensorflow:global_step/sec: 41.7894\n",
      "INFO:tensorflow:loss = 0.04949587, step = 8601 (2.393 sec)\n",
      "INFO:tensorflow:global_step/sec: 43.1111\n",
      "INFO:tensorflow:loss = 0.011750406, step = 8701 (2.320 sec)\n",
      "INFO:tensorflow:global_step/sec: 45.0534\n",
      "INFO:tensorflow:loss = 0.018069739, step = 8801 (2.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 43.9874\n",
      "INFO:tensorflow:loss = 0.031785212, step = 8901 (2.273 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.1784\n",
      "INFO:tensorflow:loss = 0.011454892, step = 9001 (2.075 sec)\n",
      "INFO:tensorflow:global_step/sec: 54.2973\n",
      "INFO:tensorflow:loss = 0.10368106, step = 9101 (1.842 sec)\n",
      "INFO:tensorflow:global_step/sec: 44.8048\n",
      "INFO:tensorflow:loss = 0.030734278, step = 9201 (2.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 42.134\n",
      "INFO:tensorflow:loss = 0.0300129, step = 9301 (2.372 sec)\n",
      "INFO:tensorflow:global_step/sec: 45.2105\n",
      "INFO:tensorflow:loss = 0.028867986, step = 9401 (2.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.6222\n",
      "INFO:tensorflow:loss = 0.041703034, step = 9501 (2.058 sec)\n",
      "INFO:tensorflow:global_step/sec: 47.8445\n",
      "INFO:tensorflow:loss = 1.7676401, step = 9601 (2.089 sec)\n",
      "INFO:tensorflow:global_step/sec: 46.6231\n",
      "INFO:tensorflow:loss = 0.018289963, step = 9701 (2.145 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.705\n",
      "INFO:tensorflow:loss = 0.06782071, step = 9801 (2.012 sec)\n",
      "INFO:tensorflow:global_step/sec: 53.2549\n",
      "INFO:tensorflow:loss = 0.0061181244, step = 9901 (1.878 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 10000 into /var/folders/l4/kglg4bbd4y1c4jgqsvgqbs500000gn/T/tmp0en6_hm1/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.007086647.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.dnn.DNNClassifier at 0x1a1f8757b8>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 100\n",
    "train_steps = 10000\n",
    "\n",
    "# Train the Model.\n",
    "classifier.train(\n",
    "    input_fn=lambda:train_input_fn(train_x, train_y, batch_size),\n",
    "    steps=train_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate the model using our test set, containing URLs our model has never seen. The code for evaluation is similar to the code for training - we pass in the test features instead of training features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-27-21:26:48\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/l4/kglg4bbd4y1c4jgqsvgqbs500000gn/T/tmp0en6_hm1/model.ckpt-10000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-27-21:26:55\n",
      "INFO:tensorflow:Saving dict for global step 10000: accuracy = 0.9896317, accuracy_baseline = 0.9542337, auc = 0.95332485, auc_precision_recall = 0.9253292, average_loss = 0.060051527, global_step = 10000, label/mean = 0.045766283, loss = 5.9947934, prediction/mean = 0.042265292\n",
      "\n",
      "Test set accuracy: 0.990\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def eval_input_fn(features, labels, batch_size):\n",
    "    features=dict(features)\n",
    "    # Convert inputs to a Dataset.\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((features, labels))\n",
    "    # Group examples in batches\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    return dataset\n",
    "\n",
    "# Evaluate the model.\n",
    "eval_result = classifier.evaluate(\n",
    "    input_fn=lambda:eval_input_fn(test_x, test_y, batch_size))\n",
    "print('\\nTest set accuracy: {accuracy:0.3f}\\n'.format(**eval_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You've trained and evaluated your first Tensorflow model, achieving 98.9% accuracy! How good is 98.9%? Let's find out in the next section, where we'll **interpret** our results. But first, run the cell below to launch Tensorboard. Tensorboard is a tool for visualizing the progress of training and evaluating models. Pass in the absolute path where your model is stored (can be found in the output of the training/evaluation steps above) to the `-logdir` parameter below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process is terminated.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "tensorboard -logdir=/var/folders/l4/kglg4bbd4y1c4jgqsvgqbs500000gn/T/tmpa_hzwjkn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can view Tensorboard by entering `localhost:6006` in your browser's address bar. Below is a sample graph you can get from Tensorboard.\n",
    "\n",
    "[<img src=\"https://github.com/VivekShankar/Tutorial/raw/master/TensorboardGraph.png\">](https://github.com/VivekShankar/Tutorial/raw/master/TensorboardGraph.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The orange curve shows the average loss of the model as a function of the global step (0 to 10,000) while training. The blue dot shows the loss of the model during evaluation: helpful for determining how many steps to train and when you're beginning to overfit! When you're finished, click the \"stop button\" in Jupyter to interrupt the kernel and quit Tensorboard. For more information, check out https://www.tensorflow.org/programmers_guide/summaries_and_tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We come back to a crucial point regarding the distribution of labels in our dataset: 95% are benign. Even a naive classifier that outputs 0 (benign) for every URL will achieve 95% accuracy! We consider different classification metrics: precision and recall for evaluating our model. Since we're using a pre-made estimator, we can't change the default evaluation metrics and directly get precision-recall statistics. First, we use `classifier.predict` to get the predictions made by our model for each example in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = test_x\n",
    "expected = test_y\n",
    "predictions = classifier.predict(input_fn=lambda:eval_input_fn(df,expected,batch_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `predict` method returns a list of dictionaries describing the model's predictions, one dictionary per example. Here is a description of the keys.\n",
    "1. `probabilities` maps to a list of probabilities for each class, representing the probability that the example is a particular class.\n",
    "2. `class_ids` maps to a singleton containing the most likely class (0 for benign, 1 for malicious).\n",
    "\n",
    "We loop through the predictions list and list of labels together to compute precision-recall statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/l4/kglg4bbd4y1c4jgqsvgqbs500000gn/T/tmp0en6_hm1/model.ckpt-10000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "Accuracy = 0.990\n",
      "Precision = 0.923\n",
      "Recall = 0.844\n"
     ]
    }
   ],
   "source": [
    "class_id_map = {0 : \"not fraudulent\", 1 : \"fraudulent\"}\n",
    "FP, FN, TP, TN = (0, 0, 0, 0) # for computing precision-recall\n",
    "\n",
    "# Store a list of the probabilities predicted by the model\n",
    "# Useful for computing PR curves later\n",
    "probabilities = []\n",
    "\n",
    "# Loop through each example in the predictions list\n",
    "for pred_dict, expec in zip(predictions, expected):\n",
    "    # Retrieve the id of the most likely class \n",
    "    # This is stored in index 0 of the class_ids list.\n",
    "    class_id = pred_dict['class_ids'][0]\n",
    "    # Retrieve the probability predicted by the model on this example\n",
    "    probabilities.append(pred_dict['logistic'][0])\n",
    "    \n",
    "    # Model made the correct prediction\n",
    "    if class_id == expec:\n",
    "        if expec == 0:\n",
    "            TN += 1\n",
    "        else:\n",
    "            assert(expec == 1)\n",
    "            TP += 1\n",
    "    \n",
    "    # Model made a mistake\n",
    "    if class_id != expec:\n",
    "        if class_id == 0 and expec == 1:\n",
    "            FN += 1\n",
    "        else:\n",
    "            assert(class_id == 1 and expec == 0)\n",
    "            FP += 1\n",
    "errors = FN + FP\n",
    "total = TN + TP + FN + FP\n",
    "print(\"Accuracy = %0.3f\" % (float(total - errors) / total))\n",
    "print(\"Precision = %0.3f\" % (float(TP) / (TP + FP)))\n",
    "print(\"Recall = %0.3f\" % (float(TP) / (TP + FN)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default threshold in Tensorflow is: 0.5 (probability above 0.5 means the model predicts fraudulent, < 0.5 means benign). At `threshold=0.5`, we achieved precision: 92.8% and recall: 86.6%; on our test set, we're able to flag 86.6% of the fraudulent URLs. When we predict a URL as fraudulent, we are correct 92.8% of the time. Using the list of probabilities (`probabilities`) and list of labels (`expected`), we use Scikit-learn to compute the precision-recall curve for our model. The PR curve shows what precision and recall our model achieves at different thresholds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'URL Classification Precision-Recall Curve: AP=0.93')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. Compute the average_precision_score\n",
    "average_precision = average_precision_score(expected, probabilities)\n",
    "# 2. Create the precision-recall (PR) curve object\n",
    "precision, recall, _ = precision_recall_curve(expected, probabilities)\n",
    "# 3. Set parameters of the PR curve\n",
    "plt.step(recall, precision, color='b', alpha=0.2,\n",
    "         where='post')\n",
    "plt.fill_between(recall, precision, step='post', alpha=0.2,\n",
    "                 color='b')\n",
    "plt.xlabel('Recall') # Set axes labels\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.1]) # Set axes limits\n",
    "plt.xlim([0.0, 1.1])\n",
    "plt.title('URL Classification Precision-Recall Curve: AP={0:0.2f}'.format(\n",
    "          average_precision))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We hope you enjoyed this brief tour of Tensorflow walking through URL classification! To learn more, check out the following links:\n",
    "1. Official Tensorflow Programming Guide: (https://www.tensorflow.org/programmers_guide/)\n",
    "2. Specific tutorials on Feature Columns (https://www.tensorflow.org/get_started/feature_columns), creating custom models (https://www.tensorflow.org/get_started/custom_estimators), and much more!\n",
    "3. Machine Learning to Classify Phishing URLs (https://github.com/surajr/URL-Classification)\n",
    "4. Survey of ML for URL Classification (https://arxiv.org/pdf/1701.07179.pdf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
