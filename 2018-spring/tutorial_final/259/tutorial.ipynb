{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "As suggested by its name, the Hidden Markov Model assumes a system is a Markov chain with \"hidden\" states. A system with underlying states transition from one to another with fixed probabilities (conditional probability depends on zero to many previous states) emits observables with fixed probabilities (conditional probability depends on the current hidden state) at each state. While the states are often unobservable, the Hidden Markov Model provides data scientists with a way to decode the underlying states based on the observables emitted by these states.\n",
    "\n",
    "The Hidden Markov Model was first introduced by Rusian L. Stratonovich in 1960. And since then, the method has been widely applied to many data science related fields such as computation finance, bioinformatics, time series analysis as well as more specific machine learning problems including speech recognition, handwriting recognition and machine translation.\n",
    "\n",
    "This tutorial will focus on the application of the model on more general data science problems.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Tutorial content\n",
    "In this tutoiral, we will present the theory behind the Hidden Markov Model, guide you through coding the algorithm from scratch and introduce [hmmlearn](http://hmmlearn.readthedocs.io/en/latest/tutorial.html), that was once part of the famous scikit-learn library but has been separated into an individual library release on Github.\n",
    "\n",
    "To facilitate understanding, a small dataset will be used to illustrate the idea in this tutorial. But do keep in mind that the actual application of Hidden Markov Model does not limit to a small dataset.\n",
    "\n",
    "The following are the section titles of the topic we are going to cover:\n",
    "* Markov Chain\n",
    "* From Markov Chain to Hidden Markov Model\n",
    "* The Evaluation Problem, and the Forward Algorithm\n",
    "* The Decoding Problem and the Viterbi Algorithm\n",
    "* The Learning Problem, the Baum-Welch Algorithm and the hmmlearn library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Markov Chain and First Order Markov Assumption\n",
    "Markov Chain is a sequence of events whose states only depends on the state of the previous event of this sequence. When we model a sequence of events to be a Markov Chain, we assume that the events obey the first order markov assumption. Probabilitically, this assumption can be written as P(e<sub>n</sub>|e<sub>n-1</sub>, e<sub>n-2</sub>, ..., e<sub>1</sub>) = P(e<sub>n</sub>|e<sub>n-1</sub>).\n",
    "\n",
    "For instance, let's define the event e<sub>n</sub> to be the act that Alvin has lunch at Underground on day n. The event can have multiple different states based on the kind of food Alvin orders on that day. By naming the state using the food ordered, we have the state of e<sub>n</sub> in an element in the set {Burger, Salad, None}. By ordering all events by time, we have a sequence of N events e<sub>1</sub>, e<sub>2</sub>, ... ,e<sub>n</sub>, ... ,e<sub>N</sub> on a time series. This alone does not make the series a Markov Chain. However, if we reasonably believe that Alvin's decision to order food only depends on his decision yesterday, in order words, P(e<sub>n</sub>|e<sub>n-1</sub>, e<sub>n-2</sub>, ..., e<sub>1</sub>) = P(e<sub>n</sub>|e<sub>n-1</sub>), then we have a Markov Chain here.\n",
    "\n",
    "The following chart shows the conditional probability from one state to another."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"files/chart1.tiff\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From Markov Chain to Hidden Markov Model\n",
    "Continuing our discussion about Alvin, Alvin's suitemate Roy loves to stalk others. He would like to know what Alvin has at Underground every day but it will be too obvious to follow him to Underground and observe. As a result, Roy decides to keep track of the time Alvin spent at Underground by computing the time interval between the time Alvin leaves the suite for Underground and the time he comes back.\n",
    "\n",
    "Roy categories his data with different labels, namely {below 5min, 5 to 20min, above 20min}. By gathering enough observables, he wishes to decode the observable sequence into the actual state sequence and understand Alvin's diet.\n",
    "\n",
    "In this case, the state of the events is unobservable for or \"hidden\" from Roy. But Roy still believes that the sequence is intrinsically a Markov Chain. Moreover, Roy believes that the value of the observable on day n, o<sub>n</sub> depends only one e<sub>n</sub>.\n",
    "\n",
    "With these conditions, we say that Roy models the system as a Hidden Markov Model.\n",
    "\n",
    "The following is the emission probability p(o<sub>n</sub>|e<sub>n</sub>) we use for this tutorial.\n",
    "\n",
    "|| below 5 min | 5 to 20 min | above 20 min |\n",
    "|---|---|---|---|\n",
    "|Burger|0.05|0.40|0.55|\n",
    "|Salad|0.08|0.66|0.26|\n",
    "|None|0.80|0.15|0.05|\n",
    "\n",
    "With the Hidden Markov Model, there are three important problems, namely, evaluation, decoding and learning. The definition of each problem is:\n",
    "* **The Evaluation Problem**: Given a HMM model, its parameters (transition probabilities, emission probabilities) and a sequence of observations, evaluate the probability of observations\n",
    "* **The Decoding Problem**: Given a HMM model, its parameters (transition probabilities, emission probabilities) and a sequence of observations, give the most likely state sequence\n",
    "* **The Learning Problem**: Given a HMM model, a sequence of observations and a sequence of states, see how we should adjust the model parameters in order to maximize the probability of observations given model\n",
    "\n",
    "Before we start to write some codes to address the three problems mentioned above, let's set up our dataset first.\n",
    "\n",
    "First is the set of all possible states and observations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "states = ['Burger', 'Salad', 'None']\n",
    "observations = {'below 5 min', '5 to 20 min', 'above 20 min'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Then we define two helper functions which returns the transition probability and the emission probability:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "transition_matrix = numpy.matrix([[0.1, 0.65, 0.25],\n",
    "                                  [0.55, 0.35, 0.1],\n",
    "                                  [0.45, 0.50, 0.05]])\n",
    "\n",
    "emission_matrix = numpy.matrix([[0.05, 0.40, 0.55],\n",
    "                                [0.08, 0.66, 0.26],\n",
    "                                [0.80, 0.15, 0.05]])\n",
    "\n",
    "def state_num_index(state):\n",
    "    return states.index(state)\n",
    "\n",
    "def index_to_state(i):\n",
    "    return states[i]\n",
    "\n",
    "def observation_num_index(o):\n",
    "    if o == 'below 5 min': return 0\n",
    "    elif o == '5 to 20 min': return 1\n",
    "    else:\n",
    "        assert(o == 'above 20 min')\n",
    "        return 2\n",
    "\n",
    "def transition_prob(current_state, to_state, transition_matrix):\n",
    "    return transition_matrix[state_num_index(current_state), state_num_index(to_state)]\n",
    "\n",
    "def emission_prob(current_state, observation, emission_matrix):\n",
    "    return emission_matrix[state_num_index(current_state), observation_num_index(observation)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## The Evaluation Problem, the Forward and Backward Algorithm\n",
    "With all the data ready, let's move on to the evaluation problem. Before explaining the concepts, we need to define some variables.\n",
    "* **Observation Sequence**: From now onwards, we use O to represent the entire observation sequence. O = o<sub>1</sub> o<sub>2</sub> ... o<sub>T</sub>. o<sub>n</sub> refers to the observation corresponding to the nth state in the sequence.\n",
    "* **State Sequence**: We use Q to represent the entire state sequence. Q = q<sub>1</sub> q<sub>2</sub> ... q<sub>T</sub>. q<sub>n</sub> refers to the nth state in the sequence.\n",
    "* **HMM model**: We use &#955; to represent the HMM model. &#955; is defined by a collection of transition probabilities and emission probabilities. \n",
    "* **Transition Probability**: We use A for the transition probability matrix, where a<sub>qiqj</sub> refers to the transition probability from the state i to state j.\n",
    "* **Emission Probability**: We use B for the collection of emission probabilities. b<sub>q</sub> refers to the emission probability for state q and b<sub>q</sub>(o) refers to the probability of having observation o at state q.\n",
    "* **Number of possible states**: N\n",
    "* **Length of the sequence**: T\n",
    "\n",
    "The evaluation problem states that given a HMM model, evaluate the probability of observations. In order words, we want to calcuate the value of P(O|&#955;).\n",
    "\n",
    "By applying the basic rules of probability, we know that P(O|&#955;) = &#8721;<sub>&#8704;Q</sub>P(O, Q|&#955;)=&#8721;<sub>&#8704;Q</sub>a<sub>q0q1</sub>b<sub>q1</sub>(o<sub>1</sub>) * a<sub>q1q2</sub>b<sub>q2</sub>(o<sub>2</sub>) * ... * a<sub>qT-1qT</sub>b<sub>qT</sub>(o<sub>T</sub>).\n",
    "\n",
    "While the math is sound, the complexity to compute that summation as it is O(N<sup>T</sup>) with N be the number of possible states and T be the length of the sequence/number of observations.\n",
    "\n",
    "To make the computation faster, we introduce the **forward algorithm**, which is essentially a dynamic programming approach to solve the evaluation problem.\n",
    "\n",
    "All dynamic programming problem defines a subproblem or a subtask whose result will be shared by multiple paths. In our case, the subproblem is to compute the value &#945;<sub>t</sub>(j) which equals to P(o<sub>1</sub> o<sub>2</sub> ... o<sub>t</sub>, q<sub>t</sub> = S<sub>j</sub> | &#955;). In plain English, it is the probability of the observation sequence to be o<sub>1</sub> o<sub>2</sub> ... o<sub>t</sub> and the tth state to be S<sub>j</sub> given the HMM model.\n",
    "\n",
    "The special value &#945;<sub>0</sub>(j) is set to be 1 if S<sub>j</sub> is the start state and 0 otherwise.\n",
    "Other values can be computed recursively by &#945;<sub>t</sub>(j) = [&#8721;<sup>N</sup><sub>j = 0</sub>&#945;<sub>t-1</sub>(i)a<sub>ij</sub>]b<sub>j</sub>(o<sub>t</sub>)\n",
    "\n",
    "Finally, as it naturally emerges from the definition of &#945;, P(O|&#955;) = &#8721;<sup>N</sup><sub>j = 0</sub>&#945;<sub>T</sub>(j)\n",
    "\n",
    "And this is the entire forward algorithm. The complexity of this algorithm is O(NNT)\n",
    "\n",
    "Let's use this algorithm to evaluate the probability of the observation sequence defined below given the Alvin Roy Underground HMM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "O = ['below 5 min', 'below 5 min', 'above 20 min', 'below 5 min', \\\n",
    "     '5 to 20 min', 'above 20 min', 'below 5 min', '5 to 20 min', \\\n",
    "     'above 20 min', 'above 20 min', 'below 5 min', '5 to 20 min', \\\n",
    "     'above 20 min', 'above 20 min']\n",
    "T = len(O)\n",
    "N = len(states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "It is **important** to realize that due to the hard limitation of the float number Python supports, the forward algorithm introduced above will almost always give 0 as Python cannot support a number too small, we want to convert all numbers into their log scale and compute the result in a logarithmic fashion.\n",
    "\n",
    "This means that multiplication becomes addition. And addition becomes logarithmic addition with the helper function provided below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "def log_add(left, right):\n",
    "    if right < left: return left + math.log1p(math.exp(right - left))\n",
    "    elif left < right: return right + math.log1p(math.exp(left - right))\n",
    "    else: return left + math.log1p(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also useful to define the following wrapper for our helper function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log_transition_matrix = numpy.log(transition_matrix)\n",
    "log_emission_matrix = numpy.log(emission_matrix)\n",
    "\n",
    "def log_transition_prob(current_state, to_state):\n",
    "    return transition_prob(current_state, to_state, log_transition_matrix) \n",
    "\n",
    "def log_emission_prob(current_state, observation):\n",
    "    return emission_prob(current_state, observation, log_emission_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can implement the evaluate function which evaluate the input observation sequence using the helper function defined above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(O):\n",
    "    # Initialize the alpha matrix\n",
    "    width = T + 1\n",
    "    height = N\n",
    "    alphas = [[0 for i in range(width)] for j in range(height)]\n",
    "    \n",
    "    # Initialize the prior. We assume the probability distribution of the initial state to be uniform\n",
    "    # for more information about picking the initial state, read online :D\n",
    "    for state_index, state in enumerate(states):\n",
    "        alphas[1][state_index] = math.log(1.0/N) + log_emission_prob(state, O[0])\n",
    "    \n",
    "    # Dynamically compute all the alpha values in the matrix alphas\n",
    "    for t in range(2, T + 1):\n",
    "        for current_state_index, current_state in enumerate(states):\n",
    "            total = 0\n",
    "            for prev_state_index, prev_state in enumerate(states):\n",
    "                if prev_state_index == 0: \n",
    "                    total = log_transition_prob(prev_state, current_state) + alphas[prev_state_index][t - 1]\n",
    "                else:\n",
    "                    total = log_add(total, \n",
    "                                    log_transition_prob(prev_state, current_state) + alphas[prev_state_index][t - 1])\n",
    "            alphas[current_state_index][t] = total + log_emission_prob(current_state, O[t - 1]) # the t - 1 was due to 0 indexing\n",
    "            \n",
    "    #Sum the final column up to get the answer\n",
    "    rtn = 0\n",
    "    for i in range(0, N):\n",
    "        if i == 0:\n",
    "            rtn = alphas[i][T]\n",
    "        else:\n",
    "            rtn = log_add(rtn, alphas[i][T])\n",
    "    return rtn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "evaluate(O)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "math.exp(evaluate(O))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function should return -14.4314... in log space or 5.401..e-07\n",
    "\n",
    "Beside the forward algorithm, there is a backward algorithm which is able to arrive at the some results. The algorithm is an important building block for the solution of the learning problem. See the [following link](http://pages.cs.wisc.edu/~matthewb/pages/notes/pdf/hmms/BackwardAlgorithm.pdf) to learn more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Decoding Problem and the Viterbi Algorithm\n",
    "Moving on, given a HMM model &#955;, we want to find the most likely underlying state sequence Q based on the observation sequence O. The Evaluation Problem has already provided us with a way to compute the probability of all possible state sequence. The decoding problem wants to find the best/most probable one out of them.\n",
    "\n",
    "We can have a similar table as the forward algorithm. The only difference is, instead of computing the sum of each value in the previous column times transimission probability times emission probability, we compute the max. Intuitively, this refers to the probability of the most probable state sequence up to the current time t with the last state to be state the cell corresponding to.\n",
    "\n",
    "This is in fact **the Viterbi Algorithm**.\n",
    "\n",
    "To define it formally, we define the subproblem VP<sub>t</sub>(i) = MAX<sub>q0,..qt-1</sub>P(o<sub>1</sub> o<sub>2</sub> ... o<sub>t</sub>, q<sub>t</sub> = S<sub>j</sub> | &#955;). where VP<sub>t</sub>(j)=MAX<sub>i=0,...,N</sub>VP<sub>t-1</sub>(i)a<sub>ij</sub>b<sub>j</sub>(o<sub>t</sub>)\n",
    "\n",
    "Moreover, we internally keep track of the past state in order to return the most probably state sequence in the end.\n",
    "\n",
    "The following is the code for encoding. Read it with the evaluate function to help you understand the similarities and differences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def decode(O):\n",
    "    # Initialize the viterbi matrix\n",
    "    width = T + 1\n",
    "    height = N\n",
    "    viterbis = [[0 for i in range(width)] for j in range(height)]\n",
    "    prev_states = [[None for i in range(width)] for j in range(height)]\n",
    "    \n",
    "    # Initialize the prior. We assume the probability distribution of the initial state to be uniform\n",
    "    # for more information about picking the initial state, read online\n",
    "    for state_index, state in enumerate(states):\n",
    "        viterbis[1][state_index] = math.log(1.0/N) + log_emission_prob(state, O[0])\n",
    "        \n",
    "    # Dynamically fill in the viterbi matrix\n",
    "    for t in range(2, T + 1):\n",
    "        for current_state_index, current_state in enumerate(states):\n",
    "            maxV = None\n",
    "            prevHopState = None\n",
    "            for prev_state_index, prev_state in enumerate(states):\n",
    "                v = log_transition_prob(prev_state, current_state) + viterbis[prev_state_index][t - 1]\n",
    "                if (maxV == None) or (maxV < v):\n",
    "                    maxV = v\n",
    "                    prevHopState = prev_state\n",
    "            viterbis[current_state_index][t] = maxV + log_emission_prob(current_state, O[t - 1]) # the t - 1 was due to 0 indexing\n",
    "            prev_states[current_state_index][t] = prevHopState\n",
    "    \n",
    "    # Final the most probable route\n",
    "    best_p = None\n",
    "    best_final_state_index = -1;\n",
    "    for i in range(0, N):\n",
    "        p = viterbis[i][T]\n",
    "        if (best_p == None) or (best_p < p):\n",
    "            best_p = p\n",
    "            best_final_state_index = i\n",
    "    \n",
    "    # Backtrace the entire path using the prev_states matrix\n",
    "    path = [index_to_state(best_final_state_index)]\n",
    "    for t in range(T, 1, -1):\n",
    "        best_final_state = prev_states[best_final_state_index][T]\n",
    "        path = [best_final_state] + path\n",
    "        best_final_state_index = state_num_index(best_final_state)\n",
    "    \n",
    "    return (best_p, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(p, path) = decode(O)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is an alternating sequence of burger and salad with p to be -18.90895... in the log space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Learning Problem, the Baum-Welch Algorithm and the hmmlearn library\n",
    "Finally, it is time to solve the learning problem. The Baum-Welch Algorithm is used in learning the probabilities based on the input observation. The Algorithm uses Forward and Backward Algorithm as building blocks. To learn more about the algorithm itself, [check here](https://people.cs.umass.edu/~mccallum/courses/inlp2004a/lect10-hmm2.pdf).\n",
    "\n",
    "Instead of showing how to write the algorithm from scratch, we want to show you how to use it using the hmmlearn library to make your life easier.\n",
    "\n",
    "First of all, install the library by using:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "$ pip install -U --user hmmlearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from hmmlearn import hmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "O_train = ['below 5 min', 'below 5 min', '5 to 20 min', 'below 5 min', \\\n",
    "     '5 to 20 min', 'below 5 min', 'below 5 min', '5 to 20 min', \\\n",
    "     'above 20 min', 'above 20 min', '5 to 20 min', '5 to 20 min', \\\n",
    "     'below 5 min', 'below 5 min', 'above 20 min', 'below 5 min', \\\n",
    "     '5 to 20 min', 'above 20 min', 'above 20 min', '5 to 20 min', \\\n",
    "     'above 20 min', 'above 20 min', 'below 5 min', '5 to 20 min']\n",
    "\n",
    "# Convert the Observation into an index array\n",
    "O_train_index = []\n",
    "for o in O_train:\n",
    "    O_train_index.append(observation_num_index(o))\n",
    "\n",
    "# Initialize the model\n",
    "model = hmm.MultinomialHMM(n_components = N, n_iter = 100)\n",
    "\n",
    "# Train the model using the observations\n",
    "model.fit([O_train_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now we can use the model trained to decode new observations using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the test observation to a list of indexes\n",
    "O_index = []\n",
    "for o in O:\n",
    "    O_index.append(observation_num_index(o))\n",
    "    \n",
    "# Let's decode!\n",
    "(logprob, state_sequence) = model.decode(O_index)\n",
    "print(logprob)\n",
    "print(state_sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, the library allows you to initialize transition probabilities, emission probabilities, prior probabilities, adjust the number of iterations and convergence threshold. Check [this link](http://hmmlearn.readthedocs.io/en/0.2.0/index.html) to learn more about the library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Further Reading\n",
    "To learn more about HMM, check these resources\n",
    "* Chapter 17 [Machine Learning: A Probabilistic Perspective](https://www.amazon.com/Machine-Learning-Probabilistic-Perspective-Computation/dp/0262018020/ref=sr_1_1?ie=UTF8&qid=1522271059&sr=8-1&keywords=Machine+Learning%3A+A+Probabilistic+Perspective%2C+by+Kevin+P.+Murphy) by Kelvin P. Murphy\n",
    "* CMU 10601 [Course Website](http://www.cs.cmu.edu/~mgormley/courses/10601-s18/schedule.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
