{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping using Selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This tutorial will introduce some basic concepts of Selenium and explain how to use Selenium to scrape data from websites. Selenium is a tool that allows you to automate your actions in a web browser and save them as automated tests that you can reply at a later time. However, Selenium is also used widely on scraping data from dynamic websites by simulating how a person navigates through the websites. Information from websites can be obtained easily using Selenium. There are several reasons why Selenium is an excellent tool to scrape data from websites. Firstly, Selenium has the capability to operate on almost every OS, including Chrome, Firefox, IE, Safari, etc. Secondly, Selenium provides more convenience when there are too many JavaScripts in a website. Thirdly, Selenium supports multiple languages, such as Python, Pearl, PHP, Ruby, C#, and Java.\n",
    "\n",
    "In this tutorial, we will talk about the installation of Selenium, a simple example to explain how to use Selenium, and a real case to obtain information of available plane tickets from Expedia (https://www.expedia.com/). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial Contents\n",
    "\n",
    "We will cover the following topics in this tutorial:\n",
    "    \n",
    "- [Installation](#Installation)\n",
    "- [Getting Started](#Getting-Started)\n",
    "- [Locating Elements](#Locating-Elements)\n",
    "- [Waits](#Waits)\n",
    "- [Case: Scraping plane tickets information from Expedia](#Case:-Scraping-plane-tickets-information-from-Expedia)\n",
    "    \n",
    "In this tutorial, we will first explain how to install Selenium. Then a simple example will be given to explain basic operations in Selenium, such as navigating to websites, locating website elements, and applying waits (explicit waits & implicit waits) to make sure pages are fully loaded. Finally, we will use a real case to explain how to obtain plane tickets information from Expedia (https://www.expedia.com/). Now, let's get started!    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selenium Python bindings provide a simple API to write functional tests using Selenium WebDriver. The convenient API provided by Selenium Python bindings is able to access Selenium WebDrivers, such as Chrome, Firefox, Ie, Safari etc. The current supported Python versions are 2.7, 3.5 and above. In this documentation, we will explain Selenium 2 WebDriver API with Python 3.5.\n",
    "\n",
    "Firstly, we need to download Python bindings for Selenium. There are two ways to download Selenium Python bindings: one is to download from the [PyPI page](https://pypi.python.org/pypi/selenium) for Selenium package; the second one, also the better approach, is to install the Selenium package using `pip`. Input the following command in your terminal to install Python bindings for Selenium:\n",
    "    \n",
    "    $ pip install selenium\n",
    "    \n",
    "Secondly, a web driver is required for Selenium to interface with the selected browser. Web drivers can be downloaded in the following links:\n",
    "\n",
    "- Chrome [driver](https://sites.google.com/a/chromium.org/chromedriver/downloads)\n",
    "- Firefox [driver](https://github.com/mozilla/geckodriver/releases)\n",
    "- Safari [driver](https://webkit.org/blog/6900/webdriver-support-in-safari-10/)\n",
    "- Edge [driver](https://developer.microsoft.com/en-us/microsoft-edge/tools/webdriver/)\n",
    "\n",
    "After downloading the web drivers, for Linux and MacOS users, make sure the web drivers are in your PATH, e.g., place it in usr/local/bin or usr/bin. For Windows users, detailed instructions can be found [here](http://selenium-python.readthedocs.io/installation.html#detailed-instructions-for-windows-users). To check whether we installed Selenium successfully, we can run the code snippet in Getting Started section, if we can get the page source, then Selenium is installed successfully and we can keep moving!    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! You have installed all required packages of Selenium successfully. Now, we can start a journey to scrape data from websites using Selenium! The following is a simple example to navigate to a URL, locate elements and get results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By running the code snippet in the next cell, you can get the page source of python official website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome() #create an instance of Chrome WebDriver\n",
    "driver.get(\"http://www.python.org\") #navigate to a web page given by the URL\n",
    "html = driver.page_source #get the source code of the website\n",
    "#print(html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you get the page source of the website. Next, you can find the search field using element locators. Then inputting search queries, pressing the search button can be simulated by Selenium using send_keys() method. After that, we can screenshot the search results and store it in our local machine to see whether we navigate to the search result page as we expected. We can make the driver sleep for 5 seconds, so that we are able to see the result page in the web browser. Finally, don't forget to close the driver, otherwise the browser will stay there forever. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "element = driver.find_element_by_name(\"q\") #find the \"Search\" field in the web page\n",
    "element.clear() #clear pre-populated text in the input field\n",
    "element.send_keys(\"python 3.5\") #enter search terms into the input field\n",
    "element.send_keys(Keys.RETURN) #start searching\n",
    "driver.get_screenshot_as_file(\"./img/sreenshot1.png\") #screenshot the search results\n",
    "time.sleep(5) #sleep for 5 seconds to see the search results\n",
    "driver.close() #close the driver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Locating Elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You've already obtained an overview of how Selenium works. Now, let's walk deeper on the methods that Selenium provides to locate elements in a page. \n",
    "\n",
    "Selenium provides many public methods to locate elements:\n",
    "    \n",
    "- find_element_by_id\n",
    "- find_element_by_name\n",
    "- find_element_by_xpath\n",
    "- find_element_by_link_text\n",
    "- find_element_by_partial_link_text\n",
    "- find_element_by_tag_name\n",
    "- find_element_by_class_name\n",
    "- find_element_by_css_selector\n",
    "\n",
    "To find multiple elements (these methods return a list):\n",
    "\n",
    "- find_elements_by_name\n",
    "- find_elements_by_xpath\n",
    "- find_elements_by_link_text\n",
    "- find_elements_by_partial_link_text\n",
    "- find_elements_by_tag_name\n",
    "- find_elements_by_class_name\n",
    "- find_elements_by_css_selector\n",
    "\n",
    "The followings are some examples of how to use the public methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome() #create an instance of Chrome WebDriver\n",
    "driver.get(\"http://www.python.org\") #navigate to a web page given by the URL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For instance, consider the following html snippet:\n",
    "\n",
    "    <li id=\"documentation\" class=\"tier-1 element-3\" aria-haspopup=\"true\">\n",
    "        <a href=\"/doc/\" title=\"\" class=\"\">Documentation</a>\n",
    "    </li>\n",
    "\n",
    "The \"documentation\" element can be located like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documentation\n"
     ]
    }
   ],
   "source": [
    "element_by_id = driver.find_element_by_id(\"documentation\")\n",
    "print(element_by_id.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For instance, consider the following html snippet:\n",
    "    \n",
    "    <button type=\"submit\" name=\"submit\" id=\"submit\" class=\"search-button\" title=\"Submit this Search\" tabindex=\"3\">\n",
    "        GO\n",
    "    </button>\n",
    "\n",
    "The \"button\" element can be located like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GO\n"
     ]
    }
   ],
   "source": [
    "element_by_name = driver.find_element_by_name(\"submit\")\n",
    "print(element_by_name.text)\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides the public methods mentioned above, there are also two private methods provided by Selenium:\n",
    "    \n",
    "- find_element\n",
    "- find_elements\n",
    "\n",
    "The examples of how to use the private methods can be found [here](http://selenium-python.readthedocs.io/locating-elements.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Waits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you know everything about how to locate elements in a website! But a new problem comes up, because a lot of websites are using AJAX nowadays, which leads to elements in a page loading at different time intervals. This makes locating elements difficult. If an element is not yet present in the DOM ([Document Object Model](https://en.wikipedia.org/wiki/Document_Object_Model)), the locate functions will throw ElementNotVisibleException exception. In order to avoid raising such exception, waits can be used to provide slacks between actions performed.\n",
    "\n",
    "Selenium WebDriver provides two types of waits: explicit waits and implicit waits. \n",
    "\n",
    "An explicit wait makes Selenium WebDriver wait for a certain condition to happen before proceeding further executions. The following is an example of explicit waits.  Notes: More expected conditions can be found [here](http://selenium-python.readthedocs.io/waits.html#explicit-waits).   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import selenium.webdriver.support.ui as ui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://www.expedia.com/\")\n",
    "try:\n",
    "    ui.WebDriverWait(driver, 10).until(EC.visibility_of_element_located((By.ID, \"tab-flight-tab-hp\")))\n",
    "finally:\n",
    "    driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An implicit wait makes Selenium WebDriver wait for a certain amount of time before finding any element. The following is an example of implicit waits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"cd1e7c721b428bedc350218fc38c459a\", element=\"0.2322158736774933-1\")>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver = webdriver.Chrome()\n",
    "driver.implicitly_wait(10) # wait for 10 seconds\n",
    "driver.get(\"https://www.expedia.com/\")\n",
    "driver.find_element_by_id(\"tab-flight-tab-hp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case: Scraping plane tickets information from Expedia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are here, then you are ready to collect data from a real website using Selenium by yourself! We have explained all basic concepts with examples in previous notes, now let's go further to take a look at a real case which applies Selenium to scrape data from websites. In this case, we want to gather plane tickets information of a round trip from Pittsburgh to Seattle, where the departure date is 4/10/2018 and the return date is 4/12/2018. \n",
    "\n",
    "Firstly, we need to initialize the web driver. We imported chrome options to ignore certificate errors and ssl errors during connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "import selenium.webdriver.support.ui as ui\n",
    "import selenium.webdriver.support.expected_conditions as EC\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--ignore-certificate-errors\")   \n",
    "chrome_options.add_argument(\"--ignore-ssl-errors\")\n",
    "driver = webdriver.Chrome(chrome_options=chrome_options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After initialization of the web driver, we can start simulating how a person navigates through the Expedia website. Selenium finds the boxes to input origin, destination, departure date, and arrival date. Then the search button is clicked automatically, and we can find the prices of all the available tickets, the airlines the tickets belong to, duration of the flights, number of stops, departure time, and arrival time. The implementations can be found in the expediaoperation() function. All the information scraped from the website is stored in a dataframe.\n",
    "\n",
    "The following is an integration of the implementation of this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class expediaTest():\n",
    "    \n",
    "    # initialize the web driver\n",
    "    def __init__(self):\n",
    "        chrome_options = Options()\n",
    "        chrome_options.add_argument(\"--ignore-certificate-errors\")   \n",
    "        chrome_options.add_argument(\"--ignore-ssl-errors\")\n",
    "        self.driver = webdriver.Chrome(chrome_options=chrome_options)\n",
    "        pass\n",
    "    \n",
    "    # sleep for 10 seconds\n",
    "    def timer(self):\n",
    "        time.sleep(10)\n",
    "        pass\n",
    "    \n",
    "    # collect plane tickets information from Expedia\n",
    "    def expediaoperation(self):\n",
    "        self.driver.get(\"https://www.expedia.com/\")\n",
    "        ui.WebDriverWait(self.driver, 10).until(EC.visibility_of_element_located((By.ID, \"tab-flight-tab-hp\")))\n",
    "        self.driver.find_element_by_id(\"tab-flight-tab-hp\").send_keys(Keys.RETURN)\n",
    "        ui.WebDriverWait(self.driver, 10).until(EC.visibility_of_element_located((By.ID, \"flight-origin-hp-flight\")))\n",
    "        self.driver.find_element_by_id(\"flight-origin-hp-flight\").clear()\n",
    "        self.driver.find_element_by_id(\"flight-origin-hp-flight\").send_keys(\"Pittsburgh\")\n",
    "        self.driver.find_element_by_id(\"flight-destination-hp-flight\").clear()\n",
    "        self.driver.find_element_by_id(\"flight-destination-hp-flight\").send_keys(\"Seattle\")\n",
    "        self.driver.find_element_by_id(\"flight-departing-hp-flight\").clear()\n",
    "        self.driver.find_element_by_id(\"flight-departing-hp-flight\").send_keys(\"4/10/2018\")\n",
    "        self.driver.find_element_by_id(\"flight-returning-hp-flight\").clear()\n",
    "        self.driver.find_element_by_id(\"flight-returning-hp-flight\").send_keys(\"4/12/2018\")\n",
    "        self.driver.find_element_by_id(\"gcw-flights-form-hp-flight\").submit()\n",
    "        time.sleep(10)\n",
    "        \n",
    "        alldata = self.driver.find_element_by_id(\"flightModuleList\")\n",
    "        \n",
    "        dataset_list = []\n",
    "        airline_list = []\n",
    "        from_list = []\n",
    "        to_list = []\n",
    "        departure_time = []\n",
    "        return_time = []\n",
    "        price_list = []\n",
    "        duration_list = []\n",
    "        num_stop_list = []\n",
    "        departure_time_list = []\n",
    "        arrival_time_list = []\n",
    "        \n",
    "        for i in alldata.find_elements_by_xpath(\"//*\"):\n",
    "            dataset_list.append(i)\n",
    "\n",
    "        for data in dataset_list:\n",
    "            attempts = 0;\n",
    "            while attempts < 2:\n",
    "                try:\n",
    "                    str_test_id = data.get_attribute(\"data-test-id\")\n",
    "                    str_duration_stop = data.get_attribute(\"class\")    \n",
    "                except StaleElementReferenceException:\n",
    "                    print(\"\")\n",
    "                attempts = attempts + 1\n",
    "                \n",
    "            if str_test_id == \"airline-name\":\n",
    "                airline_list.append(data.text)\n",
    "                \n",
    "            if str_test_id == \"listing-price-dollars\":\n",
    "                price_list.append(data.text)\n",
    "\n",
    "            if str_duration_stop == \"duration-emphasis\":\n",
    "                duration_list.append(data.text)\n",
    "\n",
    "            if str_duration_stop == \"number-stops\":\n",
    "                num_stop_list.append(data.text.strip()[1])\n",
    "                       \n",
    "            if str_test_id == \"departure-time\":\n",
    "                departure_time_list.append(data.text)\n",
    "           \n",
    "            if str_test_id == \"arrival-time\":\n",
    "                arrival_time_list.append(data.text)\n",
    "            \n",
    "            from_list.append(\"Pittsburgh\")\n",
    "            to_list.append(\"Seattle\")\n",
    "            departure_time.append(\"4/10/2018\")\n",
    "            return_time.append(\"4/12/2018\")\n",
    "        \n",
    "        print(pd.DataFrame(list(zip(from_list, to_list, departure_time, return_time, airline_list, price_list, duration_list, num_stop_list, departure_time_list, arrival_time_list)), columns=['from', 'to', 'departure_date', 'return_date', 'airline', 'price', 'duration', 'number_of_stops', 'departure_time', 'arrival_time']))\n",
    "            \n",
    "    def stop(self):\n",
    "        self.driver.close()\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "          from       to departure_date return_date            airline price  \\\n",
      "0   Pittsburgh  Seattle      4/10/2018   4/12/2018              Delta  $342   \n",
      "1   Pittsburgh  Seattle      4/10/2018   4/12/2018              Delta  $342   \n",
      "2   Pittsburgh  Seattle      4/10/2018   4/12/2018              Delta  $342   \n",
      "3   Pittsburgh  Seattle      4/10/2018   4/12/2018             United  $342   \n",
      "4   Pittsburgh  Seattle      4/10/2018   4/12/2018  American Airlines  $342   \n",
      "5   Pittsburgh  Seattle      4/10/2018   4/12/2018             United  $342   \n",
      "6   Pittsburgh  Seattle      4/10/2018   4/12/2018              Delta  $342   \n",
      "7   Pittsburgh  Seattle      4/10/2018   4/12/2018  American Airlines  $342   \n",
      "8   Pittsburgh  Seattle      4/10/2018   4/12/2018              Delta  $342   \n",
      "9   Pittsburgh  Seattle      4/10/2018   4/12/2018             United  $342   \n",
      "10  Pittsburgh  Seattle      4/10/2018   4/12/2018             United  $386   \n",
      "11  Pittsburgh  Seattle      4/10/2018   4/12/2018    Spirit Airlines  $398   \n",
      "12  Pittsburgh  Seattle      4/10/2018   4/12/2018    JetBlue Airways  $398   \n",
      "13  Pittsburgh  Seattle      4/10/2018   4/12/2018    JetBlue Airways  $420   \n",
      "14  Pittsburgh  Seattle      4/10/2018   4/12/2018              Delta  $420   \n",
      "15  Pittsburgh  Seattle      4/10/2018   4/12/2018             United  $420   \n",
      "16  Pittsburgh  Seattle      4/10/2018   4/12/2018              Delta  $420   \n",
      "17  Pittsburgh  Seattle      4/10/2018   4/12/2018             United  $420   \n",
      "18  Pittsburgh  Seattle      4/10/2018   4/12/2018  American Airlines  $420   \n",
      "19  Pittsburgh  Seattle      4/10/2018   4/12/2018             United  $420   \n",
      "20  Pittsburgh  Seattle      4/10/2018   4/12/2018             United  $420   \n",
      "21  Pittsburgh  Seattle      4/10/2018   4/12/2018              Delta  $420   \n",
      "22  Pittsburgh  Seattle      4/10/2018   4/12/2018             United  $420   \n",
      "23  Pittsburgh  Seattle      4/10/2018   4/12/2018  American Airlines  $420   \n",
      "24  Pittsburgh  Seattle      4/10/2018   4/12/2018  American Airlines  $424   \n",
      "25  Pittsburgh  Seattle      4/10/2018   4/12/2018             United  $447   \n",
      "26  Pittsburgh  Seattle      4/10/2018   4/12/2018  Multiple Airlines  $447   \n",
      "27  Pittsburgh  Seattle      4/10/2018   4/12/2018  Multiple Airlines  $451   \n",
      "28  Pittsburgh  Seattle      4/10/2018   4/12/2018    Alaska Airlines  $507   \n",
      "29  Pittsburgh  Seattle      4/10/2018   4/12/2018  Multiple Airlines  $510   \n",
      "30  Pittsburgh  Seattle      4/10/2018   4/12/2018  Multiple Airlines  $510   \n",
      "31  Pittsburgh  Seattle      4/10/2018   4/12/2018  Multiple Airlines  $518   \n",
      "32  Pittsburgh  Seattle      4/10/2018   4/12/2018  American Airlines  $518   \n",
      "33  Pittsburgh  Seattle      4/10/2018   4/12/2018  American Airlines  $518   \n",
      "34  Pittsburgh  Seattle      4/10/2018   4/12/2018  American Airlines  $531   \n",
      "35  Pittsburgh  Seattle      4/10/2018   4/12/2018  Multiple Airlines  $536   \n",
      "36  Pittsburgh  Seattle      4/10/2018   4/12/2018  Multiple Airlines  $555   \n",
      "37  Pittsburgh  Seattle      4/10/2018   4/12/2018    Alaska Airlines  $599   \n",
      "38  Pittsburgh  Seattle      4/10/2018   4/12/2018  Multiple Airlines  $661   \n",
      "\n",
      "   duration number_of_stops departure_time arrival_time  \n",
      "0    6h 25m               1         9:27am      12:52pm  \n",
      "1    6h 47m               1         9:27am      12:52pm  \n",
      "2    6h 57m               1         5:53pm       9:40pm  \n",
      "3    7h 15m               1         6:15am      10:12am  \n",
      "4    7h 45m               1         5:45am      10:00am  \n",
      "5    7h 57m               1         5:30pm      10:15pm  \n",
      "6    8h 27m               1         5:13pm      10:10pm  \n",
      "7    9h 27m               1         7:20pm      12:47am  \n",
      "8    10h 0m               1         6:25am      12:52pm  \n",
      "9   10h 31m               1         2:35pm       9:35pm  \n",
      "10   8h 49m               1         5:25pm      12:56am  \n",
      "11   9h 11m               1         7:10pm      12:59am  \n",
      "12  11h 13m               1         4:38pm      10:49pm  \n",
      "13   6h 43m               1         2:36pm      10:49pm  \n",
      "14   6h 58m               1        10:18am       2:01pm  \n",
      "15   7h 16m               1         4:50pm       8:48pm  \n",
      "16   7h 31m               1         6:25am      10:41am  \n",
      "17   7h 34m               1         2:10pm       6:41pm  \n",
      "18   7h 38m               1         8:26am       1:00pm  \n",
      "19   8h 31m               1        11:05am       3:43pm  \n",
      "20   9h 18m               1        12:35pm       6:06pm  \n",
      "21   9h 32m               1         1:15pm       7:33pm  \n",
      "22  10h 12m               1         6:15am      12:47pm  \n",
      "23   11h 9m               1         1:43pm       8:55pm  \n",
      "24   9h 38m               2        10:55am       7:04pm  \n",
      "25  15h 37m               2         2:10pm       8:48pm  \n",
      "26  15h 37m               2         9:27am      10:04pm  \n",
      "27   7h 43m               1         9:27am      10:04pm  \n",
      "28   7h 13m               1         5:45am      10:28am  \n",
      "29  13h 51m               2         6:15am      10:28am  \n",
      "30  16h 53m               2         9:27am       8:18pm  \n",
      "31   7h 22m               1         6:25am       8:18pm  \n",
      "32   8h 41m               1        12:00pm       4:22pm  \n",
      "33   8h 54m               1         3:48pm       9:29pm  \n",
      "34   10h 3m               2         1:10pm       7:04pm  \n",
      "35   13h 5m               2         9:27am       4:30pm  \n",
      "36   9h 43m               1         6:25am       4:30pm  \n",
      "37   7h 33m               1         3:20pm      10:03pm  \n",
      "38   7h 32m               1         5:30pm      10:03pm  \n"
     ]
    }
   ],
   "source": [
    "expediatest = expediaTest()\n",
    "#expediatest.timer()\n",
    "expediatest.expediaoperation()\n",
    "expediatest.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial explained basic concepts of Selenium for novices to gain an overview of how to use Selenium to collect data from websites. And a real case example is explained step by step to help novices get a deeper understanding of Selenium. However, this tutorial only explained how to use Selenium to obtain data from websites in a Chrome browser, scraping data from websites opened in other browsers are similar to the Chrome one though. More details and references can be found in the following links:\n",
    "    \n",
    "- [Selenium Documentation](http://selenium-python.readthedocs.io/index.html)\n",
    "- [Extract information from website using Selenium](https://www.youtube.com/watch?v=zZjucAn_JYk)\n",
    "\n",
    "Hope this Selenium tutorial helps!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
