{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: Performing Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References:\n",
    "- https://en.wikipedia.org/wiki/Sentiment_analysis\n",
    "- https://towardsdatascience.com/sentiment-analysis-concept-analysis-and-applications-6c94d6f58c17\n",
    "- https://www.kaggle.com/rahulin05/sentiment-labelled-sentences-data-set\n",
    "- http://textblob.readthedocs.io/en/dev/\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentiment Analysis, sometimes also reffered as Opinion Mining, is the process of analyzing textual data computationally as a means to identify and classify the opinions (emotions) depicted in the text. After performing this process of sentiment analysis the opinion expressed by the author of the text can be categorized in different classes.\n",
    "\n",
    "Sentiment Analysis can be categorized into different classes such as:\n",
    "- like, love, dislike, hate, desire, etc.\n",
    "- positive, negative or neutral.\n",
    "\n",
    "NOTE: In this tutorial we will be categorizing sentiments in positive and negative\n",
    "\n",
    "Examples:\n",
    "- Text: \"I like sushi.\" =>  Sentiment: Positive;\n",
    "- Text: \"Very bad service.\" => Sentiment: Negative\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applications of Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Movie Reviews: Analyzing if a review is positive or negative\n",
    "- Audience Analysis: Predicting voter sentiment during elections, twitter sentiments of users to determine stock prices of Fortune 500 companies\n",
    "- Products: product positioning in markets by analysis on product reviews on amazon etc.\n",
    "- Yelp (Restaurant reviews): reading restaurant reviews to gauge people sentiments for a restaurant and services"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial we wil learn how to perform sentiment analysis. We will cover two techniques on how to perform sentiment analysis. We will start off with loading a labelled Yelp dataset (with sentiments given for each text) from the URL (*mentioned in Section 2*). \n",
    "\n",
    "- Firstly, we will use the TextBlob library (*explained below in Section 5.1*), calculate the accuracy achieved and other performance metrics. \n",
    "- After this we will split the given dataset in training and testing and then use machine learning algorithm (Random Forest - *Explained below in Section 5.2*) to learn on the training set and then predict the sentiment class for the test dataset, we will calulate the performance metrics for this step as well.\n",
    "\n",
    "At the end we will conclude by comparing the results and discussing how we can improve our analysis for further learnings.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for regular expressions\n",
    "import re\n",
    "import nltk\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "%matplotlib inline\n",
    "import string\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "# Load scikit's random forest classifier library\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data can be extracted from this url: https://archive.ics.uci.edu/ml/datasets/Sentiment+Labelled+Sentences#\n",
    "The zip file contains three text files for Amazon product reviews, imdb movie reviews and yelp reviews. This data set contains 1000 rows in each of the three files with 500 for positive and 500 for negative sentiments. For this tutorial we will focus only on the yelp dataset.\n",
    "\n",
    "I used MS Excel to clean the data and save it into a csv file which can be downloaded from this url: https://drive.google.com/open?id=1fsmORnvsHB9ydfVCed_bm75-9EZGJR7m\n",
    "\n",
    "After dowloading this yelp.csv file please save it in the same directory as this jupyter notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Sentiment\n",
       "0                           Wow... Loved this place.          1\n",
       "1                                 Crust is not good.          0\n",
       "2          Not tasty and the texture was just nasty.          0\n",
       "3  Stopped by during the late May bank holiday of...          1\n",
       "4  The selection on the menu was great and so wer...          1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reading the yelp.csv adding headers 'Review' and 'Sentiment'\n",
    "yelpdf =  pd.read_csv(\"yelp.csv\",names = [\"Review\", \"Sentiment\"])\n",
    "yelpdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total size of the test dataset: 1000\n",
      "Total positive reviews in the test dataset: 500\n",
      "Total negative reviews in the test dataset: 500\n"
     ]
    }
   ],
   "source": [
    "print('Total size of the test dataset:',len(yelpdf))\n",
    "print('Total positive reviews in the test dataset:',yelpdf['Sentiment'].sum())\n",
    "print('Total negative reviews in the test dataset:',len(yelpdf)-yelpdf['Sentiment'].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that out of 1000 records 500 are positive and 500 are negative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Performing Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Using TextBlob library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TextBlob is a Python library which can be utilized for processing textual data. This library provides user friendly API's which can be used to perform several NLP (natural language processing) tasks such as part-of-speech tagging, noun phrase extraction, sentiment analysis, classification, translation, and many more. In our tutorial we will use this library to perform sentiment analysis of textual data.\n",
    "\n",
    "Please install this library if you don't have using the command: pip install TextBlob\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.1 Data Cleaning & Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As text input might contains all kind of data (numbers, weblinks, special characters), these characters affect the performance of sentiment analysis so we must clean the text before it can be analyzed.\n",
    "\n",
    "The method ('clean_text') below is used to clean the text input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"  Utility function to clean the text in a text by removing links and special characters using regex. \n",
    "    Normalizes case and handles punctuation\n",
    "    Inputs:\n",
    "        text: str: raw text\n",
    "    Outputs:\n",
    "        (str): cleaned text\n",
    "    \"\"\"\n",
    "    lowerText = text.lower()\n",
    "    newText = lowerText.replace(\"'s\", ' ')\n",
    "    newText = newText.replace(\"'\", '')\n",
    "    newText = newText.replace(\"-\", ' ')\n",
    "    newText = re.sub('\\d', '', newText)\n",
    "    transtable = str.maketrans(string.punctuation.replace(\"\",\" \"), ' '*len(string.punctuation.replace(\"\",\" \"))) #map punctuation to space\n",
    "    clean_words = newText.translate(transtable)\n",
    "    return clean_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method ('analyze_sentiment') below calls the method ('clean_text') defined above to clean the text and using textblob library calcualted the polarity of the input text and returns 1 (for positive sentiments) or 0 (for negative sentiments).\n",
    "\n",
    "[As our dataset only has positive and negative sentiments we are not categorizing into neutral, else with textblob we can get positive, neutral as well as negative polarity]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def analyze_sentiment(text):\n",
    "    \"\"\" Function to classify the polarity of a text using textblob.\n",
    "    Inputs:\n",
    "        text: str: raw text\n",
    "    Outputs:\n",
    "        (int): predicted sentiment 1 for positive and 0 for negative\n",
    "    \"\"\"\n",
    "    analysis = TextBlob(clean_text(text))\n",
    "    if analysis.sentiment.polarity > 0:\n",
    "    #for positive sentiments return 1\n",
    "        return 1\n",
    "    else:\n",
    "    #for negative sentiments, we are not handling for neutral sentiments else even that is possible        \n",
    "        return 0   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Sentiment  pred\n",
       "0                           Wow... Loved this place.          1     1\n",
       "1                                 Crust is not good.          0     0\n",
       "2          Not tasty and the texture was just nasty.          0     0\n",
       "3  Stopped by during the late May bank holiday of...          1     1\n",
       "4  The selection on the menu was great and so wer...          1     1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#adding a column 'pred' to the dataframe which contains the predicted sentiment as analyzed with the help of textblob library \n",
    "yelpdf['pred']=yelpdf['Review'].apply(analyze_sentiment)\n",
    "yelpdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see above that a new column 'pred' has been added with the predicted sentiments for the input text ('Review')."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.2 Analyzing performance of this analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we already have the labeled sentiments in the dataset we can calculate the performance of our analysis by comparing the predicted sentiments with the sentiment labels provided in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of predicting sentiments of the dataset is: 77.2 %\n"
     ]
    }
   ],
   "source": [
    "#calculating accuracy of our predicted sentiments\n",
    "x= (yelpdf['pred']==yelpdf['Sentiment'])\n",
    "accuracy = sum(x)/len(yelpdf['pred'])\n",
    "print('Accuracy of predicting sentiments of the dataset is:',accuracy*100,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Along with Accuracy, we can measure other performance metrics of our predictions based on the context of our analysis:\n",
    "\n",
    "- Confusion matrix: its a tabular layout which describes the performance of any algorithm prediction, with both expected and predicted instances. Each row of this matrix denotes the instances in a predicted class while column in this matrix represents the instances in an actual class (or vice versa).\n",
    "\n",
    "In terms of our tutorial, the Confusion matrix is like this,\n",
    "\n",
    "\n",
    "                            |Actual Class     |\n",
    "                            |Positive|Negative|\n",
    "    Predicted Class|Positive|TP      |FP      |\n",
    "    Predicted Class|Negative|FN      |TN      |\n",
    "               \n",
    "               TP: True Positive- Both actual and predicted sentiment is positive\n",
    "               FP: False Positive- Actually negative sentiment but predicted as positive\n",
    "               FN: False Negative- Actually positive sentiment but predicted as negative \n",
    "               TN: True Negative- Both actual and predicted sentiment is negative\n",
    "               \n",
    "               \n",
    "               \n",
    "- Precision: Precision sometimes also called as positive predicted value (PPV) is the proportion of predicted positive cases which were actually positive, i.e. TP/TP+FP\n",
    "\n",
    "\n",
    "- Recall: Also known as sensitivity, it is the fraction of actual positive cases which were correctly predicted as positive, i.e. TP/TP+FN\n",
    "\n",
    "\n",
    "- F1 score: this is a F measure which is calcualted using both Precision as well as Recall. It is basically the harmonic mean of Precision and recall,\n",
    "F1 score = 2x(Precision)x(Recall)/(Precision+Recall)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[379 121]\n",
      " [107 393]]\n",
      "Precision: 0.764591439689\n",
      "Recall: 0.786\n",
      "F1 score: 0.775147928994\n"
     ]
    }
   ],
   "source": [
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(yelpdf['Sentiment'], yelpdf['pred']))\n",
    "print('Precision:',precision_score(yelpdf['Sentiment'], yelpdf['pred']))\n",
    "print('Recall:',recall_score(yelpdf['Sentiment'], yelpdf['pred']))\n",
    "print('F1 score:',f1_score(yelpdf['Sentiment'], yelpdf['pred']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix can be seen above. Precision of prediction was 0.764, Recal is 0.786 and F1 score is 0.775;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Using Random forest for sentiment analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As our dataset already contain sentiment labels, our hypothesis is to use this textual reviews to train a random forest classifier and then to test this model on unseen data to predict a sentiment class for any given text.\n",
    "\n",
    "- Random Forest: It is a widely used machine learning algorithm which find applications in numerous fields. It's an Ensemble method (Ensembling is a divide-and-conquer approach, basically we used several group of \"weak-learners\" combine their knowledge and make a \"strong-learner\") and can be used for both prediction as well as classification purpose. This algorithm is capable of handlings very large number of features, and it's helpful for estimating which of your variables are important in the underlying data being modeled.\n",
    "\n",
    "A random forest fits a number of classifying decision trees on various sub-samples of the dataset and uses ensembling (averaging) to improve the predictive accuracy of the model while controling the over-fitting. The sub-sample size is always the same as the original input sample size but the samples are drawn with replacement.\n",
    "\n",
    "\n",
    "References:\n",
    "- http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "- http://blog.citizennet.com/blog/2012/11/10/random-forests-ensembles-and-performance-metrics\n",
    "- https://towardsdatascience.com/the-random-forest-algorithm-d457d499ffcd\n",
    "- https://en.wikipedia.org/wiki/Random_forest\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2.1 Install necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#I've commented the code for installing if you don't have them already please uncomment the code \n",
    "#and execute all the lines in this code chunk \n",
    "\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('wordnet')\n",
    "#nltk.download('punkt')\n",
    "#nltk.download()\n",
    "\n",
    "#these would be used in data cleaning steps\n",
    "lemmatizer=nltk.stem.wordnet.WordNetLemmatizer()\n",
    "stopwords=nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.2 Splitting the dataset in train and test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the yelp.csv dataset into training and test set, i'm splitting it into 80% training and 20% test set. I'm reloading the dataset again as earlier i had updated it in the previous section while predicting sentiments using the TextBlob library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A fantastic neighborhood gem !!!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Best fish I've ever had in my life!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Unfortunately, we must have hit the bakery on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If you love authentic Mexican food and want a ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It's a great place and I highly recommend it.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Sentiment\n",
       "0                   A fantastic neighborhood gem !!!          1\n",
       "1                Best fish I've ever had in my life!          1\n",
       "2  Unfortunately, we must have hit the bakery on ...          0\n",
       "3  If you love authentic Mexican food and want a ...          1\n",
       "4      It's a great place and I highly recommend it.          1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reading the yelp.csv adding headers 'Review' and 'Sentiment'\n",
    "newdf= pd.read_csv(\"yelp.csv\",names = [\"Review\", \"Sentiment\"])\n",
    "\n",
    "#Splitting the dataset in train and testing set 20% test and rest training\n",
    "train, test = train_test_split(newdf, test_size=0.2,random_state=100)\n",
    "\n",
    "#dropping index in train set to handle randomness (because of splitting of dataset) in previous indexing\n",
    "train = train.reset_index(drop=True)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.3 Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total size of the training dataset: 800\n",
      "Total positive reviews in the training dataset: 394\n",
      "Total negative reviews in the training dataset: 406\n"
     ]
    }
   ],
   "source": [
    "#dropping index in train set to handle randomness (because of splitting of dataset) in previous indexing\n",
    "train = train.reset_index(drop=True)\n",
    "print('Total size of the training dataset:',len(train))\n",
    "print('Total positive reviews in the training dataset:',train['Sentiment'].sum())\n",
    "print('Total negative reviews in the training dataset:',len(train)-train['Sentiment'].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that out of 800 records in the training dataset 394 are positive and 406 are negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total size of the test dataset: 200\n",
      "Total positive reviews in the test dataset: 106\n",
      "Total negative reviews in the test dataset: 94\n"
     ]
    }
   ],
   "source": [
    "#dropping index in test set to handle randomness (because of splitting of dataset) in previous indexing\n",
    "test = test.reset_index(drop=True)\n",
    "print('Total size of the test dataset:',len(test))\n",
    "print('Total positive reviews in the test dataset:',test['Sentiment'].sum())\n",
    "print('Total negative reviews in the test dataset:',len(test)-test['Sentiment'].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that out of 200 records in the test dataset 106 are positive and 94 are negative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.4 Data Cleaning & Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As text input might contains all kind of data (numbers, weblinks, special characters), these characters affect the performance of sentiment analysis so we must clean the text before it can be analyzed.\n",
    "\n",
    "\n",
    "Here we are going to perform tokenization, stop word removals, stemming/lemmatizing etc. which we help us to identify accurate patterns with out considering redundant patterns or missing original patterns. \n",
    "\n",
    "Generally there are many words in our text which our rarely used. We might want to remove them and other stop words from our text dataset. Removing stop words is important as multiple instances of words like 'a', 'an', 'the' etc. does not help in our purpose of sentiment analysis.\n",
    "\n",
    "Tokenization is the process of splitting a sequence of text into individual constituent pieces. For example 'James,' should be split as 'James' and ','. Lemmatizing involves combining words that carry same meaning as per the dictionary meaning.\n",
    "\n",
    "\n",
    "\n",
    "The method ('text_tokenizer') below is used to clean the text input, lematize the text and returns the text in form of tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def text_tokenizer(text):\n",
    "    \"\"\" Normalizes case and handles punctuation\n",
    "    Inputs:\n",
    "        text: str: raw text\n",
    "    Outputs:\n",
    "        list(str): tokenized text\n",
    "    \"\"\"       \n",
    "    listFinal=[]\n",
    "    lemmatizer=nltk.stem.wordnet.WordNetLemmatizer()\n",
    "    clean_words = clean_text(text)\n",
    "    tokens = nltk.word_tokenize(clean_words)\n",
    "    for x in tokens:\n",
    "        listFinal.append(lemmatizer.lemmatize(x))\n",
    "    return listFinal\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[a, fantastic, neighborhood, gem]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[best, fish, ive, ever, had, in, my, life]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[unfortunately, we, must, have, hit, the, bake...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[if, you, love, authentic, mexican, food, and,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[it, a, great, place, and, i, highly, recommen...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Sentiment\n",
       "0                  [a, fantastic, neighborhood, gem]          1\n",
       "1         [best, fish, ive, ever, had, in, my, life]          1\n",
       "2  [unfortunately, we, must, have, hit, the, bake...          0\n",
       "3  [if, you, love, authentic, mexican, food, and,...          1\n",
       "4  [it, a, great, place, and, i, highly, recommen...          1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tokenize the train set lemmatize as well\n",
    "train['Review'] = train['Review'].apply(text_tokenizer)\n",
    "processed_reviews=train\n",
    "#dispaly head after processing the reviews\n",
    "processed_reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method 'get_rare_words' helps us in finding rare words in our text data ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_rare_words(processed_reviews):\n",
    "    \"\"\" use the word count information across all texts in training data to come up with a feature list\n",
    "    Inputs:\n",
    "        processed_reviews: pd.DataFrame: lematized list of words from the input text\n",
    "    Outputs:\n",
    "        list(str): list of rare words, sorted alphabetically.\n",
    "    \"\"\"    \n",
    "    resultList=[]\n",
    "    for index, row in processed_reviews.iterrows():\n",
    "        resultList.extend((row['Review']))        \n",
    "    cnt=dict(Counter(resultList))    \n",
    "    resultList=[]\n",
    "    for k,v in cnt.items():\n",
    "        if v==1:\n",
    "            resultList.append(k)\n",
    "            \n",
    "    a=sorted(resultList)\n",
    "    return a    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine learning algorithms can't understand text data (unstructured data), so we need to convert our text data into a form suitable to be fed into our classifier (Random forest). We use the method 'create_features' to transform text data into a sparse matrix (bag-of-words feature matrix)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_features(processed_reviews):\n",
    "    \"\"\" creates the feature matrix using the processed reviews text\n",
    "    Inputs:\n",
    "        processed_reviews: pd.DataFrame: text read from yelp.csv file, containing the column 'Review'\n",
    "    Outputs:\n",
    "        sklearn.feature_extraction.text.TfidfVectorizer: the TfidfVectorizer object used\n",
    "                                                we need this to tranform test reviews in the same way as train reviews\n",
    "        scipy.sparse.csr.csr_matrix: sparse bag-of-words TF-IDF feature matrix\n",
    "    \"\"\"\n",
    "    rare_words = get_rare_words(processed_reviews)\n",
    "    temp=processed_reviews['Review'].apply(lambda x: ' '.join(x))\n",
    "    #transform the text data using TfidfVectorizer, in stop words we have added the rare words from our dataset as well \n",
    "    sklearn_tfidf  = sklearn.feature_extraction.text.TfidfVectorizer(stop_words=rare_words+stopwords)\n",
    "    features=sklearn_tfidf.fit_transform(temp)\n",
    "    return sklearn_tfidf,features\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#to generate features in a form suitable for our classification model\n",
    "(tfidf, X) = create_features(processed_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sentiment labels for training set\n",
    "y_validation=train['Sentiment']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After transforming out Yelp reviews into a suitable format, now we will model a Random Forest classifier. We would use our training data set to train our classifier. \n",
    "\n",
    "But before that, we want to chose the best possible configuration for our model, we use GridSearchCV to compute the best possible configuration for which our training accuracy is best. This uses crossvalidation approach to find the best accuracy on the training set.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next chunk of code takes a long execution time, executing 10-fold cross validation with several configuration, execute only when you have time (execution time approx: 15-20mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 30, 'min_samples_leaf': 1, 'n_estimators': 36}\n"
     ]
    }
   ],
   "source": [
    "#takes a long execution time, crossvalidation\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "rfc = RandomForestClassifier(n_jobs=4, max_features='sqrt', oob_score = True) \n",
    " \n",
    "# Use a grid over parameters of interest\n",
    "param_grid = { \n",
    "           \"n_estimators\" : [9, 18, 27, 36, 45, 54, 63],\n",
    "           \"max_depth\" : [1, 5, 10, 15, 20, 25, 30],\n",
    "           \"min_samples_leaf\" : [1, 2, 4, 6, 8, 10]}\n",
    " \n",
    "CV_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, cv= 10)\n",
    "CV_rfc.fit(X, y_validation)\n",
    "print (CV_rfc.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now using the best configuration as given by the GridSearchCV above we will train our RandomForest classifer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#training a optimized random forrest classification model\n",
    "clf = RandomForestClassifier(n_estimators=36, max_depth=30, max_features='sqrt', min_samples_leaf = 1)\n",
    "\n",
    "#X is the transformed text input as calculated above\n",
    "classifier= clf.fit(X, y_validation) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate our classifier we first test it by calculating training accuracy, validating on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy of the model is: 98.0 %\n"
     ]
    }
   ],
   "source": [
    "#using the classifier modeled in the code chunk above we predict outcome (sentiments) of the input transformed text (X)\n",
    "predictList=classifier.predict(X)\n",
    "result = predictList.tolist()\n",
    "\n",
    "#to calculate accuracy\n",
    "x= (y_validation==result)\n",
    "accuracy = sum(x)/len(y_validation)\n",
    "print('Training accuracy of the model is:',accuracy*100,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of the model when the training set was provided again to predict the sentiment class has been calulated above and it can be seen that on training set accuracy is 98%. Which is obvious As the model was trainined on the same dataset it would perform better on it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to see how our model performs on new unseen data, test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Based on the sub-par service I received and no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It shouldn't take 30 min for pancakes and eggs.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Great steak, great sides, great wine, amazing ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What a mistake that was!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Generous portions and great taste.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review\n",
       "0  Based on the sub-par service I received and no...\n",
       "1    It shouldn't take 30 min for pancakes and eggs.\n",
       "2  Great steak, great sides, great wine, amazing ...\n",
       "3                           What a mistake that was!\n",
       "4                 Generous portions and great taste."
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this is the test set, without the sentiment labels\n",
    "unlabeled_reviews = test[['Review']]\n",
    "unlabeled_reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method 'classify_sentiments' can be used to classify unlabeled text into positive or negative sentiments using the classification model we developed above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classify_sentiments(tfidf, classifier, unlabeled_reviews):\n",
    "    \"\"\" predicts class labels for raw review text\n",
    "    Inputs:\n",
    "        tfidf: sklearn.feature_extraction.text.TfidfVectorizer: the TfidfVectorizer object used on training data\n",
    "        classifier: sklearn.ensemble.forest.RandomForestClassifier: classifier learnt\n",
    "        unlabeled_reviews: pd.DataFrame: unlabeled text for sentiment analysis\n",
    "    Outputs:\n",
    "        numpy.ndarray(int): dense binary vector of class labels for unlabeled reviews\n",
    "    \"\"\"\n",
    "    #tokenize and clean the unlabeled text\n",
    "    unlabeled_reviews['Review'] = unlabeled_reviews['Review'].apply(text_tokenizer)\n",
    "    \n",
    "    #find the rare words in the test set\n",
    "    rare_words = get_rare_words(unlabeled_reviews)\n",
    "    \n",
    "    temp=unlabeled_reviews['Review'].apply(lambda x: ' '.join(x))\n",
    "    \n",
    "    #TfidfVectorizer object used on training data, used to transform our text input to features \n",
    "    #to be fed into the classifier for predicting the sentiments of these text inputs\n",
    "    features=tfidf.transform(temp)\n",
    "    predictList=classifier.predict(features)\n",
    "    \n",
    "    return predictList\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "unlabeled_reviews = test[['Review']]\n",
    "y_pred = classify_sentiments(tfidf, classifier, unlabeled_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.5 Analyzing performance of this analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of predicting sentiments of test dataset is: 71.0 %\n"
     ]
    }
   ],
   "source": [
    "#calculate the testing accuracy\n",
    "x= (y_pred==test['Sentiment'])\n",
    "accuracy = sum(x)/len(y_pred)\n",
    "print('Accuracy of predicting sentiments of test dataset is:',accuracy*100,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[78 16]\n",
      " [42 64]]\n",
      "Precision: 0.8\n",
      "Recall: 0.603773584906\n",
      "F1 score: 0.688172043011\n"
     ]
    }
   ],
   "source": [
    "#calcualting other performance metrics as computed in the earlier steps (with TextBlob library analysis)\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(test['Sentiment'], y_pred))\n",
    "print('Precision:',precision_score(test['Sentiment'], y_pred))\n",
    "print('Recall:',recall_score(test['Sentiment'], y_pred))\n",
    "print('F1 score:',f1_score(test['Sentiment'], y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix for the sentiment predicted by our model can be seen above. Precision of prediction was 0.8, Recal is 0.604 and F1 score is 0.688;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In section 5. we observed how we can perform sentiment analysis on text data. We used two techniques for this, \n",
    "- in first we were able to analyze sentiments using TextBlob library. We can use this approach for any text and we don't need any sentiment labels to predict sentiments (but if we have sentiment labels we can compare our predictions to pre-labelled sentiments for accuracy and performance purpose).\n",
    "- in second approach we need sentiment labels, to perform our analysis, to train a random forest classification model (text data and corresponding sentiments to train the model). After this step we use this trained classifier and a test data set to predict the sentiments for the test set.\n",
    "\n",
    "After performing the sentiment analysis using both the techniques we also compared the performance metrics for both the steps we observed that the first method (TextBlob) was slightly better that the second (random forest) method.\n",
    "\n",
    "Additionally, we need sentiment labels in the second case (for Random Forest), so if we don't have a pre-labeled data set (which is most genrally the case) we can use the TextBlob method to perform sentiment analysis and obtain a pretty good accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Further Motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a next step we can take this tutorial and our analysis further by using word embeddings and neural networks approach for even better results for our analysis.\n",
    "\n",
    "Also we can segregate our analysis of reviews for a restaurant further by categorize it by different aspects. Like quality of food, ambience, services, tangibles etc. for a holistic analysis of a restaurant by analyzing its reviews.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
