{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial- Movie Recommender System using Text Mining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this modern era, all the companies have started using recommender systems more and more to enhance their customer experience. \n",
    "There are two basic types of recommender systems algorithm namely Collabrative filtering based and content-based filtering (also known as pensonality-based approach). Both these approaches are used heavily. \n",
    "I will be discussing the former approach that is the content-based approach. Let me discuss few examples of this approach first-\n",
    "\n",
    "\n",
    "• Pandora uses the properties of songs and artist (around 400 and so variables) to create different types of stations for users like pop artist and pop songs are listed under the same station.\n",
    "\n",
    "\n",
    "• Content based systems are also used by e-commerce companies to suggest items to the user based on filters set by the user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, that we have some rough sketch on what a *content based system* does. Lets talk about the algorithm on a high level and understand how does this work. So basically, we have to create different profiles for the pool of items among which we need to make the recommendations and we create a profile based on user's choice or previous items they have rated highly. Once this is done, we compare these in n-dimensional space and compute the similarity between them and recommend those items to the user which are the most similar to the user's profile."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Motivation\n",
    "Motivation behind this movie recommender system is say a user searches for a movie that he likes then it is upto which movies should we recommend to him that he can look at after that movie. This is the similar approach that is used by big companies like Netflix, IMDB for recommending movies based on user choice. A similar approach is used by amazon to show suggested items in their catalog once a user clicks and opens a particular item. This helps companies to show users only those items that are relevant to them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='http://blog.allmyfaves.com/wp-content/uploads/2012/07/foundd-what-movie-should-I-watch-tonight.jpg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Datasets\n",
    "\n",
    "The data used for this tutorial has been consumed from Kaggle\n",
    "Dataset Source :-  https://www.kaggle.com/tmdb/tmdb-movie-metadata/data\n",
    "\n",
    "I have uploaded the datasets at the following google drive as well:-\n",
    "https://goo.gl/bms7ES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Methodology\n",
    "\n",
    "So my methodology for this tutorial is based on the same algorithm.\n",
    "1. I have used a movie dataset where user profile will be created by using user's selection.\n",
    "2. We compare these user's selection with all the movies in the dataset.\n",
    "3. We compare these profiles(vectors) using cosine similarities. (To make these profiles we will have to process our dataset into data that will be required for making vectors)\n",
    "\n",
    "To create the user profiles and the item profiles I will be using keywords from the movie's overview (which are calculated using Tf-Idf) and similarly, among the tags for each I have calculated the top tags that represent that movie. I will also be using features like movie ratings, actors, director etc to create profiles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Let's get started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First step is importing required libraries\n",
    "1. We have imported pandas for basic dataframe manipulations\n",
    "2. We have imported numpy for array manipulation\n",
    "3. We have imported matplotlib for initial visualization\n",
    "4. We have imported csv to import csv files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#Library used for initial visualization\n",
    "import matplotlib.pyplot as plt \n",
    "#Library used for initial visualization\n",
    "import csv \n",
    "import ast\n",
    "import re\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now load and merge the two datasets that we have one dataset is credits dataset that contains information like cast, crew information. Second dataset is movies dataset which contains information genres, language, overview, vote_average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>budget</th>\n",
       "      <th>popularity</th>\n",
       "      <th>revenue</th>\n",
       "      <th>runtime</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4803.000000</td>\n",
       "      <td>4.803000e+03</td>\n",
       "      <td>4803.000000</td>\n",
       "      <td>4.803000e+03</td>\n",
       "      <td>4801.000000</td>\n",
       "      <td>4803.000000</td>\n",
       "      <td>4803.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>57165.484281</td>\n",
       "      <td>2.904504e+07</td>\n",
       "      <td>21.492301</td>\n",
       "      <td>8.226064e+07</td>\n",
       "      <td>106.875859</td>\n",
       "      <td>6.092172</td>\n",
       "      <td>690.217989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>88694.614033</td>\n",
       "      <td>4.072239e+07</td>\n",
       "      <td>31.816650</td>\n",
       "      <td>1.628571e+08</td>\n",
       "      <td>22.611935</td>\n",
       "      <td>1.194612</td>\n",
       "      <td>1234.585891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>9014.500000</td>\n",
       "      <td>7.900000e+05</td>\n",
       "      <td>4.668070</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>54.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>14629.000000</td>\n",
       "      <td>1.500000e+07</td>\n",
       "      <td>12.921594</td>\n",
       "      <td>1.917000e+07</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>235.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>58610.500000</td>\n",
       "      <td>4.000000e+07</td>\n",
       "      <td>28.313505</td>\n",
       "      <td>9.291719e+07</td>\n",
       "      <td>118.000000</td>\n",
       "      <td>6.800000</td>\n",
       "      <td>737.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>459488.000000</td>\n",
       "      <td>3.800000e+08</td>\n",
       "      <td>875.581305</td>\n",
       "      <td>2.787965e+09</td>\n",
       "      <td>338.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>13752.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            movie_id        budget   popularity       revenue      runtime  \\\n",
       "count    4803.000000  4.803000e+03  4803.000000  4.803000e+03  4801.000000   \n",
       "mean    57165.484281  2.904504e+07    21.492301  8.226064e+07   106.875859   \n",
       "std     88694.614033  4.072239e+07    31.816650  1.628571e+08    22.611935   \n",
       "min         5.000000  0.000000e+00     0.000000  0.000000e+00     0.000000   \n",
       "25%      9014.500000  7.900000e+05     4.668070  0.000000e+00    94.000000   \n",
       "50%     14629.000000  1.500000e+07    12.921594  1.917000e+07   103.000000   \n",
       "75%     58610.500000  4.000000e+07    28.313505  9.291719e+07   118.000000   \n",
       "max    459488.000000  3.800000e+08   875.581305  2.787965e+09   338.000000   \n",
       "\n",
       "       vote_average    vote_count  \n",
       "count   4803.000000   4803.000000  \n",
       "mean       6.092172    690.217989  \n",
       "std        1.194612   1234.585891  \n",
       "min        0.000000      0.000000  \n",
       "25%        5.600000     54.000000  \n",
       "50%        6.200000    235.000000  \n",
       "75%        6.800000    737.000000  \n",
       "max       10.000000  13752.000000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credits_csv=pd.read_csv('E:\\\\Film Recommendation Engine\\\\tmdb_5000_credits.csv')#change file path\n",
    "movies_csv=pd.read_csv('E:\\\\Film Recommendation Engine\\\\tmdb_5000_movies.csv')#change file path\n",
    "data=pd.merge(credits_csv, movies_csv, left_on='movie_id', right_on='id')\n",
    "#To drop columns that have been repeated\n",
    "data=data.drop(['id','title_x'],axis=1) \n",
    "#Renaming particular columns\n",
    "data.rename(columns={'title_y':'title'}, inplace=True) \n",
    "#Descriptive Statistics on the numberical data\n",
    "data.describe() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking outliers in numberical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x29eb99bfb70>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEECAYAAADTdnSRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRURS6P8D5HYY+LKZ3/kAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x29eb6c36240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.boxplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking for null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "movie_id                   0\n",
       "cast                       0\n",
       "crew                       0\n",
       "budget                     0\n",
       "genres                     0\n",
       "homepage                3091\n",
       "keywords                   0\n",
       "original_language          0\n",
       "original_title             0\n",
       "overview                   3\n",
       "popularity                 0\n",
       "production_companies       0\n",
       "production_countries       0\n",
       "release_date               1\n",
       "revenue                    0\n",
       "runtime                    2\n",
       "spoken_languages           0\n",
       "status                     0\n",
       "tagline                  844\n",
       "title                      0\n",
       "vote_average               0\n",
       "vote_count                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check the datatype for each of the column in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "movie_id                  int64\n",
       "cast                     object\n",
       "crew                     object\n",
       "budget                    int64\n",
       "genres                   object\n",
       "homepage                 object\n",
       "keywords                 object\n",
       "original_language        object\n",
       "original_title           object\n",
       "overview                 object\n",
       "popularity              float64\n",
       "production_companies     object\n",
       "production_countries     object\n",
       "release_date             object\n",
       "revenue                   int64\n",
       "runtime                 float64\n",
       "spoken_languages         object\n",
       "status                   object\n",
       "tagline                  object\n",
       "title                    object\n",
       "vote_average            float64\n",
       "vote_count                int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to process the types for columns that contain JSON type data(lists, dictionaries) because while reading the files they are just loaded as strings (represented as object types). We have to convert them to their appropriate types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#This cell should be run only once because the values once converted are no longer string type \n",
    "data[\"genres\"]=data[\"genres\"].apply(ast.literal_eval)\n",
    "data[\"spoken_languages\"]=data[\"spoken_languages\"].apply(ast.literal_eval)\n",
    "data[\"cast\"]=data[\"cast\"].apply(ast.literal_eval)\n",
    "data[\"crew\"]=data[\"crew\"].apply(ast.literal_eval)\n",
    "data[\"keywords\"]=data[\"keywords\"].apply(ast.literal_eval)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following libraries are required for text manipulation and text mining of the overview and keywords in the movie.\n",
    "Stemmer is used to extract only the stem of a word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After looking at the whole dataset I have decided to use only the following columns:-\n",
    "\n",
    "1. Overview (Description of the movie can suggest the type of movie and give us the keywords in a movie for example say we have Superman, the movie is based on a comic so most likely comic will be a keyword in the overview)\n",
    "\n",
    "2. Genres (Genre is very indicative of the taste of the user and thus must be used)\n",
    "\n",
    "3. Keywords (These are keywords pre existing in the data that can be said to be tags representing a movie)\n",
    "\n",
    "4. Actors (A person watches a movie if he likes a particular actor and that is why we need to include main actors but not all actors as supporing actors are not much of interest)\n",
    "\n",
    "5. Director (People often go for watching a movie based on the director as a director who has a good reputation in the industry is more sort after)\n",
    "\n",
    "6. Language (Language which the movie is indicate of a person's native language)\n",
    "\n",
    "7. voting_average (The score of the movie and how much it has been rated overall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This following functions takes in a document and calculates the term-frequencies and returns the dictionary with frequencies for each word in the document.\n",
    "\n",
    "Though the TF formula used here is different from what we studied in the class which was just calculating the total count of each word in each document.\n",
    "\n",
    "Here rather we have documents(overviews) which are very different in lengths so TF alone will not be indicative enough. Thus we normalize them by calculating (1+log(word_count)) and then normalizing these across all the documents by dividing this by vector length.\n",
    "\n",
    "Reference:- \n",
    "https://www.analyticsvidhya.com/blog/2015/08/beginners-guide-learn-content-based-recommender-systems/\n",
    "\n",
    "The formula used here is :- (1+np.log10(word_count))/vector_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "def tf(overview):\n",
    "    vector_length=0\n",
    "    overview_words=re.sub(\"[^\\w'-]\",\" \", str(overview).lower()).split()\n",
    "    stemmed_words=list()\n",
    "    for word in overview_words:\n",
    "        stemmed_words.append(ps.stem(word))\n",
    "    overview_words=Counter(stemmed_words) \n",
    "    \n",
    "    words_dicts=dict()\n",
    "    for word,count in overview_words.items():\n",
    "        vector_length+=((1+np.log10(count))**(2))\n",
    "    vector_length=vector_length**(0.5)\n",
    "    for word,count in overview_words.items():\n",
    "        words_dicts.update({ps.stem(word):((1+np.log10(count))/vector_length)})\n",
    "    return words_dicts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function is used to calculate idf from a set of documents that is passed using a list and we calculate idf for each term.\n",
    "\n",
    "The motivation behind idf(inverse document frequency) is that all the words in a document are not necessarily useful in modelling the topics for that document.\n",
    "\n",
    "In the function we use a loop to iteratre over each document and split it into words and stem the words that is extracting only the root of that word because words can be in different forms. Then we use idf formula to calculate idf for each unique word in the set of documents.\n",
    "\n",
    "Formula used for calculating the IDF is :- np.log10(number of documents/number of documents containg that word)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#pass a list of documents\n",
    "def idf(idf_data): \n",
    "    idf_dict=dict()\n",
    "    for docs in idf_data:\n",
    "        doc_words=re.sub(\"[^\\w'-]\",\" \", str(docs).lower()).split()\n",
    "        stemmed_words=list()\n",
    "        for word in doc_words:\n",
    "            stemmed_words.append(ps.stem(word))\n",
    "        \n",
    "        doc_words=list(set(stemmed_words))\n",
    "        for word in doc_words:\n",
    "            if ps.stem(word.lower()) not in idf_dict.keys():\n",
    "                idf_dict.setdefault(ps.stem(word.lower()), 1)\n",
    "            else:\n",
    "                idf_dict[ps.stem(word.lower())]+=1\n",
    "    for key,value in idf_dict.items():\n",
    "        idf_dict[key]=np.log10(len(idf_data)/value)\n",
    "    return idf_dict\n",
    "       \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we start processing our data based on our requirements\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are processing following columns that we discussed to be using initially."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have to process our data to extract actors from the dataset we will be using the main actors in a movie to do so we will only be using the main three actors of the movie which are represented in the cast of the movie as actor with order 0,1 and 2.\n",
    "We create a dataframe that has the top three actors in each movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "actors=list()\n",
    "\n",
    "for i in range(0,len(data.index)):\n",
    "    actors.append([d['name'].strip() for d in data['cast'][i] if d['order'] == 0 or d['order'] == 1 or d['order'] == 2])\n",
    "    \n",
    "labels=['actor1','actor2','actor3','actor4','actor5']\n",
    "actors_df=pd.DataFrame.from_records(actors,columns=labels,exclude=['actor4','actor5'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We apply TF-IDF on overview and make a new dataframe with only top 5 important words in each document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Key1</th>\n",
       "      <th>Key2</th>\n",
       "      <th>Key3</th>\n",
       "      <th>Key4</th>\n",
       "      <th>Key5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>parapleg</td>\n",
       "      <td>pandora</td>\n",
       "      <td>22nd</td>\n",
       "      <td>moon</td>\n",
       "      <td>dispatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>barbossa</td>\n",
       "      <td>swann</td>\n",
       "      <td>turner</td>\n",
       "      <td>edg</td>\n",
       "      <td>elizabeth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>peel</td>\n",
       "      <td>layer</td>\n",
       "      <td>spectr</td>\n",
       "      <td>cryptic</td>\n",
       "      <td>deceit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dent'</td>\n",
       "      <td>attorney'</td>\n",
       "      <td>batman</td>\n",
       "      <td>selina</td>\n",
       "      <td>bane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>barsoom</td>\n",
       "      <td>war-weari</td>\n",
       "      <td>carter</td>\n",
       "      <td>rediscov</td>\n",
       "      <td>embroil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spider-man</td>\n",
       "      <td>sandman</td>\n",
       "      <td>shape-shift</td>\n",
       "      <td>all-new</td>\n",
       "      <td>brock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>wanted-and</td>\n",
       "      <td>charming-bandit</td>\n",
       "      <td>rapunzel</td>\n",
       "      <td>tower-bound</td>\n",
       "      <td>flynn'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>jumpstart</td>\n",
       "      <td>mightiest</td>\n",
       "      <td>peacekeep</td>\n",
       "      <td>ultron</td>\n",
       "      <td>enact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>'properti</td>\n",
       "      <td>half-blood</td>\n",
       "      <td>voldemort'</td>\n",
       "      <td>prince'</td>\n",
       "      <td>sixth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>god-lik</td>\n",
       "      <td>uncheck</td>\n",
       "      <td>metropoli</td>\n",
       "      <td>savior</td>\n",
       "      <td>superman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>luthor</td>\n",
       "      <td>5-year</td>\n",
       "      <td>felt</td>\n",
       "      <td>lex</td>\n",
       "      <td>closest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>vesper</td>\n",
       "      <td>quantum</td>\n",
       "      <td>solac</td>\n",
       "      <td>interrog</td>\n",
       "      <td>007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>davey</td>\n",
       "      <td>damnat</td>\n",
       "      <td>sparrow</td>\n",
       "      <td>ghostli</td>\n",
       "      <td>etern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>tonto</td>\n",
       "      <td>cavendish</td>\n",
       "      <td>ilk</td>\n",
       "      <td>ranger</td>\n",
       "      <td>stallion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>annihil</td>\n",
       "      <td>here</td>\n",
       "      <td>symbol</td>\n",
       "      <td>mankind</td>\n",
       "      <td>came</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>pevensi</td>\n",
       "      <td>narnia</td>\n",
       "      <td>miraz</td>\n",
       "      <td>trufflehunt</td>\n",
       "      <td>badger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>peacekeep</td>\n",
       "      <td>furi</td>\n",
       "      <td>h</td>\n",
       "      <td>brink</td>\n",
       "      <td>span</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>blackbeard</td>\n",
       "      <td>anne'</td>\n",
       "      <td>fountain</td>\n",
       "      <td>sparrow</td>\n",
       "      <td>fabl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>j</td>\n",
       "      <td>k</td>\n",
       "      <td>perplex</td>\n",
       "      <td>wri</td>\n",
       "      <td>k'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>dwarv</td>\n",
       "      <td>elv</td>\n",
       "      <td>erebor'</td>\n",
       "      <td>laketown</td>\n",
       "      <td>mirkwood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>oscorp</td>\n",
       "      <td>connors'</td>\n",
       "      <td>peter</td>\n",
       "      <td>briefca</td>\n",
       "      <td>curt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>loxley</td>\n",
       "      <td>henchman</td>\n",
       "      <td>godfrey</td>\n",
       "      <td>robert'</td>\n",
       "      <td>nottingham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>bilbo</td>\n",
       "      <td>gandalf</td>\n",
       "      <td>misti</td>\n",
       "      <td>smaug</td>\n",
       "      <td>dwarv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>lyra</td>\n",
       "      <td>belacqua</td>\n",
       "      <td>precoci</td>\n",
       "      <td>overhear</td>\n",
       "      <td>carefr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1933</td>\n",
       "      <td>coerc</td>\n",
       "      <td>overli</td>\n",
       "      <td>skull</td>\n",
       "      <td>ape</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>dewitt</td>\n",
       "      <td>bukat</td>\n",
       "      <td>1912</td>\n",
       "      <td>titan</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ultron</td>\n",
       "      <td>regul</td>\n",
       "      <td>superhuman</td>\n",
       "      <td>opinion</td>\n",
       "      <td>amongst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>hopper</td>\n",
       "      <td>repli</td>\n",
       "      <td>coalit</td>\n",
       "      <td>fiancée'</td>\n",
       "      <td>splash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>jurass</td>\n",
       "      <td>nublar</td>\n",
       "      <td>isla</td>\n",
       "      <td>twenty-two</td>\n",
       "      <td>hammond</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>mi6</td>\n",
       "      <td>bond'</td>\n",
       "      <td>gareth</td>\n",
       "      <td>silva</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4773</th>\n",
       "      <td>potty-mouth</td>\n",
       "      <td>dant</td>\n",
       "      <td>needl</td>\n",
       "      <td>counter</td>\n",
       "      <td>conveni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4774</th>\n",
       "      <td>poem</td>\n",
       "      <td>erot</td>\n",
       "      <td>prostitut</td>\n",
       "      <td>fantasi</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4775</th>\n",
       "      <td>marni</td>\n",
       "      <td>23-year-old</td>\n",
       "      <td>tomorrow</td>\n",
       "      <td>temp</td>\n",
       "      <td>unsur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4776</th>\n",
       "      <td>executives--on</td>\n",
       "      <td>avow</td>\n",
       "      <td>interest--set</td>\n",
       "      <td>gender</td>\n",
       "      <td>uncorrupt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4777</th>\n",
       "      <td>manni</td>\n",
       "      <td>crack-cocain</td>\n",
       "      <td>spanish-speak</td>\n",
       "      <td>salutatorian</td>\n",
       "      <td>legaci</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4778</th>\n",
       "      <td>williamson</td>\n",
       "      <td>constrain</td>\n",
       "      <td>meaningless</td>\n",
       "      <td>drudgeri</td>\n",
       "      <td>dissolut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4779</th>\n",
       "      <td>linear</td>\n",
       "      <td>seamlessli</td>\n",
       "      <td>randomli</td>\n",
       "      <td>predominantli</td>\n",
       "      <td>vignett</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4780</th>\n",
       "      <td>sister'</td>\n",
       "      <td>ex-con</td>\n",
       "      <td>debt</td>\n",
       "      <td>gather</td>\n",
       "      <td>pay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4781</th>\n",
       "      <td>guilt-fr</td>\n",
       "      <td>sasha</td>\n",
       "      <td>soon-to-b</td>\n",
       "      <td>kyle</td>\n",
       "      <td>ex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4782</th>\n",
       "      <td>austin</td>\n",
       "      <td>hasti</td>\n",
       "      <td>dishonesti</td>\n",
       "      <td>disgust</td>\n",
       "      <td>jay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4783</th>\n",
       "      <td>flare</td>\n",
       "      <td>teen'</td>\n",
       "      <td>occult</td>\n",
       "      <td>asylum'</td>\n",
       "      <td>all-night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4784</th>\n",
       "      <td>chair</td>\n",
       "      <td>josh'</td>\n",
       "      <td>ebay</td>\n",
       "      <td>too-smal</td>\n",
       "      <td>trip'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4785</th>\n",
       "      <td>nairobi-ba</td>\n",
       "      <td>repri</td>\n",
       "      <td>lgbtq</td>\n",
       "      <td>antholog</td>\n",
       "      <td>kenya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4786</th>\n",
       "      <td>'break</td>\n",
       "      <td>upwards'</td>\n",
       "      <td>codepend</td>\n",
       "      <td>wein</td>\n",
       "      <td>lister-jon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4787</th>\n",
       "      <td>trost</td>\n",
       "      <td>valmassi</td>\n",
       "      <td>merkley</td>\n",
       "      <td>remar</td>\n",
       "      <td>rovi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4788</th>\n",
       "      <td>marbl</td>\n",
       "      <td>tabloid-given</td>\n",
       "      <td>filthiest</td>\n",
       "      <td>divin</td>\n",
       "      <td>baltimor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4789</th>\n",
       "      <td>overdo</td>\n",
       "      <td>wang</td>\n",
       "      <td>heroin</td>\n",
       "      <td>reconcil</td>\n",
       "      <td>emili</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4790</th>\n",
       "      <td>sexist</td>\n",
       "      <td>iran</td>\n",
       "      <td>function</td>\n",
       "      <td>contemporari</td>\n",
       "      <td>oppress</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4791</th>\n",
       "      <td>girlfirend</td>\n",
       "      <td>knock</td>\n",
       "      <td>hate</td>\n",
       "      <td>dump</td>\n",
       "      <td>door</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4792</th>\n",
       "      <td>takab</td>\n",
       "      <td>sakuma</td>\n",
       "      <td>carv</td>\n",
       "      <td>neck</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4793</th>\n",
       "      <td>isaac</td>\n",
       "      <td>latino</td>\n",
       "      <td>forbidden</td>\n",
       "      <td>chicago</td>\n",
       "      <td>south</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4794</th>\n",
       "      <td>tabitha</td>\n",
       "      <td>mimi</td>\n",
       "      <td>over-privileg</td>\n",
       "      <td>debaucheri</td>\n",
       "      <td>normalci</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4795</th>\n",
       "      <td>cop'</td>\n",
       "      <td>fellatio</td>\n",
       "      <td>cuf</td>\n",
       "      <td>self-protect</td>\n",
       "      <td>defenseless</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4796</th>\n",
       "      <td>reduc</td>\n",
       "      <td>garag</td>\n",
       "      <td>entrepreneur</td>\n",
       "      <td>fledgl</td>\n",
       "      <td>enabl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4797</th>\n",
       "      <td>adam</td>\n",
       "      <td>manila</td>\n",
       "      <td>tricycl</td>\n",
       "      <td>cramp</td>\n",
       "      <td>fetid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4798</th>\n",
       "      <td>guitar</td>\n",
       "      <td>mariachi</td>\n",
       "      <td>azul</td>\n",
       "      <td>henchmen</td>\n",
       "      <td>el</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4799</th>\n",
       "      <td>upend</td>\n",
       "      <td>honeymoon</td>\n",
       "      <td>newlyw</td>\n",
       "      <td>couple'</td>\n",
       "      <td>respect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4800</th>\n",
       "      <td>lost-mail</td>\n",
       "      <td>undeliv</td>\n",
       "      <td>postal</td>\n",
       "      <td>quartet</td>\n",
       "      <td>deliv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4801</th>\n",
       "      <td>shanghai</td>\n",
       "      <td>well-connect</td>\n",
       "      <td>old-tim</td>\n",
       "      <td>imdb</td>\n",
       "      <td>street-smart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4802</th>\n",
       "      <td>herzl</td>\n",
       "      <td>barrymor</td>\n",
       "      <td>drew</td>\n",
       "      <td>27-year-old</td>\n",
       "      <td>brian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4803 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Key1             Key2           Key3           Key4  \\\n",
       "0           parapleg          pandora           22nd           moon   \n",
       "1           barbossa            swann         turner            edg   \n",
       "2               peel            layer         spectr        cryptic   \n",
       "3              dent'        attorney'         batman         selina   \n",
       "4            barsoom        war-weari         carter       rediscov   \n",
       "5         spider-man          sandman    shape-shift        all-new   \n",
       "6         wanted-and  charming-bandit       rapunzel    tower-bound   \n",
       "7          jumpstart        mightiest      peacekeep         ultron   \n",
       "8          'properti       half-blood     voldemort'        prince'   \n",
       "9            god-lik          uncheck      metropoli         savior   \n",
       "10            luthor           5-year           felt            lex   \n",
       "11            vesper          quantum          solac       interrog   \n",
       "12             davey           damnat        sparrow        ghostli   \n",
       "13             tonto        cavendish            ilk         ranger   \n",
       "14           annihil             here         symbol        mankind   \n",
       "15           pevensi           narnia          miraz    trufflehunt   \n",
       "16         peacekeep             furi              h          brink   \n",
       "17        blackbeard            anne'       fountain        sparrow   \n",
       "18                 j                k        perplex            wri   \n",
       "19             dwarv              elv        erebor'       laketown   \n",
       "20            oscorp         connors'          peter        briefca   \n",
       "21            loxley         henchman        godfrey        robert'   \n",
       "22             bilbo          gandalf          misti          smaug   \n",
       "23              lyra         belacqua        precoci       overhear   \n",
       "24              1933            coerc         overli          skull   \n",
       "25            dewitt            bukat           1912          titan   \n",
       "26            ultron            regul     superhuman        opinion   \n",
       "27            hopper            repli         coalit       fiancée'   \n",
       "28            jurass           nublar           isla     twenty-two   \n",
       "29               mi6            bond'         gareth          silva   \n",
       "...              ...              ...            ...            ...   \n",
       "4773     potty-mouth             dant          needl        counter   \n",
       "4774            poem             erot      prostitut        fantasi   \n",
       "4775           marni      23-year-old       tomorrow           temp   \n",
       "4776  executives--on             avow  interest--set         gender   \n",
       "4777           manni     crack-cocain  spanish-speak   salutatorian   \n",
       "4778      williamson        constrain    meaningless       drudgeri   \n",
       "4779          linear       seamlessli       randomli  predominantli   \n",
       "4780         sister'           ex-con           debt         gather   \n",
       "4781        guilt-fr            sasha      soon-to-b           kyle   \n",
       "4782          austin            hasti     dishonesti        disgust   \n",
       "4783           flare            teen'         occult        asylum'   \n",
       "4784           chair            josh'           ebay       too-smal   \n",
       "4785      nairobi-ba            repri          lgbtq       antholog   \n",
       "4786          'break         upwards'       codepend           wein   \n",
       "4787           trost         valmassi        merkley          remar   \n",
       "4788           marbl    tabloid-given      filthiest          divin   \n",
       "4789          overdo             wang         heroin       reconcil   \n",
       "4790          sexist             iran       function   contemporari   \n",
       "4791      girlfirend            knock           hate           dump   \n",
       "4792           takab           sakuma           carv           neck   \n",
       "4793           isaac           latino      forbidden        chicago   \n",
       "4794         tabitha             mimi  over-privileg     debaucheri   \n",
       "4795            cop'         fellatio            cuf   self-protect   \n",
       "4796           reduc            garag   entrepreneur         fledgl   \n",
       "4797            adam           manila        tricycl          cramp   \n",
       "4798          guitar         mariachi           azul       henchmen   \n",
       "4799           upend        honeymoon         newlyw        couple'   \n",
       "4800       lost-mail          undeliv         postal        quartet   \n",
       "4801        shanghai     well-connect        old-tim           imdb   \n",
       "4802           herzl         barrymor           drew    27-year-old   \n",
       "\n",
       "              Key5  \n",
       "0         dispatch  \n",
       "1        elizabeth  \n",
       "2           deceit  \n",
       "3             bane  \n",
       "4          embroil  \n",
       "5            brock  \n",
       "6           flynn'  \n",
       "7            enact  \n",
       "8            sixth  \n",
       "9         superman  \n",
       "10         closest  \n",
       "11             007  \n",
       "12           etern  \n",
       "13        stallion  \n",
       "14            came  \n",
       "15          badger  \n",
       "16            span  \n",
       "17            fabl  \n",
       "18              k'  \n",
       "19        mirkwood  \n",
       "20            curt  \n",
       "21      nottingham  \n",
       "22           dwarv  \n",
       "23          carefr  \n",
       "24             ape  \n",
       "25              84  \n",
       "26         amongst  \n",
       "27          splash  \n",
       "28         hammond  \n",
       "29               m  \n",
       "...            ...  \n",
       "4773       conveni  \n",
       "4774          male  \n",
       "4775         unsur  \n",
       "4776     uncorrupt  \n",
       "4777        legaci  \n",
       "4778      dissolut  \n",
       "4779       vignett  \n",
       "4780           pay  \n",
       "4781            ex  \n",
       "4782           jay  \n",
       "4783     all-night  \n",
       "4784         trip'  \n",
       "4785         kenya  \n",
       "4786    lister-jon  \n",
       "4787          rovi  \n",
       "4788      baltimor  \n",
       "4789         emili  \n",
       "4790       oppress  \n",
       "4791          door  \n",
       "4792             x  \n",
       "4793         south  \n",
       "4794      normalci  \n",
       "4795   defenseless  \n",
       "4796         enabl  \n",
       "4797         fetid  \n",
       "4798            el  \n",
       "4799       respect  \n",
       "4800         deliv  \n",
       "4801  street-smart  \n",
       "4802         brian  \n",
       "\n",
       "[4803 rows x 5 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_column=[]\n",
    "idf_dict=idf(data[\"overview\"])\n",
    "for overview in data[\"overview\"]:        \n",
    "    tfidf_dict=tf(overview)\n",
    "    for key,value in tfidf_dict.items():\n",
    "        tfidf_dict[key]=value*idf_dict[key]\n",
    "    tfidf_dict=sorted(tfidf_dict, key=tfidf_dict.get, reverse=True)[:5]\n",
    "    tfidf_column.append(tfidf_dict)\n",
    "importantwords_df=pd.DataFrame(tfidf_column,columns=[\"Key1\",\"Key2\",\"Key3\",\"Key4\",\"Key5\"])\n",
    "importantwords_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, for looking at the genres of the movie we are going to make a dataframe that gets all the genres from the movies and creates a dummy variable that gives 0 or 1 respective to if that movie corresponds to that genre or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "genre_list=[]\n",
    "for genre in data[\"genres\"]:\n",
    "    for d in genre:\n",
    "        if d['name'] not in genre_list:\n",
    "            genre_list.append(d['name'])\n",
    "\n",
    "all_movies=[]\n",
    "for genre in data[\"genres\"]:\n",
    "    movie_genres=dict()\n",
    "    for gen in genre_list:\n",
    "        movie_genres.setdefault(gen, 0)\n",
    "    for d in genre:\n",
    "        movie_genres[d['name']]=1\n",
    "    all_movies.append(movie_genres)\n",
    "genres_df=pd.DataFrame(all_movies)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We extract the Director from the list of crew members and create a new column that has the director of each movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "directors_list=list()\n",
    "for crew in data[\"crew\"]:\n",
    "    director_flag=0\n",
    "    for d in crew:\n",
    "        if d['job']==\"Director\":\n",
    "            directors_list.append({\"Director\":d['name']})\n",
    "            director_flag=1\n",
    "            break\n",
    "    if director_flag==0:\n",
    "        directors_list.append({\"Director\":''})\n",
    "\n",
    "directors_df=pd.DataFrame(directors_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for the list of keywords that exists in our movie dataset already are basically the search tags that represent the movie and the we extract the keywords that have the highest tf-idf among the list of words as those keywords are the most unique tags for each movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keywords_column=list()\n",
    "for movie_keywords in data[\"keywords\"]:\n",
    "    keywords=''\n",
    "    for d in movie_keywords:\n",
    "        keywords=keywords+ps.stem(d['name'])+' '\n",
    "    keywords_column.append(keywords.strip())\n",
    "    \n",
    "keywords_df=pd.DataFrame(keywords_column)\n",
    "\n",
    "tfidf_column2=[]\n",
    "idf_dict2=idf(keywords_df[0])\n",
    "for docs in keywords_df[0]:        \n",
    "    tfidf_dict=tf(docs)\n",
    "    for key,value in tfidf_dict.items():\n",
    "        tfidf_dict[key]=value*idf_dict2[key]\n",
    "    tfidf_dict=sorted(tfidf_dict, key=tfidf_dict.get, reverse=True)[:5]\n",
    "    tfidf_column2.append(tfidf_dict)\n",
    "keywords_5df=pd.DataFrame(tfidf_column2,columns=[\"Keyword1\",\"Keyword2\",\"Keyword3\",\"Keyword4\",\"Keyword5\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We concatenate all the columns that we have processed and create a new result dataset that we will use to make the user and item profiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Concatenating\n",
    "result=pd.concat([data,actors_df,directors_df,genres_df,importantwords_df,keywords_5df],axis=1)\n",
    "#Normalizing vote_average to change the range to 0 to 1\n",
    "result[\"vote_average\"]=result[\"vote_average\"]*0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the user selection that we need use to create the user profile."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You can make the user selection multiple times but you need to run the next cell too with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "086f1eb3774e4e71bbb7f6f52806f7ad"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "\n",
    "user_movie=widgets.Dropdown(\n",
    "    options=sorted(list(result[\"title\"])),\n",
    "    description='Please choose a movie:',\n",
    "    disabled=False,\n",
    ")\n",
    "user_movie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above is a dropdown when you run the notebook you can choose the movie using this drop down. \n",
    "\n",
    "I have run the notebook and selecting the movie as **\"2 Fast 2 Furious\"**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps Followed:-\n",
    "\n",
    "1. We create a user profile and first the row from the dataset that corresponds to users selected movie.\n",
    "2. We use original_language, actors, director, keys(from overview) and keywords and code 1 or 0 for each movie.\n",
    "3. For the user profile each of the above is 1.\n",
    "4. Then we drop irrelevant columns.\n",
    "5. We subset the data to remove the user's selection from the original dataset.\n",
    "6. We compute the cosine similarities between to dataset(one dataset represents user profile and other represents item profiles)\n",
    "7. We sort the cosine similarities by lowest to highest.\n",
    "8. We pick the last 5.\n",
    "9. Recommend the 5 movies we picked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie selected is 2 Fast 2 Furious\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>original_language</th>\n",
       "      <th>title</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>actor1</th>\n",
       "      <th>actor2</th>\n",
       "      <th>actor3</th>\n",
       "      <th>Director</th>\n",
       "      <th>Action</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>...</th>\n",
       "      <th>Key1</th>\n",
       "      <th>Key2</th>\n",
       "      <th>Key3</th>\n",
       "      <th>Key4</th>\n",
       "      <th>Key5</th>\n",
       "      <th>Keyword1</th>\n",
       "      <th>Keyword2</th>\n",
       "      <th>Keyword3</th>\n",
       "      <th>Keyword4</th>\n",
       "      <th>Keyword5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>9799</td>\n",
       "      <td>1</td>\n",
       "      <td>The Fast and the Furious</td>\n",
       "      <td>0.66</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>51497</td>\n",
       "      <td>1</td>\n",
       "      <td>Fast Five</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>9615</td>\n",
       "      <td>1</td>\n",
       "      <td>The Fast and the Furious: Tokyo Drift</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>136797</td>\n",
       "      <td>1</td>\n",
       "      <td>Need for Speed</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1792</th>\n",
       "      <td>134374</td>\n",
       "      <td>1</td>\n",
       "      <td>Pain &amp; Gain</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      movie_id  original_language                                  title  \\\n",
       "99        9799                  1               The Fast and the Furious   \n",
       "204      51497                  1                              Fast Five   \n",
       "405       9615                  1  The Fast and the Furious: Tokyo Drift   \n",
       "629     136797                  1                         Need for Speed   \n",
       "1792    134374                  1                            Pain & Gain   \n",
       "\n",
       "      vote_average  actor1  actor2  actor3  Director  Action  Adventure  \\\n",
       "99            0.66       1       0       0         0       1          0   \n",
       "204           0.71       0       1       0         0       1          0   \n",
       "405           0.61       0       0       0         0       1          0   \n",
       "629           0.61       0       0       0         0       1          0   \n",
       "1792          0.61       0       0       0         0       1          0   \n",
       "\n",
       "        ...     Key1  Key2  Key3  Key4  Key5  Keyword1  Keyword2  Keyword3  \\\n",
       "99      ...        0     0     0     0     0         0         1         1   \n",
       "204     ...        0     0     0     0     0         0         1         0   \n",
       "405     ...        0     0     0     0     0         0         0         1   \n",
       "629     ...        0     0     0     0     0         0         0         0   \n",
       "1792    ...        0     0     0     0     0         0         0         0   \n",
       "\n",
       "      Keyword4  Keyword5  \n",
       "99           0         1  \n",
       "204          0         0  \n",
       "405          1         0  \n",
       "629          1         1  \n",
       "1792         0         1  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn.metrics.pairwise\n",
    "print(\"Movie selected is \"+user_movie.value)\n",
    "user_profile=result.loc[result['title']==str(user_movie.value)]\n",
    "\n",
    "user_profile=user_profile.drop(['cast','crew','popularity', 'budget', 'genres', 'homepage', 'keywords','original_title','overview', 'production_companies','production_countries','release_date', 'revenue', 'runtime', 'spoken_languages', 'status','tagline','vote_count'],axis=1)\n",
    "actor1=user_profile['actor1'].tolist()\n",
    "actor2=user_profile['actor2'].tolist()\n",
    "actor3=user_profile['actor3'].tolist()\n",
    "original_language=user_profile['original_language'].tolist()\n",
    "Director=user_profile['Director'].tolist()\n",
    "Key1=user_profile['Key1'].tolist()\n",
    "Key2=user_profile['Key2'].tolist()\n",
    "Key3=user_profile['Key3'].tolist()\n",
    "Key4=user_profile['Key4'].tolist()\n",
    "Key5=user_profile['Key5'].tolist()\n",
    "Keyword1=user_profile['Keyword1'].tolist()\n",
    "Keyword2=user_profile['Keyword2'].tolist()\n",
    "Keyword3=user_profile['Keyword3'].tolist()\n",
    "Keyword4=user_profile['Keyword4'].tolist()\n",
    "Keyword5=user_profile['Keyword5'].tolist()\n",
    "\n",
    "\n",
    "actor_list=[actor1[0],actor2[0],actor3[0]]\n",
    "key_list=[Key1[0],Key2[0],Key3[0],Key4[0],Key5[0]]\n",
    "keyword_list=[Keyword1[0],Keyword2[0],Keyword3[0],Keyword4[0],Keyword5[0]]\n",
    "\n",
    "\n",
    "user_profile['actor1'] = np.where(user_profile.actor1.isin(actor1),1,0)\n",
    "user_profile['actor2'] = np.where(user_profile.actor2.isin(actor2),1,0)\n",
    "user_profile['actor3'] = np.where(user_profile.actor3.isin(actor3),1,0)\n",
    "user_profile['original_language'] = np.where(user_profile.original_language.isin(original_language),1,0)\n",
    "user_profile['Director'] = np.where(user_profile.Director.isin(Director),1,0)\n",
    "user_profile['Key1'] = np.where(user_profile.Key1.isin(Key1),1,0)\n",
    "user_profile['Key2'] = np.where(user_profile.Key2.isin(Key2),1,0)\n",
    "user_profile['Key3'] = np.where(user_profile.Key3.isin(Key3),1,0)\n",
    "user_profile['Key4'] = np.where(user_profile.Key4.isin(Key4),1,0)\n",
    "user_profile['Key5'] = np.where(user_profile.Key5.isin(Key5),1,0)\n",
    "user_profile['Keyword1'] = np.where(user_profile.Keyword1.isin(Keyword1),1,0)\n",
    "user_profile['Keyword2'] = np.where(user_profile.Keyword2.isin(Keyword2),1,0)\n",
    "user_profile['Keyword3'] = np.where(user_profile.Keyword3.isin(Keyword3),1,0)\n",
    "user_profile['Keyword4'] = np.where(user_profile.Keyword4.isin(Keyword4),1,0)\n",
    "user_profile['Keyword5'] = np.where(user_profile.Keyword5.isin(Keyword5),1,0)\n",
    "\n",
    "item_profiles=result.drop(['cast','crew','popularity', 'budget', 'genres', 'homepage', 'keywords','original_title','overview', 'production_companies','production_countries','release_date', 'revenue', 'runtime', 'spoken_languages', 'status','tagline','vote_count'],axis=1)\n",
    "item_profiles=item_profiles.loc[~(data['original_title']==str(user_movie.value))]\n",
    "item_profiles['actor1'] = np.where(item_profiles.actor1.isin(actor_list),1,0)\n",
    "item_profiles['actor2'] = np.where(item_profiles.actor2.isin(actor_list),1,0)\n",
    "item_profiles['actor3'] = np.where(item_profiles.actor3.isin(actor_list),1,0)\n",
    "item_profiles['original_language'] = np.where(item_profiles.original_language.isin(original_language),1,0)\n",
    "item_profiles['Director'] = np.where(item_profiles.Director.isin(Director),1,0)\n",
    "item_profiles['Key1'] = np.where(item_profiles.Key1.isin(key_list),1,0)\n",
    "item_profiles['Key2'] = np.where(item_profiles.Key2.isin(key_list),1,0)\n",
    "item_profiles['Key3'] = np.where(item_profiles.Key3.isin(key_list),1,0)\n",
    "item_profiles['Key4'] = np.where(item_profiles.Key4.isin(key_list),1,0)\n",
    "item_profiles['Key5'] = np.where(item_profiles.Key5.isin(key_list),1,0)\n",
    "\n",
    "item_profiles['Keyword1'] = np.where(item_profiles.Keyword1.isin(keyword_list),1,0)\n",
    "item_profiles['Keyword2'] = np.where(item_profiles.Keyword2.isin(keyword_list),1,0)\n",
    "item_profiles['Keyword3'] = np.where(item_profiles.Keyword3.isin(keyword_list),1,0)\n",
    "item_profiles['Keyword4'] = np.where(item_profiles.Keyword4.isin(keyword_list),1,0)\n",
    "item_profiles['Keyword5'] = np.where(item_profiles.Keyword5.isin(keyword_list),1,0)\n",
    "\n",
    "\n",
    "item_profiles\n",
    "x=user_profile.drop(['title','movie_id'],axis=1)\n",
    "y=item_profiles.drop(['title','movie_id'],axis=1)\n",
    "\n",
    "\n",
    "arr = sklearn.metrics.pairwise.cosine_similarity(x,y, dense_output=True)\n",
    "arr_index=arr.argsort()\n",
    "arr_index=arr_index.ravel()\n",
    "final_df=pd.DataFrame(arr_index).tail(5)\n",
    "final_df\n",
    "item_profiles=item_profiles.iloc[final_df[0]]\n",
    "item_profiles=item_profiles.iloc[::-1]\n",
    "item_profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended Movies for 2 Fast 2 Furious: \n",
      "\n",
      "The Fast and the Furious\n",
      "Fast Five\n",
      "The Fast and the Furious: Tokyo Drift\n",
      "Need for Speed\n",
      "Pain & Gain\n"
     ]
    }
   ],
   "source": [
    "print(\"Recommended Movies for \"+ user_movie.value + \": \\n\\n\"+'\\n'.join(list(item_profiles[\"title\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Play Around and try other movies choose different movies from the dropdown."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## References\n",
    "\n",
    "1. Content Based Recommendations | Stanford University. (2018). YouTube. Retrieved 31 March 2018, from https://www.youtube.com/watch?v=2uxXPzm-7FY\n",
    "\n",
    "2. Engines, B., Engines, B., & Das, S. (2018). Beginners Guide to learn about Content Based Recommender Engine. Analytics Vidhya. Retrieved 31 March 2018, from https://www.analyticsvidhya.com/blog/2015/08/beginners-guide-learn-content-based-recommender-systems/\n",
    "\n",
    "3. Lecture 16.2 — Recommender Systems | Content Based Recommendations — [ Andrew Ng ]. (2018). YouTube. Retrieved 31 March 2018, from https://www.youtube.com/watch?v=9siFuMMHNIA\n",
    "\n",
    "4. Overview of Recommender Systems | Stanford University. (2018). YouTube. Retrieved 31 March 2018, from https://www.youtube.com/watch?v=1JRrCEgiyHM&t=627s\n",
    "\n",
    "5. Recommender system. (2018). En.wikipedia.org. Retrieved 31 March 2018, from https://en.wikipedia.org/wiki/Recommender_system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further reads\n",
    "\n",
    "Further resources for better understanding of recommender systems:-\n",
    "\n",
    "A good read to know more about the other most widely used recommendation algorithm Collaborative Filtering http://www.cs.umd.edu/~samir/498/Amazon-Recommendations.pdf .This paper talks about amazon's use of item-to-item collaborative filtering.\n",
    "\n",
    "If you want to deep dive into the topic and understand different algorithms more thoroughly. I recommend this course https://www.coursera.org/specializations/recommender-systems.\n",
    "\n",
    "Another great tutorial if you want to look at another example of content based recommender systems.\n",
    "https://www.themarketingtechnologist.co/a-recommendation-system-for-blogs-content-based-similarity-part-2/\n",
    "\n",
    "A good read on hybrid recommender systems\n",
    "https://www.hindawi.com/journals/mpe/2015/145636/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "Recommender systems are very widely used in the industry right now and is one of the must have skills on your resume. For the other most widely used recommender systems and you can go through the some of the readings I suggested above and look at the problems related to recommender systems like cold start problem(The algorithm we have discussed in this tutorial can address this problem). And read how both these algorithms are used in a hybrid algorithm to solve some of these problems.\n",
    "Apart from this content based recommender system does not have any particular fixed metric for evaluation, but in the case of Collaborative filtering we can evaluate our model using users previous ratings and dividing our data into training and test sets. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
