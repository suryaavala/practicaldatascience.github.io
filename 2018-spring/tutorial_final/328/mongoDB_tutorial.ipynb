{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial gives a brief introduction to Non-relational database (NoSQL). Specifically it focuses on MongoDB, a document-oriented NoSQL database. It provides a simple example showing how to interact with MongoDB in Python using the [PyMongo](https://api.mongodb.com/python/current/) library. \n",
    "We will cover the following topics in this tutorial:\n",
    "- [Introduction to NoSQL and MongoDB](#Introduction-to-NoSQL-and-MongoDB)\n",
    "- [Getting Started](#Getting-Started)\n",
    "- [Query Operations](#Query-Operations)\n",
    "    - [Insert Document](#Insert-Document)\n",
    "    - [Update Document](#Update-Document)\n",
    "    - [Find Document](#Find-Document)\n",
    "    - [Aggregate Document](#Aggregate-Document)\n",
    "    - [MapReduce Document](#MapReduce-Document)\n",
    "    - [Delete Document](#Delete-Document)\n",
    "- [Summary and References](#Summary-and-References)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to NoSQL and MongoDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-relational Database (NoSQL)\n",
    "Traditional relational databases (RDBMS) impose strict schema definition. Table structures and data types must be pre-defined at creation time. While RDBMS can effeciently handle organized and structured data, it can't effectively deal with data that are less organized. More importantly it is extremely hard to scale up to clusters of machines for big data and real-time web applications. \n",
    "\n",
    "Non-relational databases are designed to do what traditional RDBMS can't do. Most NoSQL databases compromise consistency for availability and partition tolerance. They typically do not enforce a schema when the databases are created. Each item in the databases are stored as an unique attribute name (or 'key') with its corresponding value, which could be actual string values, column sets, semi-structured JSON or XMLs depending on different types of NoSQL databases. Since keys are unique within a collection(table), it is easy to horizontally scale up the database by partioning data based on some hash functions on keys. Because of these traits, NoSQL databases are widely used to handle unstrcutured data (e.g. texts, social media posts, videos).  \n",
    "\n",
    "### MongoDB\n",
    "MongoDB is a scalable high-performance open-source, document-orientated NoSQL database. It is called document-orientated as it paris each key with a JSON-like data structure known as a document. Each document can contain many different key-value pairs or key-array pairs and the data structure can be changed over time. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get started, we will first need to install MongoDB. On a Mac machine, we can simply install the MongoDB community edition using `Homebrew`:\n",
    "\n",
    "    $ brew install mongodb\n",
    "\n",
    "To install MongoDB on Linux or Windows, please follow the instruction on https://docs.mongodb.com/manual/administration/install-community\n",
    "\n",
    "After installation, please continue following the instructions to set up the database environment. (__IMPORTANT__: you must create a folder named `/data/db` as the data directory.)\n",
    "\n",
    "Next we can install the [PyMongo](https://api.mongodb.com/python/current/) library using `pip`:\n",
    "\n",
    "    $ pip install pymongo\n",
    "    \n",
    "After finishing all the installations, make sure the following commands works for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from pymongo import MongoClient\n",
    "from bson.json_util import loads\n",
    "from bson.son import SON\n",
    "from bson.code import Code\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now finally start interacting with MongoDB. First we will start a MongoDB server. Open a new terminal window and use the following command to start the server."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    $ mongod --dbpath <path-to-database-directory> # Example: mongod --dbpath ./data/db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, back to this notebook and start a connection with the database. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MongoClient(host=['localhost:27017'], document_class=dict, tz_aware=False, connect=True)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mongo_url = 'mongodb://localhost:27017' # the broadcasting port\n",
    "\n",
    "client = MongoClient(mongo_url) # connect to MongoDB\n",
    "client\n",
    "\n",
    "# Check the MongoDB server terminal to make sure you have establish a connection\n",
    "# You should expect to see something like '1 connection now open' in the terminal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset we will be using is the __*restaurants*__ collection from the __*test*__ database. The dataset is available at https://raw.githubusercontent.com/mongodb/docs-assets/primer-dataset/primer-dataset.json. Please get a copy of the dataset and name it `restaurants_dataset.json` and store it in the current directory. This dataset stores basic locational information about restaurants as well as review grades from customers as shown below. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"borough\": \"Bronx\",\n",
      "  \"restaurant_id\": \"30075445\",\n",
      "  \"name\": \"Morris Park Bake Shop\",\n",
      "  \"cuisine\": \"Bakery\",\n",
      "  \"address\": {\n",
      "    \"street\": \"Morris Park Ave\",\n",
      "    \"building\": \"1007\",\n",
      "    \"coord\": [\n",
      "      -73.856077,\n",
      "      40.848447\n",
      "    ],\n",
      "    \"zipcode\": \"10462\"\n",
      "  },\n",
      "  \"grades\": [\n",
      "    {\n",
      "      \"grade\": \"A\",\n",
      "      \"date\": \"2014-03-03T00:00:00+00:00\",\n",
      "      \"score\": 2\n",
      "    },\n",
      "    {\n",
      "      \"grade\": \"A\",\n",
      "      \"date\": \"2013-09-11T00:00:00+00:00\",\n",
      "      \"score\": 6\n",
      "    },\n",
      "    {\n",
      "      \"grade\": \"A\",\n",
      "      \"date\": \"2013-01-24T00:00:00+00:00\",\n",
      "      \"score\": 10\n",
      "    },\n",
      "    {\n",
      "      \"grade\": \"A\",\n",
      "      \"date\": \"2011-11-23T00:00:00+00:00\",\n",
      "      \"score\": 9\n",
      "    },\n",
      "    {\n",
      "      \"grade\": \"B\",\n",
      "      \"date\": \"2011-03-10T00:00:00+00:00\",\n",
      "      \"score\": 14\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# glimpse the first data in the dataset\n",
    "\n",
    "# I add a tiny function to display datetime.date type more elegantly\n",
    "def date_handler(obj):\n",
    "    return obj.isoformat() if hasattr(obj, 'isoformat') else obj\n",
    "\n",
    "with open('restaurants_dataset.json') as f:\n",
    "    first_line = loads(f.readline())\n",
    "    print(json.dumps(first_line, indent=2, default=date_handler))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insert Document\n",
    "The first step will be to load our JSON data into mongoDB. Similar to the concept of tables in relationship database, it is called 'Collections' in mongoDB and each key-value pair is known as a document. If `_id` is not specified in the document, mongoDB will automatically create an ObjectId as key for this document, which will be unique in this collection. In our case, we will use `restaurant_id` as our unique identifier of documents.\n",
    "You should expect to see 25359 records in the collection after loading all the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of documents in the collection:       25359\n"
     ]
    }
   ],
   "source": [
    "# each line in our data file represents a document\n",
    "# we read the file line by line and insert into the database\n",
    "\n",
    "# if a database or collection is not existed, PyMonogo will create it automatically\n",
    "\n",
    "my_db = client.demo_db\n",
    "my_col = my_db.demo_collection\n",
    "\n",
    "with open('restaurants_dataset.json') as f:\n",
    "    for line in f:\n",
    "        doc = loads(line) # read line in json format\n",
    "        doc['_id'] = doc['restaurant_id'] # set _id as restaurant_id\n",
    "        my_col.insert_one(doc) # insert into my_col collection\n",
    "\n",
    "print(\"total number of documents in the collection: \\\n",
    "      \"+str(my_col.count()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update Document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we mentioned above, one of the biggest advantages of NoSQL is its flexibility in handling semi-structured data. If there is a new customer who just visited the Morris Park Bake Shop (the example above) and gave a review to this restaurant (in this case a bad one), we could simply update the document by inserting a new element into this document. Notice that here we can add a `comment` element and do not have a `date` element, but NoSQL has not problem handling this semi-structured data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ok': 1.0, 'n': 1, 'nModified': 1, 'updatedExisting': True}\n"
     ]
    }
   ],
   "source": [
    "new_review = {\"score\":1, \"grade\":\"C\", \"comment\":\"This is too expensive!\"}\n",
    "restaurant_id = \"30075445\" # _id for Morris Park Bake Shop\n",
    "\n",
    "result = client.demo_db.demo_collection.update_one({'_id': restaurant_id}, \\\n",
    "            {\"$addToSet\": {\"grades\": new_review}}, upsert=True)\n",
    "\n",
    "print(result.raw_result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to update a value of an elements in the array (score of the first element in grades field):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ok': 1.0, 'n': 1, 'nModified': 1, 'updatedExisting': True}\n"
     ]
    }
   ],
   "source": [
    "restaurant_id = \"30075445\" # _id for Morris Park Bake Shop\n",
    "\n",
    "result = client.demo_db.demo_collection.update_one({'_id': restaurant_id}, \\\n",
    "            {\"$set\": {\"grades.0.score\": 5}})\n",
    "print(result.raw_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find Document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next is about querying the database. Although the syntax is a little bit different from relationship database, the basic idea is the same. \n",
    "- If we want to see the document we just updated, we can search by key(since we know its restaurant id) and see the newly-inserted grades in the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"borough\": \"Bronx\",\n",
      "  \"restaurant_id\": \"30075445\",\n",
      "  \"_id\": \"30075445\",\n",
      "  \"name\": \"Morris Park Bake Shop\",\n",
      "  \"cuisine\": \"Bakery\",\n",
      "  \"address\": {\n",
      "    \"street\": \"Morris Park Ave\",\n",
      "    \"building\": \"1007\",\n",
      "    \"coord\": [\n",
      "      -73.856077,\n",
      "      40.848447\n",
      "    ],\n",
      "    \"zipcode\": \"10462\"\n",
      "  },\n",
      "  \"grades\": [\n",
      "    {\n",
      "      \"grade\": \"A\",\n",
      "      \"date\": \"2014-03-03T00:00:00\",\n",
      "      \"score\": 5\n",
      "    },\n",
      "    {\n",
      "      \"grade\": \"A\",\n",
      "      \"date\": \"2013-09-11T00:00:00\",\n",
      "      \"score\": 6\n",
      "    },\n",
      "    {\n",
      "      \"grade\": \"A\",\n",
      "      \"date\": \"2013-01-24T00:00:00\",\n",
      "      \"score\": 10\n",
      "    },\n",
      "    {\n",
      "      \"grade\": \"A\",\n",
      "      \"date\": \"2011-11-23T00:00:00\",\n",
      "      \"score\": 9\n",
      "    },\n",
      "    {\n",
      "      \"grade\": \"B\",\n",
      "      \"date\": \"2011-03-10T00:00:00\",\n",
      "      \"score\": 14\n",
      "    },\n",
      "    {\n",
      "      \"grade\": \"C\",\n",
      "      \"score\": 1,\n",
      "      \"comment\": \"This is too expensive!\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "result = client.demo_db.demo_collection.find_one({\"_id\":\"30075445\"})\n",
    "print(json.dumps(result, indent=2, default=date_handler))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can also find this restaurant by name, but it might return multiple restaurants that happens to have the same name (although not in this case)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched documents: 1\n"
     ]
    }
   ],
   "source": [
    "result = client.demo_db.demo_collection.find(\n",
    "    {\"name\":\"Morris Park Bake Shop\"})\n",
    "print(\"Matched documents: \" + str(result.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If we are in the Bronx borough and it's lunch time and we want to find a restaurant in this area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched documents: 2338\n"
     ]
    }
   ],
   "source": [
    "result = client.demo_db.demo_collection.find(\n",
    "    {\"borough\":\"Bronx\"})\n",
    "print(\"Matched documents: \" + str(result.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If we are in the Bronx and only interested in Bakery:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched documents: 71\n"
     ]
    }
   ],
   "source": [
    "result = client.demo_db.demo_collection.find(\n",
    "    {\"borough\":\"Bronx\", \"cuisine\":\"Bakery\"})\n",
    "print(\"Matched documents: \" + str(result.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If we are in the Bronx and no interested in Bakery:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched documents: 2267\n"
     ]
    }
   ],
   "source": [
    "result = client.demo_db.demo_collection.find(\n",
    "    {\"borough\":\"Bronx\", \"cuisine\":{\"$ne\":\"Bakery\"}})\n",
    "print(\"Matched documents: \" + str(result.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If we want to find restaurants that are either Bakery or American:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched documents: 6874\n"
     ]
    }
   ],
   "source": [
    "result = client.demo_db.demo_collection.find(\n",
    "    {\"cuisine\":{\"$in\": [\"Bakery\", \"American\"]}})\n",
    "print(\"Matched documents: \" + str(result.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If we want to do a OR query on different fields: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched documents: 2958\n"
     ]
    }
   ],
   "source": [
    "result = client.demo_db.demo_collection.find(\n",
    "    {\"$or\": [{\"cuisine\":\"Bakery\"}, {\"borough\":\"Bronx\"}]})\n",
    "print(\"Matched documents: \" + str(result.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If we want to retrieve documents in a specific range, for example we want to find restaurants with zip code starting with 104xx:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched documents: 2353\n"
     ]
    }
   ],
   "source": [
    "result = client.demo_db.demo_collection.find(\n",
    "    {\"address.zipcode\":{\"$gt\": \"10400\", \"$lt\": \"10500\"}})\n",
    "print(\"Matched documents: \" + str(result.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that if we want to query a file that contains an array with multiple conditional operators, the filed as a whole will match if either a single array element meets the conditions or a combination of array elements meet the conditions.  \n",
    "- If we want to do an exact-match query on embedded documents(or array), for instance, we would like to find the restaurant based on the coordinate, the following query can do the job. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched documents: 1\n",
      "Matched documents: 0\n"
     ]
    }
   ],
   "source": [
    "# correct coordinate\n",
    "result = client.demo_db.demo_collection.find(\n",
    "    {\"address.coord\": [-73.856077, 40.848447]})\n",
    "print(\"Matched documents: \" + str(result.count()))\n",
    "\n",
    "# if we flip the coordinates\n",
    "result = client.demo_db.demo_collection.find(\n",
    "    {\"address.coord\": [40.848447, -73.856077]})\n",
    "print(\"Matched documents: \" + str(result.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the embedded document must exactly the field, including the order, which makes sense in our case. \n",
    "- But if we want to treat the array as a set and ignore the order: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched documents: 1\n",
      "Matched documents: 1\n"
     ]
    }
   ],
   "source": [
    "# correct coordinate\n",
    "result = client.demo_db.demo_collection.find(\n",
    "    {\"address.coord\": {\"$all\": [-73.856077, 40.848447]}})\n",
    "print(\"Matched documents: \" + str(result.count()))\n",
    "\n",
    "# if we flip the coordinates\n",
    "result = client.demo_db.demo_collection.find(\n",
    "    {\"address.coord\": {\"$all\": [40.848447, -73.856077]}})\n",
    "print(\"Matched documents: \" + str(result.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate Document\n",
    "Of course in NoSQL we can also perform aggregations on documents, just like the GROUPBY operation in relational database. \n",
    "For example, if we want to know the total number of different cuisine sorted by the frequency:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'count': 6183, '_id': 'American'}\n",
      "{'count': 2418, '_id': 'Chinese'}\n",
      "{'count': 1214, '_id': 'CafÃ©/Coffee/Tea'}\n",
      "{'count': 1163, '_id': 'Pizza'}\n",
      "{'count': 1069, '_id': 'Italian'}\n"
     ]
    }
   ],
   "source": [
    "pipeline = [\n",
    "        {\"$unwind\": \"$cuisine\"},\n",
    "        {\"$group\": {\"_id\": \"$cuisine\", \"count\": {\"$sum\": 1}}},\n",
    "        {\"$sort\": SON([(\"count\", -1)])}]\n",
    "\n",
    "result = client.demo_db.demo_collection.aggregate(pipeline)\n",
    "\n",
    "count = 0\n",
    "for r in result:\n",
    "    if(count >= 5):\n",
    "        break\n",
    "    print(r)\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MapReduce Document\n",
    "Another even cooler feature for MongoDB  is that you can use the mapReduce framework for the aggregation. We can define our own map and reduce functions and apply it on the data. For example, we want to calculate the average score for different level grades. The mapper would produce (grade, score) tuple for each data and the reducer will group tuples that have the same grade together and calculate the average score in the end. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': 'A', 'value': 4.310672030330556}\n",
      "{'_id': 'B', 'value': 16.029527949429514}\n",
      "{'_id': 'C', 'value': 33.150695668621594}\n",
      "{'_id': 'Not Yet Graded', 'value': 18.07369160359854}\n",
      "{'_id': 'P', 'value': 4.801638104421059}\n",
      "{'_id': 'Z', 'value': 25.672659777312138}\n"
     ]
    }
   ],
   "source": [
    "mapper = Code(\"\"\"\n",
    "    function() {\n",
    "        this.grades.forEach(function(g) {\n",
    "            emit(g.grade, g.score);\n",
    "        });\n",
    "    }\"\"\")\n",
    "\n",
    "reducer = Code(\"\"\"\n",
    "               function (key, values) {\n",
    "                  var total = 0;\n",
    "                  var count = 0;\n",
    "                  for (var i = 0; i < values.length; i++) {\n",
    "                    total += values[i];\n",
    "                    count += 1\n",
    "                  }\n",
    "                  return total / count;\n",
    "                }\n",
    "                \"\"\")\n",
    "\n",
    "# result will be stored in the 'output' collection\n",
    "result = client.demo_db.demo_collection.map_reduce(\n",
    "    mapper, reducer, \"demo_output\")\n",
    "\n",
    "for doc in result.find():\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have the average score result, you can tell that this is not a real-world dataset but you get the idea :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete Document\n",
    "Finally, if we want to remove some documents from the collection, for example, if we want to remove Bakery from the dataset, we can do the following: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted documents using delete_one: 1\n",
      "Deleted documents using delete_many: 690\n"
     ]
    }
   ],
   "source": [
    "# remove only one record that match from the collection\n",
    "drop_results = client.demo_db.demo_collection.delete_one({'cuisine':'Bakery'})\n",
    "print(\"Deleted documents using delete_one: \"+ str(drop_results.deleted_count))\n",
    "\n",
    "# remove all the records that match from the collection\n",
    "drop_results = client.demo_db.demo_collection.delete_many({'cuisine':'Bakery'})\n",
    "print(\"Deleted documents using delete_many: \"+ str(drop_results.deleted_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to drop the entire collection, simple use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available collection before dropping: \n",
      "demo_output\n",
      "demo_collection\n",
      "\n",
      "Available collection after dropping: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Available collection before dropping: \")\n",
    "cols = client.demo_db.collection_names()\n",
    "for c in cols:\n",
    "    print(c)\n",
    "print(\"\")\n",
    "\n",
    "client.demo_db.demo_collection.drop()\n",
    "client.demo_db.demo_output.drop()\n",
    "\n",
    "print(\"Available collection after dropping: \")\n",
    "cols = client.demo_db.collection_names()\n",
    "for c in cols:\n",
    "    print(c)\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the end, you should shutdown the backend MongoDB server by using Ctrl+c or simplying closing the terminial the server is running on.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial only covers the basic funtionalities of MongoDB and how it handles semi-structured data. The tutorial has not talked about another important feature of NoSQL: scalability. I have provided some readings about sharding in the references below. \n",
    "\n",
    "1. MongoDB - https://www.mongodb.com\n",
    "2. PyMongo - https://api.mongodb.com/python/current/\n",
    "3. High Scalability With MongoDB Sharding - https://dzone.com/articles/divide-and-conquer-high-scalability-with-mongodb-t\n",
    "4. Restaurant Dataset - https://raw.githubusercontent.com/mongodb/docs-assets/primer-dataset/primer-dataset.json\n",
    "5. MongoDB Source Code - https://github.com/mongodb/mongo\n",
    "6. MongoDB Operator Cheatsheet - https://blog.codecentric.de/files/2012/12/MongoDB-CheatSheet-v1_0.pdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
