{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial Overview\n",
    "The purpose of this tutorial is walking you through the whole process of sentiment analysis by building deep learning models. Sentiment analysis is a binary classifier to determine whether a piece of text is postive or negative, so that the attitude of a author can be derived. Sentiment analysis is widely used in marketing, political election, and public opinion analysis. This toturial will use a Python deep learning library Keras to build models by different approaches, and evaluate performance by several benchmarks.\n",
    "### Outcome\n",
    "After reading this tutorial you will know:\n",
    "- How to prepare and preprocese data to make it available to build deep learning models\n",
    "- How to use deep learning packages (Keras and Tensorflow) to build models\n",
    "- How to develop and fit CNN (Convolutional Neural Network) and RNN (Recurrent Neural Network) for sentiment classfication\n",
    "- How to tune parameters and configration of neural networks to improve correctness\n",
    "- How to use Tweepy to pull out data from Twitter to evaluate performance by unseen data\n",
    "\n",
    "\n",
    "### Dataset Description\n",
    "We will use [IMDB Movie Review](http://ai.stanford.edu/~amaas/data/sentiment/) to train our models. You can learn more and download the dataset through the link. The dataset contains a set of 25,000 highly polar movie reviews. In this tutorial, only the data from training dataset will be used, including 12,500 positive and negative reviews, the data is in pos and neg folders.\n",
    "\n",
    "\n",
    "### Table of Contents:\n",
    "- [Installing the libraries](#Installing-Libraries)\n",
    "- [Data Loading and Preprocessing](#Data-Loading-and-Preprocessing)\n",
    "- [Convolutional Neural Network Model](#Convolutional-Neural-Network-Model)\n",
    "- [LSTM Recurrent Neural Network Model](#LSTM-Recurrent-Neural-Network-Model)\n",
    "- [Performance Compare with TextBlob and Future Work](#Performance-Compare-with-TextBlob-and-Future-Work)\n",
    "- [Reference](#Reference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installing Libraries\n",
    "\n",
    "This tutorial is developed to run under Python 3.7. The packages we need to install are:\n",
    "\n",
    "- Keras: Keras is a Python deep learning library building on Tensorflow and Theano\n",
    "- Tweepy: Tweepy make is easier retrive Twitter by Twitter API\n",
    "- TextBlob: TextBlob is a Python library for NLP tasks such as sentiment analysis, POS etc\n",
    "- Numpy, Pandas, Matplotlib\n",
    "\n",
    "All of them can be installed by:\n",
    "\n",
    "    $ conda install package_name\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading and Preprocessing\n",
    "\n",
    "Loading and Cleaning data\n",
    "Row 5 stores tweet content. Row 0 indicates if the sentiment of this tweet is postive (0 means negative, 1 means positive)\n",
    "\n",
    "Cleaning rule:\n",
    "1. remove those rows that either sentiment or content is missing\n",
    "2. extract sentiment and tweet content row\n",
    "3. shuffle rows to mix positive and negative tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading\n",
    "\n",
    "Download the dataset from Stanford AI website: http://ai.stanford.edu/~amaas/data/sentiment/, unzip and only keep the \"train\" folder. There shoule be \"neg\" and \"pos\" subfolders within. \n",
    "\n",
    "We load the dataset by Blob and Pandas. Blob will read all the files with the extension \".txt\" into a Python list. Then positive and negative reviews and their corresponding labels are assemble into a Pandas dataframe, and shuffle the dataframe to mix positive and negative reviews. Finally, we calculate the average review length for further vectorizing use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GetReviews will read all files into a Python list, and return the list.\n",
    "# Each item in the list is a file content\n",
    "def getReviews(path):\n",
    "    # read all files with .txt \n",
    "    path = path + '*.txt'\n",
    "    files = glob.glob(path)\n",
    "    review = []\n",
    "    for file in files:\n",
    "        text = open(file).read()\n",
    "        review.append(text)\n",
    "    return review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>I don't know what movie some of these other people watched, but they must have seen a different ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>I just couldn't stop laughing!! This movie is incredibly funny and stupid! But, never mind that,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>I happened to watch this movie by chance some days ago while flipping channels. My expectations ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok, first the good: Cher's performance and the cinematography. Although I'm no Cher fan, she giv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>There is one detail, which is not very common for Jackie Chan movies, but which is present here....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sentiment                                                                                                 Text\n",
       "0          1  I don't know what movie some of these other people watched, but they must have seen a different ...\n",
       "1          0  I just couldn't stop laughing!! This movie is incredibly funny and stupid! But, never mind that,...\n",
       "2          1  I happened to watch this movie by chance some days ago while flipping channels. My expectations ...\n",
       "3          0  Ok, first the good: Cher's performance and the cinematography. Although I'm no Cher fan, she giv...\n",
       "4          1  There is one detail, which is not very common for Jackie Chan movies, but which is present here...."
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load positive reviews from train folder\n",
    "pos_reviews = getReviews('./aclImdb/train/pos/')\n",
    "# label positive reviews as 1\n",
    "pos_label = [1] * len(pos_reviews) \n",
    "# load negative reviews from train folder\n",
    "neg_reviews = getReviews('./aclImdb/train/neg/')\n",
    "# label negatibe reviews as 0\n",
    "neg_label = [0] * len(pos_reviews) \n",
    "df = pd.DataFrame(\n",
    "    {'Sentiment': pos_label + neg_label,\n",
    "    'Text': pos_reviews + neg_reviews\n",
    "    })\n",
    "df = df.sample(frac=1).reset_index(drop=True) # shuffle\n",
    "# show the summary of the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet length: \n",
      "Mean 233.79 words (173.729557)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x130c585f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# average length of tweets\n",
    "print(\"Tweet length: \")\n",
    "result = [len(x.split()) for x in df.Text]\n",
    "print(\"Mean %.2f words (%f)\" % (np.mean(result), np.std(result)))\n",
    "# plot review length\n",
    "plt.boxplot(result)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "From the boxplot we can find the average review length is 234 with a 174 standard deviation. So we set the length fo review as 400 to cover most of the reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing \n",
    "\n",
    "In this part, we perform text preprocessing on the tweet corpus using NLP techniques.\n",
    "Keras requires the input format a matrix with shape(a, b), where a is the number of reviews, and b is the sequence length of each review (which is 400 in this case)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is vectorizing the text corpus. We tokenize tweets using keras.preprocessing.text package. After tokenizing, texts are encoded as a sequence of integer value\n",
    "\n",
    "We only keep the most common 10,000 words after removing all punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "docs = df.Text\n",
    "max_words = 10000\n",
    "# create the tokenizer\n",
    "t = Tokenizer(num_words=max_words)\n",
    "# fit the tokenizer on the documents\n",
    "t.fit_on_texts(docs)\n",
    "# encode documents in the dataset using the fitted tokenizer\n",
    "encoded_docs = t.texts_to_sequences(docs)\n",
    "# print(encoded_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we pads sequence to make every review has the same length\n",
    "(400 is the length of one review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 400)\n",
      "[[   0    0    0 ...,  146   11   17]\n",
      " [   0    0    0 ...,   73   50  438]\n",
      " [   0    0    0 ...,  287    3  103]\n",
      " ..., \n",
      " [   0    0    0 ...,    5   64    9]\n",
      " [   0    0    0 ...,  718  155  155]\n",
      " [   0    0    0 ...,   20  126 4178]]\n"
     ]
    }
   ],
   "source": [
    "from keras import preprocessing\n",
    "max_length = 400\n",
    "# pad or remove values from the start of each sequence\n",
    "encoded_docs = preprocessing.sequence.pad_sequences(encoded_docs, maxlen=max_length)\n",
    "print (encoded_docs.shape)\n",
    "print (encoded_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split dataset\n",
    "Split the dataset into training (50%) and validation (50%) sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(encoded_docs, df.Sentiment, test_size=0.5, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network Model\n",
    "\n",
    "In this part, we will used the dataframe we created in the last part to develop a Convolutional Neural Network model. CNN is designed to analyze spatial structure data or imagery data. As we have converted every review to a sequence of words. The sequence of words can be treated as a one-dimensional vector, then CNN can learn to recognize sentence structure as recognizing images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build CNN Model \n",
    "\n",
    "In this part, we will walk through every layer of the CNN model we build.\n",
    "\n",
    "1. The first layer is an Embedding layer, which is the input layer. The basic idea of word embedding is turning postive integers into dense vectors, so that each word is mapped into a high-dimensioanl space. In this tutorial, we set embedding_dim as 64, which means each word is represented as a 64-dimension vector\n",
    "\n",
    "2. After the embedding layer, there is a Conv1D layer.Conv1D is used for one dimensional data. This layer will use 32 different siliding windows and the size of each window is 3.\n",
    "\n",
    "3. Next is a MaxPooling1D layer for temporal data to sample features from a 2*2 area\n",
    "\n",
    "4. Then We flatten the input layer into one dimensional\n",
    "\n",
    "5. Since the output is eithor 0 or 1, the output layer has one neuron and activated by sigmoid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_9 (Embedding)      (None, 400, 64)           640000    \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 400, 32)           6176      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 200, 32)           0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 6400)              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 250)               1600250   \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 251       \n",
      "=================================================================\n",
      "Total params: 2,246,677\n",
      "Trainable params: 2,246,677\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/5\n",
      " - 21s - loss: 0.5564 - acc: 0.6856 - val_loss: 0.4673 - val_acc: 0.7905\n",
      "Epoch 2/5\n",
      " - 20s - loss: 0.2528 - acc: 0.8989 - val_loss: 0.2980 - val_acc: 0.8817\n",
      "Epoch 3/5\n",
      " - 19s - loss: 0.1667 - acc: 0.9372 - val_loss: 0.2717 - val_acc: 0.8901\n",
      "Epoch 4/5\n",
      " - 20s - loss: 0.1066 - acc: 0.9638 - val_loss: 0.3238 - val_acc: 0.8870\n",
      "Epoch 5/5\n",
      " - 19s - loss: 0.0615 - acc: 0.9806 - val_loss: 0.3700 - val_acc: 0.8862\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, SimpleRNN, Dense, Flatten\n",
    "from keras.layers.convolutional import MaxPooling1D, Conv1D\n",
    "# Use a 64-dimension vector to represent each word\n",
    "embedding_dim = 64\n",
    "# create the model\n",
    "cnn_model = Sequential()\n",
    "cnn_model.add(Embedding(max_words, embedding_dim, input_length=max_length))\n",
    "cnn_model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "cnn_model.add(MaxPooling1D(pool_size=2))\n",
    "cnn_model.add(Flatten())\n",
    "cnn_model.add(Dense(250, activation='relu'))\n",
    "cnn_model.add(Dense(1, activation='sigmoid'))\n",
    "# Complie the model\n",
    "cnn_model.compile(loss='binary_crossentropy', \n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "print(cnn_model.summary())\n",
    "\n",
    "# Train the model, training the model 5 times, using 128 samples in each pass\n",
    "history = cnn_model.fit(X_train, y_train, \n",
    "          validation_data=(X_test, y_test), \n",
    "          epochs=5, batch_size=128, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Evaluation\n",
    "\n",
    "In this part, we can see how performace changes by epochs and the its final accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 88.62%\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFxGJkP8HI2CRzqivrhUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x145f0ecc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Final evaluation of the model\n",
    "scores = cnn_model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Recurrent Neural Network Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, we will work with Recurrent Neural Network to develop another model. Long Short Term Memory (LSTM) is used to improve the performace of RNN. One of the problems of RNN is that when the length of a text growing, even though it is designed to learn recurrently, it loses the ability to connect to information far away. In order to address the long-term dependency problem, so that the model can remember information for long period of time. \n",
    "\n",
    "The difference between LSTM and CNN model is that the Conv1D and MaxPooling layer are replaced by LSTM layer. In our case, we use 200 units as memory units and set dropout to address overfitting issue\n",
    "\n",
    "The LSTM model is activated by Sigmoid as Sigmoid can output 0 or 1, it can help the model decide to store or forget certain information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_10 (Embedding)     (None, 400, 32)           320000    \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 100)               53200     \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 373,301\n",
      "Trainable params: 373,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/1\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Dense, LSTM\n",
    "np.random.seed(7)\n",
    "lstm_model = Sequential()\n",
    "embedding_dim = 32\n",
    "lstm_model.add(Embedding(max_words, embedding_dim, input_length = max_length))\n",
    "# We use a LSTM layer\n",
    "lstm_model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "cnn_model.add(Dense(250, activation='relu'))\n",
    "lstm_model.add(Dense(1, activation='sigmoid'))\n",
    "lstm_model.summary()\n",
    "# Complie the model\n",
    "lstm_model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])\n",
    "\n",
    "history = lstm_model.fit(X_train, y_train, \n",
    "          validation_data=(X_test, y_test), \n",
    "          epochs=1, batch_size=64, verbose=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 83.26%\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation of the model\n",
    "scores = lstm_model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Application: Analyze Tweet Sentiment\n",
    "\n",
    "In this part, we use the trained model to predict the sentiments of Donald Trump's twitter. First, we use Twitter API together with an library Tweepy to pull Trump's tweets. Then we preprocess the tweets by the same rules we process the training dataset.  \n",
    "\n",
    "** The filter rule is designed for extracting contents from Trump's twitter account. If you try other's Twitter, the function may fail due to the format of tweet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "def getTweetsByName(query):\n",
    "    consumer_key = 'bxA0fKeNXosrxAVnD9vEopblj'\n",
    "    consumer_secret = 'gU55fTD7fxyrwxS9irs7DTzHALoKGqAbCwV8bhP8AY50vDpqLK'\n",
    "    access_token = '4518122892-fn6CoLOGqMuD1b0IxNCqx5tbKIRJZTtRucoFeeM'\n",
    "    access_token_secret = '2Osqvjqsn5Py8Yf773xVUv4jRsYIOvwn3SGyQTNFygG9w'\n",
    "    \n",
    "    auth = tweepy.OAuthHandler(consumer_key = consumer_key, \n",
    "                               consumer_secret = consumer_secret)\n",
    "    auth.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "    api = tweepy.API(auth)\n",
    "    tweets = api.user_timeline(screen_name=query)\n",
    "    res = []\n",
    "    for tweet in tweets:\n",
    "        text = tweet.text.strip()\n",
    "        # filter out tweets without text, which only contains video or link\n",
    "        if text.startswith('https'):\n",
    "            continue\n",
    "        # remove \"RT\" (Retweet label)\n",
    "        if text.startswith('RT @'):\n",
    "            text = text[text.find(':') + 1:]\n",
    "        # extract text from tweet, removing link\n",
    "        idx = text.find('https')\n",
    "        # if no link in this tweet\n",
    "        if idx == -1:\n",
    "            res.append(text)\n",
    "        # otherwise remove link\n",
    "        else:\n",
    "            res.append(text[:idx])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call the function to retrive tweets and preprocess to the tokenizer we trained before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "docs = getTweetsByName('realDonaldTrump')\n",
    "processed_docs = t.texts_to_sequences(docs)\n",
    "processed_docs = preprocessing.sequence.pad_sequences(processed_docs, maxlen=max_length, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the trained model to predict the first 20 tweets from trump.\n",
    "\n",
    "** One reason causing inaccuracy: **\n",
    "\n",
    "One reason may lead to the inaccurate prediction is the length difference between training dataset and tweets. \n",
    "\n",
    "The averge length of movie reviews is 300, while that of tweet is 70. Due to the limited number of words, models may hard extract enough features to make prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19, 400)\n",
      "    Score By CNN                                                                                                Tweet\n",
      "0       0.716297  Governor Jerry “Moonbeam” Brown pardoned 5 criminal illegal aliens whose crimes include (1) Kidn...\n",
      "1       0.551064  ...does not include the Fake Washington Post, which is used as a “lobbyist” and should so  REGIS...\n",
      "2       0.447002  While we are on the subject, it is reported that the U.S. Post Office will lose $1.50 on average...\n",
      "3       0.749204  Washington spent trillions building up foreign countries while allowing OUR OWN infrastructure t...\n",
      "4       0.627715  JOBS, JOBS, JOBS! Unemployment claims have fallen to a 45-year low. Together, we are making the ...\n",
      "5       0.593934  We are going to REBUILD our crumbling infrastructure, and there is no better place to begin this...\n",
      "6       0.515603  I have stated my concerns with Amazon long before the Election. Unlike others, they pay little o...\n",
      "7       0.588390  ....In the interim, Hon. Robert Wilkie of DOD will serve as Acting Secretary. I am thankful for ...\n",
      "8       0.601905  I am pleased to announce that I intend to nominate highly respected Admiral Ronny L. Jackson, MD...\n",
      "9       0.639244                             Great briefing this afternoon on the start of our Southern Border WALL! \n",
      "10      0.740487  ....release known dangerous criminals into communities across the State. All citizens have the r...\n",
      "11      0.694244  My Administration stands in solidarity with the brave citizens in Orange County defending their ...\n",
      "12      0.670796  .@USTradeRep just announced an agreement in principle with South Korea on KORUS! A great deal fo...\n",
      "13      0.627706  Received message last night from XI JINPING of China that his meeting with KIM JONG UN went very...\n",
      "14      0.574347  For years and through many administrations, everyone said that peace and the denuclearization of...\n",
      "15      0.586153  THE SECOND AMENDMENT WILL NEVER BE REPEALED! As much as Democrats would like to see this happen,...\n",
      "16      0.639235  I am very pleased to welcome the opioid memorial to the President's Park in April. I encourage a...\n",
      "17      0.586778   Because of the $700 &amp; $716 Billion Dollars gotten to rebuild our Military, many jobs are cr...\n",
      "18      0.572932  Trade talks going on with numerous countries that, for many years, have not treated the United S...\n"
     ]
    }
   ],
   "source": [
    "# pd.options.display.max_colwidth = 100\n",
    "# makeing predictions \n",
    "print (processed_docs.shape)\n",
    "sentiments_cnn = cnn_model.predict(processed_docs)\n",
    "# sentiments_rnn = lstm_model.predict(processed_docs)\n",
    "# combine tweets and corresponding sentiment together\n",
    "predict_df = pd.DataFrame(\n",
    "    {'Score By CNN': sentiments_cnn.flatten(),\n",
    "    'Tweet': docs\n",
    "    })\n",
    "print (predict_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Compare with TextBlob and Future Work\n",
    "\n",
    "In this part, we compare the performance between the model we trained using IMDB dataset and a third-party NLP library TextBlob. TextBlob allows the content as input and predict the sentiment is positive, negative or neutral. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Score By CNN                                              Tweet TextBlob_Result\n",
      "0       0.716297  Governor Jerry “Moonbeam” Brown pardoned 5 cri...        negative\n",
      "1       0.551064  ...does not include the Fake Washington Post, ...        negative\n",
      "2       0.447002  While we are on the subject, it is reported th...        negative\n",
      "3       0.749204  Washington spent trillions building up foreign...        positive\n",
      "4       0.627715  JOBS, JOBS, JOBS! Unemployment claims have fal...        positive\n",
      "5       0.593934  We are going to REBUILD our crumbling infrastr...        negative\n",
      "6       0.515603  I have stated my concerns with Amazon long bef...        negative\n",
      "7       0.588390  ....In the interim, Hon. Robert Wilkie of DOD ...         neutral\n",
      "8       0.601905  I am pleased to announce that I intend to nomi...        positive\n",
      "9       0.639244  Great briefing this afternoon on the start of ...        positive\n",
      "10      0.740487  ....release known dangerous criminals into com...        negative\n",
      "11      0.694244  My Administration stands in solidarity with th...        positive\n",
      "12      0.670796  .@USTradeRep just announced an agreement in pr...        positive\n",
      "13      0.627706  Received message last night from XI JINPING of...        positive\n",
      "14      0.574347  For years and through many administrations, ev...        positive\n",
      "15      0.586153  THE SECOND AMENDMENT WILL NEVER BE REPEALED! A...        positive\n",
      "16      0.639235  I am very pleased to welcome the opioid memori...        positive\n",
      "17      0.586778   Because of the $700 &amp; $716 Billion Dollar...        positive\n",
      "18      0.572932  Trade talks going on with numerous countries t...        positive\n"
     ]
    }
   ],
   "source": [
    "pd.options.display.max_colwidth = 50\n",
    "from textblob import TextBlob\n",
    "textbolb_res = []\n",
    "for doc in docs:\n",
    "    # predict using textblob\n",
    "    analysis = TextBlob(doc)\n",
    "    # set sentiment\n",
    "    if analysis.sentiment.polarity > 0:\n",
    "        textbolb_res.append('positive')\n",
    "    elif analysis.sentiment.polarity == 0:\n",
    "        textbolb_res.append( 'neutral')\n",
    "    else:\n",
    "        textbolb_res.append ('negative')\n",
    "predict_df['TextBlob_Result'] = pd.Series(textbolb_res)\n",
    "print (predict_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future Work\n",
    "- In this tutorial, we train the embedding layer using the IMDB dataset. To improve accuracy, we can try to use some pre-trained word embeddings such as GloVe and word2vec\n",
    "- We can use larger dataset with more epochs to improve  performance\n",
    "- We can always add more hidden layers and tune the parameters to improve performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference\n",
    "- http://colah.github.io/posts/2015-08-Understanding-LSTMs/\n",
    "- https://machinelearningmastery.com/predict-sentiment-movie-reviews-using-deep-learning/\n",
    "- http://deeplearning.net/tutorial/lstm.html\n",
    "- https://towardsdatascience.com/understanding-lstm-and-its-quick-implementation-in-keras-for-sentiment-analysis-af410fd85b47\n",
    "- http://ai.stanford.edu/~amaas/data/sentiment/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}