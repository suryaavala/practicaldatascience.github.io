{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction:\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial will give you an insight of the concept of Random Forests, how to use them and when to use them. I assume that the readers have the basic knowledge of decision trees. Random Forest is a supervised machine learning algorithm, it is used for classification as well as regression. We will see the implementation for a classification problem. It is one of the goto methods for data scientists in classification problems. Also, random forests perform well even without paramter tuning. Decision trees suﬀer from high variance. This means that if we change the training data even little, the decision trees change alot. Bootstrap aggregation, or bagging, is a general-purpose procedure for reducing the bagging variance of a statistical learning method; it is particularly useful and frequently used in the context of decision trees. \n",
    "\n",
    "In bagging, we bootstrap, by taking repeated samples from the (single) training data set. In this approach we generate B diﬀerent bootstrapped training data sets. We then train our model on the bth bootstrapped training set and average all the predictions. Random forests provide an improvement over bagged trees by decorrelating the trees. In this technique, we build a number of decision trees on bootstrapped training samples. But when building these decision trees, each time a split in a tree is considered, a random sample of say m predictors is chosen as split candidates from the full set of p predictors. The split is allowed to use only one of those m predictors. Thus, this ensures the randomness, and decreases the variance. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing the libraries:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before getting started, you need to install graphviz library which is used to visualize the decsion tree. You can install it using:\n",
    "\n",
    "$ pip install graphviz  \n",
    "\n",
    "or\n",
    "\n",
    "$conda install graphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import collections\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from sklearn.tree import export_graphviz\n",
    "import graphviz\n",
    "from sklearn import tree\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Description:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this tutorial, we will be using wine dataset available in sklearn library. It is hosted in the UCI machine learning repository https://archive.ics.uci.edu/ml/datasets/wine . It contains chemical analysis of the content of wines grown in the same region in Italy, but derived from three different cultivars. The instances are classified into three classes: 1, 2 and 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and exploring dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(178, 13)\n",
      "[0 1 2]\n",
      "Counter({1: 71, 0: 59, 2: 48})\n",
      "False\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113.0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
       "0    14.23        1.71  2.43               15.6      127.0           2.80   \n",
       "1    13.20        1.78  2.14               11.2      100.0           2.65   \n",
       "2    13.16        2.36  2.67               18.6      101.0           2.80   \n",
       "3    14.37        1.95  2.50               16.8      113.0           3.85   \n",
       "4    13.24        2.59  2.87               21.0      118.0           2.80   \n",
       "\n",
       "   flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
       "0        3.06                  0.28             2.29             5.64  1.04   \n",
       "1        2.76                  0.26             1.28             4.38  1.05   \n",
       "2        3.24                  0.30             2.81             5.68  1.03   \n",
       "3        3.49                  0.24             2.18             7.80  0.86   \n",
       "4        2.69                  0.39             1.82             4.32  1.04   \n",
       "\n",
       "   od280/od315_of_diluted_wines  proline  \n",
       "0                          3.92   1065.0  \n",
       "1                          3.40   1050.0  \n",
       "2                          3.17   1185.0  \n",
       "3                          3.45   1480.0  \n",
       "4                          2.93    735.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##loading wine data from sklearn with features and target variable\n",
    "data = load_wine()\n",
    "\n",
    "target = data.target\n",
    "features = data.data\n",
    "\n",
    "##Let us look at the size of the data\n",
    "print(features.shape)\n",
    "## There are 13 features and 178 rows\n",
    "\n",
    "##Let us check for the target classes\n",
    "print(np.unique(target))\n",
    "print(collections.Counter(target))\n",
    "## Here we have 71 in class 1, 59 in class 0 and 48 in class 2\n",
    "\n",
    "\n",
    "df = pd.DataFrame(features, columns=data.feature_names)\n",
    "## Let us check for null values in the dataframe\n",
    "print(df.isnull().values.any())\n",
    "## No NULL values found\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let us split data to train and test set 30% test size\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target,test_size=0.30,random_state=1000)\n",
    "\n",
    "## Fitting the model i.e. using train data set to train the random forest\n",
    "rf = RandomForestClassifier(criterion ='gini', n_estimators=100, oob_score=True, random_state=1000)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "##Predicting using the test data set\n",
    "predicted = rf.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 47, 0: 44, 2: 33})\n"
     ]
    }
   ],
   "source": [
    "print(collections.Counter(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us talk about few important parameters used for  tuning in Random forests:\n",
    "1. n_estimators: it is the number of trees in the random forest. More number of trees will decrease the variance and will be good for the model.\n",
    "2. oob_score: It is the out of bag error calculated on training dataset. We will dive deep into this in the following section.\n",
    "3. random_state: Each time you run the random forest algorithm, the models will change, as each tree chooses predictors to split randomly. To keep the results constant every time you run the random forest using same training set, you need to set the random_state. \n",
    "4. criterion: This is the objective function on which the split is based on. It could be gini or entropy. Both of these are discused in detail in later part of the tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the useful features of treebased models is that it helps for feature selection in data science problems. Many a times data scientists use tree based models in feature engineering, to select the features. Feature importance is computed using the mean decrease in Gini index, and expressed relative to the maximum. \n",
    "\n",
    "We will use sklearn library to see the feature importanace in our model. It measures the importance by looking at how much the tree nodes, which use that feature, reduce impurity across all trees in the forest. It computes this score for each feature after training and averages across the trees in the forest. Note that this importance values lie in 0-1. Also, the sum of all the feature importances is 1. Thus, we can analyze which features contribute the most in the prediction process. Many a times, you would want to drop the features with very low importance, as it would be leading to overfitting  of the model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking:\n",
      "1. feature: proline , importance: 0.172874\n",
      "2. feature: flavanoids , importance: 0.168300\n",
      "3. feature: color_intensity , importance: 0.132163\n",
      "4. feature: alcohol , importance: 0.131633\n",
      "5. feature: od280/od315_of_diluted_wines , importance: 0.131210\n",
      "6. feature: hue , importance: 0.069135\n",
      "7. feature: total_phenols , importance: 0.052826\n",
      "8. feature: alcalinity_of_ash , importance: 0.036188\n",
      "9. feature: magnesium , importance: 0.036119\n",
      "10. feature: malic_acid , importance: 0.028318\n",
      "11. feature: proanthocyanins , importance: 0.021559\n",
      "12. feature: ash , importance: 0.010107\n",
      "13. feature: nonflavanoid_phenols , importance: 0.009569\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAGZCAYAAAByjnEMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1fbafa17e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Feature Importance:\n",
    "importances = rf.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in rf.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "\n",
    "sorted_features_importances =[]\n",
    "\n",
    "for f in range(X_train.shape[1]):\n",
    "    sorted_features_importances.append(data.feature_names[indices[f]])\n",
    "    print(\"%d. feature: %s , importance: %f\" % (f + 1, data.feature_names[indices[f]], importances[indices[f]]))\n",
    "\n",
    "\n",
    "# Plot the feature importances of the forest\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(X_train.shape[1]), importances[indices],\n",
    "       color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(X_train.shape[1]), sorted_features_importances, rotation='vertical')\n",
    "plt.xlim([-1, X_train.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our model, we can see that proline has the highest importance, followed by flavanoids, color_intensity, alcohol, od280/od315_of_diluted_wines. We can also see that the importance of ash, nonflavanoid_phenols is too low."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us see how Random forest perform on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accurcay score is: 0.962963\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        15\n",
      "          1       1.00      0.92      0.96        24\n",
      "          2       0.88      1.00      0.94        15\n",
      "\n",
      "avg / total       0.97      0.96      0.96        54\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##Accuracy\n",
    "accuracy = accuracy_score(y_test, predicted)\n",
    "print(\"Accurcay score is: %f\" %(accuracy))\n",
    "\n",
    "## precision recall f1score\n",
    "print(classification_report(y_test, predicted, target_names= ['0','1','2']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Out Of Bag Error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us understand how Out of Bag Error gives an estimate of performace of Random forest. In Random forest, the trees are formed by bootstrapping the observations with replacement. Every observation is likely to be in a sample with a probability of 2/3. Which means it is used for training in approximately 2/3 of the trees, and is a part of test set for 1/3 of the trees in the random forest. Thus, each tree is trained for 2/3 of the samples and tested for 1/3 of the samples. OOB or Out of Bag error is the average of errors for the trees in which the ibservations are test set. Thus, in Random forests, we do not need to do cross-validation. This itself provides an estimate of the errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Out Of Bag error is: 0.032258\n"
     ]
    }
   ],
   "source": [
    "print(\"The Out Of Bag error is: %f\"%( 1- rf.oob_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us see how well our classifier is doing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVoAAAD8CAYAAAA2Y2wxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nABAYQQsAgRG0ABDY/wPFQCgmg3Kg9wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1fbb33a4c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "matrix = pd.DataFrame(confusion_matrix(y_test, predicted), columns=np.unique(target), index=np.unique(target))\n",
    "sns.heatmap(matrix, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2]\n"
     ]
    }
   ],
   "source": [
    "## Let us visualize underlying decision trees:\n",
    "## the following code produces .dot files for all the decion trees\n",
    "\n",
    "i_tree = 0\n",
    "class_names = np.unique(target)\n",
    "print(class_names)\n",
    "for tree_in_forest in rf.estimators_:\n",
    "    with open('tree_' + str(i_tree) + '.dot', 'w') as trees:\n",
    "        trees = tree.export_graphviz(tree_in_forest,feature_names=data.feature_names, class_names=['0','1','2'],out_file = trees)\n",
    "        graph = graphviz.Source(trees)  \n",
    "    i_tree = i_tree + 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To generate the decision trees http://webgraphviz.com/ has been used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gini Index and Entropy:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us understand how the decision trees are build. At each split, we need to consider an objective function. That is what the criterion parameter in the classifier accounts for.\n",
    "\n",
    "Gini index:\n",
    "It is the measure of probability of classifying a wrong label of a randomly chosen observation. It is 0 when all the subsets are pure or of the same class.\n",
    "\n",
    "Gini index= 1-$\\sum p^2$\n",
    "\n",
    "Thus, when you are choosing Gini index as your criterion, you would want to minimize the gini index.\n",
    "\n",
    "Entropy:\n",
    "Entropy defines how disorgnized the data is. For example if I have a node with 50 of class 1 and 50 of class 2, it is completely disorganized having entropy of 1. On the other hand, if I have a node with 95 of class 1 and 5 of class 2, it has less entropy. Thus, splitting on the latter will be more useful. It is 0, when the data is pure.\n",
    "\n",
    "Entropy = - p log p - q log q\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To understand how a decision tree splits using gini index or entropy, let us fit a decision tree classifier and calculate the gini indexes at each split. Please note, random forest does not split on minimum gini index of all features, but it uses the minimum index considering restricted predictors. This is to produce randomness in our model. To demostarte let us fit a decision tree classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\r\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\r\n",
       " -->\r\n",
       "<!-- Title: Tree Pages: 1 -->\r\n",
       "<svg width=\"531pt\" height=\"552pt\"\r\n",
       " viewBox=\"0.00 0.00 531.00 552.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 548)\">\r\n",
       "<title>Tree</title>\r\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-548 527,-548 527,4 -4,4\"/>\r\n",
       "<!-- 0 -->\r\n",
       "<g id=\"node1\" class=\"node\"><title>0</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"336,-544 187,-544 187,-461 336,-461 336,-544\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"261.5\" y=\"-528.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">petal width (cm) &lt;= 0.8</text>\r\n",
       "<text text-anchor=\"middle\" x=\"261.5\" y=\"-513.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">gini = 0.664</text>\r\n",
       "<text text-anchor=\"middle\" x=\"261.5\" y=\"-498.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 105</text>\r\n",
       "<text text-anchor=\"middle\" x=\"261.5\" y=\"-483.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [39, 34, 32]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"261.5\" y=\"-468.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = setosa</text>\r\n",
       "</g>\r\n",
       "<!-- 1 -->\r\n",
       "<g id=\"node2\" class=\"node\"><title>1</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"241.5,-417.5 129.5,-417.5 129.5,-349.5 241.5,-349.5 241.5,-417.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"185.5\" y=\"-402.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">gini = 0.0</text>\r\n",
       "<text text-anchor=\"middle\" x=\"185.5\" y=\"-387.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 39</text>\r\n",
       "<text text-anchor=\"middle\" x=\"185.5\" y=\"-372.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [39, 0, 0]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"185.5\" y=\"-357.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = setosa</text>\r\n",
       "</g>\r\n",
       "<!-- 0&#45;&gt;1 -->\r\n",
       "<g id=\"edge1\" class=\"edge\"><title>0&#45;&gt;1</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M235.132,-460.907C227.821,-449.652 219.874,-437.418 212.526,-426.106\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"215.427,-424.146 207.044,-417.667 209.557,-427.96 215.427,-424.146\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"201.849\" y=\"-438.421\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">True</text>\r\n",
       "</g>\r\n",
       "<!-- 2 -->\r\n",
       "<g id=\"node3\" class=\"node\"><title>2</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"415,-425 260,-425 260,-342 415,-342 415,-425\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"337.5\" y=\"-409.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">petal width (cm) &lt;= 1.75</text>\r\n",
       "<text text-anchor=\"middle\" x=\"337.5\" y=\"-394.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">gini = 0.5</text>\r\n",
       "<text text-anchor=\"middle\" x=\"337.5\" y=\"-379.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 66</text>\r\n",
       "<text text-anchor=\"middle\" x=\"337.5\" y=\"-364.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [0, 34, 32]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"337.5\" y=\"-349.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = versicolor</text>\r\n",
       "</g>\r\n",
       "<!-- 0&#45;&gt;2 -->\r\n",
       "<g id=\"edge2\" class=\"edge\"><title>0&#45;&gt;2</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M287.868,-460.907C293.586,-452.105 299.693,-442.703 305.598,-433.612\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"308.667,-435.313 311.179,-425.021 302.796,-431.5 308.667,-435.313\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"316.374\" y=\"-445.775\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">False</text>\r\n",
       "</g>\r\n",
       "<!-- 3 -->\r\n",
       "<g id=\"node4\" class=\"node\"><title>3</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"340.5,-306 182.5,-306 182.5,-223 340.5,-223 340.5,-306\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"261.5\" y=\"-290.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">petal length (cm) &lt;= 5.05</text>\r\n",
       "<text text-anchor=\"middle\" x=\"261.5\" y=\"-275.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">gini = 0.188</text>\r\n",
       "<text text-anchor=\"middle\" x=\"261.5\" y=\"-260.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 38</text>\r\n",
       "<text text-anchor=\"middle\" x=\"261.5\" y=\"-245.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [0, 34, 4]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"261.5\" y=\"-230.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = versicolor</text>\r\n",
       "</g>\r\n",
       "<!-- 2&#45;&gt;3 -->\r\n",
       "<g id=\"edge3\" class=\"edge\"><title>2&#45;&gt;3</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M311.132,-341.907C305.414,-333.105 299.307,-323.703 293.402,-314.612\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"296.204,-312.5 287.821,-306.021 290.333,-316.313 296.204,-312.5\"/>\r\n",
       "</g>\r\n",
       "<!-- 10 -->\r\n",
       "<g id=\"node11\" class=\"node\"><title>10</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"470.5,-298.5 358.5,-298.5 358.5,-230.5 470.5,-230.5 470.5,-298.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"414.5\" y=\"-283.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">gini = 0.0</text>\r\n",
       "<text text-anchor=\"middle\" x=\"414.5\" y=\"-268.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 28</text>\r\n",
       "<text text-anchor=\"middle\" x=\"414.5\" y=\"-253.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [0, 0, 28]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"414.5\" y=\"-238.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = virginica</text>\r\n",
       "</g>\r\n",
       "<!-- 2&#45;&gt;10 -->\r\n",
       "<g id=\"edge10\" class=\"edge\"><title>2&#45;&gt;10</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M364.215,-341.907C371.622,-330.652 379.673,-318.418 387.118,-307.106\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"390.098,-308.944 392.672,-298.667 384.251,-305.096 390.098,-308.944\"/>\r\n",
       "</g>\r\n",
       "<!-- 4 -->\r\n",
       "<g id=\"node5\" class=\"node\"><title>4</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"252.5,-187 92.5,-187 92.5,-104 252.5,-104 252.5,-187\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"172.5\" y=\"-171.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">sepal length (cm) &lt;= 4.95</text>\r\n",
       "<text text-anchor=\"middle\" x=\"172.5\" y=\"-156.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">gini = 0.057</text>\r\n",
       "<text text-anchor=\"middle\" x=\"172.5\" y=\"-141.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 34</text>\r\n",
       "<text text-anchor=\"middle\" x=\"172.5\" y=\"-126.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [0, 33, 1]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"172.5\" y=\"-111.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = versicolor</text>\r\n",
       "</g>\r\n",
       "<!-- 3&#45;&gt;4 -->\r\n",
       "<g id=\"edge4\" class=\"edge\"><title>3&#45;&gt;4</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M230.622,-222.907C223.788,-213.923 216.479,-204.315 209.431,-195.05\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"212.164,-192.861 203.324,-187.021 206.592,-197.099 212.164,-192.861\"/>\r\n",
       "</g>\r\n",
       "<!-- 7 -->\r\n",
       "<g id=\"node8\" class=\"node\"><title>7</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"430.5,-187 270.5,-187 270.5,-104 430.5,-104 430.5,-187\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"350.5\" y=\"-171.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">sepal length (cm) &lt;= 6.05</text>\r\n",
       "<text text-anchor=\"middle\" x=\"350.5\" y=\"-156.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">gini = 0.375</text>\r\n",
       "<text text-anchor=\"middle\" x=\"350.5\" y=\"-141.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 4</text>\r\n",
       "<text text-anchor=\"middle\" x=\"350.5\" y=\"-126.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [0, 1, 3]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"350.5\" y=\"-111.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = virginica</text>\r\n",
       "</g>\r\n",
       "<!-- 3&#45;&gt;7 -->\r\n",
       "<g id=\"edge7\" class=\"edge\"><title>3&#45;&gt;7</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M292.378,-222.907C299.212,-213.923 306.521,-204.315 313.569,-195.05\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"316.408,-197.099 319.676,-187.021 310.836,-192.861 316.408,-197.099\"/>\r\n",
       "</g>\r\n",
       "<!-- 5 -->\r\n",
       "<g id=\"node6\" class=\"node\"><title>5</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"107,-68 0,-68 0,-0 107,-0 107,-68\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"53.5\" y=\"-52.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">gini = 0.0</text>\r\n",
       "<text text-anchor=\"middle\" x=\"53.5\" y=\"-37.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 1</text>\r\n",
       "<text text-anchor=\"middle\" x=\"53.5\" y=\"-22.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [0, 0, 1]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"53.5\" y=\"-7.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = virginica</text>\r\n",
       "</g>\r\n",
       "<!-- 4&#45;&gt;5 -->\r\n",
       "<g id=\"edge5\" class=\"edge\"><title>4&#45;&gt;5</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M128.189,-103.726C118.078,-94.423 107.341,-84.5428 97.2541,-75.2612\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"99.4173,-72.4953 89.6886,-68.2996 94.6774,-77.6464 99.4173,-72.4953\"/>\r\n",
       "</g>\r\n",
       "<!-- 6 -->\r\n",
       "<g id=\"node7\" class=\"node\"><title>6</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"241.5,-68 125.5,-68 125.5,-0 241.5,-0 241.5,-68\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"183.5\" y=\"-52.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">gini = 0.0</text>\r\n",
       "<text text-anchor=\"middle\" x=\"183.5\" y=\"-37.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 33</text>\r\n",
       "<text text-anchor=\"middle\" x=\"183.5\" y=\"-22.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [0, 33, 0]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"183.5\" y=\"-7.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = versicolor</text>\r\n",
       "</g>\r\n",
       "<!-- 4&#45;&gt;6 -->\r\n",
       "<g id=\"edge6\" class=\"edge\"><title>4&#45;&gt;6</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M176.596,-103.726C177.43,-95.4263 178.31,-86.6671 179.152,-78.2834\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"182.638,-78.5994 180.155,-68.2996 175.673,-77.8997 182.638,-78.5994\"/>\r\n",
       "</g>\r\n",
       "<!-- 8 -->\r\n",
       "<g id=\"node9\" class=\"node\"><title>8</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"397.5,-68 281.5,-68 281.5,-0 397.5,-0 397.5,-68\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"339.5\" y=\"-52.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">gini = 0.0</text>\r\n",
       "<text text-anchor=\"middle\" x=\"339.5\" y=\"-37.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 1</text>\r\n",
       "<text text-anchor=\"middle\" x=\"339.5\" y=\"-22.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [0, 1, 0]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"339.5\" y=\"-7.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = versicolor</text>\r\n",
       "</g>\r\n",
       "<!-- 7&#45;&gt;8 -->\r\n",
       "<g id=\"edge8\" class=\"edge\"><title>7&#45;&gt;8</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M346.404,-103.726C345.57,-95.4263 344.69,-86.6671 343.848,-78.2834\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"347.327,-77.8997 342.845,-68.2996 340.362,-78.5994 347.327,-77.8997\"/>\r\n",
       "</g>\r\n",
       "<!-- 9 -->\r\n",
       "<g id=\"node10\" class=\"node\"><title>9</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"523,-68 416,-68 416,-0 523,-0 523,-68\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"469.5\" y=\"-52.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">gini = 0.0</text>\r\n",
       "<text text-anchor=\"middle\" x=\"469.5\" y=\"-37.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 3</text>\r\n",
       "<text text-anchor=\"middle\" x=\"469.5\" y=\"-22.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [0, 0, 3]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"469.5\" y=\"-7.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = virginica</text>\r\n",
       "</g>\r\n",
       "<!-- 7&#45;&gt;9 -->\r\n",
       "<g id=\"edge9\" class=\"edge\"><title>7&#45;&gt;9</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M394.811,-103.726C404.922,-94.423 415.659,-84.5428 425.746,-75.2612\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"428.323,-77.6464 433.311,-68.2996 423.583,-72.4953 428.323,-77.6464\"/>\r\n",
       "</g>\r\n",
       "</g>\r\n",
       "</svg>\r\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x1fbb3612d68>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## we will use iris dataset to learn about splitting in decision trees:\n",
    "\n",
    "## we need to have graphviz in the ystem path\n",
    "import os\n",
    "os.environ[\"PATH\"] += os.pathsep + 'C:/Program Files (x86)/Graphviz2.38/bin/'\n",
    "\n",
    "decision_data = load_iris()\n",
    "target = decision_data.target\n",
    "features = decision_data.data\n",
    "\n",
    "##splitting data to test and train\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target,test_size=0.30,random_state=1000)\n",
    "\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "\n",
    "##fitting the decision tree classifier\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "##predicting using the above model\n",
    "clf.predict(X_test)\n",
    "\n",
    "##using graphviz to visualize our tree\n",
    "dot_data = tree.export_graphviz(clf, out_file=None, \n",
    "                         feature_names=decision_data.feature_names,  \n",
    "                         class_names=decision_data.target_names)  \n",
    "graph = graphviz.Source(dot_data)  \n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.664\n",
      "0.0\n",
      "0.5\n",
      "0.188\n",
      "0.057\n",
      "0.0\n",
      "0.0\n",
      "0.375\n",
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "## let's fetch data of the above tree and calculate the gini index for each node\n",
    "## the tree traversal is preorder, i.e. preorder\n",
    "\n",
    "def calGini(values):\n",
    "    if(len(values)==1):\n",
    "        values = np.append(values,0)\n",
    "        values = np.append(values,0)\n",
    "    if(len(values)==2):\n",
    "        values = np.append(values,0)\n",
    "    total = values[0]+values[1]+values[2]\n",
    "\n",
    "    gini = 1-((values[0]/total)**2 + (values[1]/total)**2 + (values[2]/total)**2)\n",
    "    return (round(gini,3))\n",
    "    \n",
    "    \n",
    "import re\n",
    "value = re.compile(r'value =( \\[[0-9, ]*\\])')\n",
    "values =value.findall(dot_data)\n",
    "\n",
    "for classes in values:\n",
    "    classes = classes.split(',')\n",
    "    class0 = int(classes[0].strip()[1:])\n",
    "    class1 = int(classes[1].strip())\n",
    "    class2 = int(classes[2].strip()[:-1])\n",
    "    print(calGini([class0,class1,class2]))\n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we know how to calculate the gini index, let us try to see what all possible splits are there at node 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weighted_gini:  0.569438095238\n",
      "0.111 0.658\n",
      "(4.9, 'sepal length (cm)')\n",
      "[16  0  1]\n",
      "[23 34 31]\n",
      "weighted_gini:  0.446876190476\n",
      "0.478 0.402\n",
      "(4.5, 'petal length (cm)')\n",
      "[39 22  1]\n",
      "[ 0 12 31]\n",
      "weighted_gini:  0.4004\n",
      "0.546 0.0\n",
      "(1.7, 'petal width (cm)')\n",
      "[39 34  4]\n",
      "[ 0  0 28]\n",
      "weighted_gini:  0.32819047619\n",
      "0.049 0.5\n",
      "(3.0, 'petal length (cm)')\n",
      "[39  1]\n",
      "[ 0 33 32]\n",
      "weighted_gini:  0.314285714286\n",
      "0.0 0.5\n",
      "(1.7, 'petal length (cm)')\n",
      "[39]\n",
      "[ 0 34 32]\n",
      "weighted_gini:  0.314285714286\n",
      "0.0 0.5\n",
      "(1.7, 'petal length (cm)')\n",
      "[39]\n",
      "[ 0 34 32]\n",
      "weighted_gini:  0.314285714286\n",
      "0.0 0.5\n",
      "(1.7, 'petal length (cm)')\n",
      "[39]\n",
      "[ 0 34 32]\n",
      "weighted_gini:  0.314285714286\n",
      "0.0 0.5\n",
      "(0.6, 'petal width (cm)')\n",
      "[39]\n",
      "[ 0 34 32]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "split = ()\n",
    "splits=[]\n",
    "for row in X_train:\n",
    "    i=0\n",
    "    for feature in row:\n",
    "        split =(float(round(feature,2)),i)\n",
    "        splits.append(split)\n",
    "        i=i+1\n",
    "\n",
    "minimum_gini =10000       \n",
    "for s,i in splits:\n",
    "    j=0\n",
    "    left_split =[]\n",
    "    right_split=[]\n",
    "    for row in X_train:\n",
    "        if(row[i]<=s):\n",
    "            left_split.append(y_train[j])\n",
    "        else:\n",
    "            right_split.append(y_train[j])\n",
    "        j=j+1   \n",
    "    left_split = np.array(left_split)\n",
    "    left_values = np.bincount(left_split)\n",
    "    \n",
    "    right_split = np.array(right_split)\n",
    "    \n",
    "    if right_split.size:\n",
    "        right_values = np.bincount(right_split)\n",
    "    else:\n",
    "        right_values =[0,0,0]\n",
    "        continue\n",
    "    ## Now we have splits on left and right, let us calculate gini of left and right nodes\n",
    "    left_gini = calGini(left_values)\n",
    "    right_gini = calGini(right_values)\n",
    "   \n",
    "    \n",
    "   \n",
    "    weighted_gini = ((np.sum(left_values)*left_gini) +  (np.sum(right_values)*right_gini))/105\n",
    "    if weighted_gini<=minimum_gini:\n",
    "        minimum_gini = weighted_gini\n",
    "        min_left_gini = left_gini\n",
    "        min_right_gini = right_gini\n",
    "        min_split = (s,decision_data.feature_names[i])\n",
    "        print(\"weighted_gini: \",minimum_gini)\n",
    "        print(left_gini,right_gini)\n",
    "        print(min_split)\n",
    "        print(left_values)\n",
    "        print(right_values)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we see the weighted gini of the above shown tree, it is around 3.14, there are multiple ways in which we can split at node 0, decision tree classifier uses greedy algorithm, thus, will choose the minimum gini index at each node split."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I would say Random forest is one of the easiest ensembling methods to have hands on. You can run on large datasets by training trees parallelly, and specifying n_jobs i.e. jobs to run parallelly. Also, we learnt how random forests can be used to extract important features for a model. It performs well even if the data has missing values. It takes interaction of features into consideration. You can explore more about other ways of splitting the trees i.e. with entropy, the concepts of information gain. Also, there are other baaging and boosting methods which you can explore - AdaBoost, XGBoost etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sources and Refernces:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An Introduction to Statistical Learning - Gareth James, Daniela Witten, Trevor Hastie and Robert Tibshirani\n",
    "\n",
    "https://archive.ics.uci.edu/ml/datasets/wine\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_wine.html\n",
    "\n",
    "http://scikit-learn.org/stable/modules/classes.html#module-sklearn.tree\n",
    "\n",
    "https://towardsdatascience.com/the-random-forest-algorithm-d457d499ffcd\n",
    "\n",
    "https://charleshsliao.wordpress.com/2017/05/20/decision-tree-in-python-with-graphviz-to-visualize/\n",
    "\n",
    "http://scikit-learn.org/stable/modules/tree.html#tree\n",
    "\n",
    "https://medium.com/deep-math-machine-learning-ai/chapter-4-decision-trees-algorithms-b93975f7a1f1\n",
    "\n",
    "https://towardsdatascience.com/random-forest-in-python-24d0893d51c0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
