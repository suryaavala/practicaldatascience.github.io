{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this tutorial, we will introduce you to machine learning, using the python library [Keras](https://keras.io/), to create deep neural networks. Machine learning is very important to data science, as it allows a data scientist to find patterns and make predictions using the data they gather. Often, patterns in data are not obvious, but machine learning can be used to find these patterns. For example, suppose you were trying to predict how a certain town votes based on information such as location, median income, etc, and you already have some examples. Machine learning would allow you to predict, given the information of a new town, how it will vote.\n",
    "\n",
    "#### What is Machine Learning?\n",
    "\n",
    "Machine learning is a field in computer science that relates to a computer's ability to improve along some metric, given 'experiences'. These typically come in the form of data, from which the computer attempts to find some underlying pattern/distribution. Given a set of examples, the algorithm attempts to find a hypothesis function, to be used for predictions on new data.\n",
    "\n",
    "For a machine learning problem, you typically need to specify the following three things:\n",
    "* A hypothesis function\n",
    "* A loss function - the penalty for incorrect predictions\n",
    "* How to optimize this loss function - solve for the minimum/maximum, or use a technique called gradient descent to iteratively improve our loss\n",
    "\n",
    "However, there is one issue - we do not really care about the loss over the data we have, we care about the loss over all data, which we approximate using what we have. This leads to the problem of overfitting - making our hypothesis function too accurate over our training data, not all the data. This is shown in the graph below:\n",
    "\n",
    "\n",
    "![alt text][overfitting_graph]\n",
    "\n",
    "[overfitting_graph]: https://image.slidesharecdn.com/overfitting-and-tbl-120312163430-phpapp01/95/overfitting-andtbl-17-728.jpg?cb=1331571562 \"Overfitting\"\n",
    "\n",
    "This is because we are using data we have to train with, so the function isn’t tested on data it hasn’t seen before. We can solve this using something called cross-validation -  hold out some part of the data from training. Once we finish training, we test on our validation data, to get an idea of how well our function will generalize. If the function does well on the training data, but not on the validation, this typically indicates overfitting. How we attempt to solve this issue is its own field, [learning theory](https://en.wikipedia.org/wiki/Computational_learning_theory).\n",
    "\n",
    "#### Supervised learning\n",
    "\n",
    "Specifically, we will look at a subset of machine learning called [supervised learning](https://en.wikipedia.org/wiki/Supervised_learning), for the purpose of classification. This means that the data we work with has labels, and each example has been pre-sorted into one of some number of bins, or classes.\n",
    "\n",
    "\n",
    "#### What are Neural Networks?\n",
    "\n",
    "A [neural network](https://en.wikipedia.org/wiki/Artificial_neural_network) is modeled after the connectionist model of the brain, in an attempt to solve problems the way a human might, like image recognition. Neural networks are made up of a large number of neurons - typically simple functions that take an input and produce an output, using modifiable parameters.\n",
    "\n",
    "\n",
    "These neurons work to connect layers - an input layer, for the input data, an output layer, which in our case will be a classification, and some number of hidden layers. Those hidden layers are what make this a deep neural network.\n",
    "\n",
    "![alt text][neural_net]\n",
    "\n",
    "[neural_net]: http://neuralnetworksanddeeplearning.com/images/tikz11.png \"Neural Network\"\n",
    "\n",
    "\n",
    "Training a neural network involves assigning values to the neuron weights so that the network classifies our data correctly. This is accomplished through backpropagation - using gradient descent, starting with the weights on the outermost neurons - the ones connecting to the output layer. Then using these new values to adjust the previous layer, and so on, working backwards to the input layer.\n",
    "\n",
    "#### What is Keras\n",
    "\n",
    "Now, we can introduce Keras. [\"Keras is a high-level neural networks API, written in Python and capable of running on top of TensorFlow, CNTK, or Theano\"](https://keras.io/).  We are going to use Keras on top of [TensorFlow](https://www.tensorflow.org/), a machine learning framework developed by Google. Using Keras makes a lot of our coding significantly easier, as it wraps much of the TensorFlow code into simple function calls. For example, to make and train a neural network, we simply instantiate a model, add layers, compile it, and then fit it over training data - each step of which is a function call. This allows us to focus less on much of the math going on behind the scenes, and quickly build networks to accomplish tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Install Libraries\n",
    "\n",
    "We need to install the libraries we are going to use during this tutorial. We need `keras`, `imutils`, and `opencv`.\n",
    "If you are using Anaconda, most of the dependencies we will need should already be installed, like `numpy`, `scikit-learn`, and `tensorflow`.\n",
    "\n",
    "    $ conda install -c conda-forge keras \n",
    "\n",
    "    $ conda install -c conda-forge opencv \n",
    "\n",
    "    $ pip install imutils\n",
    "\n",
    "\n",
    "Test that everything has been installed correctly by running the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from imutils import paths\n",
    "import cv2\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras should output that it is using the Tensorflow backend. If not, you may need to [edit your keras config](https://keras.io/backend/#switching-from-one-backend-to-another), or change it [programatically](https://stackoverflow.com/questions/47104415/how-do-i-use-tensorflow-backend-in-keras-without-changing-keras-json).\n",
    "\n",
    "If imutils/cv2 throw a `libfreetype` error, you may need to run:\n",
    "\n",
    "    $ conda install openblas=0.2.19\n",
    "\n",
    "Now we can begin to import everything we need from Keras. First we import the different layer types we will need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Dropout, Flatten, Convolution2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also import np_utils, which has some useful functions for processing data later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we introduce a fixed seed, so that randomness will stay the same between runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(8765)  # for reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin with, we will create a neural network to classify the [MNIST dataset](http://yann.lecun.com/exdb/mnist/). The MNIST dataset is a commonly used image classification dataset, consisting of 60000 training, and 10000 testing images. Each image is grayscale, 28x28 pixels, and corresponds to a written digit. Since each image is pretty small, it means that it is easy to train over. \n",
    "\n",
    "Lucky for us, Keras includes MNIST as one of its built in datasets, so we can simply import it. This also means we need to do very little preprocessing on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the size of the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see an example using `matplotlib`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a26161470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "plt.imshow(X_train[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need to reshape our data to explicitly include the channel dimension. In our case, since we have grayscale images, we only have 1 channel. However, if you had an RGB image, then you would have 3 channels.\n",
    "\n",
    "We just run the below code to specify the channels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, one thing about the MNIST dataset is that the values in the images range form 0 to 255. There's nothing wrong with this, but since these values range pretty high, it may lead to large weights in our neural network. Therefore, we rescale our data to between 0 and 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's take a look at our labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000,)\n",
      "[5 0 4 1 9 2 1 3 1 4]\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "print(y_train[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, it is an array of values ranging from 0 to 9. Since we are doing classification, it would be pretty hard to generate the exact number to correspond to the label. Furthermore, since we have numbers for each label, the network may assume some incorrect things - like a relationship between a 5 and a 6, which may not exist in the image data, but does as a comparison between the labels. \n",
    "\n",
    "Thus, we will convert our labels to a one-hot encoding - each label will be a 10 entry array, with a 1 in a position to indicate the label. This can easily be done with np_utils, which we imported earlier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_train = np_utils.to_categorical(y_train, 10)\n",
    "Y_test = np_utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's make sure our labels look correct:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 10)\n",
      "[ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "print(Y_train.shape)\n",
    "print(Y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can begin to build our model. We first instantiate a model using the Sequential constructor from Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to add our input layer. We need to be careful here, as the input layer needs to correspond to our data.  So we specify the input shape, and the data format.\n",
    "\n",
    "Another thing you can see is we are adding a `Convolutional2D` layer. Convolution is, to put it simply, moving a window across a (in our case) 2D space, and computing a value using the pixels in that space. You can read more [here](https://en.wikipedia.org/wiki/Convolutional_neural_network).\n",
    "\n",
    "\n",
    "![alt text][convolution]\n",
    "\n",
    "[convolution]: https://adeshpande3.github.io/assets/Cover.png \"Convolution\"\n",
    "\n",
    "\n",
    "We specify our space with the tuple `(3, 3)`, and the output size as 32. In most Keras layers, we need to specify at least the output size.\n",
    "\n",
    "\n",
    "Finally, we specify `activation='relu'`. This simply defines the function these neurons will be applying, which is different from the default of linear. Using different functions in these layers allows us to modify the way the network will make its decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 26, 26, 32)\n"
     ]
    }
   ],
   "source": [
    "model.add(Convolution2D(32, (3, 3), activation='relu', input_shape=(28,28, 1), data_format=\"channels_last\"))\n",
    "print(model.output_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can continue to add more layers. We do another convolution, and then `MaxPooling2D`. This simply is a way of sampling every 2x2 set of pixels into 1, in order to reduce our width and height. This means we will have less parameters to train for later layers, and provides some prevention against overfitting, since we make decisions based on a less specific part of the image.\n",
    "\n",
    "We also add a `Dropout` layer. This randomly chooses some neurons from the previous layer to ignore when modifying the weights. This doesn't sound good, but it helps to avoid overfitting by not always training all of the network on the training examples. Read more [here](https://en.wikipedia.org/wiki/Convolutional_neural_network#Dropout)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Convolution2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then flatten the network so that it is a 1D array, to which we connect some `Dense` layers. This means that every part of the previous layer is connected to the next. Notice that the last layer has output specified as 10 - which is the number of classes we are trying to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now see the structure of our completed network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 24, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               589952    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 600,810\n",
      "Trainable params: 600,810\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You're probably wondering how we decided this structure, and how to do so for other problems. There isn't really any general consensus, except to [add layers until the test error doesn't improve](https://www.quora.com/Artificial-Neural-Networks/Artificial-Neural-Networks-How-can-I-estimate-the-number-of-neurons-and-layers/answer/Yoshua-Bengio?share=7b58dc3b&srid=hqJd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we compile our network. We specify the loss and optimizer here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can begin training our network. This line will take a decent amount of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 106s 2ms/step - loss: 0.2721 - acc: 0.9168\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 105s 2ms/step - loss: 0.0953 - acc: 0.9710\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 104s 2ms/step - loss: 0.0714 - acc: 0.9783\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 104s 2ms/step - loss: 0.0592 - acc: 0.9821\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 106s 2ms/step - loss: 0.0507 - acc: 0.9843\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 109s 2ms/step - loss: 0.0443 - acc: 0.9866\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 104s 2ms/step - loss: 0.0397 - acc: 0.9876\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 105s 2ms/step - loss: 0.0360 - acc: 0.9880\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 107s 2ms/step - loss: 0.0335 - acc: 0.9892\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 118s 2ms/step - loss: 0.0300 - acc: 0.9902\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a2e69d5f8>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, \n",
    "          batch_size=128 , epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can test our network on our test dataset, to determine how well it generalizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 6s 645us/step\n",
      "[0.024785956587327747, 0.99129999999999996]\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test, verbose=1)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can test on a random image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a3f6eeba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Label: 2\n",
      "True Label: 2\n"
     ]
    }
   ],
   "source": [
    "# get random location in test data\n",
    "num = np.random.randint(0, 10000)\n",
    "\n",
    "# get image and label\n",
    "img = (X_test[num] * 255).astype('int')\n",
    "img = img.reshape(img.shape[0], 28)\n",
    "\n",
    "true_label = Y_test[num].tolist().index(1)\n",
    "\n",
    "\n",
    "# # show image\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "# # predict using model\n",
    "prediction = model.predict([X_test[num:num+1]])\n",
    "print(\"Predicted Label: %d\"% prediction.argmax())\n",
    "print(\"True Label: %d\"% true_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can explore this more using [this visualizer](http://scs.ryerson.ca/~aharley/vis/conv/). It visualizes the LeNet, developed by Yann Lecun, for the MNIST dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can apply our knowledge to a harder problem: Classifying fruits. We will be using [this](https://github.com/Horea94/Fruit-Images-Dataset) dataset, which contains 28736 train and 9673 test images, in 60 classes. Each image is 100x100 pixels. Extract it to the same directory as this notebook, so we can open it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import img_to_array\n",
    "import os\n",
    "\n",
    "train_data = []\n",
    "train_labels = []\n",
    "test_data = []\n",
    "test_labels = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next steps will take some time, depending on the speed of your computer. If you want, you can import the following library, which is a wrapper for iterators that will print the progress of the iterations. You may need to `pip install tqdm`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to open our training dataset, resize it, and get the corresponding label. We resize it to simplify our training significantly, albeit at the cost of some accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imagePaths = sorted(list(paths.list_images(\"fruits-360/Training\")))\n",
    "np.random.shuffle(imagePaths)\n",
    "\n",
    "# for imagePath in tqdm(imagePaths):\n",
    "for imagePath in imagePaths:\n",
    "#     Some folder names have spaces, which are escaped with a backslash\n",
    "#     We need to remove them so that we can open them\n",
    "    imagePath = imagePath.replace(\"\\\\\", \"\")\n",
    "#     Open the image\n",
    "    image = cv2.imread(imagePath)\n",
    "#     resize\n",
    "    image = cv2.resize(image, (45, 45))\n",
    "#     get array, and append\n",
    "    image = img_to_array(image)\n",
    "    train_data.append(image)\n",
    "#     The labels are simply the containing folder name\n",
    "    label = imagePath.split(os.path.sep)[-2]\n",
    "    train_labels.append(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see one of the opened images using `matplotlib`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJztnXmQJPV157+vKuuuPqbnomcGGEAY\nISx5ZINELLZXiyQbIa/Au1pb8hFsBGF5I1YROKy1hbQRa1lrb0gbkvGGQ6FdkLBxhNbIxmJHoVh5\nhWGwwBY3AwYNMJzDQDPDMFdfdWW+/aNrpM7fezNd09Vd3T35/RAVPfn4ZeYvs/JVVn7rHaKqIIRk\nj9xKT4AQsjLQ+QnJKHR+QjIKnZ+QjELnJySj0PkJySh0fkIyCp2fkIzSl/OLyFUi8qyIPC8iNy7V\npAghy48sNsJPRPIAngPwQQD7ATwM4OOq+sNTrMNwQkKWGVWVXsZFfezjPQCeV9UXAUBEbgdwDYCT\nOn93XB+7PMNY7KlwPkLzvQ1DsshdkrXB6dzM+/navxXAq/OW93dthJA1QD93fu++ZT52ROQTAD7R\nx34IIctAP86/H8DZ85a3AXg9HKSqNwO4GeAzPyGriX6c/2EAF4rIeQBeA/AxAL+2JLPKCHnno3Cx\nz+neGH7SklOxaOdX1Y6IfBLA/8Oc3nSrqj69ZDMjhCwri/6pb1E7E1Gq/T9mKRX6ngQYcsajqj3/\n1McIP0IyCp2fkIzSj+BH+sT7btbL9zWKe2Qp4J2fkIxC5ycko9D5CckodH5CMgoFvxUkduQ9T/BL\nepHz+vih37sDMPvvzId3fkIyCp2fkIxC5ycko/CZfxnw8he8HAovAruXXAt3+z0+4Huf9sy2yCa8\n8xOSUej8hGQUOj8hGaWvZ34ReRnAJIAYQEdVL12KSRFClp+lEPz+laoeWoLtrEl6FffccU5JQ6/K\nYcHuwIxpO3PrtTBI3iuwMsAiL2Rl4Nd+QjJKv86vAL4nIo92S3QTQtYI/X7tv0JVXxeRTQDuEpFn\nVPX78wewbj8hq5MlK+ApIp8DMKWqXzrFmDOugOeSP/M7D+Xmmd+h12d+D++ZP+Yz/5rkdAp4LvrO\nLyI1ADlVnez++xcAfH6x2zvT8T4QIsfp8o7LlsNt9fiB430gwFk3ca8VOv+ZTj9f+zcDuLN7R4sA\n/G9V/bslmRUhZNlh3f4+6fVrv0eUc+78yeLu/LN93PnFufMrM/rXJKzbTwhZEDo/IRll8Cm9km5S\nVUJshjRd/Sn8nHK+WrtNgL1SWXZcwVm1FXwtL6FoxhSHhozt0rPWGdsFOmVsF501amxbNm0ytk6j\nlVquVu0+jzU6xrZ/umFszx05bmyvx/bgH35hf2q5PTtjxiQd+2DhPQYl5r0DEue90lzwqOHXNDOE\nq80Nc1busUl02EbNOT1nBLzzE5JR6PyEZBQ6PyEZhc5PSEYZ/O/8gYiWc8Qgr299J4h79UJevTr4\nntikjs45UrJi3jvXj6SWf23bWWbMptgKaGOxFceKnthUtEcaq1WvClF6vvnIHr3m7fwbznF2yjVj\na5Xs9qaraTHygSl7Hnfufc7YXnh2j7FFjiDXcfS4KFDzvGsjdsRat69Bj3qfeteMuSdaUXq1wt/5\nCSELQucnJKPQ+QnJKHR+QjLKwAW/XD6tRUhiRamcJ+pIWnTxZu0JROKEf713m42iu3aoamw/VUqv\nW21MmzEzOSvaVdTaZmEj8IrOfAvFkrHFUfqctRJ7TEnBEfciKwKiFKYJAZK3+6yX0zYZtts/sPU8\nY3tw0mpNO//+PmN77vnn7TyCe1HiiJ8e3vXST0qyBCKgJzKuVij4EUIWhM5PSEZZ0PlF5FYROSgi\nT82zjYnIXSKyt/vXZrIQQlY1Cz7zi8jPA5gC8Jeq+pNd238HcFhVvyAiNwJYp6qfXmhnOREtSPrz\npu3VsfPXTi15z8sjG+1z+29tXW9sV3QmjW3MeU6fitNZazkni21GW8ZW8561O/Y4S5F9jm46z5dx\noJMkzjN/2ckubDnbz1fsOSqXKsYm9XQwULtidYF2xeoH7e1nG9uBaXtMjz13xNj+7M7vBRs7ZsbE\nblqfNbkXUY+P7vlgF2snxGeJn/m71XgPB+ZrANzW/fdtAK49rRkSQlacxT7zb1bVCQDo/rXyOSFk\nVbPsxTxYt5+Q1cli7/wHRGQcALp/D55soKrerKqXquqlZ1bpTkLWNou9838bwHUAvtD9u7OXlRS2\nCpOXnedWnQ00jHOH7NQ/e8n5xja87wVjO+5Uza06ClFDg5k0baBOnLPzONSx47RsBcWqowu2Yisv\n5YI8xyFHyPMy59SZW8GxIW/vAe1iWh1bV3My/zpO4M/e14zt7CErFp71ExuNbfQTv5pa/ruHHjVj\nHn7M2tQRQPOO5pVzKxw7DUuCUnPiSH6eUJ7LORmkzrhBBtadil5+6vsrAD8AcJGI7BeR6zHn9B8U\nkb0APthdJoSsIRa886vqx0/yv96/xHMhhAwQRvgRklHo/IRklMGX8Qoy1ApO+FTbqf3+tnpaHfvd\nbTaieH3TRo0diKzQNjp+rrF1nrElqeJARdtQtBFthdh+fuackloz6ohGTr2ySbViYaWUFszOqtTt\niuKIdnVbsqudt+e2XrZRf5Vi+hiiESvazYShcAAqsd1WQ+08jg85amctfS1Ow/Y1eOaILZG284Hd\nxrYn6DsAAFMzNrITYiM0kQt8wrlG++rOvIw+x6w+QsiC0PkJySh0fkIyCp2fkIwy+DJegQCSd6r0\n1+r2M+kzW8dSyxe3bb38V1tNYzv7Z95jbA8dmjC2LS/bCOVK0CtgnZfCmth4xOnEinazjiBXddJ8\n8045sUIxHV1XmJk1Y4ZHrAhY2mzTmctVu/3WlN1erpmeW6U+bMbMVm0qsJasMFisOIJfyyvRlb4W\nmmWnLJtYofC4ExL60lFbcu35Y/aaue+Jp43tjcPpJNbjTXtduQ1JnUjDQUPBjxCyIHR+QjIKnZ+Q\njELnJySjDFTwy4loFKRLdsQKfr/xNisQfSQIs2o6qa9Ry+ocB7ZsNrbJqhVmxp953dhqQdpwwRG4\nmtM2N+rlhq09Nz4+Ymwzk45SNWsjzqbiRmr5bCcir+yk5ebqdr4jTi0+Ldn3oBinxc0pJ/m6WLbi\nW75utz+03jY4PTjZMLbpfHoetdgKp7m6FV1nK3ZuBee6SibCanRAO7Lz/WEn/R7c+egrZswz+/Ya\n23TbCoNe01l17rn5wA+92pa91CCk4EcIWRA6PyEZhc5PSEZZbNOOz4nIayKyu/u6enmnSQhZahbb\ntONzAKZU9UuntTMRjYJIt42OaPSfzrGCXyVOR6GdFVmRp1O1AtH4tT9nbPsesWLN4Uf3GVstEK9i\np+DgobYVoDBtRbvIae4xEzt14ApWIhqppefRbtiIvJG8FR5HnCai9boVC3NFr3lI+mBHh2167ZSj\nQA05UZCJE1XYKFhbeyYtgErBqbVYsNdLM0zBBTDTtIJitWFF4oJzjlrBNdlyCl5NdOx98xuHrKB4\n/677jS1sBAoAUdDIte0IuIgXjiAcRNMOQsgap59n/k+KyJPdx4KT9uoTkU+IyCMi8kgf+yKELDGL\ndf6vArgAwA4AEwC+fLKB8+v2L3JfhJBlYFHOr6oHVDVW1QTALQBs6hwhZFWzqKYdIjJ+olcfgF8G\n8NSpxs8nDgS/952/xYwZxZSxTQViTatmhZ/xn7/I2ErDtq5fObKfeS1H+Exm0vuUslOzrmO1lSed\nFFlPVh1zUkBnS1YYHA7qHm50mnZ4NfxmnSixlmPb7NQczAcNKNTpUFws2HloydqmY3tM6hyDBpF1\nB5rOuXBShmuO+Bs54tgbLZvmm2/bcVvidPrycNXOY7Ru06U/O3ahsX3D0ehuv+/7xhaHXadjLzZw\naVOGF3T+btOO9wHYICL7AfwBgPeJyA7MXdMvA/jtJZ0VIWTZWWzTjq8vw1wIIQOEEX6EZJRlb9Gd\n2lk+jw31dHbb+Xn7LNk4asstVYKn5qnEecY9bp9nNx0bM7aJJ//Z2I627Kk4HmQS1hIbJPJW4mgF\nsdNI06nb33Cad55dsM+01eD5e7ZotyWJ1R7GIvssHzXs+XYkEISP7m3Y514vkzB2dIySE9RSatmA\nrDc76cCcdU69/E7HPrfHzjyKXtk055G56Wg9M7Pp3gBF5z3pdI4aWy2ygUW/8s4L7E6doKQ7Hngw\nPS/nfeolq+904J2fkIxC5ycko9D5CckodH5CMspABb96IcLl4+ngiHNmbb38yBGvQtPRKSuuVB6x\n5Zaeu+sFY3ttxoopsVNwqRgIVRMNq7i82bDC1bGWFdqqJXtMW2DX3ZhzSlJpMF8nE7I0Zefm5Xbl\nS3bdpGD3ebyTLkkVOdl0Za+Ml5NdKB2rtBXy9nwXglr4kdO0dKpthceOU0M/coKI6s69ruQEKrUC\n0XLa6QchwzbztCR2W5WWne+179phbLlcet1v7tplxrQd4TTkdMry8c5PSEah8xOSUej8hGQUOj8h\nGWWggl9RFNtLaREnmrFiCtQKRG0N6/1b8ePN6RljW7/O1ow/NPuqsSV5G042HKXr3r81bec13Xai\n7RyB65yCLW91kZMl2HJELg1Ke21ab0tqvTFliy2VEicqL7LnLedEH7YlyGh0GpKKI4SpU7IrX7H9\nA9pOJOBMIICOOHOtO6Ja22mkqU17Hgt5J/vPKeMVBm0600DiCJuRkx1Zrjvib8fO96MXXJJa3nT+\nO82YL9/yP+xE+oB3fkIyCp2fkIxC5ycko/RSt/9sEdklIntE5GkRuaFrHxORu0Rkb/fvSYt4EkJW\nH70Ifh0An1LVx0RkCMCjInIXgH8P4G5V/YKI3AjgRgCfPtWGRIEoaL7YdFJiz7IZlDgYpNzW2laA\nmnFEwONvWXFvfdXuoK42YvCZQNA61rFzHa5bweh4y87t+TBKD0AptvPdJHZuW0tDqeX8evs5Wzxk\n539u2QpcUrFCW9OJltwYRPQ1qvY4j5Xt+SjHTjRcxwqKuaKdWzlIoW47UXrTTjmxUsHew8QRYvPe\n+XAiF0MtslC071PtmFOqbaNtxtoqWqF3wmmMOj2T3t4loxvNmA0bNhjboUOHjK1XeqnbP6Gqj3X/\nPQlgD4CtAK4BcFt32G0Arl30LAghA+e0nvlFZDuAdwN4EMDmE0U8u383nWSdH9Xtn3HaahNCVoae\nnV9E6gD+FsDvqKottXMS5tftrzrJHISQlaEn5xeRAuYc/xuq+q2u+YCIjHf//zgAm55HCFm19FK6\nWzBXrXePqv7JvP/1bQDXAfhC9+/OhbalImjl0tFem8UKLq3E1u2PmqEKY7e/tWQj3yplKxDVWvYz\n76WOjYZbF+yk7giRbx+zEW2zsPs86EQfDjmhY+dW6sZWHkkLfjLsjHHSco+JjXLbumWzsVUO2nHt\noL7/8HYbKannbTU2OWhr200dPGZsI2NWtKzPpuvzlb30YKc2X9Kw711N7LfM3KwVNgvOPtpGx7Tn\n9q2KvW4r9jSipfa9Ghq1xz6WT5+jyYLd2MiIFRQPH05Hdsan8Wjdi9p/BYDfBPDPIrK7a/ss5pz+\nr0XkegD7APy7nvdKCFlxeqnbfz9w0ioC71/a6RBCBgUj/AjJKHR+QjLKQFN6mwnw4nRaTXlH2U6h\n2LRRUZ1Ac2nkrCBSqTrpwW0rzEzlbZRbnHdSUZP09jarFZYKbfv5Oe6IWblZK/iNOt0yYie9tjU9\nmVouvmmjumple87ykRW9Jl5/y9jGalZImmmkn/R0v214OvWGnUdps21gmavZ93jyiE1BDlNuZxzB\nMqx1BwDtxI5rOFd2uWiNifPrcz7YR7tlIxlF7YrtYae5R8W+L6XtVnSd2p++PiK1zWZyOUfsdFKj\ne4V3fkIyCp2fkIxC5yckowz0mb8Vd7DvWPo5cZ9T5mjUaeJYD5paVpzgIISBQACOidUBas5HXtl5\nPq7k089rxVmnBJZT9332mI1+HnOyuyrOus1ZqyuMbEkf69Rxm1HWmLHzr5WcWv7O8+uM2uaXnSit\ngXScQJqiU5oMb9htFcKunwASR9vQ4Jk8DoUeAK3YBuqUnOfqgthrIe9kCeadrL5W0PBgqmovmJpz\n7FKw14dUrK04YjWhQjN4T2tDZow4Wav9wDs/IRmFzk9IRqHzE5JR6PyEZJSBCn4xBJNBnfRq1Yof\nW6u2CeLBI+kgk0bHioJelhycwI6KU1eg7oiMGsx1qGoDLw4ddoJV6nb+VScbLUqs6FUat5mJZaQz\nISPnbYuGnWApp+yYE5uCqGCDfIqV9MDjTtmqkiOSRk7UTDnnZW465zusyR9b0U6cPpSlkhUGq15A\nj10VcLIhoygdrFMu2Wu06TTEbNdtBt/wZhvQ42iMqI2m34P7nrIBVC+8YJvOhiIgG3USQhaEzk9I\nRqHzE5JR+qnb/zkReU1EdndfVy//dAkhS0U/dfsB4CZV/VKvO1MFGu20QHHc0Sc6kRWDhoMaWuJE\nqm268Fxje/Ol142tHVmRp6LW1mikRa5W25YXGx6y4l7sCFBe7fqRISsQNeFEvjXTb1N5yCpGsSug\n2Syz4Q1WtJxyxM4wfm2dU0LKE+2iYZsd2XR02JxzvuOguWZVnFptTnkudYTTqVmnUWfZzq1csZF0\n0+30ujmn50IZw8ZW22ALWOc3W9vxaIux3bUrXQXvS3/238wY9dTak9bZWZheKvlMADhRontSRE7U\n7SeErGH6qdsPAJ8UkSdF5Fa26yJkbdFP3f6vArgAwA7MfTP48knW+1HTjkQXX3iAELK0LLpuv6oe\nUNVYVRMAtwB4j7fu/KYdOSfQhRCyMiy6br+IjJ9o1wXglwE8tdC2Ek0w00qnZOZaVpTaYDUYTAcN\nMVstK7S9dMSmk444TRYVVjA7mrcpq1FQzknydluNgpMK7KXvDltbs+HUWHc0Lgyl99vIV8yQUsWe\nD8RWqGrFTipqzkbvtYPoushJy42dD/OGI1iWnYjNeNoKcsUofVydhi19lq/Y6yVymn56wmCSs+tK\n1QqZUZBuHCVOhOI6p/TZBqcev3MtHDn2orFtvyAt/v70pT9nxjz9xEPG1mza67ZX+qnb/3ER2QFA\nAbwM4LcXPQtCyMDpp27//1366RBCBgUfwgnJKHR+QjLKQFN6kyTBzExaxJkRKxAdnbV1994MasgV\nHIFrbMRJ7RyxKZUzE5PGNlu2YlA9ELQaTo30YtERkQrWVly3wc5j0tb66zgpmdXxdERYfdw2zWzN\n2ujDOmwEYfuQFdHEaWDZaqcFs07JClet2M616IxrTjuilJNunOTSNi3Ze1N91J7Hcs0e56wT4aex\nvT6m1e6jEqTXzoqdf354o7FFTv+DRs7u87v3PGNsW9alr+fr/o398ezwBy43tvv/6Qep5QceftyM\nORm88xOSUej8hGQUOj8hGYXOT0hGGajgpwJ0orTA95jT7PGSLTb1sl5KR38daVjBqJFY4apes8IP\nalaUGnIaP5SDVb1gh+HYSbN0GjpMJ46wNGTFq3MutmLegU76bTpWtiGQZaexxPRxK5xGBRv1V5q1\n22uV0uey5QhXcWzPSNJw6vp5qahOtGShln6PC1WbNluu2+jGdmK3FZXsMeU6dh5NJ9+kHTTtGKpY\n0XiyarevVdukdPYt+x58946/NLZXDr6aWv7Fqz5kxnzoip82tovetj21vPvJp82Yk8E7PyEZhc5P\nSEah8xOSUeR06nz3vTPJaZRPPzt65ac++f6fMbZ3t9KBOYWi1QUOTNugmQ0VG0RUiJyAlY4N5IiD\nAutRyz5b5iMb0DM0amvvTxdtIMpQ1UourbbNTCytTz/7StU+f5da9lk+esuej6oThDM1Y59LS5Ie\nN9ty7hORfQ/Uq+XvKEtx7DRQDXUXp1xZlLc2zTs7iKw2kDjZkOpoGQiyOTFkz1lu/TZjm6xYjeIr\nt37N2Hbe+TfGJggCnJzgIyd2DB/+8C+klnfdfT+OHDnWU20v3vkJySh0fkIyCp2fkIzSS93+sog8\nJCJPdOv2/2HXfp6IPCgie0XkmyLidCAjhKxWFhT8umW8aqo61a3ldz+AGwD8LoBvqertIvI/ATyh\nql9dYFuay6U/b3JO6EzFydL61HsvSS3/RGSFsUknO02cIA6FFZs6sRWNcoEYVIQVs9o1G+xRdERA\nbLYZX/V1Tjku5/2ojKYzvkojdr2Zfa8a2/ARm72Yrzgi3agVquJm+ljbM05jSnsaUanbbVkpEogd\nFTAflOOKHEE07wiW8ERAdURA7/5UsudDgnOU1Kwo2C7b47z/yR8a23/9488bW6dly6aFV5aTMAk/\nJi8UCjtQdaKeHBa88+scJ/JFC92XArgSwB1d+20Aru1lh4SQ1UGv1Xvz3fp9BwHcBeAFAEdV9cTv\ndPvBRh6ErCl6cv5uie4dALZhrkT3xd4wb935dfsXP01CyFJzWmq/qh4FcC+AywGMisiJh5BtAGxT\nPKTr9vczUULI0tJL3f6NANqqelREKgA+AOCLAHYB+CiA2wFcB2DnybfS3RaAQpAx1YqsIDczZUtN\n3fLEG6nl37vyXWbM5ryth95wsummJ63wU3E0krgUlLLK2bm2pq3q1cpZYbAAW2Yrf9yKlrmyM7dA\neOyMWJEx3mgzBGXYRhomTiSgFu0+S4Gw1unY92SsboVZdZprJk60Wq5i180F9f1FHLHWObcdRx3T\ngr20tWxtRaefglTS52MGtmTcg7ufMLY/+LwV9+BEsIo48w1M4gjhmnMyVMNxvlLo0ktK7ziA20Qk\nj7lvCn+tqt8RkR8CuF1E/gjA45hr7EEIWSP0Urf/Scw15wztL+IkLboIIasfRvgRklHo/IRklIGm\n9OZFtCxpgaLtxCJ1HFuUpKPmxkfGzJjf+pdvN7YtiRWqkqYV2hpOafnpIMptNLLCWC6yKcNDkRW9\nOmUrcJUdUark1apflxb4KqNOumrilOcq23nMiCMkOSmxOpUWMvNOB9FKxQqPHed+kjjNKhMnJbsQ\niIBS85ptWluuYM+HOO9Vx0nfbTli57F2Wli7++/vN2O+evP/MrZ27DXNtP6Vc2zhuxKr4wSOUGj2\nlihUvZUtvPMTklHo/IRkFDo/IRmFzk9IRhlwDT9RyQVaRI/CRqhTeZrGujHbPPE3L7ORgP9i1G5/\numVFwFagRlZjm6rbdpo4jtetiORFuVVLToScE+EXV9MiV80ZU/A+xkt2XCu2AqXk7XElwdzEEdWa\n3r3DaVwaO3X9Sk6EX6WaTnvuOOnYRUc8bDnntp046ddihc0nnn3W2L5yyy2p5VdfedmMUSf6MFF7\nbj3Bz9PtQpM6EX6eUBhKhbEmFPwIIaeGzk9IRqHzE5JR6PyEZJQVEPzygc0KJzknvTYJVBKv96M4\nTTPFGXjNlT9rbJett0LVObX03NY5jSmrQzbS8NCsIx6KTcdcX7biVT7vpANH6c/oUsWKb7mqEzHn\npPQ2Z61AWXbq2DVywfko2rTWpOQ0wXBq7CWO4JcvWDFSAkHuUNvem2aaNoX6yKStVXjvP/yDsf2f\nnXcaW6tj6z5qJ4iWdPUzR8jzbqX28nYbvjrDDN7mw6kljPAjhCwEnZ+QjNJP3f6/EJGXRGR397Vj\n+adLCFkqeqnk0wRw5fy6/SLy3e7/+z1VveMU6xJCVim9VPJRAF7d/kWRCwS+fOKkk8KJQgs1jI6T\n2umsF4u13XnvPcb2j6M2OvCyi9MpwldfdpEZM1az2so559gq5jNO9FfeidSLHMEvCpSk2ZYVvWKn\nvFsxdlKLnSYjrRHbgEKCtGTNW1GwJVYkPeI0Tjl83NYvvO+fHjC2Z/Y8nd5+wx7nvtdeM7bpaSuw\ndlpW2PQauHhRc0FfGbS9y92R1HrVzr3oPW9USOJ9UTc77d01F1W3X1Uf7P6vPxaRJ0XkJhHnSiCE\nrFoWVbdfRH4SwGcAvB3AZQDGAHzaW5d1+wlZnSy2bv9VqjrRbeXVBPDnOEkxT9btJ2R10kujzrBu\n//cwV7f/UVWd6DbyvAlAQ1VvXGBbKk4ZqUHjTcE/DemBRSeQ5rIdprAxRqo2+OW977Y/huy4eLux\nVSM7uXw4t47VDxInwkSdhqGxE1zTyVnd5WgjvY97f7DbjNk/ccDYHn3gPmM7dGCfsYXJnQCQBOdb\nnWd0cmpUew/y6adu/z3dDwYBsBvAf1j0jAkhA6efuv1XLsuMCCEDgRF+hGQUOj8hGWXwWX2rQPBz\ns6PckdLDGIuj2aHo1OiHI8j963/7UWMb37QptTw9ZYNajhw5amwVJ6vvB488amxvvPqKscUzx1LL\nTdsWAElsBTmBE1zj5qw5mZvmBA/u2jxTOB3Bj3d+QjIKnZ+QjELnJySj0PkJySgU/Lp48wrPjZeN\n1UNg4ElH5no89WE0nHsKvYanjs7mvd2Sd85Ikl5Ze8ooA/JuhKKdSNspca9hlCIj/E4bCn6EkAWh\n8xOSUej8hGQUOj8hGaWXrL4zDnUUs8QRr8JPRvFEO2dbsauqORMRW7LLE2A7gU084dGGx7l46zrV\nz6CmoapXp97ZZ2xtXvtKvw5WeMYp+C0nvPMTklHo/IRklJ6dv1vE83ER+U53+TwReVBE9orIN0XE\nloghhKxaTufOfwOAPfOWvwjgJlW9EMARANcv5cQIIctLr6W7twH4MICvdZcFwJUATjTsuA3Atcsx\nweVAnf88kuDlbmsuoir1ygHmBbUv1di+kJhXuKJqYl7eDkTsyx7VSV6hSdW8JIF5OcP8lzNjz0KW\nj17v/H8K4PfxYx9YD+Coqp5oFbEfgO1UQQhZtfTSq++XABxU1flVIHrrWQzW7SdktdLL7/xXAPiI\niFwNoAxgGHPfBEZFJOre/bcBeN1bWVVvBnAzMJfYsySzJoT0zYJ3flX9jKpuU9XtAD4G4B5V/XUA\nuwCcqDl1HYCdyzZLQsiS00+E36cB3C4ifwTgcQBfX5opDYBFfv/orRKdj183sOenpwX36gYQOlF5\nvnC58FH0Kg71nPbs7iMdC8j4vuUlk/n8S0mvR+O7uecoS+j8bqfX3rYX4nWz9ejP+dMj6fynD/P5\nCSELQucnJKNkMqvPO2jvq2nhZnnoAAADoklEQVT4tdMb0+tXWvf5vscfP8I1vWf5vnDm0cvU+vla\n7mdIBtvnb0PLCu/8hGQUOj8hGYXOT0hGofMTklH4Oz8hZxD8nZ8QsiB0fkIyCp2fkIxC5ycko9D5\nCckodH5CMgqdn5CMQucnJKPQ+QnJKINO6T2kqq8A2ADg0ID3vdSs9WPg/Fee5TiGc3sdONDw3h/t\nVOQRVb104DteQtb6MXD+K89KHwO/9hOSUej8hGSUlXL+m1dov0vJWj8Gzn/lWdFjWJFnfkLIysOv\n/YRklIE7v4hcJSLPisjzInLjoPd/uojIrSJyUESemmcbE5G7RGRv9++6lZzjqRCRs0Vkl4jsEZGn\nReSGrn0tHUNZRB4SkSe6x/CHXft5IvJg9xi+KSLFlZ7rqRCRvIg8LiLf6S6v6PwH6vwikgfwFQAf\nAvAOAB8XkXcMcg6L4C8AXBXYbgRwt6peCODu7vJqpQPgU6p6MYDLAfzH7jlfS8fQBHClqv4UgB0A\nrhKRywF8EcBN3WM4AuD6FZxjL9wAYM+85RWd/6Dv/O8B8LyqvqiqLQC3A7hmwHM4LVT1+wAOB+Zr\nANzW/fdtAK4d6KROA1WdUNXHuv+exNzFtxVr6xhUVae6i4XuSwFcCeCOrn1VH4OIbAPwYQBf6y4L\nVnj+g3b+rQBenbe8v2tba2xW1QlgzrkAbFrh+fSEiGwH8G4AD2KNHUP3K/NuAAcB3AXgBQBHuy3i\ngdV/Lf0pgN/Hj3udrMcKz3/Qzr/YtrSkT0SkDuBvAfyOqh5f6fmcLqoaq+oOANsw9w3yYm/YYGfV\nGyLySwAOquqj883O0IHOf9Cx/fsBnD1veRuA1wc8h6XggIiMq+qEiIxj7m60ahGRAuYc/xuq+q2u\neU0dwwlU9aiI3Is5/WJURKLu3XM1X0tXAPiIiFwNoAxgGHPfBFZ0/oO+8z8M4MKuylkE8DEA3x7w\nHJaCbwO4rvvv6wDsXMG5nJLus+XXAexR1T+Z97/W0jFsFJHR7r8rAD6AOe1iF4CPdoet2mNQ1c+o\n6jZV3Y65a/4eVf11rPT8u3W+B/YCcDWA5zD3zPafB73/Rcz3rwBMAGhj7pvL9Zh7XrsbwN7u37GV\nnucp5v+zmPs6+SSA3d3X1WvsGN4F4PHuMTwF4L907ecDeAjA8wD+BkBppefaw7G8D8B3VsP8GeFH\nSEZhhB8hGYXOT0hGofMTklHo/IRkFDo/IRmFzk9IRqHzE5JR6PyEZJT/D/xGX4u0hq0QAAAAAElF\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a3fb239b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pear Monster\n"
     ]
    }
   ],
   "source": [
    "plt.imshow(train_data[0])\n",
    "plt.show()\n",
    "print(train_labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we need to convert our data to floats, to prevent large weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# explicitly convert to np arrays, since data not preprocessed like MNIST\n",
    "train_data = np.array(train_data, dtype=np.float32) / 255.0\n",
    "train_labels = np.array(train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also import the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imagePaths2 = sorted(list(paths.list_images(\"fruits-360/Validation\")))\n",
    "np.random.shuffle(imagePaths2)\n",
    "\n",
    "# for imagePath in tqdm(imagePaths2):\n",
    "for imagePath in imagePaths2:\n",
    "    imagePath = imagePath.replace(\"\\\\\", \"\")\n",
    "    image = cv2.imread(imagePath)\n",
    "    image = cv2.resize(image, (45, 45))\n",
    "    image = img_to_array(image)\n",
    "    test_data.append(image)\n",
    " \n",
    "    label = imagePath.split(os.path.sep)[-2]\n",
    "    test_labels.append(label)\n",
    "    \n",
    "test_data = np.array(test_data, dtype=np.float32) / 255.0\n",
    "test_labels = np.array(test_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, since our labels are strings, and not numbers, we cannot use the same np_utils function exactly as before. First, we use LabelEncoder from scikit-learn, to convert our strings to integers, using which we can convert to one-hot encodings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(train_labels)\n",
    "encoded_train = encoder.transform(train_labels)\n",
    "train_labels = np_utils.to_categorical(encoded_train)\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(test_labels)\n",
    "encoded_test = encoder.transform(test_labels)\n",
    "test_labels = np_utils.to_categorical(encoded_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see our number of train and test examples, which should be 28736, and 9673, respectively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28736 9673\n"
     ]
    }
   ],
   "source": [
    "no_train_samples = np.shape(train_data)[0]\n",
    "no_test_samples = np.shape(test_data)[0]\n",
    "print(no_train_samples, no_test_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we have just read in our dataset entirely into memory. In many cases, this may not be possible, in which case you may want to use something that reads data sequentially as it is trained, such as the Keras [flow_from_directory](https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html).\n",
    "\n",
    "Now we can create our neural network, and train it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28736 samples, validate on 9673 samples\n",
      "Epoch 1/5\n",
      "28736/28736 [==============================] - 214s 7ms/step - loss: 1.5587 - acc: 0.5758 - val_loss: 0.3180 - val_acc: 0.9036\n",
      "Epoch 2/5\n",
      "28736/28736 [==============================] - 237s 8ms/step - loss: 0.2950 - acc: 0.9046 - val_loss: 0.1646 - val_acc: 0.9457\n",
      "Epoch 3/5\n",
      "28736/28736 [==============================] - 217s 8ms/step - loss: 0.1612 - acc: 0.9463 - val_loss: 0.1578 - val_acc: 0.9525\n",
      "Epoch 4/5\n",
      "28736/28736 [==============================] - 215s 7ms/step - loss: 0.1221 - acc: 0.9588 - val_loss: 0.1707 - val_acc: 0.9553\n",
      "Epoch 5/5\n",
      "28736/28736 [==============================] - 223s 8ms/step - loss: 0.0910 - acc: 0.9685 - val_loss: 0.1321 - val_acc: 0.9586\n",
      "9673/9673 [==============================] - 21s 2ms/step\n",
      "Test loss: 0.132134125281\n",
      "Test accuracy: 0.958647782487\n"
     ]
    }
   ],
   "source": [
    "fruit_model = Sequential()\n",
    "fruit_model.add(Convolution2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=(45, 45, 3)))\n",
    "fruit_model.add(Convolution2D(64, (3, 3), activation='relu'))\n",
    "fruit_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "fruit_model.add(Dropout(0.25))\n",
    "fruit_model.add(Flatten())\n",
    "fruit_model.add(Dense(128, activation='relu'))\n",
    "fruit_model.add(Dropout(0.5))\n",
    "fruit_model.add(Dense(60, activation='softmax'))\n",
    "\n",
    "fruit_model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "fruit_model.fit(train_data, train_labels,\n",
    "          batch_size=128,\n",
    "          epochs=5,\n",
    "          verbose=1,\n",
    "          validation_data=(test_data, test_labels))\n",
    "score = fruit_model.evaluate(test_data, test_labels, verbose=1)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we get pretty high accuracy over both the train and test data, meaning we have made a good classifier, without too much overfitting. Once you've trained your model, you can save it for later, for further predictions, or further training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('MNIST_model.h5')\n",
    "fruit_model.save('fruit_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "For more information, feel free to consult these links:\n",
    "\n",
    "1. Keras: https://keras.io/\n",
    "2. TensorFlow: https://www.tensorflow.org/\n",
    "3. Keras Examples: https://keras.io/getting-started/sequential-model-guide/#examples\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
