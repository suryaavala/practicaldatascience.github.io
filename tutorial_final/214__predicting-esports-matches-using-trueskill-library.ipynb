{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Esports Matches Using `TrueSkill` Library\n",
    "\n",
    "## Introduction\n",
    "\n",
    "### TrueSkill\n",
    "\n",
    "TrueSkill is a ranking system designed by [Microsoft Research](https://www.microsoft.com/en-us/research):\n",
    "\n",
    "> \"The TrueSkill ranking system is a skill based ranking system for Xbox Live developed at Microsoft Research. The purpose of a ranking system is to both identify and track the skills of gamers in a game (mode) in order to be able to match them into competitive matches. The TrueSkill ranking system only uses the final standings of all teams in a game in order to update the skill estimates (ranks) of all gamers playing in this game. Ranking systems have been proposed for many sports but possibly the most prominent ranking system in use today is ELO.\"\n",
    "\n",
    "It assume that the skill of a given player conforms Normal Distribution. By playing more and more games, the system knows you better, so the σ will be lower and lower.\n",
    "\n",
    "![skill](skill.jpg)\n",
    "\n",
    "For a team game, it assumes that the skill of a team is the sum of the skills of its players. In this way we can use it for **sports prediction**: by training the skills of the players based on the history games, we can predict the results of the upcoming games, which are always the dreams of sport fans!\n",
    "\n",
    "In this tutorial, we will use the Python library `trueskill` to do the task on Overwatch League, a global esport league."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setups\n",
    "\n",
    "### Python Version\n",
    "\n",
    "Python 3.6 is used for this tutorial.\n",
    "\n",
    "### Libraries\n",
    "\n",
    "The following libraries are needed for this tutorial:\n",
    "\n",
    "- **trueskill**\n",
    "- request\n",
    "- matplotlib\n",
    "- numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, deque\n",
    "from functools import cmp_to_key\n",
    "from itertools import chain\n",
    "from math import sqrt\n",
    "from pprint import pprint\n",
    "from random import choices, random\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from trueskill import calc_draw_margin, Rating, TrueSkill\n",
    "\n",
    "from fetcher import load_games\n",
    "from game import Roster, Game"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Data\n",
    "\n",
    "Overwatch League is a global esports league with city-based teams based on the Blizzard video game **Overwatch**. There are **12 teams** in total, and there will be many matches per week.\n",
    "\n",
    "![owl-matches](owl-matches.png)\n",
    "\n",
    "Each of the matches is a **Best-of-4** match played on **4 maps**. If two teams draw after 4 games, a tie-breaker map will be played.\n",
    "\n",
    "![match-summary](match-summary.png)\n",
    "\n",
    "The results of all the games are stored in `game.csv`. There are two types of rows:\n",
    "\n",
    "- **Future Match**: A match that has not been completed. It contains the following fields:\n",
    "    - `match_id`: The id of the match.\n",
    "    - `stage`: The stage of the match.\n",
    "    - `start_time`: The start time of the match.\n",
    "    - `team{1,2}`: The two teams involved in this match.\n",
    "    - `match_format`: The format of this match. Possible values are `regular` and `title`.\n",
    "- **Past Game**: A game that has completed. It contains all the above fields, as well as:\n",
    "    - `game_id`: The id of the game.\n",
    "    - `game_number`: The order of the game in the corresponding match. Start from 1.\n",
    "    - `map_name`: The name of the map.\n",
    "    - `score{1,2}`: The score of the game.\n",
    "    - `team{1,2}_p{1,2,3,4,5,6}`: The players of each team in this game.\n",
    "\n",
    "We can use the `load_games()` function to load all the rows into the `Game` objects. For a future match, some of the fields are set to `None`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(OrderedDict([('match_id', 10525),\n",
       "              ('stage', 'Preseason'),\n",
       "              ('start_time', datetime.datetime(2017, 12, 6, 16, 0)),\n",
       "              ('teams', ('FLA', 'SFS')),\n",
       "              ('match_format', 'regular'),\n",
       "              ('game_id', 4759),\n",
       "              ('game_number', 1),\n",
       "              ('map_name', 'dorado'),\n",
       "              ('score', (1, 2)),\n",
       "              ('rosters',\n",
       "               (('Zebbosai', 'TviQ', 'Zuppeh', 'Logix', 'Manneten', 'CWoosH'),\n",
       "                ('dhaK', 'sleepy', 'Danteh', 'BABYBAY', 'Nomy', 'Nevix')))]),\n",
       " OrderedDict([('match_id', 10582),\n",
       "              ('stage', 'Stage 2'),\n",
       "              ('start_time', datetime.datetime(2018, 3, 23, 16, 0)),\n",
       "              ('teams', ('SEO', 'FLA')),\n",
       "              ('match_format', 'regular'),\n",
       "              ('game_id', None),\n",
       "              ('game_number', None),\n",
       "              ('map_name', None),\n",
       "              ('score', None),\n",
       "              ('rosters', None)]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "past_games, future_matches = load_games()\n",
    "past_games[0]._asdict(), future_matches[0]._asdict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters\n",
    "\n",
    "Then we need to choose the parameters for the TrueSkill algorithm. This should be done by tuning the model on the history data. For the simplicity of the tutorial, we omit this process and use the following parameters:\n",
    "\n",
    "- *mu* = 2500\n",
    "- *sigma* = 2500 / 3\n",
    "- *beta* = 2500 / 2\n",
    "- *tau* = 25 / 3\n",
    "- *draw_probability* = 0.06 or 0 (based on the map)\n",
    "\n",
    "Note that we have two *draw_probability*. This is because there are many types of maps in Overwatch. Some of the maps are drawable, while others are not.\n",
    "\n",
    "Using these parameters, we can create `TrueSkill` objects by:\n",
    "\n",
    "    TrueSkill(mu=25.0, sigma=8.333333333333334, beta=4.166666666666667, tau=0.08333333333333334, draw_probability=0.1)\n",
    "    \n",
    "Here we created two `TrueSkill` objects, one for drawable games and the other for undrawable games."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MU = 2500.0\n",
    "SIGMA = 2500.0 / 3.0\n",
    "BETA = 2500.0 / 2.0\n",
    "TAU = 25.0 / 3.0\n",
    "P_DRAW = 0.06\n",
    "\n",
    "env_drawable = TrueSkill(mu=MU, sigma=SIGMA, beta=BETA, tau=TAU, draw_probability=P_DRAW)\n",
    "env_undrawable = TrueSkill(mu=MU, sigma=SIGMA, beta=BETA, tau=TAU, draw_probability=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "\n",
    "### Rating Jar\n",
    "\n",
    "Using the `TrueSkill` object, we can create a rating jar which stores the ratings of all the players. We use `defaultdict` here so that if a rating cannot be found, a default rating is returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEAMS = ['BOS', 'DAL', 'FLA', 'GLA', 'HOU', 'LDN', 'NYE', 'PHI', 'SEO', 'SFS', 'SHD', 'VAL']\n",
    "ratings = defaultdict(lambda: env_drawable.create_rating())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Roster Queue\n",
    "\n",
    "As we explained ealier, TrueSkill assigns a skill rating for every individual players. However, we cannot know the roster of the two teams before a match starts. Thus, in order to predict matches in advance, we have to \"guess\" the rosters of teams beforehand.\n",
    "\n",
    "Here we will use a queue approach: the roster that has the highest rating in the past 12 games will be used. In other words, we predict that the team will use their \"strongest\" roster that they have used recently. If such a roster cannot be found, we will just return six empty strings, which will lead to six default ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "roster_queues = defaultdict(lambda: deque(maxlen=12))\n",
    "best_rosters = defaultdict(lambda: [''] * 6)\n",
    "\n",
    "\n",
    "def roster_rating_lower_bound(roster):\n",
    "    sum_mu = sum(ratings[name].mu for name in roster)\n",
    "    sum_sigma = sqrt(sum(ratings[name].sigma**2 for name in roster))\n",
    "\n",
    "    mu = sum_mu / 6.0\n",
    "    sigma = sum_sigma / 6.0\n",
    "    \n",
    "    return mu - 3.0 * sigma\n",
    "\n",
    "\n",
    "def update_best_roster(team, roster):\n",
    "    roster_queues[team].appendleft(roster)\n",
    "    best_rosters[team] = max(roster_queues[team], key=roster_rating_lower_bound)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "In order to predict future matches, we have to first train the model so that we can have the ratings for all the players. This is done by the function `TrueSkill.rate()`:\n",
    "\n",
    "    TrueSkill.rate(rating_groups, ranks=None) -> new_rating_groups\n",
    "\n",
    "where `rating_groups` is the ratings of the teams, and `ranks` is the ranks of the teams. For example, if team 1 wins and team 2 losses, the `ranks` should be `[0, 1]`, meaning that team 1 ranks `0` while team 2 ranks `1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\mathcal{ N }( 2461.962, 542.731^2 )$"
      ],
      "text/plain": [
       "trueskill.Rating(mu=2461.962, sigma=542.731)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def train(game):\n",
    "    \"\"\"Given a game result, train the underlying model.\n",
    "    Return the prediction point for this game before training.\"\"\"\n",
    "    env = env_drawable if game.drawable else env_undrawable\n",
    "    teams_ratings = [[ratings[name] for name in roster] for roster in game.rosters]\n",
    "    \n",
    "    if game.score[0] > game.score[1]:\n",
    "        ranks = [0, 1]  # Team 1 wins.\n",
    "    elif game.score[0] == game.score[1]:\n",
    "        ranks = [0, 0]  # Draw.\n",
    "    else:\n",
    "        ranks = [1, 0]  # Team 2 wins.\n",
    "    \n",
    "    teams_ratings = env.rate(teams_ratings, ranks=ranks)\n",
    "    \n",
    "    for team, roster, team_ratings in zip(game.teams, game.rosters, teams_ratings):\n",
    "        # Update ratings for the players.\n",
    "        for name, rating in zip(roster, team_ratings):\n",
    "            ratings[name] = rating\n",
    "\n",
    "        update_best_roster(team, roster)  # Update the best roster for this team.\n",
    "\n",
    "\n",
    "for game in past_games:\n",
    "    train(game)\n",
    "ratings['Logix']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can draw the means of all the ratings in a histogram:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1.,  5.,  5., 10., 20., 28., 21., 15.,  7.,  2.]),\n",
       " array([1004.11038434, 1274.4307963 , 1544.75120826, 1815.07162022,\n",
       "        2085.39203218, 2355.71244414, 2626.03285609, 2896.35326805,\n",
       "        3166.67368001, 3436.99409197, 3707.31450393]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1064b8c88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mus = [r.mu for r in ratings.values()]\n",
    "plt.hist(mus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As well as the best roster for a given team:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('MG', 'Xushu', 'Freefeel', 'Fiveking', 'Ado', 'Fearless')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_rosters['SHD']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting Matches\n",
    "\n",
    "Now that we have the ratings for all the players in the league, we can predict the future matches.\n",
    "\n",
    "First we want to precit a single game. There are some math here so the code is a little bit hard to read, but the idea is to compute `P(X > Y)`, where `X` and `Y` are two random variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5042132316828962, 0.055065096636604305)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict(rosters, drawable=False):\n",
    "    env = env_drawable if drawable else env_undrawable\n",
    "    teams_ratings = [[ratings[name] for name in roster] for roster in rosters]\n",
    "    \n",
    "    delta_mu = (sum(r.mu for r in teams_ratings[0]) - sum(r.mu for r in teams_ratings[1]))\n",
    "    draw_margin = calc_draw_margin(env.draw_probability, 12, env=env)\n",
    "    sum_sigma = sum(r.sigma**2 for r in chain(*teams_ratings))\n",
    "    denom = sqrt(12 * env.beta**2 + sum_sigma)\n",
    "\n",
    "    p_win = env.cdf((delta_mu - draw_margin) / denom)\n",
    "    p_not_loss = env.cdf((delta_mu + draw_margin) / denom)\n",
    "\n",
    "    return p_win, p_not_loss - p_win\n",
    "\n",
    "predict([('Zebbosai', 'TviQ', 'Zuppeh', 'Logix', 'Manneten', 'CWoosH'),\n",
    "         ('dhaK', 'sleepy', 'Danteh', 'BABYBAY', 'Nomy', 'Nevix')], drawable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using probabilities above, we can in turn predict all the possible results of a given match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(float,\n",
       "            {(0, 2): 0.0006646222699297546,\n",
       "             (0, 3): 0.01063880591266652,\n",
       "             (0, 4): 0.042574630872416745,\n",
       "             (1, 2): 0.03704846249422922,\n",
       "             (1, 3): 0.19414050604488414,\n",
       "             (2, 0): 0.0008576010406760136,\n",
       "             (2, 1): 0.042182981550115003,\n",
       "             (2, 3): 0.15542536376095822,\n",
       "             (3, 0): 0.015705549199978065,\n",
       "             (3, 1): 0.25230229093771395,\n",
       "             (3, 2): 0.17655381140884602,\n",
       "             (4, 0): 0.07190531027064047})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict_bo_match_score(rosters, drawables):\n",
    "    \"\"\"Predict the scores of a given Best-Of-N match.\"\"\"\n",
    "    p_scores = defaultdict(float)\n",
    "    p_scores[(0, 0)] = 1.0\n",
    "\n",
    "    p_undrawable = predict(rosters, drawable=False)\n",
    "    p_drawable = predict(rosters, drawable=True)\n",
    "\n",
    "    for drawable in drawables:\n",
    "        p_win, p_draw = p_drawable if drawable else p_undrawable\n",
    "        p_loss = 1.0 - p_win - p_draw\n",
    "        new_p_scores = defaultdict(float)\n",
    "\n",
    "        for (score1, score2), p in p_scores.items():\n",
    "            new_p_scores[(score1 + 1, score2)] += p * p_win\n",
    "            new_p_scores[(score1, score2 + 1)] += p * p_loss\n",
    "            if drawable:\n",
    "                new_p_scores[(score1, score2)] += p * p_draw\n",
    "\n",
    "        p_scores = new_p_scores\n",
    "\n",
    "    # Add a tie-breaker game if needed.\n",
    "    p_win, p_draw = p_undrawable\n",
    "    new_p_scores = defaultdict(float)\n",
    "\n",
    "    for (score1, score2), p in p_scores.items():\n",
    "        if score1 == score2:\n",
    "            new_p_scores[(score1 + 1, score2)] += p * p_win\n",
    "            new_p_scores[(score1, score2 + 1)] += p * p_loss\n",
    "        else:\n",
    "            new_p_scores[(score1, score2)] += p\n",
    "\n",
    "    p_scores = new_p_scores\n",
    "    \n",
    "    return p_scores\n",
    "\n",
    "\n",
    "def predict_match_score(rosters, match_format='regular'):\n",
    "    \"\"\"Predict the scores of a given match.\"\"\"\n",
    "    if match_format == 'regular':\n",
    "        drawables = [True, False, True, False]\n",
    "    else:\n",
    "        drawables = [False, False, True, True, False]\n",
    "    \n",
    "    return predict_bo_match_score(rosters, drawables=drawables)\n",
    "\n",
    "\n",
    "predict_match_score([('Zebbosai', 'TviQ', 'Zuppeh', 'Logix', 'Manneten', 'CWoosH'),\n",
    "                     ('dhaK', 'sleepy', 'Danteh', 'BABYBAY', 'Nomy', 'Nevix')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above results are a little bit hard to understand. Sometime we just want two numbers: **how likely** will I win, and **how much** will I win?\n",
    "\n",
    "This can be done by calculating the **win percentage** and the **map differential expectation**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p_win =  82%, e_diff = +1.6\n",
      "p_win =  86%, e_diff = +1.8\n",
      "p_win = 100%, e_diff = +3.8\n",
      "p_win =   1%, e_diff = -3.2\n",
      "p_win =   9%, e_diff = -2.2\n",
      "p_win =  41%, e_diff = -0.4\n"
     ]
    }
   ],
   "source": [
    "def predict_match(rosters, match_format='regular'):\n",
    "    \"\"\"Predict the win probability & diff expectation of a given match.\"\"\"\n",
    "    p_scores = predict_match_score(rosters, match_format)\n",
    "    p_win = 0.0\n",
    "    e_diff = 0.0\n",
    "\n",
    "    for (score1, score2), p in p_scores.items():\n",
    "        if score1 > score2:\n",
    "            p_win += p\n",
    "        e_diff += p * (score1 - score2)\n",
    "\n",
    "    return p_win, e_diff\n",
    "\n",
    "\n",
    "for match in future_matches[:6]:\n",
    "    p_win, e_diff = predict_match([best_rosters[team] for team in match.teams])\n",
    "    print(f'p_win = {round(p_win * 100):>3}%, e_diff = {e_diff:+.1f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which can be visualized as following."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Matches](matches.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting Stages\n",
    "\n",
    "For each stage, the standing of the teams is determined by their match wins and map differentials.\n",
    "\n",
    "![stage-standing](stage-standing.png)\n",
    "\n",
    "At the end of that stage, the top 3 teams will enter the **stage title matches**, fighting for the stage champion.\n",
    "\n",
    "![stage-finals](stage-finals.png)\n",
    "\n",
    "As we can predict the match results now, we can use that infomation to predict the stage champions. However, the exact probabilities are very hard to compute. For example, there are 12 possible outcomes for any given match, so 60 matches will lead to 12^60 ≈ 5.6 \\* 10^64 states.\n",
    "\n",
    "An alternative way to do that is by simulation. We can simulate the future matches many times to approximate the probabilities. This will lower the time complexity from O(12^N) to O(N), while still giving reasonable results.\n",
    "\n",
    "The win rate between any two teams can be calculated in advance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4509863401911519"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def all_p_wins(match_format):\n",
    "    p_wins = {}\n",
    "    \n",
    "    for team1 in TEAMS:\n",
    "        for team2 in TEAMS:\n",
    "            teams = (team1, team2)\n",
    "            rosters = [best_rosters[team] for team in teams]\n",
    "            p_wins[teams], _ = predict_match(rosters, match_format)\n",
    "            \n",
    "    return p_wins\n",
    "\n",
    "all_p_wins('regular')[('DAL', 'FLA')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, in order to use the `random.choices` function, we have to convert the possibilities of all the scores to cum weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(4, 0), (3, 1), (3, 2), (2, 3), (3, 0), (2, 1), (1, 3), (1, 2), (0, 4), (0, 3), (2, 0), (0, 2)]\n",
      "[0.2094, 0.5796, 0.7487, 0.825, 0.8556, 0.8972, 0.9695, 0.988, 0.996, 0.9987, 0.9998, 1.0]\n"
     ]
    }
   ],
   "source": [
    "def predict_matches_scores_cum_weights(matches):\n",
    "    scores_list = []\n",
    "    cum_weights_list = []\n",
    "\n",
    "    for match in matches:\n",
    "        p_scores = predict_match_score([best_rosters[team] for team in match.teams])\n",
    "        scores = []\n",
    "        cum_weights = []\n",
    "        cum_weight = 0.0\n",
    "\n",
    "        for score, p in p_scores.items():\n",
    "            scores.append(score)\n",
    "            cum_weight += p\n",
    "            cum_weights.append(cum_weight)\n",
    "\n",
    "        scores_list.append(scores)\n",
    "        cum_weights_list.append(cum_weights)\n",
    "\n",
    "    return scores_list, cum_weights_list\n",
    "\n",
    "scores_list, cum_weights_list = predict_matches_scores_cum_weights(future_matches)\n",
    "print(scores_list[0])\n",
    "print([round(cum_p, 4) for cum_p in cum_weights_list[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also have to sort the teams by their wins, map differentials, etc., and apply tie breakers if needed. This can be done by creating a comparision function, and then use `sorted` to sort the teams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top3_teams(wins, map_diffs, head_to_head_map_diffs, p_wins_regular):\n",
    "    def cmp_team(team1, team2):\n",
    "        if wins[team1] < wins[team2]:\n",
    "            return -1\n",
    "        elif wins[team1] > wins[team2]:\n",
    "            return 1\n",
    "        elif map_diffs[team1] < map_diffs[team2]:\n",
    "            return -1\n",
    "        elif map_diffs[team1] > map_diffs[team2]:\n",
    "            return 1\n",
    "        elif head_to_head_map_diffs[(team1, team2)] < 0:\n",
    "            return -1\n",
    "        elif head_to_head_map_diffs[(team1, team2)] > 0:\n",
    "            return 1\n",
    "        elif random() < p_wins_regular[(team1, team2)]:\n",
    "            return 1\n",
    "        else:\n",
    "            return -1\n",
    "\n",
    "    teams = list(sorted(TEAMS, key=cmp_to_key(cmp_team), reverse=True))\n",
    "    return teams[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have all the tools we need. We can move on and filter the remaining matches of the current stage out of all the future matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "stage = past_games[-1].stage\n",
    "stage_past_games = [game for game in past_games if game.stage == stage]\n",
    "stage_future_matches = [match for match in future_matches if match.stage == stage]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And calculate the current standings. We will need three numbers for the comparision function:\n",
    "\n",
    "- `stage_wins`\n",
    "- `stage_map_diffs`\n",
    "- `stage_head_to_head_map_diffs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group past games by matches.\n",
    "stage_past_matches = defaultdict(list)\n",
    "for game in stage_past_games:\n",
    "    if game.stage == stage:\n",
    "        stage_past_matches[game.match_id].append(game)\n",
    "\n",
    "stage_wins = defaultdict(int)\n",
    "stage_map_diffs = defaultdict(int)\n",
    "stage_head_to_head_map_diffs = defaultdict(int)\n",
    "\n",
    "for games in stage_past_matches.values():\n",
    "    score = [0, 0]\n",
    "\n",
    "    for game in games:\n",
    "        if game.score[0] > game.score[1]:  # Team 1 wins the game.\n",
    "            winner = game.teams[0]\n",
    "            loser = game.teams[1]\n",
    "            score[0] += 1\n",
    "        elif game.score[0] < game.score[1]:  # Team 2 wins the game.\n",
    "            winner = game.teams[1]\n",
    "            loser = game.teams[0]\n",
    "            score[1] += 1\n",
    "        else:  # Draw.\n",
    "            continue\n",
    "\n",
    "        stage_map_diffs[winner] += 1\n",
    "        stage_map_diffs[loser] -= 1\n",
    "        stage_head_to_head_map_diffs[(winner, loser)] += 1\n",
    "        stage_head_to_head_map_diffs[(loser, winner)] -= 1\n",
    "\n",
    "    if score[0] > score[1]:  # Team 1 wins the match.\n",
    "        stage_wins[game.teams[0]] += 1\n",
    "    else:  # Team 2 wins the match.\n",
    "        stage_wins[game.teams[1]] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fianlly, it's time to do the simulations!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BOS': (0.0, 0.0),\n",
       " 'DAL': (0.0, 0.0),\n",
       " 'FLA': (0.0, 0.0),\n",
       " 'GLA': (0.12862, 0.00161),\n",
       " 'HOU': (0.0, 0.0),\n",
       " 'LDN': (0.99997, 0.64703),\n",
       " 'NYE': (1.0, 0.29392),\n",
       " 'PHI': (0.81665, 0.05644),\n",
       " 'SEO': (0.05476, 0.001),\n",
       " 'SFS': (0.0, 0.0),\n",
       " 'SHD': (0.0, 0.0),\n",
       " 'VAL': (0.0, 0.0)}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_list, cum_weights_list = predict_matches_scores_cum_weights(future_matches)\n",
    "p_wins_regular = all_p_wins('regular')\n",
    "p_wins_title = all_p_wins('title')\n",
    "\n",
    "top3_count = defaultdict(int)\n",
    "top1_count = defaultdict(int)\n",
    "\n",
    "ITERS = 100000\n",
    "\n",
    "for _ in range(ITERS):\n",
    "    wins = stage_wins.copy()\n",
    "    map_diffs = stage_map_diffs.copy()\n",
    "    head_to_head_map_diffs = stage_head_to_head_map_diffs.copy()\n",
    "\n",
    "    for match, scores, cum_weights in zip(stage_future_matches, scores_list, cum_weights_list):\n",
    "        team1, team2 = match.teams\n",
    "        score1, score2 = choices(scores, cum_weights=cum_weights)[0]\n",
    "\n",
    "        if score1 > score2:\n",
    "            wins[team1] += 1\n",
    "        elif score1 < score2:\n",
    "            wins[team2] += 1\n",
    "\n",
    "        map_diff = score1 - score2\n",
    "        map_diffs[team1] += map_diff\n",
    "        map_diffs[team2] -= map_diff\n",
    "\n",
    "        head_to_head_map_diffs[(team1, team2)] += map_diff\n",
    "        head_to_head_map_diffs[(team2, team1)] -= map_diff\n",
    "\n",
    "    # Determine top 3 teams.\n",
    "    top3 = top3_teams(wins, map_diffs, head_to_head_map_diffs, p_wins_regular)\n",
    "    for team in top3:\n",
    "        top3_count[team] += 1\n",
    "\n",
    "    # Determine top 1 teams.\n",
    "    first, second, third = top3\n",
    "\n",
    "    if random() < p_wins_title[(third, second)]:\n",
    "        second = third\n",
    "    if random() < p_wins_title[(second, first)]:\n",
    "        first = second\n",
    "\n",
    "    top1_count[first] += 1\n",
    "\n",
    "prediction = {team: (top3_count[team] / ITERS, top1_count[team] / ITERS) for team in TEAMS}\n",
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we have some `0.0` and some `1.0` in the above results. However, it does not mean that the team cannot be Top 3, or have already secured a spot in top 3. To handle those cases, we have to calculate whether a team has won enough games to become a top 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BOS': (False, False),\n",
       " 'DAL': (False, False),\n",
       " 'FLA': (False, False),\n",
       " 'GLA': (0.12862, 0.00161),\n",
       " 'HOU': (False, False),\n",
       " 'LDN': (0.99997, 0.64703),\n",
       " 'NYE': (True, 0.29392),\n",
       " 'PHI': (0.81665, 0.05644),\n",
       " 'SEO': (0.05476, 0.001),\n",
       " 'SFS': (False, False),\n",
       " 'SHD': (False, False),\n",
       " 'VAL': (0.0, 0.0)}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalize 0% and 100% for predictions.\n",
    "wins = {team: (stage_wins[team], stage_map_diffs[team]) for team in TEAMS}\n",
    "min_wins = wins.copy()\n",
    "max_wins = wins.copy()\n",
    "\n",
    "for match in stage_future_matches:\n",
    "    for team in match.teams:\n",
    "        win, map_diff = min_wins[team]\n",
    "        min_wins[team] = (win, map_diff - 4)\n",
    "\n",
    "        win, map_diff = max_wins[team]\n",
    "        max_wins[team] = (win + 1, map_diff + 4)\n",
    "\n",
    "min_3rd_wins = list(sorted(min_wins.values()))[-3]\n",
    "max_4th_wins = list(sorted(max_wins.values()))[-4]\n",
    "\n",
    "for team, (p_top3, p_top1) in prediction.items():\n",
    "    if max_wins[team] < min_3rd_wins:\n",
    "        p_top3 = False\n",
    "        p_top1 = False\n",
    "    elif min_wins[team] > max_4th_wins:\n",
    "        p_top3 = True\n",
    "\n",
    "    prediction[team] = (p_top3, p_top1)\n",
    "    \n",
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! As you can see, the `False` means \"impossible\", while the `True` means \"absolutely\". Now we can visualize our data!\n",
    "\n",
    "![Standings](standings.png)\n",
    "\n",
    "I have actually create a [website](https://owl.clumsy.li) to show these data, which even includes the rating trends of all the teams.\n",
    "\n",
    "![rating-trend](rating-trend.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Further Readings\n",
    "\n",
    "- [My Website for Data Visualization of This Tutorial](owl.clumsy.li)\n",
    "- [TrueSkill — trueskill 0.4.4 documentation](http://trueskill.org)\n",
    "- [https://www.microsoft.com/en-us/research/project/trueskill-ranking-system](https://www.microsoft.com/en-us/research/project/trueskill-ranking-system/)\n",
    "- [TrueSkill(TM): A Bayesian Skill Rating System](https://www.microsoft.com/en-us/research/publication/trueskilltm-a-bayesian-skill-rating-system/?from=http%3A%2F%2Fresearch.microsoft.com%2Fapps%2Fpubs%2Fdefault.aspx%3Fid%3D67956)\n",
    "- [The Math Behind TrueSkill](http://www.moserware.com/assets/computing-your-skill/The%20Math%20Behind%20TrueSkill.pdf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
