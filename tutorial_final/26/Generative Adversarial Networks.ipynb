{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction \n",
    "This tutorial will introduce you the basic of Generative Adversarial Networks(GANs) and provide a simple implementation for generating MNIST pictures. Generative Adversarial Networks, which was proposed by Ian Goodfellow in 2014, are set of models to create data that is similar to the input data. Formally, GANs are generative models which can learn the data distribution of data from the training examples. By using the distribution, we can create greate outputs. In data science, sometimes we can not get enough data to train our models. GANs can help us to generate more data and we can utilize semi-supervised learning algorithm to obtain better model.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial content\n",
    "In this tutorial, we will introduce the basis of GANs and provide a simple example implementing with [Tensorflow](https://www.tensorflow.org/).\n",
    "\n",
    "We'll take an overview of the architecture of GANs. Then we'll go a little deeper into the formal definition of GANs. After that we implement GANs with [Tensorflow](https://www.tensorflow.org/) and try to generate some MNIST images. Finally, we'll cover the problems of GANs and some interesting applications of GANs.\n",
    "\n",
    "We will cover the following topics in this tutorial.\n",
    "- [Architecture](#Architecture)\n",
    "- [Formal definition](#Formal-definition)\n",
    "- [Implementation](#Implementation)\n",
    "- [Problems](#Problems)\n",
    "- [More applications](#More-applications)\n",
    "- [Summary and reference](#Summary-and-reference)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architecture \n",
    "Generative Adversarial Networks consists two networks, one is generative network and another is discriminator network. The training process is like playing a game: the generative network tries to generate data that is indistinguishable from the training data and the discriminator tries to identify whether the data is from the training data or from the generative network. As the gaming playing, the generative network becomes better and better at making fake data and it becomes harder for the discriminator network to distinguish whether the data is fake. According to the game theory, finally they might reach the Nash equilibrium where the generative network can perfectly model the distribution of training data and the discriminator network can not identify samples from the generative model or from training data. The general architecture of GANs looks like this:\n",
    "![image.png](./pic/2.jpg)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formal definition\n",
    "Formally, let $G(z; \\theta_g)$ denotes the generative model, where $z$ is noise and $\\theta_g$ is parameters of model, and $D(x; \\theta_d)$ denotes the discriminator model. The $G(z; \\theta_g)$ outputs the same form of data as training data and the $D(x; \\theta_d)$ outputs a single scala which represents the probability that $x$ from training data. We train both networks through stochastic gradient descent and for D, we are trying to maximize the probability of output the right label for both training data and generated data. In the meantime, we train G to minimize the $log(1 - D(G(z)))$. And the whole game can be represents as: $$\\min_{G}\\max_D V(D, G) = E_{x - p_{data}(x)}[logD(x)] + E_{z - p_{z}(z)}[log(1 - D(G(z)))]$$\n",
    "The training process can be expressed as Algorithm 1.\n",
    "![image.png](./pic/3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation\n",
    "In this section, we present a example implementation of GANs based on Tensorflow, and try to generate some MNIST images.\n",
    "First, we import the required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also import MNIST datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we define a helper function for conv2d. The conv2d() will create a variable w and forward the call to tf.nn.conv, after that, it will create a bias variable and add it to the result. The barch_norm() function just forwards calls to tf.contrib.layers.batch_norm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(x, df_dim, name = 'conv2d'):\n",
    "    with tf.variable_scope(name):\n",
    "        w = tf.get_variable('w', [5, 5, x.get_shape()[-1], df_dim],\n",
    "                            initializer=tf.truncated_normal_initializer(stddev=0.04))\n",
    "        conv = tf.nn.conv2d(x, w, strides = [1, 2, 2, 1], padding = 'SAME')\n",
    "        b = tf.get_variable('b', [df_dim], \n",
    "                            initializer=tf.constant_initializer(0.0))\n",
    "        conv = tf.nn.bias_add(conv, b)\n",
    "        return conv\n",
    "    \n",
    "def batch_norm(input_, name):\n",
    "    return tf.contrib.layers.batch_norm(input_, \n",
    "                                       center=True,\n",
    "                                       scale=True,\n",
    "                                       is_training=True,\n",
    "                                       scope=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first define our discriminator model, it's just like the Tensorflow sample CNN model for MNIST, you can refer [here](https://www.tensorflow.org/tutorials/layers) for details. \n",
    "\n",
    "In this model, we have 3 conv layers. For each layer, there is a pipeline, which contains conv + batch_norm + relu. And Finally, we create two variables and get the output of the network, which is a \\[batch_size, 1\\] vector consists possibilities of the image to be in training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator(image, reuse = False):\n",
    "    with tf.variable_scope('dis') as scope:\n",
    "        if (reuse):\n",
    "            tf.get_variable_scope().reuse_variables()\n",
    "        # number of filters in first conv layer\n",
    "        df_dim = 64\n",
    "\n",
    "        # with three conv layer\n",
    "        h0 = tf.nn.relu(conv2d(image, df_dim, 'd_h0'))\n",
    "        h1 = tf.nn.relu(batch_norm(conv2d(image, df_dim * 2, 'd_h1'), 'd_bn1'))\n",
    "        h2 = tf.nn.relu(batch_norm(conv2d(image, df_dim * 4, 'd_h2'), 'd_bn2'))\n",
    "        h3 = tf.nn.relu(batch_norm(conv2d(image, df_dim * 8, 'd_h3'), 'd_bn3'))\n",
    "\n",
    "        h3 = tf.reshape(h3, [batch_size, -1])\n",
    "\n",
    "        # Final layer\n",
    "        w = tf.get_variable('d_w', [h3.get_shape().as_list[1], 1], \n",
    "                            initializer=tf.truncated_normal_initializer(stddev=0.04))\n",
    "        b = tf.get_variable('d_b', [1], initializer=tf.constant_initializer(0))\n",
    "        y_pred = tf.matmul(h3, w) + b\n",
    "\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can define our generator network. The network takes a vector of noise and unsamples it to build a 28x28 image. On the opposite, the generator performs this operation through a convolutional transpose layer. \n",
    "\n",
    "We also define a helper function here to make our code look cleaner. In deconv2d(), it just creates a new variable and forwards the call to tf.nn.conv2d_transpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deconv2d(input_, out_shape, name = 'deconv2d'):\n",
    "    with tf.variable_scope(name):\n",
    "        w = tf.get_variable('w', [5, 5, out_shape[-1], input_.get_shape()[-1]], \n",
    "                           initializer=tf.random_normal_initializer(stddev=0.04))\n",
    "        deconv = tf.nn.conv2d_transpose(input_, w, output_shape = out_shape, \n",
    "                                        strides = [1, 2, 2, 1])\n",
    "        return deconv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The generator consists four conv transposes, which is just a pipeline of deconv2d + batch_norm + relu. And we gradually increase the output until it becomes a 28x28 image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(z, batch_size, reuse = False):\n",
    "    with tf.variable_scope('gen') as scope:\n",
    "        if (reuse):\n",
    "            tf.get_variable_scope().reuse_variables()\n",
    "        s = 28 # Output size of the image\n",
    "        def out_size(size, stride):\n",
    "            return int(math.ceil(float(size) / stride))\n",
    "        s2 = out_size(s, 2)\n",
    "        s4 = out_size(s, 4)\n",
    "        s8 = out_size(s, 8)\n",
    "        s16 = out_size(s, 16)\n",
    "        gf_dim = 64 #Dimension of gen filters in first conv layer\n",
    "\n",
    "        h0 = tf.reshape(z, [-1, s16, s16, gf_dim * 8])\n",
    "        h0 = tf.nn.relu(batch_norm(h0, 'g_bn0'))\n",
    "\n",
    "        # First Deconv layer\n",
    "        h1 = deconv2d(h0, [batch_size, s8, s8, gf_dim * 4], 'g_h1')\n",
    "        h1 = tf.nn.relu(batch_norm(h1, 'g_bn1'))\n",
    "\n",
    "        # Second Deconv layer\n",
    "        h2 = deconv2d(h1, [batch_size, s4, s4, gf_dim * 2], 'g_h2')\n",
    "        h2 = tf.nn.relu(batch_norm(h2, 'g_bn2'))\n",
    "\n",
    "        # Third Deconv layer\n",
    "        h3 = deconv2d(h2, [batch_size, s2, s2, gf_dim], 'g_h3')\n",
    "        h3 = tf.nn.relu(batch_norm(h3, 'g_bn3'))\n",
    "\n",
    "        # Forth Deconv Layer\n",
    "        h4 = deconv2d(h3, [batch_size, s, s, 1], 'g_h4')\n",
    "        return tf.nn.tanh(h4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, now we have both generator model and discriminator model. We can write code to train our model. In tensorflow, we first should create a sesssion. We also create placeholders for the input of generator and discriminator. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = tf.Session()\n",
    "z_dim = 100 # dim for vector z\n",
    "batch_size = 64\n",
    "x = tf.placeholder(\"float\", [None, 28, 28, 1])\n",
    "z = tf.placeholder(\"float\", [None, z_dim])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we create the output of our networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = discriminator(x) # predicted probabilities for real images\n",
    "G = generator(z, batch_size) # generated images\n",
    "Dg = discriminator(G, reuse = True) # predicted probabilities for generated images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can generate loss function for both networks. For the loss function of generator model, the model wants to generate images looks real(labeled 1 by discriminator model). Therefore, the loss function can be computed with Dg and 1. We use tf.nn.sigmoid_cross_entropy_with_logits to calculate our loss function. The function takes 2 parameters, which are logits(x) and label(z), and returns $z * -log(sigmoid(x)) + (1 - z) * -log(1 - sigmoid(x))$. And the reduce_mean function just calculates the mean value in the matrix reutrned by tf.nn.sigmoid_cross_entropy_with_logits. So the loss is a value rather than a vector or matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the loss function for generator model\n",
    "g_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = Dg, \n",
    "                                                                labels = tf.ones_like(Dg)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As for loss function of discriminator model, it consists two parts, one is the loss of predicting the real image and another is the loss of predicting the fake one. We just add them together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function for predicting real data\n",
    "d_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = D, \n",
    "                                                                    labels = tf.ones_like(D)))\n",
    "# Loss function for predicting fake data\n",
    "d_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = Dg, \n",
    "                                                                    labels = tf.ones_like(Dg)))\n",
    "d_loss = d_loss_real + d_loss_fake"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we build two optimizers with variables. We choose Adam to perform SGD for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_vars = tf.trainable_variables()\n",
    "# Optimizer for discriminator\n",
    "d_optim = tf.train.AdamOptimizer()\\\n",
    "    .minimize(d_loss, var_list = [var for var in t_vars if 'd_' in var.name])\n",
    "# Optimizer for generator\n",
    "g_optim = tf.train.AdamOptimizer()\\\n",
    "    .minimize(g_loss, var_list= [var for var in t_vars if 'g_' in var.name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init the variables\n",
    "tf.global_variables_initializer().run()\n",
    "\n",
    "# run 20 epoches\n",
    "epoch = 20\n",
    "# each epoches with 1000 iteractions\n",
    "iteration = 1000\n",
    "for i in xrange(epoch):\n",
    "    for j in xrange(iteration):\n",
    "        # generate random z vector\n",
    "        batch_z = np.random.uniform(-1, 1, [batch_size, z_dim]).astype(np.float32)\n",
    "        # get the real image\n",
    "        batch_images = mnist.train.next_batch(batch_size)\n",
    "        batch_images = np.reshape(batch_images[0], [batch_size, 28, 28, 1])\n",
    "        # update the discriminator\n",
    "        _, dLoss = session.run([d_optim, d_loss], feed_dict = {\n",
    "            z: batch_z, \n",
    "            x: batch_images\n",
    "        })\n",
    "        \n",
    "        # update the generator\n",
    "        _, gLoss = session.run([g_optim, g_loss], feed_dict = {\n",
    "            z: batch_z\n",
    "        })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training, we can see the outputs. The training will take a while, especially on computers without GPU support for tensorflow. Here is a sample output.\n",
    "![image.png](./pic/4.png)\n",
    "Looks just like the real training data. Here is a sample output in the middle of training process.\n",
    "![image.png](./pic/5.png)\n",
    "Looks not as good as the previous one, right? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problems\n",
    "It seems that our model get a good result, but there are some problems related to GANs.\n",
    "1. It's hard to define what is a good result. Unlike other models, which we can define how well the model perform, GANs do not have a really clear criterion of goodness. \n",
    "2. GANs are hard to train. Since we use SGD to train our model, there is no guarantee that we can reach the global optimal. We should be really careful for picking the right hyperparameters and training process. Otherwise one network can overpower another so that we can not get the desired outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More applications\n",
    "GANs can be used more than generate images. Here are some applications.\n",
    "- [Text-to-image](https://github.com/reedscot/icml2016): generate images from plain text.\n",
    "- [Generating time-lapse videos with image](https://arxiv.org/abs/1709.07592): predict the next few frames of image\n",
    "- [Generating new data with GANs](https://www.toptal.com/machine-learning/generative-adversarial-networks): generate new data with GANs to improve the performance of model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary and reference\n",
    "This tutorial only highlights the basic of GANs and give a very simple example. For further detail about GANs, please refer the following links.\n",
    "1. [GANs tutorial by Ian Goodfellow, NIPS 2016](https://channel9.msdn.com/Events/Neural-Information-Processing-Systems-Conference/Neural-Information-Processing-Systems-Conference-NIPS-2016/Generative-Adversarial-Networks)\n",
    "2. [DCGAN implementation](https://github.com/carpedm20/DCGAN-tensorflow)\n",
    "3. [GANs paper](https://arxiv.org/pdf/1406.2661.pdf)\n",
    "4. [Brandon Amos's Image Completion Project](https://bamos.github.io/2016/08/09/deep-completion/)\n",
    "5. [Tensorflow](https://www.tensorflow.org/)\n",
    "6. [MNIST datasets](http://yann.lecun.com/exdb/mnist/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
