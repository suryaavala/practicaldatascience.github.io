{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This tutorial will introduce you to some basic methods for processing Yelp data from [Yelp Data Challenge](https://www.yelp.com/dataset/challenge), particularly focusing on sentimental analysis on yelp data. We will predict yelp star-rating of a review based on the text review of the customer.\n",
    "\n",
    "For example, if the review is \"Food was very delicious, Very good ambience.\" the rating is expected to be 5-star. If the review is \"very bad food, horrible taste.\" the rating is expected to be 1-star.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial Content\n",
    "In this tutorial, we will learn how to implement supervised machine learning on yelp review texts to predict star-ratings of the reviews. We will be using scikit-learn python library to do the same.\n",
    "\n",
    "We will cover the following topics in this tutorial:\n",
    "- [Installing Libraries](#Installing-Libraries)\n",
    "- [Loading Data](#Loading-Data)\n",
    "- [Balancing Data](#Balancing-Data)\n",
    "- [Converting Text to TF-IDF Vectors](#Converting-Text-to-TF-IDF-Vectors)\n",
    "- [Splitting Data into Train and Test](#Splitting-Data-into-Train-and-Test)\n",
    "- [Train Text Data using Support Vector Machine(SVM) ](#Train-Text-Data-using-Support-Vector-Machine(SVM)\n",
    "- [Predict Data ](#Predict-Data)\n",
    "- [Evaluate Classifier ](#Evaluate-Classifier)\n",
    "- [Positive or Negative Classification](#Positive-or-Negative-Classification)\n",
    "- [Conclusion](#Conclusion)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing Libraries\n",
    "Before getting started, you will have to install scikit-learn using pip:\n",
    "\n",
    "    $ pip install -U scikit-learn\n",
    "\n",
    "or using conda:\n",
    "\n",
    "    $ conda install scikit-learn\n",
    "\n",
    "You can get more information about installing scikit-learn library [here](http://scikit-learn.org/stable/install.html)\n",
    "\n",
    "After you install the libraries, make sure the following imports work correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from collections import Counter\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the versions of the libraries We will be using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas version 0.18.1\n",
      "json version 2.0.9\n",
      "numpy version 1.13.3\n"
     ]
    }
   ],
   "source": [
    "print(\"pandas version\",pd.__version__)\n",
    "print(\"json version\",json.__version__)\n",
    "print(\"numpy version\",np.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data\n",
    "Firstly, we will download yelp data from [Yelp Data Challenge](https://www.yelp.com/dataset/challenge). Click on \"Download Dataset\", fill the form and click \"Download\".\n",
    "\n",
    "You will have 3 options of downloading formats: JSON, SQL, Photos.\n",
    "Download the Json format by clicking on \"Download JSON\" and untar the downloaded file.\n",
    "\n",
    "From the downloaded files, we need \"review.json\" for our analysis. We will be analysing first 50000 reviews from review.json \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store reviews text to list named \"text\" and ratings to list named \"stars\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get first 50000 reviews from review.json\n",
    "with open(\"review.json\") as f:\n",
    "    head = [json.loads(next(f)) for x in range(50000)]\n",
    "stars=[]\n",
    "text = []\n",
    "# store review text and rating in text and stars lists respectively\n",
    "for review in head:\n",
    "    stars.append(review[\"stars\"])\n",
    "    text.append(review[\"text\"])\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us check out the total number of reviews for each star-rating by using Counter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({5: 20187, 4: 12876, 3: 6527, 1: 6263, 2: 4147})\n"
     ]
    }
   ],
   "source": [
    "star_counts=Counter(stars)\n",
    "print(star_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a2f63a7f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot bar graph between number of reviews and ratings\n",
    "\n",
    "lists = sorted(star_counts.items()) \n",
    "\n",
    "x, y = zip(*lists) \n",
    "\n",
    "plt.bar(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, there are 20187 reviews with 5-star rating and just 4147 reviews with 2-star rating. This is an imbalanced data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Balancing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In machine learning classifiers, results will be biased if the input data is imbalanced.\n",
    "\n",
    "We will now reduce our dataset to the number of reviews with the rating which has the minimum number of reviews. In this case, 2-star rating has the minimum number of reviews i.e 4147 reviews. This will help to balance our data and get less biased prediction from our machine learning algorithm.\n",
    "\n",
    "[Click here](https://www.analyticsvidhya.com/blog/2017/03/imbalanced-classification-problem/) if you want to learn more about imbalanced data problem and other methods to handle this problem.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def balance(text, stars):\n",
    "    freq = Counter(stars)\n",
    "    # find minimum number of reviews\n",
    "    min_rev = freq.most_common()[-1][1]\n",
    "    print(\"minimum number of reviews:\", min_rev)\n",
    "    \n",
    "    dic={}\n",
    "    for k in freq.keys():\n",
    "        dic[k] = 0\n",
    "    \n",
    "    new_stars = []\n",
    "    new_text = []\n",
    "    for i, s in enumerate(stars):\n",
    "        if dic[s] < min_rev:\n",
    "            new_stars.append(s)\n",
    "            new_text.append(text[i])\n",
    "            dic[s] = dic[s] + 1\n",
    "    return new_text, new_stars\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({5: 20187, 4: 12876, 3: 6527, 1: 6263, 2: 4147})\n",
      "minimum number of reviews: 4147\n",
      "Counter({5: 4147, 4: 4147, 3: 4147, 1: 4147, 2: 4147})\n"
     ]
    }
   ],
   "source": [
    "print(Counter(stars))\n",
    "balanced_x, balanced_y = balance(text, stars)\n",
    "print(Counter(balanced_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a38513b70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot bar graph between number of reviews and ratings\n",
    "star_counts = Counter(balanced_y)\n",
    "lists = sorted(star_counts.items()) \n",
    "\n",
    "x, y = zip(*lists) \n",
    "\n",
    "plt.bar(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a balanced data set and we can work on vectorizing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting Text to TF-IDF Vectors "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will convert our text into vectors so that it is understood by our machine learning algorithm. We will be constructing Term Frequency Inverse Document Frequency(TF-IDF) vectors which is one of the most sophisticated method to create vectors for Natural Language Processing. It will divide our text into frequency of words and will exclude the very common words like \"of\", \"the\" because these words are not important for the review classification. \n",
    "\n",
    "Words often mean different when combined with other words. We would expect our machine learning algorithm to classify words like 'amazing' as positive. \n",
    "But what will happen if the review is \"The Food was not so amazing\"?\n",
    "\n",
    "Here we will be using n-gram model where text will be broken into n-grams.\n",
    "e.g. \"The Food was not so amazing\" will be divided in bi-gram model as (\"The Food\",\"Food was\",\"was not\",\"not so\",\"so amazing\"). This would help to learn fine-grained meanings of the sentences in the text. As we increase the \"n\" in n-gram model, more processing power will be required.\n",
    "We will stick to bigram model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=False,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,2))\n",
    "print(vectorizer)\n",
    "vectors = vectorizer.fit_transform(balanced_x)\n",
    "# print(vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting Data into Train and Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will divide our dataset into two parts: Train and Test. For Train, both text and ratings of the reviews will be provided, but for Test, only text of reviews will be provided to our learning algorithm. We will predict the ratings of reviews using our machine learning algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "# split data into test and train\n",
    "X_train, X_test, y_train, y_test = train_test_split(vectors, balanced_y, test_size=0.30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Text Data using Support Vector Machine(SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use Linear Support Vector Machine classifier for text classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn version: 0.17.1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "print(\"sklearn version:\",sklearn.__version__)\n",
    " \n",
    "# initialise the SVM classifier\n",
    "classifier = LinearSVC()\n",
    " \n",
    "# train the classifier\n",
    "classifier.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will predict our data display a small sample of data to look how close our prediction is to the actual rating. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction: [4, 2, 5, 1, 1, 2, 4, 1, 3, 4]\n",
      "Actual:     [3, 3, 4, 1, 1, 1, 5, 1, 3, 5]\n"
     ]
    }
   ],
   "source": [
    "preds = classifier.predict(X_test)\n",
    "print(\"prediction:\",list(preds[:10]))\n",
    "print(\"Actual:    \",y_test[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, our prediction is not perfect but it is quite good as 4 out of 10 ratings are correct. This is a good sanity check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now evaluate our prediction classifier by calculating the accuracy of our classifier. We can calculate the accuracy of our machine learning algorithm by comparing the predicted ratings with the real ratings. If the accuracy is 1, that means our prediction was 100% correct. If accuracy is 0.8, that means our prediction is 80% correct. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.576434656808\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that our classifier is around 56% accurate. This score is quite low.\n",
    "For a given review and rating, the classifier might give false positive or false negative classification. If a classifier predicts the rating to be 5-star but it is actually below that, it is false positive classification. On the other hand, if a review is actually 5-star but the classifier classifies a review to be 5-star.\n",
    "\n",
    "We will have a look other evaluation methods like precision and recall to evaluate our classifier.\n",
    "\n",
    "A classifier with high precision for 5-star rating is less likely to predict other reviews to be 5-star but it might classify actual 5-star reviews to be in other class. \n",
    "On the other hand, A classifier with high recall is more likely to predict 5-star reviews correctly but it may also predict other class reviews to be 5-star reviews.\n",
    "\n",
    "We would like to have a balance between precision and recall. For this we measure F1 score which is a combination of both precision and recall in a single metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.67      0.80      0.73      1220\n",
      "          2       0.52      0.43      0.47      1244\n",
      "          3       0.47      0.47      0.47      1213\n",
      "          4       0.51      0.45      0.48      1275\n",
      "          5       0.66      0.74      0.70      1269\n",
      "\n",
      "avg / total       0.57      0.58      0.57      6221\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We look at As we can see, 1-star and 5-star ratings have higher f1 score which means that they are easier to predict but it is more difficult to predict ratings in class {2,3,4}.\n",
    "\n",
    "It is important for us to predict 1-star as 5-star review or vice verca.\n",
    "But predicting 4-star as 5-star is not much problem and can be ignored. \n",
    "\n",
    "We will have a look at another evaluation metric which is Confusion Matrix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[979 178  35   9  19]\n",
      " [348 529 280  54  33]\n",
      " [ 80 247 569 244  73]\n",
      " [ 22  56 265 568 364]\n",
      " [ 28  17  52 231 941]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first row shows the reviews predicted as 1-star.\n",
    "The first column shows the actual reviews in 1-star category.\n",
    "On the first row-second column , we see that there were 229 reviews which were actually 2 star but predicted as 1-star by our classifier.\n",
    "We can see that the classifier has mainly confused between subsequent ratings like 4-star or 5-star ratings, 1-star or 2-star ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Positive or Negative Classification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will try to classify our reviews into positive(1-2 star) or negative(4-5 star). We will remove the 3-star reviews.\n",
    "\n",
    "We will label n for negative reviews(1-2 star reviews) and p for positive reviews(4-5 star reviews) and we will remove 3-star reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sset = set([1,2,4,5])\n",
    " \n",
    "# indices to keep\n",
    "k_train = []\n",
    "for i, y in enumerate(y_train):\n",
    "    if y in sset:\n",
    "        k_train.append(i)\n",
    "\n",
    "k_test = []\n",
    "for i, y in enumerate(y_test):\n",
    "    if y in sset:\n",
    "        k_test.append(i)\n",
    "\n",
    "        \n",
    "# convert the train set\n",
    "X_train2 = X_train[k_train, :]\n",
    "y_train2 = [y_train[i] for i in k_train]\n",
    "y_train2 = [\"n\" if (y == 1 or y == 2) else \"p\" for y in y_train2]\n",
    " \n",
    "# convert the test set\n",
    "X_test2 = X_test[k_test, :]\n",
    "y_test2 = [y_test[i] for i in k_test]\n",
    "y_test2 = [\"n\" if (y == 1 or y == 2) else \"p\" for y in y_test2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can train the classifier again on new data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          n       0.93      0.94      0.93      2464\n",
      "          p       0.94      0.93      0.93      2544\n",
      "\n",
      "avg / total       0.93      0.93      0.93      5008\n",
      "\n",
      "[[2308  156]\n",
      " [ 176 2368]]\n"
     ]
    }
   ],
   "source": [
    "classifier.fit(X_train2, y_train2)\n",
    "preds = classifier.predict(X_test2)\n",
    "print(classification_report(y_test2, preds))\n",
    "print(confusion_matrix(y_test2, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the classifier is 94% accurate which is really good accuracy. \n",
    "Confusion matrix tells that 156 negative reviews were classified as positive and 178 positive reviews were classified as negative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We covered basics of TFIDF and Support Vector Machine to classify text. We vectorized our text and train a classifier. \n",
    "We predicted the rating or the review based on the text and also predicted if the review is negative or positive.\n",
    "\n",
    "These results from the experiments can help a restaurant to know the trend of general sentiment of the restaurant from other social media platforms like facebook or twitter. \n",
    "\n",
    "for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['n' 'p']\n"
     ]
    }
   ],
   "source": [
    "comments = [\"I hated the food. Worst experience ever\",\"I loved the food,amazing ambience\"]\n",
    "v = vectorizer.transform(comments)\n",
    "print(classifier.predict(v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code, classifier determines that first comment was negative and second comment was positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}